






© Springer Nature Singapore Pte Ltd. 2018


Friedemann Köster



Multidimensional Analysis of Conversational Telephone Speech


T-Labs Series in Telecommunication Services


https://doi.org/10.1007/978-981-10-5224-8_1





1. Introduction




Friedemann Köster
1  




(1)
Quality and Usability Lab, Technical University of Berlin, Berlin, Germany

 



 

Friedemann Köster


Email: 
friedemann.koester@tu-berlin.de






Vocal human-to-human communication is the main purpose for using speech telephony services. Technological development within traditional and modern packet-based (Voice-over-IP) telephony networks can affect—and possibly also impair—the transmitted speech signal. The network and terminal device elements which are responsible for this (referred to as quality elements), are for example codecs, bandwidth limitations, linear and non-linear filters, delay, packet-loss, echo, or noise, to name just a few.
It is therefore of high priority for telecommunication providers to find out how end-users perceive and experience degradations. For this, assessing the quality of transmitted speech over telecommunication systems allows the providers to improve their services and encounter possible issues. In this context, the quality of transmitted speech is also referred to the so-called Quality of Experience (QoE).
In telephony services, passive subjective experiments with human participants in a laboratory context are common means to study and understand QoE (so-called Listening-Only Tests (LOTs)). In these experiments, overall (or integral) quality ratings on five-point Absolute Category Rating (ACR) scales are gathered. The experiments yield a Mean Opinion Score (MOS), representing the average overall quality rating of an average person.
Since subjective experiments are time and money consuming, the demand of telecommunication service providers for instrumental models to predict the overall quality of transmitted speech, as gathered in LOTs, increased. Research led to the development of multiple different types and approaches (parametric and signal-based) for instrumental models. Nevertheless, as described in [1], the aforementioned LOTs and the instrumental models hold two main limitations:
Overall quality: Only the overall quality (MOS) is considered; the MOS value provides little insight into the cause of a possible low quality.
Non-interactive settings: The introduced methods refer to the passive listening situation; active conversational and interactive aspects of the transmission system are not considered.

The first limitation (overall quality) indicates that two speech signals may be rated with the same overall quality while showing dissimilar perceptual characteristics. For example, the perception of a certain noise type and of a certain packet-loss may lead to the same overall quality rating (MOS), whereas the MOS value does not uncover information of its origin. Thus, traditional methods do not provide diagnostic information. To counter this problem, new subjective [2] as well as new instrumental [3] diagnostic methods have been developed. They identify and assess quality-relevant perceptual dimensions to obtain diagnostic information.
The underlying idea to these methods is the following: The output of a transmission system, a speech signal that is possibly degraded by the aforementioned quality elements, is perceived by the system user as a composition of explicit features that are orthogonal (and thus independent) and represent recognizable and nameable characteristics of the speech sound. These features are perceptual quality dimensions in a multidimensional perceptual quality space. When the user judges quality, she or he makes use of these perceptual dimensions to determine a perceptual difference to an optimum, degradation-free situation. Overall quality can thus be determined on the basis of perceptual dimensions. In turn, the dimensions allow identifying reasons for quality losses. For example, two speech samples showing the same overall quality rating may exhibit different perceptual dimension judgments that are connected to specific quality elements.
The second limitation (non-interactive settings) reveals that the aforementioned traditional methods only consider the unrealistic passive listening-only situation. Quality elements that affect the interaction or the speaking (for example echo or delay) cannot be determined in LOTs. To fill this gap, conversational tests and speaking tests have been designed.
Feasible solutions to both limitations have only been developed separately. This leads to the trade-off for an experimenter to either extract diagnostic information or to address different conversational phases in an experiment—diagnosing a complete conversational situation is not possible with traditional methods, a Multidimensional Analysis of Conversational Telephone Speech is necessary. Thus, the following main research question for the book at hand is formulated to address this trade-off:

What are the quality-relevant perceptual dimensions that an interactive conversational situation is composed of?

In the present book, the answering of the stated research question and the modeling of the speech quality in a telephone conversation situation is addressed in a systematic way. In five consecutive steps, fundamental research towards deeply analyzing conversational speech quality for diagnosis and instrumental optimization of telecommunication systems is presented. First, the perceptual quality space, and its perceptual dimensions, of a conversational situation, is identified. Second, a new test method to quantify the identified perceptual dimensions in a direct way is developed. Third, the identified perceptual quality space and the developed test method are validated in two extensive conversational experiments. Fourth, the results of the conducted experiments allow to model the overall conversational quality based on the gathered dimension scores. Finally, in the fifth step, the gathered ratings and the identified relations between the overall conversational quality and its underlying dimensions allows developing a new instrumental diagnostic conversational quality model to estimate and diagnose the quality of conversational telephone speech. Thus, the presented research merges in the following result:

For the first time, an instrumental quality model that provides diagnostic information of a telephone conversation and thus allows analyzing and optimizing a complete telephone transmission system is available.

This book is structured as follows: Chap. 2 provides the fundamental knowledge important for the presented research. This is an introduction into the basic research scenario and a brief presentation of human speech production, transmission, and perception. This introduction leads to the definition of perceived quality of transmitted speech, its assessment methods, as well as analyzing and diagnosing concepts, used and referred to in this book.
In Chap. 3, the introduced fundamentals are adapted and transferred to the context of a telephone conversation. For this, a telephone conversation will be analyzed with respect to its three conversational phases that occur in an everyday conversation, namely the Listening, the Speaking, and the Interaction Phase. Moreover, a deeper insight into the already introduced quality elements affecting a telephone conversation, and thus each conversational phase, will be given. This is followed by a detailed review of each of the three conversational phases in terms of their perceptual quality spaces as well as state-of-the-art subjective and instrumental quality-assessment methods. The review highlights again the limitations of traditional methods, which leads to the enumeration of the research topics covered in this book.
While the perceptual dimensions for the Listening Phase are already known, the perceptual quality space of the Speaking and the Interaction Phase of a conversation is identified in Chap. 4. By applying the two test paradigms of pairwise similarity scaling and Semantic Differential for each conversational phase, in sum, four experiments were conducted. The resulting perceptual quality spaces are analyzed and discussed, leading to interpretations of the perceptual quality dimensions underlying the overall quality of the Speaking and the Interaction Phase. The chapter closes with a conclusion of the resulting perceptual quality space of a telephone conversation that is in total composed of seven perceptual quality dimensions.
Since the identification of the perceptual quality dimensions in the way followed in Chap. 4 requires a high experimental effort, a method to directly quantify the resulting perceptual quality dimensions by naïve test subjects is required. Chapter 5 introduces the required test method, the dimension rating scales, the test procedure, and a recommended setup.
In Chap. 6, two sophisticated conversational experiments and their results are presented. The first experiment addresses the validation of the perceptual quality space in a telephone conversation. While the perceptual quality space of conversational speech quality has been identified in separate experiments regarding the three conversational phases, it is shown that the identified dimensions are also valid in a conversational situation. The second experiment is focused on the validation and the verification of the new proposed test method. In particular, it is shown that the new test method provides meaningful and reliable ratings as the dimension scales measure what they were designed for.
The results of the second validation experiment allow modeling the overall conversational quality based on the dimension scores. Thus, in Chap. 7, the relation between the overall conversational quality ratings, the conversational phase quality ratings, and the dimension ratings are analyzed. The perceptual quality dimensions, as they are orthogonal, can be combined to a quality rating for each conversational phase, and the quality ratings for each conversational phase, in turn, can be used to determine the overall conversational quality. For this, multiple linear regression models are used that reveal the weights of the individual phases for the overall conversational quality, and the weights of the perceptual quality dimensions for the quality of each individual phase.
In Chap. 8, the results of the conducted research are merged to develop a new instrumental diagnostic conversational quality model. The model allows estimating the overall conversational quality based on estimations of the seven perceptual quality dimensions. In addition, the model provides estimations for the conversational phase quality ratings according to the relation identified in Chap. 7. Three new dimension estimators for the perceptual dimensions of the Speaking and the Interaction Phase are developed for this. The model and its estimators are trained and evaluated on the data gathered in Chap. 6.
Finally, conclusions and an outlook into future work are presented in Chap. 9.











© Springer Nature Singapore Pte Ltd. 2018


Friedemann Köster



Multidimensional Analysis of Conversational Telephone Speech


T-Labs Series in Telecommunication Services


https://doi.org/10.1007/978-981-10-5224-8_2





2. Fundamentals




Friedemann Köster
1  




(1)
Quality and Usability Lab, Technical University of Berlin, Berlin, Germany

 



 

Friedemann Köster


Email: 
friedemann.koester@tu-berlin.de






This book is about the quality assessment, diagnosis, and estimation of transmitted speech in a telephone conversation. This chapter will give insights into the main concepts, definitions, and approaches to introduce important fundamental knowledge of speech that is transmitted over a telephone system. After a brief description of the general research scenario in Sect. 2.1, the characteristics of speech production, transmission, and perception are given in Sect. 2.2. This detailed introduction leads to the definition of perceived quality of transmitted speech, its assessment methods, as well as analyzing and diagnosing concepts that are described in Sect. 2.3.

2.1 Research Scenario
A simple and very basic schema of the general research scenario that this book is about can be seen in Fig. 2.1. The illustration shows the classical concept of two-party human-to-human speech communication. Here, the term communication is defined as the "intentional transmission of information" [4]. Thus, two humans participating in the communication intend to exchange information. The information exchange in this research scenario is based on speech, while also written language or sign language could be considered at this point.
Speech communication between two participants requires the transmission of speech in both directions, thus speech communication is bidirectional. The transmission of speech usually starts at one participant, the speaker that produces speech, that is the source of information. The speech is then transmitted through a transmission system. Finally, the transmitted speech reaches the sink of an information, the second participant named the listener who perceives speech. This introduced speech communication with two participants that intentionally exchange information and thus take turns in the role of listening and speaking is from now on called a conversation and the two participants are called interlocutors.
This schematic transmission of speech is often referred to as the so-called speech chain [5]. Starting from the brain of the speaker as the source of information and ending at the brain of the listener as the sink of an information, it describes the causal concatenation of physiological and physical processes of speech communication. Thus, the speech chain covers three fundamental processes:
Speech production as the source of the information
Speech transmission to exchange information
Speech perception as the sink of information.
Fig. 2.1Two-party speech communication based on [2]

In the present book, the focus is on the perception of transmitted speech in a conversation in terms of its perceived quality (see Sect. 2.3). As a traditional transmission service, this book is targeting at telephone communication services. The only definite methods for testing and evaluating bidirectional communication services in terms of quality are conversational methods [6]. This is because only in a conversation all three processes of a the speech chain can be respected. In turn, the three processes are all important for the perceived quality in a conversation (see Chap. 3 and [7]). A telephone communication is composed of specific elements that might introduce degradations to the transmitted speech. For example, a corrupt microphone (element) might lead to an attenuated transmitted speech (see Sect. 2.2.2). The focus of this book, that is the quality perception of transmitted speech in a conversation, is explained by analyzing and optimizing a given transmission system by diagnosing (identifying elements that are responsible for degradations) the perceived speech quality (see Sect. 2.3.3).
In sum, the research scenario of this book is the bidirectional speech communication in a conversation over a telephone transmission system. To give more information about the aforementioned fundamentals, the three processes of the speech chain will be described in Sect. 2.2. In addition, Sect. 2.3 introduces and defines the quality of transmitted speech, its assessment methods, as well as approaches of analyzing the quality of transmitted speech in terms of diagnosis and optimization. Section 2.4 concludes the fundamentals and summarizes their relation to the present book.


2.2 Human Speech
Speech production and speech perception are two complex research fields that have been studied in different scientific area such as acoustics, physiology, and linguistics. This section will provide fundamental knowledge about the two processes in terms of basic concepts of acoustics, perception, and cognition. Following the time line of the speech chain, the first subsection is about the production of speech (see Sect. 2.2.1). Afterwards, the produced speech is transmitted through a transmission system. Section 2.2.2 will provide substantial information about telecommunication systems, as this book will concentrate on telephone speech transmission systems. Finally, the transmitted speech reaches the listener. The hearing process, the analysis of speech in the listener's brain, and consequently the speech perception are briefly introduced in Sect. 2.2.3.

2.2.1 Production
As described in Sect. 2.1, the first process of human-to-human communication is the speech production. In other words, no production of intelligible speech sounds, no conversation. The basic concept of generating a speech sound is built up in two consecutive events, the excitation and the sound shaping [8].

2.2.1.1 Excitation
During the excitation, from the lungs (serving as an "energy reservoir") the chest musculature (serving as a "pump") produces an airflow. This airflow is then led through the glottis. The vocal cords can either be opened (the airflow will pass without limitation), or they are closed at first and become opened by the airflow. This leads to two different "excitation types":The first excitation type is called periodic excitation. As said before, first the vocal cords are closed. The airflow lets the air pressure at the vocal cords rise and at a certain pressure level, the vocal cords jump open. In turn, this leads to a fast drop in pressure, and the vocal cords close again. The repetition of these steps results in a quasi-periodic opening and closing of the vocal cords. The period of the opening and closing is defined with .  is called the fundamental frequency (also referred to as pitch frequency). The fundamental frequency depends on the length of the vocal cords. Hence, the fundamental frequencies between males (approximately 132 Hz), females (approximately 223 Hz), and children (300 Hz or higher) vary [9]. The fundamental frequency can change rapidly, however it is constant for about 20 ms. Therefore, periodically excited speech can also be seen as constant for 20 ms [10].The aperiodic excitation can be separated into two different modes. (I) If the vocal cords are already open, the airflow can pass through. This leads to turbulences behind the vocal cords (in the vocal tract (see Sect. 2.2.1.2)) that build a noise-shaped excitation signal. (II) The vocal cords are open, but the airflow is hold by a barrier (e.g. the lips) at a different point in the vocal tract. With raising air pressure this barrier is suddenly opened, it "explodes" or "bursts". This results in a so-called explosive (or plosive) excitation signal [8].

The introduced extraction types can also be combined or adapted, for example when humans whisper (see [10]). At this point, whatever excitation signal is produced, no information are so far "printed" on the signal. For this, the signal at hand has to be shaped to carry information. This happens during the so-called sound shaping.Fig. 2.2Schematic illustration of the human vocal apparatus based on [8]



2.2.1.2 Sound Shaping
Responsible for the sound shaping is the vocal tract. The vocal tract consists of pharyngeal, oral, and nasal cavities. It is limited at the lower end by the vocal cords, and at the upper end by the mouth. The vocal tract serves as a resonator that introduces different energy levels in the frequency spectrum of the pressure wave. The maximum energy levels are called formants and are approximately equal over different speakers. The positions of the so-called articulators (lips, jaws, tongue, or velum) have a strong effect on the sound wave traveling through the vocal tract and therefore shape the speech sound. Together with the excitation (source), the vocal tract (filter) forms a so-called source-filter-model that produces and shapes a specific speech sound. A schematic illustration of the vocal apparatus can be seen in Fig. 2.2.


2.2.1.3 Speech Sound
As described before, the sound shaping, together with the excitation, characterize a speech sound for a short period of time. The basic components of speech production are referred to as phones. They are grouped in the abstract class called phonemes. Phonemes are the smallest distinctive unit of a language that do not carry a meaning in itself (e.g. /b/ in bit and /p/ in pit) [8]. They can be divided into two groups: the vowels and the consonants [11]. Vowel sounds (e.g. [i], [e], or [u]) are characterized by a periodic excitation (constant airflow through the vocal tract) and they can be defined by their formant frequencies (see, e.g. the formant maps for German vowels in [12]). Consonant sounds are mostly created with an aperiodic excitation and can for example be divided into plosive ([p] or [t]) or fricative ([s] or [f]) consonants. Formants are also important for consonants, but for these phonemes they often vary in time. Different phonemes are concatenated into phoneme sequences by a speaker in order to form the words to be expressed, in which the exchange of one phoneme leads to a change in the meaning (hat—fat).
The produced speech sound leaves the speaker at the output of the mouth. The spectrum of the produced human speech typically ranges between 100 and 7000 Hz [13]. The bandwidth is dependent on the phoneme that is produced. Vowels concentrate most energy between 300 and 3000 Hz, while fricatives have little energy below 7000 Hz. However, between 100 and 600 Hz (here the first formants as well as the fundamental frequency are included) the energy of human speech is usually the highest. For more detailed information and a broader overview about speech production, see for example [8] or [10].



2.2.2 Transmission
As described in Sect. 2.1, the second process of human-to-human communication is the speech transmission. Again, in other words, no speech transmission, no conversation. In Fig. 2.1, the speech transmission is represented as a "black-box". This combines all possible "systems" that transmit speech from the mouth of the speaker to the ear of the listener. In a face-to-face conversation the transmission "system" is the pure acoustic sound field, the direct air-path from mouth to ear. However, in this book the focus is on telephone communication systems. In this context, speech telecommunication is realized by applying a speech transmission system that is replacing the natural air-path in a face-to-face conversation. A speech transmission system "follows the aim of supporting natural communicative possibilities involving people by means of technical devices and facilities" [14]. This section will give a brief overview of the basic concepts of speech transmission and its possible implementations.

2.2.2.1 Speech Transmission in a Telephone Communication System
In Sect. 2.1, Fig. 2.1 shows a very simple schema of speech communication. An (again very basic) example of a one-way (source to sink or speaker's mouth to listener's ear) speech transmission in a telephone communication system is displayed in Fig. 2.3. After the speech sound is produced (see Sect. 2.2.1), the acoustic signal x(t) is received by the microphone of the speaker's handset. However, the acoustic signal might be disturbed by different acoustic signals n(t) that are produced by sources surrounding the speaker. Thus, the microphone does not only receive the pure speech signal, but rather a "signal mixture" consisting of the speech signal x(t) and the background noise n(t).
Subsequently, the acoustic signal is converted into an electrical signal. This signal is digitized, that means that it is sampled and quantized in a form of x(k) (k representing the sample index). In addition, the "signal mixture" is pre-processed to remove the undesired signals like background noise.
Finally, the digitized and pre-processed signal is compressed and sent through the telephone network (see Sect. 2.2.2.2) where it passes several gateways and nodes. After the signal has passed the network it arrives at the listeners side. Here, the digitized electric signal is synthesized by several post-processing steps, resulting in a digital signal y(k). Then, the signal is again converted into an acoustic signal y(t) that is played back at the speaker(s) of the listener's handset where it is presented to the listener (see Sect. 2.2.3).
In a conversation, speaker and listener change roles and this mouth-to-ear schema (Fig. 2.3) could be flipped. As it is described, it follows that multiple elements of the speech transmission could effect and possibly degrade the transmitted speech signal. For now, these elements are illustrated as "black-boxes" in Fig. 2.3 (Element A, B, and C). An overview of these elements is given in Chap. 3.Fig. 2.3Schema of one-way speech transmission in a telephone communication system based on [15]



2.2.2.2 Telephone Networks
At the very beginning of the evolution of analog telephone networks, two telephones were directly connected to each other. It was not possible to reach other telephones. Later, it was possible to manually connect two telephones. If one person wanted to reach another one, the operator was called and he manually set up the connection. This process was then automated which led to the public fixed-line telephone networks, also called Public Switched Telephone Network (PSTN).
In PSTN the bandwidth of transmitted speech corresponds to the transmission of frequencies between 300 and 3400 Hz. This bandwidth is referred to as Narrowband (NB). In PSTN the two interlocutors are connected by a physical circuit that is held for the conversation and duration of the call.
The next step of evolution was the introduction of digital transmission. The Integrated Services Digital Network (ISDN) was introduced and standardized in the mid-nineties [16]. ISDN replaced analog transmission, however, the digitally encoded information are still transmitted by an analog electrical signal.
Besides PSTN, also mobile phone networks were established over the world in the last decades. Other than in fixed-line telephony networks, the two interlocutors can move during their conversation. This, however, is dependent on the radio channel between the mobile phone and the antenna. Also, during movement the interlocutors may switch from one transmission channel to another one (referred to as handover see e.g. [17]). This and for example interferences produce errors and degradations (e.g. bit errors or frame drops) that are new in comparison to fixed-line networks. The global expansion of mobile phone networks began with the Global System for Mobile Communications (GSM) network [18]. The GSM network was first replaced by the third generation network ("3G") called Universal Mobile Telecommunications System (UMTS) [19] and later by the fourth generation network ("4G") called Long Term Evolution (LTE) [20].1 The new networks provide a higher transmission bit-rate and thus enable new services as well as usage possibilities.
Apart from PSTN and mobile phone networks, computer networks like the Internet have been established. They are also known as packet-switched networks as they transmit packets of data. In the context of speech telephony, the system providers adapted the networks to transmit speech as data in packets of equal size (frames). Since speech is assumed to be stationary for a short period (see Sect. 2.2.1.1), for the digital speech signal, the source signal is chopped into frames of equal length. At this point, each sample in each frame is represented by bits. The bitrate specifies how many bits per second the network can transmit, it is also called the network rate. The packet transmission is handled by protocols like the User Datagram Protocol (UDP) or the Real-time Transport Protocol (RTP). Thus, in packet-switched networks the transmission of speech (or voice) is called Voice over Internet Protocol (VoIP).
VoIP services have been spread widely in the last decade and are nowadays one of the most widely used transmission paths. This is because of their flexibility and the higher audio bandwidths that can be transmitted. While PSTN is limited to NB, it is possible to transmit speech with a bandwidth of 50-7000 Hz (referred to as Wideband (WB)), 50-14000 Hz (referred to as Super-Wideband (S-WB)), or 20-20000 Hz (referred to as Fullband (FB)). However, also packet-switched networks introduce new kinds of degradations in comparison to fixed-line networks. For example, the process of creating the packets could lead to a higher overall transmission delay that may introduce talker echoes or affect the interactivity of a conversation. In addition, packets could be lost in the transmission path, referred to as packet-loss, which leads to time-varying degradations and discontinuities. An overview of degradations introduced in packet-switched networks can be found in [21].



2.2.3 Perception
As described in Sect. 2.1, the third process of human-to-human communication is the speech perception. And yet again, in other words, no speech perception, no conversation. So, as described in Sect. 2.1, a speech signal transmitted through a transmission system finally arrives at the sink of an information, the speakers ear. The sound reception and the human hearing system have been researched in numerous studies. Detailed information can for example be found in [5, 8], or [10]. Basically, the human ear consists of three parts (see Fig. 2.4):
The outer Ear is composed of the pinna, the ear canal, and the eardrum. The sound wave is received by the pinna. The pinna supports the localization of the sound source and its funnel-shaped form serves to send the sound wave through the ear canal. At the end of the ear canal the eardrum is excited.
The middle Ear is a leverage that transmits the pressure from the eardrum on to the oval window of the cochlea. It is composed of three connected small bones that form the chain of ossicular bones, the malleus, incus, and stapes. Thus, these ossicles are an impedance-matching system that converts the acoustic sound wave into a mechanical wave.
The main component of the inner Ear is the cochlea. It is formed by three fluid-filled parallel and snail-shaped (2 and a half turns) chambers, where two of them are connected at their ends. The membrane separating these two chambers is called basilar membrane. The basilar membrane contains sensory hair cells connected with the auditory nerve system. Thus, the oval window excites the fluid in the cochlea and the hair cells convert the mechanical wave into electrical pulses. At this point, a spectral decomposition through a frequency-to-place transformation, which is of non-linear nature, is performed. Finally, the brain transforms the electrical pulses into a massage that is interpretable by the listener.Fig. 2.4Anatomy of the human outer, middle, and inner ear based on [3, 22]

The actual speech perception is taking place in the human brain on a psychological level. The study of relating physical acoustic events to auditory perceptual events is called psycho-acoustics [23]. An overview of psycho-acoustic research for noise and tones (including masking, thresholds, or localization) can be found in [24] or [25].
While much is known about how speech signals are converted into patterns of auditory nerve signals, much less is known about how the brain translates these signals into an interpretable message [26]. For speech, it has to be considered that a speech signal does not "mean" anything by itself [14]. Thus, speech can be seen as a system of signs (something which can stand for something other than itself) that can be represented with a triangle (see Fig. 2.5) of three correlates in a semiotic (the science of signs) approach (following [27]). A sign can be modeled by a (I) sign vehicle, (II) its meaning, and (III) an object of reference [28]. Thus, the listener extracts the meaning from the sign vehicle (the form of a speech signal, e.g. sound wave) and the object the sign stands for.
In addition, an important part in speech communication is the auditory memory that gives the base for different theories about speech perception [10]. One of these theories implies that in the auditory process acoustic features are stored in the auditory memory. The interpretable message is then based on these acoustic features and stored again. Thus, different types of storage at different stages of perception are defined (see for example [29, 30], or [31]):
In the Echoic Memory only the important acoustic features for durations of 150-300 ms are stored. Following, the features are transferred to the Short-Term Memory (STM) where the phonetic process appears. Here, the information is stored for 2-20 s. If sounds are not directly processed in the STM they could be stored in the echoic memory for up to 3-4 s (for example no speech sounds). The third component of the memory is the Long-Term Memory (LTM). Here, information is stored from a few days up to decades. The LTM allows people to recognize speaker and instruments.Fig. 2.5Semiotic triangle based on [27, 28]

Finally, in speech communication the target of the two interlocutors is that their messages are understood. This process of speech recognition is called comprehension and describes the perceptual analysis of the speech signal [14]. According to [6], comprehension is the last stage in the speech perception process that is composed of four successive steps:The Comprehensibility describes the capability of the speech signal to transport phonemic information (sign vehicle). A high comprehensibility indicates a perfect recognition of each phoneme from the speech signal.The Intelligibility describes the capability to extract the content of the speech signal (object of reference).The Communicability describes the capability to understand the speech signal (meaning).The Comprehension describes the result of the speech perception process in terms of (a) achieved communication efficiency, and (b) understood messages.




2.3 Quality of Transmitted Speech
The previous section briefly introduced the processes of speech production, transmission, and perception. Obviously, a transmitted speech signal in a telephone conversation contains numerous information: for example linguistic (the actual message) or paralinguistic (identity or emotion of the speaker) information. Thus, for a speech transmission system, it is important to provide intelligibility and comprehension. In modern telephone transmission systems, the intelligibility and comprehension of a speech message is almost always given. However, the system user's perception in a telephone situation is different from a natural face-to-face conversation. Other factors, like annoyance due to an undesired sound additional to the desired speech sound for example, influence the user's perception of a particular telephone connection. Hence, speech intelligibility and comprehension are important, but not enough to fully quantify the user's perception of a speech transmission system [32]. In fact, besides intelligibility and comprehension a fundamental part of the speech transmission system is the user's perception of the quality of the transmitted speech signal. The quality of transmitted speech reflects the undesired degradations introduced by, e.g. the transmission system and perceived by the system users. In this section, the terms related to speech quality are introduced, providing the fundamental understanding and the scope of research this book is about.

2.3.1 Definition of Perceived Quality
According to [14],
perceived quality is "[the] result of [the] judgment of the perceived composition of an entity with respect to its desired composition."
Here,
the perceived composition is "[the] totality of features of an entity."
and
the desired composition is "[the] totality of features of individual expectations and/or relevant demands and/or social requirements."
while
a feature is "[a] recognizable and nameable characteristic of an entity."
In the context of speech quality the mentioned entity is the acoustic speech signal experienced by a human. According to [33],

experiencing "is the individual stream of perceptions (of feelings, sensory percepts and concepts) that occurs in a particular situation of reference."
Thus, quality is a subjective value dependent on the human experiencing an entity. However, the quality formation process inside a human (or here a listener) is not a comparison of a desired and a perceived composition alone. In fact, according to [21] and based on the work in [14], the speech quality formation process can be divided into five successive steps (see Fig. 2.6) resulting in the perceived quality (see also [33]):Fig. 2.6Speech quality formation process based on [3] according to [14, 21]. Ellipses represent processes, italicized names storages and rectangles the inputs and outputs of the human/listener

In the perception step, the speech signal is perceived by the listener, resulting in the perceived composition. In terms of speech quality, this is the perceived auditory composition composed of all perceptual aspects like the duration, loudness, or the phonetic information. The modifying factors are formed by the personal and the context characteristics [21]. Personal characteristics are for example the motivation, knowledge, experiences, or memory of the listener. The context characteristics describe the listener's environment and the particular communication situation. Thus, the modifying factors form the desired auditory composition (also called internal reference) for a listening situation. Each human has his or her own desired composition and therefore different quality formation results are produced when the same speech sample is presented to two different listeners. The desired components are stored in the LTM (see Sect. 2.2.3) and are expected to change with training (see for example [34]).
During the reflection, the listener reflects the perceived signal characteristics and transforms them into a set of perceived features. These quality-related features define the perceived composition and form a specific position in the multidimensional space (b in Fig. 2.6). Accordingly, the desired characteristics are decomposed and the desired features are identified to form a specific position in the desired composition space (a in Fig. 2.6). Thus, for each perceived feature, there exists a desired feature.
The comparison step covers the required comparison between the desired and the perceived features a and b.
In the judgment step, the listener uses the comparison step to actually judge the perceived quality. Here, the features are associated into a single quality value by weighting each feature with its influence on the quality. At this point the single quality value is called integral quality or overall quality
2 as it is composed of the different features (see also Sect. 2.3.2). Consequently, high quality values can only be formed if the desired and the perceived composition are as similar as possible.
In the final description step the listener has to describe the perceived quality. Typically, listeners are asked to do that on a rating scale. One famous rating scale is the 5-point rating scale defined in [35], where listeners choose between bad, poor, fair, good, and excellent. However, more information about subjective quality ratings can be found in Sect. 2.3.4 and Chap. 3.
In addition to the term perceived quality, the term Quality of Experience (QoE) was introduced in [36]. Based on [33], the definition of QoE was extended to:

Quality of Experience "is the degree of delight or annoyance of a person whose experiencing involves an application, service, or system. It results from the persons evaluation of the fulfillment of his or her expectations and needs with respect to the utility and/or enjoyment in the light of the persons context, personality and current state."
Here, following [36]
an application is "[a] software and/or hardware that enables usage and interaction by a user for a given purpose. Such purpose may include entertainment or information retrieval, or other."
Here, an application refers to an Information and Communication Technology (ICT) like a gaming, video, television, or communication service. In this book, the focus is on a telecommunication system and in this case QoE includes the effects of the complete end-to-end (speaker-to-listener and back—conversational situation) system (terminal, all system elements, and the network itself). Taking these definitions into account, the human experiencing an entity is not only passively describing the perceived quality (see step V of the quality formation process) but rather actively using an application. Thus, the person who is proactively using and interacting with a particular technology or an ICT product is "introjected" in the role of a user [37]. Regarding the topic of this book, an interlocutor in a conversation is therefore rating the QoE as an end-user of a telecommunication system.
This implies that a certain degree of interaction of a user is required and respected when talking about QoE. The introduced schema of the quality formation process is mainly targeting at a passive situation (listening, see Chap. 3). An extended version for the QoE formation process regarding ICTs in general can be found in [33]. A detailed introduction to interactive situations (conversations) is given in Sect. 3.​5.
As QoE is regarding quality from the perspective of the user, quality can also be regarded from the network perspective, referred to as Quality of Service (QoS). According to [38] QoS is defined as:

Quality of Service is "[the] totality of characteristics of a telecommunication service that bear on its ability to satisfy stated and imply needs of the user of the service."
However, QoS covers technical parameters and the performance of a physical system. Thus, QoS is targeting at the technical quality that is different from the perceived quality as the context and human factors are not taken into account. An overview about the QoS taxonomy can be found in [6, 39].


2.3.2 Quality Features and Quality Elements
As described in Sect. 2.3.1, during the speech-quality formation process in the comparison and judgment steps the features of the desired and the perceived composition are compared and associated to form the single overall-quality value. From this it follows that the overall speech quality is a multidimensional value—it is composed of the perceived features that are the perceived characteristics of the speech signal such as the loudness or timbre. These features of the perceived composition that are obviously relevant for the overall quality are called quality features. Along the definition in Sect. 2.3.1 and according to [14] is a

quality feature "[a] recognizable and nameable characteristic of an entity that is relevant to the entity's quality."
In contrast, looking at the technical domain of speech transmission systems (see Sect. 2.2.2), specific elements of the transmission system can actually cause an impact on the quality perception. These elements of the speech transmission system (see Sect. 3.​2) are referred to as quality elements. Following [14]
a quality element [is the] contribution to the qualityof a material or immaterial product as the result of an action/ activity or a process in one of the planning, execution or usage phasesof an action or of a process as the result of an element in the course of this action or process.

Hence, quality elements are the physical counterparts to quality features: "While an element of quality is the building block for designing an entity, a quality feature is the analyzed result of the perceived, designed entity and is therefore the basis of any description of its quality" [14]. Quality elements and quality features serve to give a deeper insight into the single overall speech-quality value. Their relation and the concept behind this are given in the next section.


2.3.3 Perceptual Quality Space and the Concept of Diagnosing Speech Quality
As mentioned in the section before, the perceived quality is a multidimensional value that is formed by the comparison between the desired and the perceived quality features. Geometrically, it is illustrated in Fig. 2.6 that the perceived composition is a specific point (b) in a multidimensional space defined by the quality features. This multidimensional space is called perceptual quality space and is defined as follows:
The perceptual quality space is the geometrically multidimensional space formed by the quality features in which the perceived composition is located.
If the perceptual quality space is a Euclidean space with an orthogonal basis and each perceptual feature is lying along one of the orthogonal axes, and thus are themselves orthogonal (independent and not correlated), the quality features are called perceptual quality dimensions. Consequential,

perceptual quality dimensions are the orthogonal, and thus independent, dimensions of the perceptual quality space.
Looking again at Fig. 2.6, the desired composition (internal reference) (a) and the perceived composition (experienced speech signal) (b) are positioned in the perceptual quality space spanned by the perceptual quality dimensions. This implies that the overall quality Q can be modeled with a mapping function  on the basis of perceptual quality dimensions, such that: (2.1)
Fig. 2.7Illustration of the vector model (a) and the ideal-point model (b) after [21, 40]

If a perceptual quality space is defined (see Sects. 2.3.4 and 4) this equation determines that the overall speech quality can be assessed on the basis of relevant perceptual quality dimensions [2]. In that case, the dimensions are (quality) underlying perceptual dimensions. The mapping function that defines the dependency between the overall quality and its underlying perceptual dimensions introduces the term quality profile that is defined as
the quality profile is the relation between the overall quality and its underlying perceptual dimensions.
Concerning the structure of the mapping function , in [40] two possible approaches are introduced:
The first approach follows the realization of a mapping function towards the overall quality with a linear relation. In a geometrical sense, this approach can be seen as a vector model: A quality vector in the perceptual quality space is pointing at an optimum quality point (desired composition or internal reference). Now, the perceived composition forms a point in the same perceptual quality spaces and its projection on the optimal quality vector is considered as the overall quality. An example in a two-dimensional perceptual quality space can be seen in Fig. 2.7a: If  is the multidimensional representation of a speech signal, and the quality vector of a user has an orientation of , the resulting quality Q is proportional to the projection q: (2.2)Thus, in algebraic terms, the influence of each perceptual dimension with regard to the overall quality Q is represented by the weighting coefficients () of a linear combination of the dimensions. In turn, this implies that the overall quality can be assessed from the linear combination of the different dimensions. Regarding the relation between dimensions and overall quality, the vector model can be seen in a "the higher the better—the lower the worse" sense—the better the dimensions, the higher the quality and vice versa. For each user of a system, a single quality vector can be determined; to cover an average user, a single vector that reflects the average individuals should be used [40].
The second approach is called the ideal-point model: A specific point in the perceptual quality space corresponds to the desired composition  (the internal reference or here the ideal point). The perceived speech signal forms the perceived composition that is also located as a specific point in the same perceptual quality space . Both points can be described as vectors, such as: (2.3)Here,  gives the number of dimensions. Now, the overall quality Q of the speech signal is anti-proportional to the squared Euclidean distance d between the two vectors a and b (see Fig. 2.7b for a two-dimensional example): (2.4)where  and  are the values of one of the  perceptual dimensions. The  variable is again a weighting coefficient that corresponds to the influence of each dimension on the overall quality (). Again, (2.4) implies that the overall quality can be assessed from the different dimensions. In difference to the vector model, the ideal point model cannot be seen in a "the higher the better" sense. In fact, degradations are introduced if the ideal point is not met in an ellipse form [40].
The introduced concepts allow to analyze the overall quality in terms of its underlying perceptual dimensions and thus the perceived quality features. As described in Sect. 2.3.2, the quality elements are the counterparts of the quality features. This means that, if a perceptual quality space is defined (see Sect. 2.3.4 and Chap. 4), the assessment of the perceptual dimensions allows to determine the quality elements that are potentially responsible for possibly low perceptual quality-dimension judgments. For providers of telecommunication systems, this process allows to identify weak points in their systems (that can be improved or eliminated) which introduces the concept of diagnosing speech quality. Traditionally (in medical science) and according to [41], diagnosis is defined as
[the] identification of the nature of an illness or other problem by examination of the symptoms.
Applied to the quality of transmitted speech, this definition modifies to the following:

Diagnosis is the identification of the quality elements of a telecommunication system that are potentially responsible for a drop of the overall speech quality (nature of an illness) by examination of the defined perceptual quality space (the symptoms).
Again, having diagnostic information at hand gives the telecommunication-system providers the possibility to analyze and improve their systems. To give an example: two different impaired speech signals (one degraded by, say, a level attenuation and the other one by background noise) may be judged with an equal overall speech-quality value. Now, having only the overall quality value at hand gives the telecommunication system providers no information about why the signals are impaired and how to improve the transmission system. Applying the introduced concept of diagnosing speech quality on the basis of perceptual dimensions, a defined perceptual quality space gives diagnostic information for the system providers. The signal degraded by a level attenuation gets lower ratings on a perceptual dimension that is connected to the "loudness" of a speech signal. This dimension in turn, is directly connected to a quality element that is responsible for the "loudness" (for example the gain control (see Sect. 3.​2)). The same with the second speech signal, the background noise causes a lower rating of a perceptual dimension that is connected to the "noise" of a speech signal and that perceptual dimension is connected to a responsible quality element, here for example the noise reduction element (again, see Sect. 3.​2).
The introduced concept of diagnosing the quality of transmitted speech is based on the assumption, or expectation, that perceptual features are one to one connected to specific quality elements. In theory, the concept promises to provide meaningful diagnostic information. However, in practice, the one to one connection between perceptual features and quality elements, or technical causes, is not always given. It is possible that one quality element is connected to more than one quality feature, and in turn, that one quality feature is connected to more than one quality element. Hence, diagnosing the quality of transmitted speech on the basis of perceptual dimensions might lead to ambiguous results. Thus, diagnosing the quality of transmitted speech on the basis of perceptual quality dimensions is only one possible approach to provide insights into the reason for a low quality rating. A second approach could be the identification of the technical causes of sub-optimum quality, in terms of characteristics of the signal or the transmission system that cause the lower quality rating. For this, the International Telecommunication Union (ITU) developed and proposes a specific test method for performing expert annotations after listening to transmitted speech files. The method is planned to be standardized in a future recommendation called Technical Causes Analysis (P.TCA) [42], and aims at identifying signal characteristics such as sub-optimum speech level, speech spectrum, noise level, echo, or alike. A detailed description of the proposed test method, first results, and possible improvements can for example be found in [1, 43, 44]. However, in this book, the focus will exclusively be on diagnosing the quality of transmitted speech following the approach of perceptual quality dimensions.
Thus, to sum up, the concept of diagnosing speech quality with the perceptual quality space exhibits inherent advantages for telecommunication system providers:Identifying of quality elements responsible for a drop of the overall speech quality,Differentiating between equally rated speech signals,Analyzing and improving the telecommunication system on the basis of the perceptual quality space,Understanding the user's perception of speech quality,Robustness against the quick evolution of signal processing elements in the transmission system [45],Modeling the overall quality on the basis of its underlying perceptual dimensions.

However, before using the introduced diagnostic concept, the perceptual quality space has to be defined. The perceptual quality space can be defined in four successive steps: (i) Generating configurations of the transmission system that span the whole perceptual space under study, (ii) conducting an auditory test using analytic assessment methods, (iii) incorporating a multidimensional analysis of the test results (for (ii) and (iii) see Sect. 2.3.4.1), and (iv) identifying and interpreting the resulting perceptual dimensions.3 The next section gives an overview about the principles of quality assessment methods for the overall quality and also for analytic methods. Nevertheless, examples and standards for quality assessment methods are also introduced in Chap. 3.


2.3.4 Assessment Methods
In Sect. 2.3.1 and in Fig. 2.6, the speech quality formation process with its five successive steps was introduced. In the last step (the description) the listeners describe their quality perception on provided scales which leads to the output of the quality formation process, the quality rating. This "encoding" process [21] of assigning numbers to objects [46] is referred to as assessing the quality of a particular speech sample or a transmission system. In other words, speech quality assessment is the quantitative description of the perceived quality. Speech quality assessment methods can be divided into two groups: auditory (or subjective) methods and instrumental (or objective) methods. Both assessment methods are introduced in the following. Note that the following introductions are of general meaning, a differentiation for different contexts of a telephone conversation is given in Chap. 3.

2.3.4.1 Auditory Methods
According to [14],
an Auditory Speech Test is "a routine procedure for examining one or more empirically restrictive quality features of perceived speech with the aim of making a quantitative statement on these features".
Here, the term features includes quality as well. The quantitative statement, that is the description step, is implemented by

measuring, that is "the entirety of all the activities in the measurement chain up to determining the value of a dimension" [14].
The term measurement chain corresponds to the actual practical application of the measuring technique. In addition,
the measurand, is the "feature of an object to be measured which can numerically be described in the course of the measuring process" [14].
In an auditory speech test, the measuring object is the acoustic speech signal. In a speech quality test, this acoustic speech signal is the output signal of a speech transmission system (as introduced in Sect. 2.2.2). The transmission system affects the perception of the speech signal in terms of its different characteristics regarding the quality elements. Due to the dependencies on the speech material (usually female and male speakers as well as different sentences are used [6]) often more than one speech signal is processed for one test. In this case, the composition of one transmission system configuration is referred to as a test condition composed of multiple acoustic speech signals called stimuli (different content and/or speakers but always the same system configuration).
The measurand is either a feature of the speech signal or the quality itself. A fundamental part of the measuring process is the scaling, that is the assignment of numbers to measuring objects (the speech signals) according to consistent rules [14, 46]. The numbers must be provided in a way that all aspects of the measuring object under consideration can be assigned to a number [2]. The set of the provided numbers is called a scale [47]. In such a test, the listener acts as the measuring organ and thus on a perceptual base, the measurement subjectively takes place [14]. Therefore, the listener is also called subject and auditory speech tests are also referred to as subjective tests. To sum up, in a subjective speech test, a test subject is asked to judge the perceived quality of a speech signal on consistent scales.
To guarantee that a subjective speech test is really quantifying the perception of a user, specific characteristics of a test have to be met. In [48] (and summarized in [3]), six characteristics were introduced to ensure a satisfying test method:
Objectivity: results are reproducible over different listeners.
Reliability: results are not widespread if the test is repeated by a listener.
Validity: the test measures what is intended to measure.
Sensitivity: differentiations and distinctions should be as fine as those made by the listener.
Comparability: enables comparisons between different transmission systems (conditions and stimuli) and its groups.
Utility: usefulness of the provided information.
Speech Quality Test Classification

According to [49], subjective speech quality tests can be divided into four categories, classified into two dichotomies: analytic versus utilitarian, and subject-oriented versus object-oriented. This classification is also illustrated in Table 2.1. In this book the focus will be on object-oriented tests.
The first dichotomy describes whether the focus of the test subject is on the overall quality or on its quality features. In utilitarian test methods, the test subjects are asked to judge the overall speech quality as a single quality value on a one-dimensional rating scale. A very famous example for these tests is described and standardized by the ITU in ITU-T Recommendation P. 800 [38]. However, more examples will be given in Chap. 3.
In analytic test methods, the subjects are asked to judge specific quality features that compose the overall quality. Either the subject judges one specific quality feature in a one-dimensional scale, or the subject judges on several scales, one per quality feature. The latter forms the basis for a multidimensional analysis that is necessary to identify orthogonal perceptual quality dimensions of the perceptual quality space. These tests serve for diagnostic quality assessment. Three famous examples for these test method are (i) the attribute scaling method like the Semantic Differential (SD) with a subsequent Principal Component Analysis (PCA) [50, 51], (ii) the Diagnostic Acceptability Measure (DAM) method according to [52], or (iii) the Multidimensional Scaling (MDS) method in which perceptual differences of pairwise presented stimuli are scaled, and then the perceptual distances/dissimilarities are mapped to a multidimensional space [53]. More information about these methods and their results can be found in Chap. 3 and Sect. 4.​2.Table 2.1Speech quality test classification based on [3] according to [49] Subject-oriented testsObject-oriented testsUtilitarian judgmentsPsycho acoustic researchOverall speech quality assessmentAnalytic judgmentsAudiological evaluationDiagnostic quality assessment

The second dichotomy describes the two possible types of analysis that speech quality tests could end in. On the one hand, the analysis is focused on the quality of the transmission system conditions (object-oriented), and on the other hand, the analysis is focused on the subject in the quality formation process (subject-oriented).

Speech Quality Test Characteristics

The introduced definitions and classifications show that planning and implementing a subjective speech quality test is a complex task in which numerous aspects have to be considered. In [6, 21], five characteristics of subjective quality tests are introduced that define exact test results. Based on the number of transmission system conditions under test and the measurand, the test supervisor chooses the appropriate characteristics:The presentation method: defines whether a comparison (relative) or an absolute assessment will be conducted (examples for both will be given in Sect. 3.​3.​2).The scale level: defines whether an interval-, ordinal-, ratio-, or nominal-scale is used (see [54] for more information).The scaling method: defines whether the rating process will be conducted on a single or on multiple scales (see Sect. 3.​3.​2 for examples).The test modality: defines whether a listening, a speaking, or a conversation test is conducted (more information about different test contexts are given and explained in Sect. 3.​1).The analysis method: defines whether a simple average analysis or a multidimensional analysis is performed (the two analysis methods will also be introduced in Sects. 3.​3.​2 and 4.​2).
Schematic of a Listener

In Sect. 2.3.1, Fig. 2.6 illustrates the quality formation process of a listener. This concept can also be adapted to a listener in a subjective test. In Fig. 2.8, the schematic of a listener in an auditory subjective test according to [2] (and based on [47]) is shown: A speech signal arrives at the listener. As the receiving speech sound is distinct in time, space, and other characteristics [47], it is called a sound event. At the first step, the sound event causes an auditory event (more generally a perceptual event) that is transformed from the physical domain to the perceptual domain by the perceiving system (see the perception step in Sect. 2.3.1). If the listener participates in a utilitarian test (the listener is asked to judge the overall quality), the perceptual event is compared to the internal reference (comparing system) and transformed into a quality event. This quality event is not accessible from the outside of the listener. Hence, the listener is asked to describe the quality event (describing system) by judging it on a scale.
If the listener participates in an analytic test (the listener is asked to judge perceptual features), the perceptual event (that is of multidimensional nature and composed of multiple quality features) is transformed into feature descriptions by the second describing system. This way dissimilarities between specific features can be described (see Sect. 4.​2.​1 for more details on dissimilarity judgments). Note that other than for the quality formation process, this concept of the schematic of a listener is very general and also applies for speaking and conversation tests (see Chap. 3 for more details about different test contexts). For more details about the schematic of a listener in a auditory test see [2, 47].Fig. 2.8Schematic of a listener in an auditory subjective test according to [2] (based on [47] and extensions by [14, 21])


Test Subjects

Depending on the purpose of the test, care should be taken when selecting test subjects. In principle, test subjects are classified according to their knowledge about subjective quality tests and the speech transmission systems under test. In general, test subjects are classified into two groups, expert subjects and naïve subjects. Utilitarian tests usually targeting at providing quality ratings of an "average" system user. Thus utilitarian tests are commonly carried out with naïve subjects. According to [38], naïve test subjects are defined as:

Naïve test subjects "taking part in listening tests are chosen at random from the normal telephone-using population, with the provisos that:they have not been directly involved in work connected with assessment of the performance of telephone circuits, or related work such as speech coding,they have not participated in any subjective test whatever for at least the previous six months, and not in any listening-opinion test for at least one year,they have never heard the same sentence lists before".

Unfortunately, to the best of the author's knowledge, no similar definition of expert subjects exists. However, experts could be defined by the contrary of a naïve test subjects. Experts should be connected with assessment of the performance of telephone circuits, or related work such as speech coding, they can have participated in any subjective test in the last six month, and may know the sentence list. Thus, experts are for example researchers that plan and conduct subjective tests, developers of new coding techniques, or audio engineers. Nevertheless, experts are more costly and difficult to recruit than naïve test subjects (students, colleagues, or friends).
Both, expert and naïve test subjects, have to fulfill two further requirements to participate in a speech quality test. First, it must be guaranteed that the test subjects are free of any hearing (or speaking in case of conversation tests) impairments. The hearing ability is usually evaluated using an audiometer that determines the hearing threshold. Second, the test subject should be a native speaker of the language that is used in the experiment. In addition, if a test is supposed to be representative for a particular user group, the test subjects should be selected according to the corresponding requirements (age, gender, experience in telecommunication, and the like).

Subjective Test Effects

In a subjective quality test, many different factors can influence and bias the way the test subject perceives the speech signal that is under test. This subsection will give a very brief overview about the aspects of a subjective quality test that may affect the judgment of the test subject. A detailed review can be found in [6, 55], or [56]. In [14], the aspects that may affect the judgment of the test subject can be classified into three groups:
The Scaling Effect describes all effects that can result from the scale itself. For example, the intervals between the categories on a category scale may be unequal. This leads to a non-linear scale where simple mean values should not be calculated. To overcome this effect, each category is connected to a number (see Sect. 3.​3.​2). Also, the sensitivity of scales may be different or the saturation at the extreme categories may be neglected by naïve test subjects. Both effects are discussed and compared on two different scales in [57].
The Subject Effect describes the effect that can result from the different internal references of the subjects. Each test subject has his or her own opinion about the perceived quality because each subject has his or her own internal reference due to different prior experiences. To minimize this effect, the number of test subjects should be large enough to ensure an average rating of the quality. The ITU-T Handbook of Telephonometry [58] recommends around 30 subjects. Also, so-called anchor conditions (for example the highest and the lowest quality of a system condition in the test) are presented before (i.e. training) and during the test to ensure high reliability. At last, also the fatigue of test subjects may have an effect on the quality judgments. It is recommended to insert short breaks in the test at regular intervals (for example every 30 min).
The Context Effect describes the effect that the assessment situation may have on the subject's judgments. The main bias introduced in subjective quality tests is the listening environment. Most tests are conducted in a laboratory context that is different from a real-life situation. In the laboratory, the quality judgment is restricted to one modality (sound), in real-life the perception is multimodal (vision, sound, temperature) [59]. Therefore, tests are conducted in standardized test rooms where the surrounding conditions are kept stable to minimize this effect [35]. In addition, the corpus and the order of the speech material influence the subject's judgment (corpus effect and order effect). Thus, a subject's judgment depends on the range and distribution of degradations within the test corpus. For example, in [6] it is found that a NB condition obtains a higher quality rating in a pure NB corpus than in a mixed NB-WB corpus. The order-effect corresponds to the influence of a preceding stimulus on the current stimulus. It is assumed that the most recent stimulus has the strongest influence. Each test subject is presented with a different order of the conditions under test to minimize the bias of the order-effect.
Regarding QoE, these effects are proposed to be called Influence Factors according to [60]. Three types of influence factors are proposed, human, system, and context influence factors. Each of the three influence factors are connected to one of the effects mentioned above. For more information see [60].


2.3.4.2 Instrumental Methods
The introduced auditory subjective quality tests depend on the test subjects and their quality ratings. Also, they are complex in terms of planning and conducting. Thus, even though these subjective test are valid, reliable, and sensitive means for evaluating a speech transmission system, they are very time and money (compensation for the test subjects) consuming. So for example, if a company develops or modifies a codec, it would not be economic to conduct a new subjective test to evaluate the enhanced transmission quality for every development phase. Hence, computer programs that estimate (often also the term prediction is used) the perceived speech quality were developed. These quality models are called instrumental speech quality models. However, these instrumental models must be based on the results of subjective tests. Thus, they are the "counterparts" of subjective test and are also often referred to as objective methods.
In [61], the development of an instrumental speech quality model is described (see Fig. 2.9). There should be at least three major steps involved in the development of an instrumental model:
First, a valid subjective quality test has to be designed and conducted. This test provides subjective quality ratings serving as a ground truth for the instrumental model. Second, a candidate instrumental quality model has to be developed and implemented. This model provides instrumental (objective) quality ratings. The third major step is the design and validation of the instrumental quality model. Here, the subjective and the instrumental quality values are compared in terms of correlation and error (see Chap. 7 for an introduction). Instrumental models that prove to be redundant or not significant may be discarded at this point. If no accurate model can be found, maybe step one (subjective quality test) and two (candidate instrumental quality model) have to be iteratively repeated. However, if the instrumental model proves to provide valid and reliable correlates between the instrumental and the subjective quality ratings, this model can be used to estimate subjective quality ratings. Note that for a robust estimation, the model has to be validated on more data provided by the subjective test design in step one, for example by other laboratories.Fig. 2.9Development of an instrumental quality model based on [61]

Instrumental models use variable input information and are used for different applications and targets (for example, an instrumental model designed for NB transmission systems does not provide valid estimations for WB transmission systems). According to these characteristics, instrumental models are classified in three different groups; parameter-based models, signal-based models, and packet-layer models. Note that in the literature the names for the different model classes vary, alternative names are given in parentheses (based on [21, 62, 63]).

Parameter-Based Models

Parameter-based models (or Opinion models or Network planning models) use parameters that characterize the different quality elements of a transmission system to plan future transmission systems. If telecommunication-system providers plan a new speech transmission system, they only have information about the elements they could use. So, based on these elements, the transmission system and its elements can be described by specific parameters that are mathematically combined to estimate the quality of a future transmission system. Examples for parameter-based instrumental models are given in Chap. 3.

Signal-Based Models

Signal-based models (or Speech-layer models) use signals that are transmitted over a speech transmission system (or degraded by a speech processing chain) to estimate the perceived speech quality of these systems (or processing chains). If a transmission system is developed and implemented, it is possible to transmit speech through it. Signal-based models try to extract specific indicators of the speech signal to estimate the perceived quality. Based on what signal the model is using, signal-based models can be classified into two groups (see Fig. 2.10):(i)
Full-reference (also known as intrusive or double-ended) models depend on a reference (system input) speech signal and a corresponding degraded (system output) speech signal. They time-align and compare both speech signals and use the difference of the indicators to estimate the speech quality. (ii)
Reference-free (also known as non-intrusive or single-ended) models depend only on the degraded signal at the system output. They extract information from the degraded signal only and use these information to estimate the speech quality. Examples and further information about signal-based instrumental models (both types) are also given in Chap. 3. 
Fig. 2.10Overview of signal-based instrumental models based on [3]


Packet-Layer Models

Packet-layer models analyze parameters of the transmission network (for example the packet pattern in VoIP networks) to monitor the speech quality. They are used in packet-switched networks and measure in gateways or at the listener's side several network related parameters (for example the delay of packets, the packet-loss rate, or the burst ratio). The current ITU-T standard for a packet-layer model is described in [64]. Packet-layer models will not further be addressed in this book, for more information see [63].




2.4 Conclusion
This chapter is targeting at giving the definitions and explanations of the fundamental knowledge important for the research that is conducted in this book. At this point, the reader should be familiar with the following topics: First the basic research scenario, a telephone conversation between two interlocutors, was presented. Second, an introduction of the three main parts of a conversation: speech production, transmission, and perception, was given. This introduction led to the definition of perceived quality of transmitted speech. In addition, the concepts of diagnosing speech quality on the basis of perceptual dimensions that form a perceptual quality space were shown. Finally, the end of this chapter explains the general methods to assess the perceived quality of transmitted speech. This covers the schema of subjective test and the different techniques for instrumental quality assessment. However, the given introductions are for now rather general than precise in case of a telephone conversation. The next chapter will give a deeper insight into the speech quality in a telephone conversation, including the different phases of a conversation and their corresponding quality elements, perceptual spaces, and subjective as well as instrumental quality assessment methods.


Footnotes


1


Note that LTE is a pure packet-switched network.

 



2


From now on the term overall quality will be used.

 



3


The identification of the perceptual space in a telephone conversation is described in detail in Chap. 4.

 













© Springer Nature Singapore Pte Ltd. 2018


Friedemann Köster



Multidimensional Analysis of Conversational Telephone Speech


T-Labs Series in Telecommunication Services


https://doi.org/10.1007/978-981-10-5224-8_3





3. Speech Quality in a Telephone Conversation




Friedemann Köster
1  




(1)
Quality and Usability Lab, Technical University of Berlin, Berlin, Germany

 



 

Friedemann Köster


Email: 
friedemann.koester@tu-berlin.de






The previous chapter introduced the fundamentals of speech communication, the perceived speech quality, the concept of diagnosing speech quality, as well as subjective and instrumental quality assessment methods. While the given information was more general, this chapter will adapt and transfer the fundamentals to the context of a telephone conversation and give more detailed information. As the first step, a telephone conversation will be analyzed with respect to the phases that occur in an everyday conversation in Sect. 3.1. This analysis yields a separation of a conversation into three phases, namely the Listening, the Speaking, and the Interaction Phase. Secondly, in Sect. 3.2, a deeper insight into the already introduced quality elements (see Sect. 2.​3.​2) of a speech transmission system will be given. Each of these quality elements affects the overall speech quality and can be allocated to one (or more) of the particular phases of a conversation. This is followed by the third part of this chapter, a detailed review of each of the three conversational phases. In the Sects. 3.3, 3.4, and 3.5, the perceptual space in terms of the introduced quality elements relating to the quality features and the resulting perceptual quality dimensions for each conversational phase is analyzed. In addition, state of the art subjective and instrumental assessment methods of all three phases are reviewed. Finally, in Sect. 3.6, the chapter closes with a summary of the limitations that the introduced methods implicate and an enumeration of the research topics covered in this book to overcome the mentioned limitations.

3.1 Phases of a Conversation
Interactive conversational evaluation methods have to be conducted to evaluate a complete speech transmission system (see Sect. 2.​1). This is motivated by the fact that specific quality elements do not have an effect of particular passive user situations. For example, in a passive listening-only situation, the user will not perceive any degradations that are related to a situation in which a user is actively speaking. Thus, to analyze a conversation all possible situations a user is confronted with have to be respected. This introduces the conversation model that defines a conversation in four stages [7] (see Fig. 3.1). While having a conversation, one interlocutor either listens to what is said (01) or speaks (10) while exchanging information. Additionally, the interlocutors can also both speak (11) or remain silent (00) at the same time. In [66], these four states build the base to model a conversation as a four-state Markov process (see Fig. 3.2).Fig. 3.1Illustration of dividing a conversation into four stages based on [7, 65]. The upper rectangles correspond to what interlocutor A is saying. The lower rectangles correspond to what interlocutor B is saying
Fig. 3.2Modeling a conversation as a four-state Markov process according to [66]

Looking at the perspective of one single user of a telephone system (in a two-party conversation), the conversation model is experienced in individual conversational phases. These phases are alternating, iterative, distinct, and differentiate in time. Because of these properties and according to [67], a conversation, as experienced from one interlocutor, can be separated into three conversational phases1 (illustrated in a state diagram in Fig. 3.3):1.The Listening Phase, corresponding to state (01) 2.The Speaking Phase, corresponding to state (10). 3.The Interaction Phase, describing the alternation of the states (10) and (01). The frequency of changes describes the degree of interaction and as a side-effect the states (00) and (11) can occur. 
Fig. 3.3The three phases of a conversation, as perceived by one interlocutor [67]

The introduced conversational phases allow to disassemble a conversation and to deeply analyze each phase by its own. This is in particular helpful when evaluating the speech quality in a conversation, because, from a speech quality point-of-view, a conversation is affected by the quality elements encountered in the Listening Phase, in the Speaking Phase, and those affecting the interactivity of the conversation in the Interaction Phase. When talking about diagnosing the speech quality in a conversation, it is therefore difficult to differentiate the sources of possible degradations without the conversational phases (see also Sect. 3.6). With the conversational phases, though, the idea is that a diagnostic analysis of a conversation becomes much more feasible (see Sect. 3.6).
The next section will give an overview of the quality elements that affect the speech quality in a conversation, and therefore also one (or more) of the conversational phases. As the three individual phases have mainly been investigated individually, each conversational phase will be introduced in detail afterwards. This includes a description of the conversational phase, a classification in the conversation, and a review of conducted studies and standards regarding the perceptual quality space as well as subjective and instrumental assessment methods.


3.2 Quality Elements
Figure 3.4 shows, in a more detailed version of Fig. 2.​3, an overview of an example realization of a speech transmission system. The figure shows the transmission system from the point of one interlocutor and can again be flipped at the network for the other interlocutor. As already described in Sect. 2.​2.​2.​1, the signal-mix (consisting of the speech signal x(t), background noise n(t) and echo e(t)) is received by the microphone and digitized to x(k) by the analog to digital converter. Then, the digital signal passes several pre-processing steps, is coded, and finally sent through the transmission network. On the receiving side, the signal is decoded, post-processed, converted to an analog signal, and played back by the speakers of the user terminal. Thus, besides the network itself, also a number of elements in the transmission system can affect, and possibly degrade, the transmitted speech signal. However, in this context, a quality element is not only an individual component of the speech transmission system, like a codec, but also certain physical characteristics of the network, like the transmission delay. The following subsections will introduce these quality elements.Fig. 3.4Elements of a speech transmission system from the interlocutor to the network and back based on [3]. A/D is the analog digital converter, EC the echo compensation, GC the gain control, NR the noise reduction, VAD the voice activity detection, and PLC the packet-loss concealment


3.2.1 User Terminal
The interface between one interlocutor and the telephony transmission system can vary. Possible interfaces are handsets (PSTN phone and mobile phones), headsets, cordless phones, or so-called Hands-Free terminals. The degradation on transmitted speech these acoustic terminals may produce are dependent on the quality of the transducers (the microphone and the speakers), as well as on the used codec and speech enhancement algorithms. The transducers are responsible for linear frequency degradations that depend on their frequency response2 and the connection between the head and the acoustic terminal. Regarding the latter, the position of the handset relative to the ear and the pressure used to press the handset against the ear introduces a signal loss in low frequency bands [21].
In addition, the environment the interlocutor is placed at could produce reverberations that may impact the frequency response. To minimize these influences on the frequency response, modern handsets are often equipped with signal-processing algorithms to suppress noise and echo degradations (see Sects. 3.2.6 and 3.2.7).


3.2.2 Sidetone
The microphone and the speakers of the acoustic terminal are often interconnected by a so-called (electric) sidetone path (arrow between the microphone and the speakers in Fig. 3.4). In telephonometry, two sidetone paths exist. They are distinguished between the perception of ambient noise (listener sidetone) and the perception of the own voice (talker sidetone). In this book, the focus will be on the talker sidetone. In the remainder of this document, when talking about sidetone, the perception how a user of an acoustic terminal hears his/her own voice is meant. Apart from the electrical sidetone path, also an acoustic sidetone exists. It results from the acoustic field between the speakers mouth and ear as well as from the bone "transmission" of the speaker.
The electrical sidetone is usually employed to compensate the loss of hearing one's own voice caused by the shielding of one or both ears by the user terminal. In addition, sidetone was also meant to give the speaker feedback if the user terminal is operating. The sidetone path is typically the direct, not delayed, back coupling of one's own voice. However, for a delay up to 30 ms, the back coupling is still considered as sidetone [70]. When the delay exceeds these 30 ms, the back coupling is considered to be perceived as a distinct talker echo (see Sect. 3.2.7).


3.2.3 Analog to Digital Converter
The analog to digital converter transforms the analog signal into a digital signal. For this, the amplitude and time continuous signal x(t) is low-pass filtered with a cut-off frequency , where  is the sampling frequency (Anti-Aliasing [71]). Subsequently, the signal is sampled (with ) and quantized, resulting in the amplitude and time discrete signal x(k). Since speech shows a constant character for about 20 ms (see Sect. 2.​2.​1.​1), most speech signal applications are using frames of limited duration. Typical distributions are for example frames with 160 samples and  8000 Hz for NB, or frames with 320 samples and  16000 Hz for WB.


3.2.4 Gain Control
A gain control (GC) algorithm is used to equalize the level of a speech signal. The input speech signal level at the microphone of a handset is adjusted before it is transmitted over the network. This is done to avoid amplitude clipping or excessive noise. In addition, the equalization compensates amplitude clipping when too loud speech signals are received [72].


3.2.5 Voice Activity Detection
To save and reduce network load, it can be useful to only transmit active speech frames. A Voice Activity Detection (VAD) algorithm identifies these active speech frames and detects silence frames of the speech signal (non-active speech frames). Finally, only the active voicing parts of the speech signal are transmitted. However, VAD algorithm may introduce time clipping as it is hard to detect starts and ends of sentences or words. Examples for VAD algorithms can be found in [73] or [74].


3.2.6 Noise
Basically, three types of noise can be present in telecommunication systems: line noise, signal-correlated noise, and background noise. Due to the signal loss in long analog lines, line noise was one of the major problems in old fixed-line telephone networks [21]. While in modern digital networks, the importance of line noise almost vanished, in mobile transmission and new transmission techniques that use a higher bandwidth, line noise regained importance. Line noise is characterized by its level and the spectral shape.3 The ITU recommends [75] to measure noise on telephone circuits.
Signal-correlated noise is not additive, contrary to line noise, but multiplicative. That means, the noise is only present in active speech frames and here correlated with the speech itself. Signal-correlated noise is usually introduced by the quantization process in the analog to digital converter. The ITU recommends [76] for creating synthetic signal-correlated noise, called Modulated Noise Reference Unit (MNRU). The MNRU degradation type used to be a reference condition in auditory speech quality tests to evaluate codecs (see for example [35]).
As described before, the input signal of a telephone microphone can be a signal-mixture composed of the desired speech signal x(t) and background noise components n(t) (also called ambient noise). Background noise is a special type of line noise and is again additive. It can be useful for the interlocutor at the receiving side because it may carry information about the environment of the interlocutor at the sending side. However, depending on the level and on the type of noise (for example cafeteria or car noise), it may be disturbing for the interlocutor at the sending side.
As noise may degrade the speech quality, so-called Noise Reduction (NR) algorithms were introduced targeting at eliminating the undesired noise components. NR algorithms try to reduce the noise signal as far as possible, by affecting the speech signal as little as possible. This is done by NR algorithms that are employed in the user terminal (e.g. mobile phone). NR algorithms can be implemented in the time or in the spectral domain (for more information see e.g. [8, 77], or [78]). However, NR algorithms may also introduce new additional degradation. Due to spectral variations, initiated by the NR algorithms, specific sounds, referred to as musical tones, are created.
The ITU recommends the procedure presented in [79] for assessing the speech quality of noisy speech stimuli processed with NR algorithms. In this three-stage procedure, the test subjects are asked to separately rate the overall quality, the distortion on the speech signal, and the intrusiveness associated with the noise signal.


3.2.7 Echo
Besides sidetone, the speaker could also be confronted with an echo of his or her own voice in a telephone call. This so-called Talker Echo is introduced by two sources [8]: (I) the Acoustic Echo that is the speech signal x(t), transmitted over the network, reproduced as y(t), and then again picketed up by the listener's microphone and sent back to the speaker. Or (II) the Electric Echo that is caused by an impedance mismatch between two networks (e.g. two analog networks or one digital and one analog network). In this book, the focus will be on acoustic echoes. Talker echo is perceived if the delay of the back coupling speech signal exceeds a threshold of 30 ms. Below this threshold, the back coupled signal is perceived as sidetone (see Sect. 3.2.2). If a transmission system introduces an echo delay larger than 150-200 ms, that is an average duration of a syllable, the speaking can become difficult [70].
Since echoes impact the speaking abilities of a speaker, Echo Reduction (ER) algorithms were developed. The target of ER algorithms is to minimize echoes. One solution is to adaptively suppress echoes by attenuating the inactive interlocutor. This, however, may impact the natural flow in a conversation. More complex algorithms try to estimate the echo signal and subtract it from the desired signal y(t), these algorithms are called Echo Cancellation (EC). An overview and more information about ER and EC algorithms can for example be found in [8] or [80].


3.2.8 Speech Codec
The amplitude and time discrete digital signal x(k) is composed of a sequence of discrete signal values. Now, if the signal is sampled with  8000 Hz and each sample value is quantized with 32 bit per sample, the signal uses 256 kilo bits per second (kbit/s) network rate. However, only frequencies below 4000 Hz are encoded and all signal levels that are not inside the quantization range are clipped. Speech coding and decoding algorithms are targeting at reducing the network rate while providing a high speech quality, low bit-rate, low complexity, and low delay [8]. After the transmission of the coded speech signal through the network, the speech decoder is synthesizing the speech signal as similar as possible to the original signal. There are several different coding algorithms available. All are developed to minimize the error between the original and the transmitted speech signal (an overview of used speech codecs can be found in [3]). Basically, speech codecs can be classified according to their coding techniques:

Waveform Codecs: These codecs reduce the bit-rate by manipulating the speech signal waveform. They are based on the Pulse Code Modulation (PCM) technique. A simple implementation of this coding technique is the G.711 [81] codec that achieves a bit-rate of 64 kbit/s. The codec compresses the signal amplitudes in a logarithmic manner. At the receiving side the compressed values are reversed. However, it is computationally difficult to use the logarithmic curve for values close to zero. Thus, for low values a displaced logarithmic curve (-law) or a mix of a linear and a logarithmic curve (A-law) is used. A different technique for waveform codecs is to use Linear Prediction (LP) filters that are generating only a residual signal that is transmitted. Thus, only the difference between the actual and the previous sample and the prediction coefficients are transmitted. This technique is called Differential Pulse Coding Modulation. An example for this technique is the G.726 codec [82].

Parametric Codecs: These codecs are also called Vocoders and they are efficient in terms of the transmission rate. They use the principle of the source-filter model (see Sect. 2.​2.​1.​2) and "parametrize" the speech signal. Information about the excitation can be saved in a few parameters, e.g. fundamental frequency, amplitude, and type of excitation. The vocal tract is modeled using adaptive LP filters (Linear Predictive Coding (LPC)). Applying this technique, very low bit-rates of typically 2.4 kbit/s can be achieved [8]. However, the quality of the speech is lower than using waveform codecs. As the intelligibility is still given, parametric codecs are used in military communication systems, like the LPC-10 codec (see [83] or [84]).

Hybrid Codecs: These codecs combine the techniques of waveform and parametric codecs. They achieve medium bit-rates between 2 and 12 kbit/s by providing a better speech quality than using solely parametric coding [8]. An example for this technique is the G.729.1 codec [85].


3.2.9 Packet-Loss
As described in Sect. 2.​2.​2.​2, packet-switched networks transmit speech as data in packets of equal size. However, the packets may take different paths through the network which can lead to time-varying transmission delay. As the sending interval of packets is usually 20 ms (see Sect. 2.​2.​1.​1), the arriving interval may be different between the packets. This characteristic of packet-switched networks is called jitter. To solve this problem and to align the speech segments for providing a continuous signal, a buffer is installed before the decoder. This jitter buffer defines the maximum delay between two arriving packets (e.g. 100 ms). Therefore, the jitter buffer is also responsible for the overall transmission delay that may affect the interactivity in a conversation (see Sect. 3.2.10). If packets arrive at the receiving side in a wrong order, the jitter buffer management handles the re-ordering [86].
In addition to the delayed arrival of packets, packets may arrive outside of the maximum jitter buffer time and get discarded or they may not arrive at all. As mentioned in Sect. 2.​2.​2.​2, this is called packet-loss. The packet-loss distribution is theoretically assumed to be random, however, in real networks a loss frequently includes more packets, called bursty loss. Information about different loss distributions and loss models can be found in [21].
Modern speech codecs usually provide decoding algorithms that can (at least approximately) reproduce the missing packets. These algorithms are called Packet-Loss Concealment (PLC) algorithms. PLC algorithms try to perceptually mask the lost information. Apart from the "straight forward" method of substituting lost information with silence, called Silence or Zero Insertion (ZI) [87], some codecs substitute the lost parts with noise or a repetition of the last good received packets. More complex methods try to reproduce a smooth signal by timescale modifications or by parameter interpolation. An overview about different PLC algorithms can for example be found in [88] or [89].


3.2.10 Delay
The overall transmission delay represents the time difference between the point in time when a speech signal is sent at the sending side of a transmission system and the point in time when the same speech signal is played back at the receiving side of the transmission system. It sums up and results from the delay of the applied encoder and decoder, the speech enhancement algorithms (EC and/or NR), the network, buffers, and other signal processing components of the transmission system. A high delay reduces the natural flow in a conversation and hence degrades the speech quality. However, the perception of delay is difficult. Users of a telephone system cannot distinguish whether delay is introduced by a delayed reply of the second user or by the transmission system. A detailed overview about delay as a quality feature will be given in Sect. 3.5.



3.3 The Listening Phase
The Listening Phase is the conversational phase in which the user is put in a passive listening-only situation, the user passively listens to a vocal message without actively speaking. For example, during a telephone conversation, interlocutor A is asking interlocutor B a question that requires an answer. For the time interlocutor B is answering the question, interlocutor A is placed in the Listening Phase. Another example is calling the answering machine and listening to recorded massages.
Since the Listening Phase is passive in terms of user action, the phase is not affected by quality elements that require the user to be active. Thus, quality elements like delay, echo, or sidetone cannot be evaluated in the Listening Phase. However, the quality elements that affect the quality of transmitted speech and that can be perceived by passively listening have an important influence on the Listening Phase. Because of that, Listening-Only Tests (LOT)s, that represent the Listening Phase, have traditionally been used to evaluate speech-quality-enhancement algorithms like NR, EC, or speech codecs. Therefore, the Listening Phase has been part of numerous studies in research and industry. Standards for subjective methods to assess the overall quality have been established from these studies. In addition, instrumental overall-quality-assessment methods, based on the subjective methods, have been developed and standardized.
Apart from the overall speech quality, also the perceptual space to diagnose the speech quality in the Listening Phase has been analyzed. Several studies using analytic auditory methods have been conducted. Most studies revealed that the perceptual space is composed of three to four perceptual dimensions. Again, subjective and instrumental methods to estimate these perceptual dimensions were developed or are under development.
In the next subsections, the standards and the conducted research related to the Listening Phase will be reviewed. First, an overview of the identification of the perceptual quality space and the corresponding perceptual quality dimensions will be given (see Sect. 3.3.1). Second, subjective overall and diagnostic speech quality assessment methods will be presented (see Sect. 3.3.2). Last, the developed instrumental speech quality methods are introduced (see Sect. 3.3.3).

3.3.1 Perceptual Quality Space
As already described in Sect. 2.​3.​3, the perceptual quality space is extracted in four steps. First, a set of test conditions that span the entire space under study has to be processed. Second, an analytic auditory test has to be conducted (see Sect. 2.​3.​4.​1). Again, three tests are usually conducted at this point: (i) the Semantic Differential (SD), (ii) the Diagnostic Acceptability Measure (DAM), or (iii) scaling perceptual distances/dissimilarities in a Pairwise Similarity (PS) or in a Preference Mapping (PM) test (see Sect. 4.​2 for detailed information on the analytic tests). Third, a multidimensional analysis has to be incorporated. Here, the Principal Component Analysis (PCA) and the Multidimensional Scaling (MDS) are typical analysis methods (again, see Sect. 4.​2). Finally, in the fourth step the results have to be interpreted to identify the perceptual quality dimensions that span the perceptual quality space. Multiple studies have been conducted following this procedure. In this subsection, the results of these studies, which led to a definition of a perceptual quality space describing the Listening Phase, will be reviewed.4

In [93], two auditory tests were conducted. The set of conditions under test covered 22 different PSTN transmission system configurations including different codecs, attenuation, echo, and noise. The two test paradigms PS and PM were used and analyzed with an MDS. The results showed that the two analytic test methods lead to similar findings. Three perceptual dimensions were identified. The dimensions were interpreted as clarity, distinction between speech signal distortion and background interference and loudness.
In [94], an overall speech quality test and a diagnostic test were compared. The set of conditions under test covered 10 different transmission systems using different NB codecs. For the diagnostic test the PS paradigm with a subsequent MDS was applied, resulting again in three dimensions. Subjects were asked to describe the resulting perceptual dimensions with their own words to find an adequate interpretation. The dimensions were interpreted as naturalness, noisiness, and the amount of low-frequency content. In the overall speech quality test, the same conditions were used. The results were compared to the diagnostic test and revealed a linear relationship between the overall quality and the identified perceptual dimensions (according to the vector model, see Sect. 2.​3.​3). According to the analysis, the naturalness showed to have the highest impact on the overall quality.
In [95, 96], the perceptual quality space in mobile transmission systems was analyzed. In sum, a set of 85 conditions were used. The conditions included real recodings and processed conditions, including background noise, different speech codecs, and user interfaces. In [95], a PS test with a subsequent MDS was conducted on the data. This revealed five perceptual dimensions: synthetic/natural, dark/bright, smooth/fluctuating/interrupted, bubbling, and noisy. In [96], the test set was analyzed using the SD test paradigm and a following PCA. Four perceptual quality dimensions were derived as the result of the PCA: low/high, synthetic/natural, smooth/fluctuating/interrupted and noisy.
In [97, 98], a DAM [52] test was conducted and analyzed with a PCA and an MDS. The set of conditions under test covered 56 different NB transmission system configurations including different codecs and background noise. The analysis resulted in a six-dimensional perceptual-quality space. The six dimensions are split into three sets of two sub-dimensions describing the coloration, the time variations, and the noise of a speech signal: (i) Degradation of low-frequency coloration, degradation of high-frequency coloration, (ii) slow-varying degradation, fast-varying degradation, (iii) degradation due to the level of background noise, and degradation due to the variability of the background noise.
In [99], the perceptual quality space of NB and WB transmission systems was investigated. For this, 14 different NB test conditions and 14 different mixed NB/WB test conditions were processed. The target of the study was to cover all potentially relevant quality features of the Listening Phase. The different conditions included NR algorithm, EC algorithm, VAD, different noises, different user terminals, VoIP transmission, and PSTN transmission. In sum, five tests were conducted. For each scenario (NB or NB/WB), one PS and MDS as well as one SD and PCA test paradigms were conducted. The analysis revealed that the perceptual quality space of NB and WB speech transmission can be spanned with three orthogonal perceptual dimensions: Coloration, Discontinuity and Noisiness. The three dimensions give a summary of the studies conducted earlier and cover a large set of possible impairments in speech transmission systems. The fifth test was an overall-quality test to identify the relation between the three perceptual dimensions and the overall quality. The results showed that in the proposed quality profile the Discontinuity is of major importance for the overall quality.
In the studies presented in [99], the used speech stimuli were all normalized to a preferred listening level. Nevertheless, in [93] and in [100], the listening level is considered as an important feature of the overall speech quality. Thus, the perceptual dimension Loudness should also be included to the perceptual quality space defined in [99]. However, it is not proven if the dimension Loudness is orthogonal to the other three dimensions. In particular, the Coloration of a speech signal (for example affected by a limited frequency bandwidth) might be correlated with the Loudness.
To summarize this subsection, four perceptual dimensions reflect the entire perceptual quality space that is used by test subjects to rate the overall quality of transmitted speech in the Listening Phase. These four perceptual quality dimensions are the following:The Discontinuity is affected by isolated and non-stationary degradations in the time domain. Possible quality elements responsible for a low Discontinuity rating are packet-loss or errors in the radio transmission. In addition, the speech enhancement algorithms like NR or EC may also affect this dimension. It was found in [99] that this dimension has the highest impact on the overall speech quality.The Coloration is influenced by frequency response distortions. These distortions are introduced by the acoustic properties of the user terminal or by the bandwidth of the used codec and transmission network. Further, the talker's and listener's environment may also affect this dimension.The Noisiness reacts to degradations that are considered as noise. This includes background noise, circuit noise, quantization noise using waveform codecs, or a corrupt NR algorithm.The Loudness is affected by degradation due to a non-optimum level. These degradations are attenuations or amplifications introduced by the transmission system or a corrupt GC.



3.3.2 Subjective Methods
Subjective speech quality assessment methods were already introduced in Sect. 2.​3.​4.​1. They require human subjects and are used to evaluate the quality of transmitted speech for telephone systems. Regarding the Listening Phase, multiple overall speech quality assessment methods and diagnostic methods were developed and standardized. This subsection will give an overview about common methods used to assess the quality of transmitted speech in the Listening Phase.

3.3.2.1 Overall Speech-Quality Assessment
Overall speech-quality assessment methods are used to evaluate and assess the quality of transmitted speech as perceived by the user of a telephone system. For this, subjects are invited to the laboratory and a set of speech stimuli grouped in different conditions under test are presented. Since these tests represent the Listening Phase and the subjects are "only" passively listening to the stimuli, these tests are called LOTs (see Sect. 3.3). The subjects are asked to rate the perceived overall quality, containing the effects of all affecting quality features, on a one-dimensional rating scale. This results in a single overall-quality value for each subject and each stimulus. The ratings of each condition are averaged (arithmetic mean) over the subjects to obtain a unique overall quality value for each stimulus and to obtain an average overall-quality rating of an "average" user (see Sect. 2.​3.​4.​1) for each condition. This average rating of an average user is referred to as the Mean Opinion Score (MOS) [101]. The framework to gather MOS values in LOTs is standardized in [38, 69].

Absolute Category Rating

The most widely used method to assess the quality of transmitted speech is the Absolute Category Rating (ACR) test. In this test, the subjects are asked to rate the overall quality on a five-point scale as presented in Table 3.1. The arithmetic mean of the ratings gathered in a ACR test is called MOS
 (LQS for Listening Quality Subjective).Table 3.1
Absolute Category Rating (ACR) test scale according to [38].Quality of the speech signalBadPoorFairGoodExcellentScore12345


Degradation Category Rating

The ACR method is not sensitive enough if the set of conditions is composed of speech files with only little differences regarding the assumed overall speech quality. For these cases, the Degradation Category Rating (DCR) test is applied. To be sensitive for small impairments, a pairwise comparison between two speech stimuli is used. So, for each condition under test the subject listens to two speech stimuli, one reference stimulus without any degradations (first) and one degraded stimulus (second). Then, the listener is asked to rate the perceived degradation of the overall quality of the second (the degraded speech stimulus) in comparison to the reference stimulus (not degraded). The scale presented in Table 3.2 is used to gather the ratings. The resulting MOS value is called Degradation Mean Opinion Score (DMOS).Table 3.2
Degradation Category Rating (DCR) test scale according to [38, 69].The degradation is ...Very annoyingAnnoyingSlightly annoyingAudible but not annoyingInaudibleScore12345


Comparison Category Rating

The Comparison Category Rating (CCR) method is a special form of the DCR method. Again, the subjects are asked to perform a paired comparison task. But other than in the DCR method, in the CCR procedure the order of the reference and the degraded speech stimulus is random. Thus, it is not mandatory to always present the reference stimulus first. It is recommended to split the set of stimuli in two halves, one presenting first the reference stimulus, one presenting first the degraded stimulus. The ratings are gathered on the two-sided rating scale presented in Table 3.3. The resulting MOS value is called Comparison Mean Opinion Score (CMOS).Table 3.3
Comparison Category Rating (CCR) test scale according to [38, 69].Quality of the first Stimulus compared to the second is ...Much worseWorseSlightly worseAbout the sameSlightly betterBetterMuch betterScore−3−2−10123



3.3.2.2 Diagnostic Quality Assessment
Diagnostic quality assessment methods are based on the results of the analytic quality tests presented in Sect. 2.​3.​4. The results of the analytic quality tests reveal the perceptual quality space the overall quality is composed of and define what subjects are actually supposed to rate. The results and the defined perceptual quality space regarding the Listening Phase have been reviewed and presented in Sect. 3.3.1. It was summarized that the four perceptual quality dimensions Coloration, Discontinuity, Noisiness, and Loudness form the perceptual quality space in the Listening Phase. In addition, in [98], six perceptual dimensions that are sub-dimensions of Coloration, Discontinuity, and Noisiness, were identified. For both perceptual quality spaces, a subjective test paradigm was defined to directly quantify the perceptual dimensions. This subsection gives an overview of diagnostic quality assessment methods for both perceptual quality spaces.
The direct quantification of the six dimensions proposed in [98] is standardized by the ITU-T by the name P.MULTI in [102] (MULTI for MULTIple rating scales). However, as discussed in [103], the rating paradigm was extended with an additional perceptual dimension regarding the overall loudness and a rating of the overall quality. For six of the seven dimensions, all except Loudness, subjects use a magnitude estimation scale to indicate the amount of the particular perceptual quality dimension that they judge to be present in the sample. Table 3.4 shows an example of the six-category rating scale used by subjects. The bottom category of the scale is labeled .0 (zero) to indicate that the specific perceptual quality dimension is not detectable in the sample. For the overall loudness, an ACR-like continuous scale is used, with the labeling: (1) Much quieter than preferred; (2) Quieter than preferred; (3) Preferred; (4) Louder than preferred; (5) Much louder than preferred. The rating paradigm was implemented in a user interface where the subject first listens to a speech stimulus and then rates each dimension and the overall quality simultaneously. The subject can listen to the speech stimulus as often as desired and has to give a rating for each dimension before continuing with the next speech stimulus. The results of this test provide an individual rating for each dimension and each condition under test.Table 3.4Magnitude estimation scale used for the six dimension ratings proposed in [102].How would you describe amount of the quality present in the sample?Not detectableJust detectableSomewhat noticeableVery noticeableSomewhat conspicuousOverwhelmingScore.01.02.03.04.05.0

The direct scaling of the four perceptual dimensions proposed in [99] (Noisiness, Coloration, Discontinuity, and Loudness) is presented in [2]. The test paradigm is similar to what the ITU recommends for noisy speech signals in [79] (see Sect. 3.2.6). The subjects first listen to a speech stimulus and then consecutively rate the four dimensions on four individual scales. Thus, for each dimension only one rating scale appears to the subject. Only if the subject rates the dimension, the next dimension rating scale appears, while the rated scale vanishes. This is done to minimize bias effects due to the known (or displayed) rating of the previous perceptual dimension. For the dimension rating, a continuous scale, like the one presented in Fig. 3.5, is used. During the rating process, the subjects can listen to the speech stimulus as often as desired. The results of this test provide an individual rating for each dimension and each condition under test.Fig. 3.5Example of the used scales for the direct quantification of the dimensions proposed in [99]. This is a Noisiness scale according to [2]




3.3.3 Instrumental Methods
The assessment of overall quality or perceptual quality dimensions of transmitted speech in the Listening Phase should initially be done by human subjects in the above listed subjective assessment methods. These methods provide reliable subjective quality ratings, as they are valid means for the quality description step in the quality formation process (see Sect. 2.​3.​1). However, as already mentioned in Sect. 2.​3.​4.​2, subjective quality assessment methods are time and money consuming. Thus, great effort has been put into the development of instrumental quality methods that estimate the human speech quality perception. Because of the fast evolution of speech technology (for example new codecs or NR algorithms) and the complexity of the human quality perception (comparison, judgment, and description), the development of instrumental speech quality methods is a continuous process and requires certain engineering efforts.
Regarding the Listening Phase, most instrumental methods have been developed to estimate the resulting MOS (the overall speech quality) of an ACR test. The output of an instrumental method estimating MOS
 values are labeled with MOS
 (LQO for Listening Quality Objective). As these LOTs have frequently been used to evaluate telephone systems, numerous instrumental methods exist. Selected signal-based and parametric methods will be presented in the following. For a detailed overview of instrumental methods see [3] or [62]. In addition to the instrumental methods that estimate the overall quality, so-called diagnostic speech quality methods are under development. These methods refer to the theory presented in Sect. 2.​3.​3: perceptual dimension can be used to model the overall quality. Thus, diagnostic speech quality methods estimate perceptual dimension ratings to obtain an overall speech quality value and to provide diagnostic information. First approaches and current standardization activities regarding these models are also presented in the following.

Signal-Based Models

In terms of full-reference signal-based models, the ITU recommended the long term standard Perceptual Evaluation of Speech Quality (PESQ) [104]. PESQ was primarily developed to estimate MOS values obtained in tests to evaluate NB transmission systems. With further evolution in telephone transmission technologies, the WB-PESQ [105] model was developed to expand the scope of PESQ to WB transmission systems. Today, the ITU recommends the successor of PESQ, called Perceptual Objective Listening Quality Assessment (POLQA) [106] that also considers SWB speech transmission. Alternatives to the standardized ITU methods are for example the Telecommunication Objective Speech-Quality Assessment (TOSQA) [15] model or the Perceptual Speech Quality Measure (PSQM) [107] model.
The named models all estimate the overall speech quality obtained in subjective ACR tests. They use the approach of assuming that the overall quality is proportional to the perceptually weighted distance between the reference and the degraded speech signal. The same approach is also used to estimate perceptual dimensions in diagnostic speech quality methods. For an overview of general diagnostic speech quality methods see [3, 108]. For the four perceptual quality dimensions Noisiness, Coloration, Discontinuity, and Loudness individual estimators were proposed in [109] and [110]. These studies were extended and led to the Diagnostic Instrumental Assessment of Listening quality (DIAL) [3] diagnostic speech quality model. DIAL is composed of four individual dimension estimators to provide diagnostic information and one additional core model that is based on TOSQA to estimate the overall quality. Each dimension estimator uses two to four indicators to compare the reference and the degraded signal resulting in four MOS values for each perceptual dimension. In addition, for the dimensions proposed in [98], a diagnostic speech quality model has been presented in [111]. None of the mentioned methods have so far been standardized by the ITU. This is planned to be done under the working title Perceptual Approaches for Multi-Dimensional analysis (P.AMD) [112]. P.AMD is targeting at providing a standardized diagnostic speech quality model for the four perceptual dimensions Noisiness, Coloration, Discontinuity, and Loudness, as well as for the six dimensions proposed in [98].
Over the past years, reference-free signal based models gained more attention for telephony service providers. Since the input speech signal of a transmission channel is mostly not readily available, intrusive models are not useful for online monitoring purposes. This is, however, the main goal service providers wish to achieve when talking about instrumental models and service evaluation. To provide new models, the ITU performed a competition to standardize a reference-free signal-based model in 2004 that produced two submissions. One is the now recommended standard ITU-T P.563 [113]. The algorithm generates an internal reference as replacement for the missing input signal using LPC-analysis and showed to be reliable for NB telecommunication scenarios. The second is called Auditory Non-Intrusive QUality Estimation (ANIQUE) and uses the approach of modeling the representation of the speech signals at the central level of the human auditory system [114]. As both algorithms are only recommended for NB speech transmission, the ITU currently launched a new standardization process to provide a reference-free signal based model that is also suitable for WB and SWB speech transmission [115].
Based on DIAL and P.AMD, the ITU also started a new work-item to standardize a reference-free diagnostic speech quality model called Single-ended Perceptual Approaches for Multi-Dimensional analysis (P.SAMD) [116]. First estimators for the dimensions Noisiness [117], Coloration [118], and Loudness [119] showed promising results. However, the estimators have to be validated on more data and the P.SAMD standardization process just recently started.

Parameter-Based Models

Parameter-based models have a long tradition in the evaluation of telephony networks. Starting already in the 1970s, telecommunication companies started to develop algorithms that estimate the user's opinion to facilitate the evaluation with auditory tests. Thus the first parameter-based quality models were also called opinion models. Popular models are for example the Bellcore TR model [120] or the Overall Performance Index model for Network Evaluation (OPINE) [121], to name just two. The evaluation of these models led to the so-called E-Model that was first presented in [122]. The E-Model uses specific parameters that are extracted from the transmission system to calculate so-called Impairment Factors that are mathematically combined to estimate a quality value. All the named models were developed to estimate the quality in analog PSTN networks, and they cover almost all elements in these networks. So, parameter-based models, and especially the E-Model, do not exclusively only cover the quality of transmitted speech in the Listening Phase. These models also consider degradations due to delay, or echo and estimate a conversational MOS value. Therefore, the E-Model will further be introduced in Sect. 3.5.3.
However, with the right adjustments, the E-Model can also give information about the quality a user perceives during the Listening Phase. Thus, the E-Model can be adjusted to be a diagnostic speech-quality model. This is done in [2] where the Discontinuity Noisiness Coloration (DNC) model is presented to estimate the three primary perceptual quality dimensions proposed in [99]. The DNC model adapts the E-Model parameters to calculate one individual impairment factor for each of the three perceptual quality dimensions. In addition, the dimension quality values are used to map the overall quality. The DNC model was evaluated on three data sets covering NB and WB codecs, different background noises, and packet-loss. The results showed that the model produces reliable and valid estimations. However, it has not been further evaluated on more data.



3.4 The Speaking Phase
The Speaking Phase is the conversational phase in which the user is put into an active speaking-only situation, i.e. the user is actively speaking a vocal message. For example, during a telephone conversation interlocutor A is asking interlocutor B a question that requires an answer. For the time interlocutor B is answering the question, interlocutor B is placed in the Speaking Phase. Another example is recording a vocal message on the answering machine.
The Speaking Phase requires the user to be active. Thus, this conversational phase is affected by the quality elements that have an impact on the activities of the user. In terms of speaking, these quality elements degrade the flow and smoothness of the user's speaking abilities. In telephone systems, the back coupling of the user's own voice and/or background noise are responsible for these types of degradations. A back coupling of the spoken voice is usually introduced by the quality elements sidetone and echo.
To evaluate the perceived quality in the Speaking Phase and the speaking in a telephone scenario, defined as the speaking quality, so-called Speaking-Only Tests (SOT)s are conducted. SOTs are common means to evaluate echo and EC algorithms. However, since SOTs require the subject to be active during the test, lowering the reliability and raising the subject's fatigue, SOTs are not as popular as LOTs. Nevertheless, standards for subjective methods to assess the overall speaking quality have been established. Based on these subjective methods, also instrumental methods to evaluate the Speaking Phase have been developed. Regarding the perceptual quality space and the diagnosis of the Speaking Phase only little is known. It is known what impact sidetone and echo have on the user's speaking, but no perceptual dimensions have been identified so far.
In the next subsections, the standards and the conducted research related to the Speaking Phase will be reviewed. In Sect. 3.4.1, the user's perception (perceptual quality space) of sidetone and echo will be described and reviewed. An overview of subjective methods to evaluate the Speaking Phase will be presented in Sect. 3.4.2. Finally, Sect. 3.4.3 introduces instrumental methods that are based on these subjective methods.

3.4.1 Perceptual Quality Space
In Sects. 3.2.2 and 3.2.7, the two quality elements sidetone and echo are introduced. Both elements are responsible for a back coupling of the own voice in a telephone conversational situation. So, while actively speaking during the Speaking Phase, this back coupling of the own voice may distort the perception of one's own voice. In turn, this distorted perception of one's own voice can influence the comfort with which the user speaks and the way he or she speaks. In [70], the term self-listening comfort is introduced to describe this influence.
A popular example for this effect is when a speaker is confronted with a loud background noise. In this case, the speaker automatically raises the voice to mask the noise. This effect is called the Lombard Effect [123, 124]. The same effect, but in the opposite direction, can be observed when a speaker is confronted with a loud copy of his or her own voice over a headset, a loud sidetone. In this case, the speaker automatically lowers the voice [125].
In addition to the level, the time lag of the sidetone has an important effect on the user's perception. In general, if the sidetone is delayed, the speaker starts to feel uncomfortable. For delays below 30 ms (considered as sidetone) and high levels, the direct signal and the delayed version will be interfered at the speakers ears which leads to a comb-filtered version of the signal [126]. The user will perceive this as a coloration in the sound of his or her own voice [70]. If the delay exceeds 30 ms (considered as echo) and the sound level is high, the speaker will experience difficulties in talking. This is expressed in a slower speaking in terms of the speaking rate and pauses between words [127]. On the other hand, if the level is low, even high delayed echo hardly gives any degradation. Thus, the level, expressed as an attenuation in dB, and the delay, expressed in ms, define the user's perception of the back coupling of one's own voice as sidetone or echo and the resulting self-listening comfort.
In sum, echo and sidetone play an important role in how the speaker perceives his or her own voice in a telephone system. Especially in the modern transmission networks (mobile or VoIP) they gained importance since more delay is introduced due to packetization and coding. The review showed that echo and sidetone have two effects on the speaker. First, the level and the delay of the sidetone path may have an impact on the speaking ability of the speaker. Second, frequency distortions of the sidetone or echo path may result in a coloration in the sound of the own voice. However, a multidimensional analysis like for the Listening Phase has so far not been conducted for the Speaking Phase. In addition, there is no test method for a multidimensional analysis of the Speaking Phase available yet. Thus, it is not known how the perceptual quality space of the Speaking Phase may look like and what perceptual dimensions might be used to span that space.


3.4.2 Subjective Methods
Subjective quality assessment methods for the Speaking Phase are usually used to evaluate the perceived quality of speech transmission systems that are degraded by echo and/or sidetone as well as to evaluate EC algorithms. Therefor, subjects are invited to the laboratory and are asked to actively use a speech transmission system under different conditions. The subjects speak sentences into a headset connected to the speech transmission system by simultaneously listening to their own voices, and rate the quality with which they perceived their own voice. The term Speaking-Only Test (SOT) is a this point not fully correct, as the subjects are speaking and listening. Thus, these tests are also called Speaking and Listening Tests. The problem with these test is that the speaking-only situation, without feedback from a second interlocutor, is artificial and rather rare in reality. In addition, simultaneously speaking and listening can cause considerable fatigue to the test subjects. Therefore, so-called 3rd Party Listening Tests have been developed, in which the spoken and the heard of the interlocutors is recorded and afterwards both are rated by a third test subject. Both test methods only determine an overall quality value, without any diagnostic information. Since no perceptual quality space is so far defined, no method for directly scaling perceptual quality dimensions exists. The framework to gather quality values in SOTs is standardized by the ITU in [128].

Speaking and Listening Tests

One popular method to assess the speaking quality in a SOT is the Speaking and Listening Test. As described before, in these tests the subjects have to speak and listen simultaneously. The subject has to fulfill speaking tasks to ensure a specific degree of activity in terms of speaking duration and content. The tasks should be designed so that subjects are stimulated to speak in a natural way that is as close as possible to reality. Three tasks are recommended in [128]: (i) the subject is asked to answer an incoming telephone call with the same greeting:, (ii) the subject is asked to read predefined short sentences aloud, or (iii) the subject is asked to describe the position of numbers in pictures. Subsequently, the subject is asked to give a quality rating. It is recommended to ask the subject "How would you judge the degradation of your own voice?" and to gather the ratings on a DCR scale (Table 3.2). However, similar questions in combination with the ACR scale (Table 3.1) are also feasible. The arithmetic mean of the ratings gathered in a speaking and listening test are called MOS
 (SQS for Speaking Quality Subjective).

3rd Party Listening Tests

Simultaneously speaking, listening, and rating requires a high amount of effort from the test subjects. Thus, it was studied how a SOT can be adapted to be more similar to a LOT to minimize the effort of the test subject and the test supervisor [128]. The studies resulted in the so-called 3rd Party Listening Tests. These tests require preparations since the conversation of two interlocutors having a conversation over a specific speech transmission system under test has to be recorded. In the actual test, the subjects are asked to listen to the recorded conversation and rate its quality. Feedback is usually gathered using the ACR scale and asking questions like "What is your opinion of the connection you have just listened to?". This test procedure is much easier to reproduce and more comfortable for the test subject. However, in the literature the correlation between recorded distortions and their perception during a live conversation is not known.


3.4.3 Instrumental Methods
For the Speaking Phase, the same applies as for the Listening Phase, subjective quality assessment methods are time and money consuming. Therefore, also instrumental methods to estimate the speaking quality have been developed. The output of an instrumental method estimating MOS
 values is labeled with MOS
 (SQO for Speaking Quality Objective).

Signal-Based Models

The development of signal-based instrumental models for the Speaking Phase implicates two major problems:
First, the recording of data is much more complicated and complex than for Listening Phase data. In the Listening Phase, a sentence is recorded and sent through a processing chain or a transmission system. Subsequently, test subjects rate the processed data to have the ground truth for the instrumental models. In the Speaking Phase, the acquisition of data is always connected to extensive speaking and listening tests to record stimuli and ratings.
Second, the approach used for Listening Phase signal-based models cannot be adapted one-to-one to signal-based models for the Speaking Phase. The presented signal-based instrumental models for the Listening Phase use the non-degraded input and the degraded output signal of a speech transmission system. The models time-align and compare both signals to estimate the overall listening quality. If the same approach was used for the development of speaking quality estimations a problem would occur. In case of a single echo, a comparison between the input signal (what the speaker is speaking) and the back coupled signal would lead to no distortion because of the time-alignment. While in the comparison approach the degraded signal is composed of the original signal and the distortion components, in a Speaking Phase the back coupled signal is only composed of the distortion, here a time-shift.
The first challenge is in the nature of the Speaking Phase, and a sophisticated possibility to solve it has so far not been found. However, the second challenge has been addressed in the development of a signal-based instrumental speaking quality model. In [70], the development of the Perceptual Echo and Sidetone Quality Measure (PESQM) model is presented. Here, the second problem is solved by constructing a degraded signal by combining the input signal and the back coupled signal into one speech file. To clarify, the model uses two speech signals for the estimation of the speaking quality. One speech signal, the non-degraded speech signal, is the input signal of the transmission system combined with the back coupled speech signal of a perfect (not degraded) transmission system. The second signal, the degraded speech signal, is the input signal of the transmission system combined with the back coupled speech signal of the transmission system under test. Based on the PSQM model, with these two signals the approach of a full-reference signal-based model is followed. The model is based on six subjective speaking tests and showed to provide valid and reliable results (see [70] for more information).

Parameter-Based Models

Officially, no parameter-based instrumental model is recommended to estimate the speaking quality. But, similar to the Listening Phase, with the right adjustments the E-Model can also give information about the speaking quality a user perceives during the Speaking Phase in a conversation. The sidetone and the echo are covered in the E-Model by three parameters [129]. The level of the echo is given by the Talker Echo Loudness Rating (TELR), a subjectively identified level of attenuation between a point, 25 mm in front of the speaker's mouth, and the speaker's ear. The SideTone Masking Rating (STMR) gives the overall measure of the frequency-dependent sensitivity of the sidetone path in decibels. The delay of the talker echo is expressed with the parameter T in milliseconds. Now, using the recommended default values for the other parameters, the E-Model can be used to estimate the influence of speaking distortions on the conversational quality (see for example [6]). However, it will not provide single speaking quality values. Again, a detailed description of the E-Model will follow in Sect. 3.5.3.



3.5 The Interaction Phase
The Interaction Phase is the conversational phase in which the participants of a conversation interactively communicate with each other. Other than for the isolated non-interactive Listening Phase and Speaking Phase, the two interlocutors exchange information by alternating and frequently adapting the role of the listener and speaker. This alternation introduces interaction between the interlocutors. Looking again at Figs. 3.2 and 3.3, the Interaction Phase not only covers the changes from state (01) to (10) and from (10) to (01), but also the states (00) and (11). For example, during a telephone conversation interlocutor A is asking interlocutor B for a credit card number or an address. For the time the interlocutors exchange the information and compare their "numbers", the interlocutors are placed in the Interaction Phase.
The Interaction Phase requires a certain amount of action by the user of a speech transmission system. In this case, action means interaction with a second user. In [130] interaction is defined the following:
An interactive pattern is a sequence of actions, references and reactions where each reference or reaction has a certain, ex-ante intended and ex-post recognizable, interrelation with preceding event(s) in terms of timing and content.
Thus, interactivity is based on a reference and reaction schema that is dependent on its timing. In terms of a telephone conversation this schema adapts to a request (for example a question by interlocutor A) and a response (the answer of interlocutor B on the question stated by interlocutor A) schema that is again dependent on its timing. If the timing gets corrupted, the natural rhythm of a conversation gets shifted and the interlocutors will perceive a low interactive quality (states (00) and (11)). This corrupted timing is usually introduced by the quality element delay.
To evaluate the perceived quality in the Interaction Phase, so-called Conversation Tests (CT)s are conducted. CTs are in general common means to gather ratings for the overall conversation quality. Most of the CT paradigms were developed to evaluate the interactivity in a transmission system that is degraded by delay. So, only little focus is put on the Speaking Phase and Listening Phase in most CT methods. The problem of CTs is that always two test subjects are required. This complicates the acquisition of test subjects and makes them even more expensive than LOTs or SOTs. Nevertheless, standards for subjective methods to assess the overall conversational quality have been established. And yet again, based on these subjective methods, also instrumental methods to evaluate the Interaction Phase have been developed. Regarding the perceptual quality space and the diagnosis of the Interaction Phase, no perceptual dimensions have been identified so far. Anyhow, numerous studies researched the impact and effects of delay on the interactivity.
It is important to mention that the quality-formation process described in Sect. 2.​3.​1 cannot be adapted one-to-one for the Interaction Phase. The quality-formation process is only considering a single and static input signal (see Fig. 2.​6). In a conversation or an interactive quality test, which spans over a longer period of time and requires interaction, the user would run through the perception and judgment steps several times. This, and the interaction of a user are not considered in the presented quality-formation process. An approach to overcome these limitations in terms of human-computer-interaction is proposed in [131, 132]. Here, the influence of the interaction on the quality-formation process is considered by introducing an additional interaction performance aspect layer. This layer can be seen as a mediation layer between the perceived/desired composition and the perceived quality features. However, this layer spans over several stages of the quality-formation process and thus the relation between the stages is not one-to-one, as they can vary in strength depending on the system, user, or context [131]. The output of the interaction-performance aspects layer are interaction-quality features that serve as an input for the comparison and judgment steps (see Fig. 2.​6). The interaction-performance aspects are composed of multiple dimensions that result from the perception of the interaction, including the smoothness, the pace, the naturalness, the comprehension effort, and the cognitive load. For more information see [130, 131], or [132].
In the next subsections, the standards and the conducted research related to the Interaction Phase will be reviewed. The user's perception (perceptual quality space) of delay will be described and reviewed in Sect. 3.5.1. Section 3.5.2 gives an overview of subjective methods to evaluate the Interaction Phase. Instrumental methods that are based on the ratings gathered in these subjective methods will be introduced in Sect. 3.5.3. Finally, so-called Conversational Parameters that were developed to measure the interactivity in a conversation are presented in Sect. 3.5.4.

3.5.1 Perceptual Quality Space
In Sect. 3.2.10, the quality element delay is introduced. Delay is responsible for a shift of the natural rhythm in a conversation as follows: As described before, the Interaction Phase covers the alternation of the states (01) and (10), but also the states (00) and (11) (see Sects. 3.1 and Fig. 3.1). The natural rhythm of a conversation is shifted if increased amounts of the states (11) and (00) occur. The states more frequently occur if a transmission delay is introduced to the speech transmission system. Figure 3.6 is a modified version of Fig. 3.1 with the extension of a delayed speech transmission system [65]. The upper part of the figure shows the conversational structure at interlocutor A's side. In turn, the lower part shows the conversational structure at interlocutor B's side. Between the two interlocutors a speech transmission system delays the conversation.5 First, the utterance 
6 is transmitted. After a period of mutual silence (speaker change) interlocutor B responds with . When this utterance is received at interlocutor A's side () interlocutor A already started to speak () and might be interrupted by interlocutor B. At this point, the time interlocutor B took to respond to interlocutor A is already increased at interlocutor A's side (the increase is similar to the added two one-way delays). Looking at interlocutor B's side, the figure shows that the delayed utterance  by interlocutor A leads to an interruption that causes interlocutor B to stop speaking. After a short period of time, interlocutor B starts to speak again and interrupts interlocutor A. However, the delayed utterance of interlocutor B () does not result in an interruption at interlocutor A's side. Here, the gap between the two utterances  and  is perceived as a pause.Fig. 3.6Conversational structure using a delayed speech transmission system based on [65]

In sum, the figure shows that a transmission delay may lead to three effects. First, the delay leads to an interruption. Interruptions are distinguished between active and passive interruptions. Active interruptions occur when one interlocutor starts to speak, while he or she still hears the other interlocutor speaking. Passive interruptions occur when one interlocutor gets interrupted by the delayed arrival of a statement of the other interlocutor. Second, due to the transmission delay, the perception of a conversation, in terms of structure and pattern, may considerably be different from one interlocutor to the other, while both are participating in the same conversation. Third, if the test subjects perceive an unnatural rhythm of the conversational flow, they adapt their behavior [65].Fig. 3.7User satisfaction as a function of one-way transmission delay as predicted by the E-Model, adapted from [133]

To minimize the effects of delay, it is recommended by the ITU to keep the delay in speech transmission systems as low as possible. Based on the E-model, it is recommended not to exceed a one-way delay of 400 ms when planning any type of application in [133]. In Fig. 3.7, the effects on the user satisfaction of delays below 500 ms in a conversation are estimated using a curve derived from the E-model (see Sect. 3.5.3 for a detailed introduction of the E-Model). To assure a high user satisfaction, delays should be kept below 150 ms, then most applications would not be significantly affected [133].
For the Interaction Phase, the same applies as for the Speaking Phase, a multidimensional analysis like for the Listening Phase has so far not been conducted. In addition, there is no test method for a multidimensional analysis of the Interaction Phase available yet. Especially a paired comparison between two transmission systems degraded by different amounts of delay is difficult to realize. That is because delay is only perceivable if two test subjects participate in a test. If both test subjects can switch between two delay configurations, one subject does not know what to compare with what. One possible solution for this problem is presented in Chap. 4. Thus, it is not known how the perceptual quality space of the Interaction Phase may look like and what perceptual dimensions might be used to span that space.


3.5.2 Subjective Methods
The Interaction Phase is usually degraded by the quality element delay. The evaluation of the perceived quality, and thus also of the effect of delay, in the Interaction Phase is therefore only possible with two test subjects. For this, so-called Conversation Tests (CT)s were developed, that are subjective tests in which two test subjects have a real-time conversation. In CTs, the subjects are invited to the laboratory and are asked to actively use a speech transmission system under different conditions. Numerous different conversation tasks have been introduced to assure a certain degree of interactivity. Even though, CTs are also used to evaluate an entire conversation with all its three phases (Listening, Speaking, and Interaction Phase) most of these tasks are targeting at the evaluation of interactivity and delay. As already mentioned in Sect. 3.5, the main problem of CTs is the difficult acquisition of two test subjects to be present at the same time. In addition, the time that is needed to evaluate one system condition is much higher than for LOTs or SOTs. This makes CTs even more time and money consuming. In CTs, mostly only an overall quality value MOS
 (CQS for Conversation Quality Subjective), without any diagnostic information, is determined. Since no perceptual quality space has been defined, no method for directly scaling perceptual quality dimensions exists. Feedback regarding the overall quality, the conversational quality, is gathered on the ACR scale (see Table 3.1) resulting in the MOS
. Besides the overall quality, also feedback regarding the subject's opinion of the connection or the effort to fulfill the conversational task is gathered. The framework to gather quality values in CTs is standardized by the ITU in [134].
In [134], specific requirements for conversation tasks are listed. According to this list, a conversation task should stimulate semi-structured conversations, it should be easily learned, it should be intrinsically motivating, it should allow for interruptions from the subjects, it should represent a cooperative effort rather than a competitive effort, and it should induce a discussion that is phonetically rich and temporally widely distributed. To meet these requirements following conversation tasks are recommended:

Postcard Test

Subjects are asked to reach an agreement on an order of preference or time for a set of picture postcards [7].

Kandinsky Test

Subjects are asked to describe to their partner the position of a set of numbers on a picture. Both subjects have similar pictures, but with some of the numbers in different positions. It is recommended to use pictures consisting of colored, geometrical figures.

Short Conversation Test

In Short Conversation Tests (SCT)s subjects are asked to play through scenarios derived from typical situations of everyday life: ordering pizza, railway inquiries, rental of a car or an apartment [6]. These scenarios have been elaborated to allow a well-balanced conversation between both participants, to stimulate the discussion between persons, and to facilitate the naturalness of the conversation. These conversations are approximately 2.5 to 3 min in duration. SCTs have been proposed and evaluated in [6, 135]. An example for such a scenario can be found in Appendix A.

Richard's Test

In the Richard's Test random shapes are presented to the subjects. There are no meaningful relationships between shapes and their names. The detail and concrete method of how to generate the shapes can be found in [7]. The test supervisor prepares the same set of sheets for both subjects, but with the shapes in a different order. During the conversation, each subject arbitrarily chooses one shape on the sheet and describes one of its features to the partner. The partner either guesses the name of the shape based on the information provided or requests additional information from their partner until the shape is identified. Finally, the partners swap their role and continue with another shape. An example for the shapes can be found in Fig. 3.8.Fig. 3.8Extract from an example sheet of random shapes for a Richard's test based on [134]


Game Test

Subjects are asked to work with their partner to complete a cooperative task or solve a problem. Care must be taken to ensure that the game does not limit the conversational vocabulary and structure. A popular example that could be used at this point is the board game "Battleship".
Besides these rather traditional conversation tasks (traditional in terms of not being limited to the Interaction Phase), tasks that can be used to specifically evaluate the interactivity and thus the effects of delay were developed. Here, the focus of the developed tasks is almost exclusively on the Interaction Phase. As these tasks are very delay sensitive they provide feasible methods to uncover the effects of even small delay degradations. However, these tasks are less realistic and more competitive than the tasks mentioned above. Following tasks are recommended:

Reading Random Numbers Task

Subjects are asked to read random numbers or other items as fast as possible [136].

Random Number Verification Task (RNVT)

Subjects are asked to verify numbers or other items as fast as possible (see [65] or [136]). An example for such a task is given in Appendix B.Fig. 3.9Example for an interactive Short Conversation Task (iSCT) scenario based on [134]


Interactive Short Conversation Task

The interactive Short Conversation Task (iSCT) is a more interactive version of the SCT (see [21] and [65]). Basically, the task consists of the fast exchange of data. Subjects are put in the position of being colleagues working in two different sections in one big company, exchanging, for example, telephone numbers and email-addresses. The task is presented in terms of tabulated data which have been iteratively filled based on a series of information exchange. Both subjects are provided with the same table with alternative missing information. In addition, one item in the list of each subject cannot be found in the list of the other subject to prevent the subjects from applying a strategy that results in semi-duplex conversation in which strict turn-taking is performed [65]. An example for an iSCT scenario can be found in Fig. 3.9.


3.5.3 Instrumental Methods
More than for the Speaking Phase and for the Listening Phase, the introduced subjective quality assessment methods for the Interaction Phase are very costly in terms of money and time. So again, tremendous effort has been carried out to provide approaches for instrumental methods to estimate the ratings gathered in the mentioned subjective quality assessment methods. These methods rather focus on the overall conversational quality than only on the Interaction Phase and thus provide an estimated conversational quality value MOS
 (CQO for Conversation Quality Objective). Parametric as well as signal-based methods were developed. However, the signal-based approaches are actually a mixture of parametric and signal-based methods as usually the delay is integrated by a parametric approach. Again, as no perceptual quality space for the Interaction Phase is so far defined, no instrumental method for estimating perceptual quality dimensions exists.

Signal-Based Models

The problem with signal-based instrumental conversational-speech quality-estimation methods is that the recorded signals alone (input and output signals of a speech transmission system) are not enough, and difficult to process for providing information that spans the entire conversational situation. As an example, the input and the output signals of a speech transmission system only give information about the Listening Phase and do not indicate any quality degradations regarding the Interaction Phase. The delay cannot be extracted from these signals. The approach of separating a conversation into the three conversational phases and estimating a quality value for each phase has been followed to solve this problem. Two models are proposed that follow this approach.
In [67], each phase is estimated separately. The perceived quality of the Listening Phase is estimated using the PESQ model and the perceived quality of the Speaking Phase is estimated using the PESQM model. In addition, the Interaction Phase is included with a delay measure. In the proposal, it is not further specified if the delay is measured by a parametric approach or by a signal-based approach. For the latter the synchronized input and output signals are compared. However, in [67] the parametric approach is used. So, this approach gives three quality values for each conversational phase. In an integration part of the model the three values are combined to estimate the overall conversational quality. The model was evaluated with multiple degradations regarding each conversational phase and showed to provide reliable results. However, the proposed model exhibits two inherent limitations: Firstly, the model only provides an overall conversational quality value without diagnostic information, and secondly, the practical generation of data usable for the evaluation of the model showed to be complicated.
The second model is proposed in [137]. The proposed method is called a subjective/objective test protocol as it proposes a mix of subjective and instrumental methods to estimate the conversational quality. According to [137], the test protocol recommends six successive tests: One LOT according to [35], that can be estimated using PESQ. Three SOTs with echo and sidetone degradations. The results of these tests could be estimated using the PESQM model, however, this has not been evaluated yet. Finally, two interactive tests are proposed, one subjective Reading Random Numbers Task and one objective delay measure. For the objective delay measure a DMOS value is calculated with the equation , where T is the mean one-way delay in milliseconds. According to Fig. 3.7, a one-way delay of 400 ms is the highest acceptable delay. The final overall conversational quality value is then not calculated by mapping the six individual quality values but by just using the lowest of the six quality values. The evaluation of the proposed method showed that a PSTN telephone system achieves a MOS of 4.0 and a GSM mobile telephone system achieves a MOS of 3.0. Due to the six individual tests, the proposed methods could be used to gain limited diagnostic information for the Speaking Phase and the Interaction Phase. For the Listening Phase, however, again only an overall quality value is assessed. As an additional disadvantage, the reproducibility and the practicability of the proposed method has so far not been evaluated further.
For now, none of the introduced methods is standardized or recommended by the ITU. Anyhow, the ITU already started a work-item in 2005 to standardize a signal-based conversational-quality estimator. The work item is called Conversational Quality Objective (P.CQO) [138]. Due to the aforementioned limitations, the experts of the ITU, however, could not agree upon one model yet. In addition, the ITU just recently started the work item Conversational Quality Subjective (P.CQS) to provide a subjective baseline for the P.CQO project [139].

Parameter-Based Models—The E-Model

As already mentioned before (see for example Sects. 3.3.3, 3.4.3, or 3.5.1), the best known and most widely used parameter-based instrumental quality estimation model is the E-Model. The E-Model is mostly used for network planning purposes (it can already be applied before the telephone system is implemented) to ensure that users will be satisfied with the overall speech quality of a transmission system. However, the E-Model is often also used to monitor the quality of speech transmission systems. The model estimates a conversational-quality MOS. With the right adjustments it can, though, also be used to estimate the listening or speaking quality (see Sects. 3.3.3 and 3.4.3).
The model was first recommended by the European Telecommunication Standard Institute (ETSI) in [140]. The E in ETSI also gives the E-Model its name. Today, the model is recommended by the ITU in [129]. The E-Model was first proposed in [122] where the advantages of former parameter-based models were integrated (for example from the OPINE model). Thus, the model includes traditional impairments like echo and delay, but also more modern impairments like low bit-rate codecs. In addition, the model respects the speaking and the listing terminals, the transmission system, and environmental factors. All these are characterized by, in sum, 21 parameters. With few exceptions, all of these parameters can be measured instrumentally, or they result from the planning values of the considered quality elements. Based on enormous effort in terms of subjective tests, the parameters are mathematically combined and transformed on a perceptually motivated approach to so-called Impairment Factors. The impairment factors for different impairments are additive on a psychological scale, i.e. the overall quality can be calculated by subtracting the sum of the impairment factors from a maximum quality value. This results in the so-called Transmission Rating R that is calculated as follows: (3.1)Here, the  value represents the "best" Signal-to-Noise Ratio (SNR)7 if no other impairments are present. It is calculated using the noise parameters like circuit or background noise. The three values , , and  are the mentioned impairment factors, each determining a specific degradation. The  impairment factor (signal-simultaneous distortions) represents the sum of all impairments which may occur more or less simultaneously with the voice transmission, the  impairment factor (delayed impairments) represents all impairments due to the delay of voice signals (including echo), and the  factor is the Equipment Impairment factor that is representing low bit-rate codecs. Finally, the Advantage Factor A allows for compensation of impairment factors when the user benefits from other types of access to the service (for example access to hard-to-reach locations).
At this point, it should be mentioned that the introduced impairment factors do not reflect perceptive quality dimensions identified in a multidimensional analysis. A separate perceptive quality dimension cannot necessarily be described by one single impairment factor. In addition, in terms of diagnosis, the E-Model is rather considering the technical distortions (regarding QoS) than the user's perception (regarding QoE). However, the E-Model can be better adapted to novel impairments if the perceptive quality dimensions are known and measurable (see Sect. 3.3.3 and [2]).
The E-Model provides a conversational quality value on the R-scale. In the NB scenario, the R-scale ranges from  (worst possible) to  (best possible). According to (3.2), the estimated R-values can be transformed into MOS values: (3.2)The initial E-Model was developed for the NB scenario. Over the last years, the E-Model was continuously enhanced leading to the WB-E-Model that also considers WB scenarios [141]. For the WB scenarios the R-scale was extended to a maximum of  and accordingly the transformation function in (3.2) was extended by . To have a reference, a set of default values for the 21 parameters has been published [129, 141]. The default values correspond to a standard ISDN connection and lead to an R-value of . In addition, in [142] multiple equipment impairment factors for almost all standard codecs have been published. For more information about the E-Model see [129, 141] and for a detailed evaluation see [6].


3.5.4 Conversational Parameters
The instrumental quality estimation methods introduced in Sect. 3.5.3 rather focus on the conversational quality than solely on the interaction. Two models that exclusively concentrate on the conversational interactivity are presented in this section. Therefor, the two models Speaker Alternation Rate and the Conversational Temperature have been introduced in [65]. These models focus on the alternation and turn-taking of the two interlocutors.

Speaker Alternation Rate

The most straight forward model for conversational interactivity is the so-called Speaker Alternation Rate (SAR). As the name already indicates, the SAR represents the number of speaker alternations per minute. Respecting the four states of a conversation presented in Sect. 3.5, a speaker alternation is described with the patterns (01)-(00)-(10), (10)-(00)-(01), (01)-(11)-(10), and (10)-(11)-(01). Thus, a speaker alternation is always considered if the role of speaker and listener changes among the two interlocutors. A low SAR corresponds to low conversational interactivity and a high SAR corresponds to a highly interactive conversation [65]. If the conversational structure, or here the pattern in terms of its speaker alternation, is known the advantage of the SAR is that it can simply be calculated by counting the speaker alternations and dividing them by the measurement time in minutes.

Conversational Temperature

The term Conversational Temperature is introduced in [65] and [143]. The metric describes the conversational interactivity as a function of mean sojourn times of the four states introduced in Sect. 3.5. So, for each state  (01), (10), (00), (11) the time  is defined as the mean sojourn time spent in each state. This results in the conversation temperature by  as a function of these mean sojourn times, leading to a simple but efficient and intuitive one-dimensional metric for describing conversational interactivity. Again, for more information about the conversational temperature see [65, 143].



3.6 Conclusion and Research Topics Covered in This Book
As already implied in Chap. 1 and described in [1], the detailed review of the conversational phases and their quality assessment methods reveals two main limitations:
Overall quality: In almost all LOTs, SOTs, and CTs only the overall quality is taken into account, reasons for underlying sub-optimum quality are not uncovered.
Non-interactive settings: Diagnostic methods are limited to the passive listening situation, but conversational and interactive aspects are not considered.

The first limitation (overall quality) points out, that the overall speech quality is a multidimensional value and that two dissimilar speech samples impaired by different degradations, for example one by a bandwidth limitation and one by background noise, can be rated with the same low MOS value. Having only the MOS value at hand, system providers cannot identify the reason for a possible quality loss, and therefore do not know how to improve their services. In LOTs, SOTs, and CTs, test supervisors can of course directly ask for specific degradations, but in that case they have to be certain about the presence of these degradations beforehand. Thus, traditional methods do not provide diagnostic information. To account for this limitation, the hypothesis that the overall quality can be explained and modeled on the basis of perceptual quality dimensions according to the definitions given Sects. 2.​3.​2 and 2.​3.​3 is followed. The review of the Listening Phase showed that its perceptual quality space is composed of four perceptual quality dimensions: Noisiness, Discontinuity, Coloration, and Loudness. In addition, subjective and instrumental diagnostic quality assessment methods have been developed based on this perceptual quality space.
However, this leads to the second limitation (non-interactive settings) that the introduced diagnostic methods only consider the unrealistic passive listening-only situation. A perceptual quality space of the Speaking or the Interaction Phase has so far not been identified and quality elements that affect the interaction or the speaking (for example echo or delay) cannot be determined in LOTs. Thus, a diagnosis of a conversation based on its phases and their underlying perceptual quality dimensions is not possible at this point.
This leads to the trade-off for a test supervisor to either extract diagnostic information or to address different conversational phases in a quality assessment test. In this book, the introduced trade-off is addressed by formulating and answering the following Research Question:

What are the quality relevant perceptual dimensions that an interactive conversational situation is composed of?

To answer this question, both advantages of diagnostic and conversational quality assessment are combined. More specifically, perceptual quality dimensions, and thus perceptual quality spaces, for each conversational phase, namely in the Listening, the Speaking, and the Interaction Phase are identified. The results are combined and analyzed to provide a diagnostic conversational quality assessment method based on the hypothesis of perceptual quality dimensions. In order to reach this target, the following five Research Topics are addressed in the present book:1.
Identification: Identification of the relevant perceptual quality dimensions. The analysis of each conversational phase allows to identify the number and the components of the perceptual quality dimensions in a conversational situation, see Chap. 4. 2.
Quantification: A new efficient analytic test method to facilitate the assessment and to provide data for potential models that are based on the identified perceptual dimensions has to be developed, see Chap. 5. 3.
Validation: Both, the identified perceptual quality spaces and the developed test methods, have to be validated in substantial tests and a following detailed analysis, see Chap. 6. 4.
Modeling: The new data provides the fundamentals to model a new quality profile for a conversational situation, see Chap. 7. 5.
Estimation: Finally, the gathered subjective data and the new quality profile serve as a basis for an instrumental diagnostic conversational speech quality model, see Chap. 8. 

The book at hand systematically addresses each of the five research topics. The new quality profile and the conducted studies allow to assess and diagnose conversational speech quality in future work. They are the direct follow up of the studies conducted in [99] and serve as a fundamental framework for developing diagnostic instrumental models to predict the quality of transmitted speech in a conversational situation as demanded in the current ITU-T work item P.CQO.
In addition, the work presented in this book is extending the knowledge of assessing and modeling dimension-based speech quality in multiple orientations. The following findings and studies are new to the quality community and have therefore not been addressed in related literature:Multidimensional analysis of a conversation: The results of four experiments yielding the perceptual dimensions in the Speaking and the Interaction Phase.A new quality profile for conversational speech quality: The multidimensional analysis reveals the perceptual quality space of conversational speech quality.A new conversational test method: For direct quantification of the perceptual dimensions and for the validation of the quality profile, a new subjective conversational test method that separately addresses each phase of a conversation is established.Validation of the proposed quality profile: Together with the new test method the quality profile and the method itself are validated in two conversational experiments.Basis for developing signal-based and parametric instrumental conversational quality models: The quality profile and the data gathered with the new test method provide the fundamentals to develop new instrumental conversational quality models.An instrumental diagnostic conversational speech quality model: All the aspects named above merge to a proposal for a new instrumental speech quality model that overcomes the two aforementioned limitations (overall quality and non-interactive settings).



Footnotes


1


Note that this separation is only true for a "regular" and "everyday" conversation when the two interlocutors want to exchange information (see Sect. 2.​1).

 



2


The average frequency response of standardized telephone handsets (in sending and receiving direction for NB) are defined as the so-called Intermediate Reference System (IRS) (see [68] and Annex D of [69]).

 



3


For example White Noise with a constant magnitude spectrum or Pink Noise with a magnitude descending spectrum.

 



4


Note that the reviewed studies are not all studies conducted to analyze the perceptual quality space of transmitted speech in the Listening Phase. The presented studies are chosen because they meet the scope of this book. For more information, see for example, [90, 91], or [92].

 



5


Here, for demonstration the delay between side A and side B is equal to the delay between side B and A. In real speech transmission systems, the delays may differ due to the codec or packet and buffer sizes in VoIP systems.

 



6


The label of the utterance is given in three characters: the first letter gives the interlocutor who is speaking, the number corresponds to the number of the utterance, and the indexed letter gives the side at which the utterance occurs.

 



7


The SNR is a widely used and easy to calculate full-reference signal-based measure to assess the quality of a transmitted speech signal. It calculates the ratio between the energy of the input signal and the noise introduced by the transmission system. However, the SNR is a poor estimator for speech quality as it does not consider human perception and time-varying distortions [3].

 













© Springer Nature Singapore Pte Ltd. 2018


Friedemann Köster



Multidimensional Analysis of Conversational Telephone Speech


T-Labs Series in Telecommunication Services


https://doi.org/10.1007/978-981-10-5224-8_4





4. Perceptual Quality Space in a Telephone Conversation




Friedemann Köster
1  




(1)
Quality and Usability Lab, Technical University of Berlin, Berlin, Germany

 



 

Friedemann Köster


Email: 
friedemann.koester@tu-berlin.de







4.1 Introduction
The approach of the work presented in this book is to combine the advantages of considering all possible user situations in a conversation and of diagnosing the quality of transmitted speech on the basis of perceptual dimensions. Table 4.1 gives an overview of the currently known perceptual quality space and its perceptual dimensions in a conversational situation (see Chap. 3). As it can be seen, except for the Listening Phase no perceptual dimensions have so far been identified. This leads to the formulation of the already stated research topic in Sect. 3.​6 (Identification), what perceptual dimensions an interactive conversational situation is composed of.
To answer this question, the perceptual quality space of a conversation in terms of the perceptual dimensions in the Speaking and the Interaction Phase have to be uncovered. The identification of the perceptual dimensions and the underlying experiments are presented in the following sections. Firstly, according to Sect. 2.​3.​3 the two paradigms to uncover perceptual quality dimensions are introduced in detail in Sect. 4.2. Secondly, the paradigms are applied to the Speaking and the Interaction Phase in Sects. 4.3 and 4.4, respectively. This chapter closes with a summary and a conclusion in Sect. 4.5. Parts of the work illustrated in this chapter are based on the data presented in a former publication [144].Table 4.1Overview of the so far identified perceptual quality dimensions in a conversational situation (see [99])Conversational phasePerceptual dimensionDescriptionPossible sourceListening phaseNoisinessBackground noise, circuit noise, coding noiseCoding, background noiseDiscontinuityIsolated and non-stationary discontinuityPacket-lossColorationFrequency response distortionsBandwidth limitations and codingLoudnessImportant for the overall quality and intelligibilityAttenuationSpeaking phase
Unknown
-Sidetone or echoInteraction phase
Unknown
-Delay



4.2 Experimental Paradigms to Analyze the Perceptual Quality Space
The work presented in this book is targeting at uncovering the perceptual space of test subjects in a conversational situation. For each of the two remaining phases of a conversation (Speaking and Interaction Phase) two analytic subjective tests with two different experimental paradigms were conducted. Both paradigms follow different approaches to transform data into a low-dimensional space with particular advantages and drawbacks.
Section 4.2.1 describes the method of Multidimensional Scaling (MDS) of dissimilarity or preference ratings gathered in a pairwise comparison experiment. The method of analyzing attribute ratings of a Semantic Differential (SD) experiment with a Principal Component Analysis (PCA) is introduced in Sect. 4.2.2.
Using and comparing both methods leads (a) to a more distinct interpretation of the resulting perceptual dimensions and (b) helps to verify the validity of the results. Thus, the two paradigms in combination provide a solid statement about the actual nature of the underlying perceptual dimensions for the phase under investigation.

4.2.1 Multidimensional Scaling
In general, MDS is used as a multivariate technique and is mainly applied to find the number of dimensions required to represent perceptual attributes of stimulus objects in a low-dimensional multidimensional space [53]. The approach is to gather the dissimilarity between two pairwise presented stimuli. For several conditions and test subjects this results in a dissimilarity matrix. The MDS maps the (average) dissimilarities into distances. It is assumed, and it has been verified, that the psychological dissimilarities correspond to Euclidean distances (higher dissimilarity, higher distance) [2, 53, 145] (see Sect. 2.​3.​3).
In the context of the presented work, the interest is focused on the quality of perceptual events, happening either during speaking or during interaction. Thus, the stimuli are obtained in an active or interactive instead of a passive situation, and instead of asking the test subjects for a dissimilarity rating, preference values were gathered. The two different approaches of gathering dissimilarities and preferences have been analyzed and compared in different studies and experiments and revealed a high degree of correlation (see for example [93] or [146]). Since the interest is not in individual preferences but in group tendencies, a multidimensional solution for an average person has to be found, and the preference ratings are averaged over the individuals resulting in a single preference matrix.
However, the gathered preference data cannot be used in a standard MDS that uses dissimilarity data. Therefore, a so called non-metric MDS, also called ordinal MDS, is applied [147]. While a classic MDS is metric, that is, the model represents various properties of the data related to algebraic operations, non-metric MDS represent only the ordinal properties of the data [53]. The preference matrix serves as input for the non-metric MDS where the mapping is restricted to be a monotone function. ALSCAL is employed as a method for computing the non-metric MDS [148].
Following [53], to determine the resulting dimensionality, both, statistical fit parameters and the ability to interpret the resulting dimensions are considered. One important statistical fit parameter is the so-called Stress. It is actually a badness-of-fit parameter specifying how bad the resulting distances match with the given data. A reasonable dimensionality is found if the Stress value does not decrease significantly with further increasing the number of dimensions. Looking at a Scree plot (see for example Fig. 4.5), ideally a sharp "elbow" marks the adequate dimensionality [53].
Using the MDS paradigm provides the advantage that the task for test subjects is practicable. No complex instructions are required and comparing two pairwise presented stimuli is uncomplicated. But, the interpretation of the resulting dimensions is only possible on the basis of the known difference between the stimuli. This may lead to intuitive and speculative interpretations. To express a valid interpretation, it should be considered to compare the results of an MDS with other methods for minimizing dimensionality.


4.2.2 Semantic Differential
In an SD experiment, a previously determined set of attributes is given to the test subjects in terms of bipolar scales. The extremities of each scale are labeled with a pair of opposite attributes, so called Antonym-Pairs (APs) (for example loud verses quiet), each describing a one-dimensional quality feature. The intensity of each feature within a given condition has to be judged by the test subjects.
Using the Principal Component Analysis (PCA) on the average ratings of the test subjects, only the components with eigenvalues above one () are kept. The columns of the resulting matrix are the Principal Components (PCs) and correspond to the coordinates of the points representing the APs in the dimension-reduced space. Finally, the result is transformed into a rotation matrix satisfying the VARIMAX criterion [149]. The rotation causes that correlating scales are summarized by one axis, which leads to a simpler structure. Detailed information about the SD and the PCA can for example be found in [2] or [51].
Compared to the MDS paradigm, the interpretation of the resulting dimensions is supposed to be easier because it is assumed that each dimension is represented by a cluster of APs giving the researcher direct hints on which aspects are covered. Nevertheless, to get a valid interpretation of the dimensions it is recommended to conduct both, an MDS and an SD experiment. The disadvantage of the SD paradigm is that it is limited to the used APs and that significant effort has to be conducted to determine the APs beforehand (see Sects. 4.3.3 and 4.4.3).



4.3 Uncovering the Perceptual Quality Space in the Speaking Phase
To uncover the perceptual dimensions of the Speaking Phase both methodologies (MDS and SD) are applied. Since the speaking can be impaired by sidetone and talker-echo (see Sect. 3.​4), for both experiments an active SOT with these two degradations was selected with the goal to investigate how hearing one's own voice while speaking influences the speaking, and how the test subjects perceive their own voice.

4.3.1 Technical Setup
The test system for the two tests conducted for the Speaking Phase is implemented with the help of the graphical programming language tool for modeling and simulating dynamic systems [150]. The system was developed to simulate sidetone and talker-echo. For the sidetone distortion, the direct back coupling of the spoken voice with different levels of attenuation and for the talker-echo the delayed back coupled and attenuated spoken voice with varying delay values is used. The used conditions can be seen in Tables 4.2 and 4.4.
The direct back coupling had a delay of  ms and was recorded as 0 ms delay. The attenuation level is simulated in association to the input speech level. Keep in mind that some conditions simulate degradations with strong characteristics to guarantee that all naïve test subjects perceive the effects of sidetone and echo (compare [35]). An EDIROL USB AudioCapture UA-25EX sound card together with a Sennheiser HMD 46 ATC 300 headset was used for presentation. The back coupling was presented diotically. The test subjects were set in a test room which meets the requirements according to [35].


4.3.2 Test Design
For both test paradigms (SD and MDS) basically the same task had to be conducted by the test subjects. For each presented condition or comparison the test subjects were asked to read out aloud a text that appeared to them on the test screen. Each piece of text consisted of two to three sentences, and all together 27 randomly presented text-pieces were used. One text-piece could for example look like this (translated from German):
"Can you please give me the best connection between Munich and Duisburg. I have to arrive on Saturday at 12.30 pm latest."
To avoid the test subjects to pay too much attention on reading the text, they were asked to learn the text by rereading it at minimum three times. Thus, it was ensured that the test subjects could speak the text as freely as possible, simulating a real Speaking Phase.


4.3.3 SD Experiment
As mentioned in Sect. 4.2.2, in an SD experiment a predefined set of attributes (APs) is given to the test subjects in terms of bipolar scales. In order to find proper attributes, two pre-tests were conducted.
In a first test, as many descriptions of the transmission system as possible were collected by three experts, resulting in a list of 25 APs. In the second test, 10 naïve test subjects were asked to select 5 of the 25 attributes they think to describe the system best. Based on the overall frequency of selection, a set of 11 APs were finally selected: exhausting—not exhausting; requires concentration—requires no concentration; distracting—not distracting; not fluent—fluent; loud—quiet; not helpful—helpful; thin—thick; distorted—undistorted; unclear—clear; reverberant—anechoic; irritating—not irritating.Fig. 4.1Overall quality rating scale (taken from [6])

The actual test was carried out by 16 naïve test subjects (4 female, 12 male, other subjects than the 10 naïve test subjects of the second pre-test) aged between 21 and 36 years. For each condition (see Table 4.2) the test subjects were asked to fulfill the task described in Sect. 4.3.2. After each task for each condition, the test subjects were asked for their subjective rating of the overall quality (MOS) for a sanity check, and of the APs introduced before.
The scale shown in Fig. 4.1 was used for the overall quality ratings (taken from [6]). This scale is in particular useful because it avoids scale-end effects and is more sensitive in comparison to the classical ACR scale (see Sect. 2.3.4.1 and [57]). A similar scale (see Fig. 4.2) with only two labels was used for the AP ratings.Fig. 4.2AP rating scale used for the SD experiments



4.3.4 Results
The results of the conducted SD experiment for the Speaking Phase are structured in two groups: First, the results of the overall quality are analyzed, second the results of the PCA on the AP ratings stemming from the SD experiment are presented.
The results of the overall quality ratings are presented in Table 4.2. The ratings are similar to the studies made in [70]. The standard deviations lie within the range of standard deviations as typically also obtained in standard ACR experiments [6]. Additionally, a repeated measure ANalysis Of VAriance (ANOVA) [151] between the conditions and the overall quality ratings (MOS
) as dependent variables was carried out. The results show that the conditions have a significant impact on the overall quality judgments of the test subjects . With this data it is proved that the different degradation levels worked as intended (falling quality—lower rating/rising quality—higher ratings).Table 4.2Conditions and Overall Quality Results for the SD Experiment in the Speaking Phase
ConditionAttenuation (dB)Roundtrip delay (ms)Overall-rating (MOS)Standard deviation1

01.6.752

01.9.823

02.0.944

02.4.825004.4.5361003.2.8171503.5.7882004.1.7190502.3.721001002.5.611101502.1.331202002.3.6413

1001.9.7114

1001.8.5815

1501.5.4716

3001.5.46

To analyze the results of the PCA, first, the number of resulting perceptual dimensions has to be identified. As described in Sect. 4.2.2, the number of the dimensions is found by keeping only components with Eigenvalues above one. To visualize the results a Scree Plot can be seen in Fig. 4.3.Fig. 4.3Scee Plot for the PCA on the SD experiment in the Speaking Phase


The figure shows that two components have Eigenvalues above one, resulting in two dimensions. The determined two dimensions cover 95.3 % of the variance of the eleven APs. Table 4.3 shows the factor loadings for each of the eleven APs to the determined two dimensions.
It can be seen that the first dimension (Dim 1) covers seven of the eleven APs with loadings above .8. These seven APs ("requires concentration—requires no concentration", "loud—quiet", "not fluent—fluent", "distracting—not distracting", "exhausting—not exhausting", "irritating—not irritating", "not helpful—helpful") describe how the hearing of the own voice is perceived by the speaker and what impact or effect hearing the own voice could trigger inside the speaker/listener. More precisely, the results for the first dimension show that hearing one's own voice can for example be very irritating and can handicap the fluency of the speaking.
The second dimension (Dim 2) covers three APs ("distorted—undistorted", "unclear—clear", "reverberant—anechoic") with loadings above .7 and two APs ("not helpful—helpful", "thin—thick") with loadings slightly below .4. The dimension seems to be descriptive in terms of representing the degree of degradation and impairment of the own voice the speaker perceives when hearing one's own voice. In other words, the resulting dimension describes possible frequency distortions of the sidetone and the echo path. This is mostly determined by results of the loadings for the APs "distorted—undistorted", "unclear— clear", "reverberant—anechoic", and "thin—thick".
The low number of APs and the inconsistent loading values show that the second dimension seems to be weak. Another reason why the second dimension might be weaker than the first dimension is explained by the fact that frequency distortions of the sidetone or the echo path (Dim 2) are only perceived by the test subjects if a sidetone or an echo that has an impact on the speaking of the test subjects (Dim 1), is present. So, while being independent as a result of a PCA, the first identified dimension (Dim 1) can be triggered while the second dimension (Dim 2) is not triggered, but the second dimension (Dim 2) might only be triggered if the first dimension is also triggered (Dim 1). However, a final interpretation (see Sect. 4.3.7) of the resulting dimensions is only possible when having also the results from the MDS experiment at hand.Table 4.3Factor loadings () of the PCA on the SD experiment in the Speaking Phase—VARIMAX rotated (Dim—Dimension)Antonym-pairDim 1Dim 2Exhausting—not exhausting.993 Concentration—no concentration.991 Distracting—not distracting.980 Not fluent—fluent.991 Loud—quiet.988 Not helpful—helpful.893.378Distorted—undistorted .939Unclear—clear

.761Reverberant—anechoic.351.875Irritating—not irritating.937 Thin—thick

.378



4.3.5 MDS Experiment
As mentioned in Sect. 4.2.1, in an MDS experiment the preferences of two pairwise presented stimuli is judged by the test subjects. Having N conditions this leads to  comparisons. Assuming that the preference between stimulus A and stimulus B is the same as the preference between stimulus B and stimulus A, this leads to  comparisons [152]. Using the 16 conditions of the SD experiment this would lead to 120 comparisons. As a paired comparison of two conditions might take up to two minutes, for a feasible experiment conducted in approximately one hour this would take too long. Therefore, only 9 conditions (see Table 4.4) were used for the test leading to 36 comparisons. The conditions were chosen from the SD experiment to cover different amounts of attenuation and delay. However, the conditions of the MDS experiment still map the effects on the user perception in a similar way as the conditions used in the SD experiment. Condition eight and one are alike and serve as reference conditions for a sanity check.
To create the complete distance matrix for the ordinal MDS, one half of the test subjects judged the preference between stimulus A and stimulus B and the other half the preference between stimulus B and stimulus A. For each comparison, the test subjects were asked to speak the text-piece (see Sect. 4.3.2) once for condition A and once for condition B. They could redo the comparison as often as desired.
Afterwards, the test subjects had to judge whether they prefer stimulus A over stimulus B (and vice-versa) on the scale presented in Fig. 4.4. The MDS experiment was carried out by 22 test subjects (14 female, 8 male) aged between 18 and 36 years (different from the SD experiment).Table 4.4Conditions for the MDS Experiment in the Speaking Phase
ConditionAttenuation [dB]Roundtrip-Delay [ms]1 (S0)002 (E50)0503 (Sminus25)2504 (S20)

05 (E250)02506 (Sminus10E150)101507 (S10E150)

1508 (S02)009 (Sminus10)100


Fig. 4.4Preference comparison rating scale used in the MDS experiments



4.3.6 Results
The adequate dimensionality is found if the badness-of-fit parameter Stress does not decrease significantly with a further increase of the number of dimensions (see Sect. 4.2.1). To visualize the results a Scree Plot is shown in Fig. 4.5. The figure shows that the sharp "elbow" is located at the second dimension, thus, two dimensions are extracted for the MDS experiment. In this regard, the MDS result is similar to the result of the SD experiment.
To analyze and compare the dimensions the resulting space of the MDS (see Fig. 4.6) has to be inspected. Looking at the two reference conditions (S0 and S02) the resulting space of the MDS shows that these two conditions are positioned with a short distance, indicating, that the different quality levels worked as intended.
Dimension one shows that from left to right the conditions start with strong characteristics (strong echo or loud sidetone − S10E150, E250, S20) and end with rather weaker characteristics (quiet sidetone, e.g., Sminus10, Sminus25). The anchor-conditions are located in the middle of the scale. As described in Chap. 3, a strong echo or a loud sidetone results in a high impact on the speaking abilities of the speaker. In turn, a quiet sidetone does not have an impact on the speaking. These introduced effects of the used conditions are reflected in the results for the first identified dimension. Looking again at this result, the scale of dimension one (from right-low, strong echo or loud sidetone, to left-high, weak echo or quiet sidetone) describes the impact on the speaker of hearing one's own voice while speaking.Fig. 4.5Scree Plot for the MDS on the comparison judgments in the Speaking Phase

Fig. 4.6Results of the MDS experiment in the Speaking Phase; normalized 


For dimension two, the scale starts with the anchor-condition S0 and then covers stepwise the conditions with stronger degradations (the higher, the stronger the degradation). Again, as described in Chap. 3, a back coupled and delayed version of the own voice is perceived as a colored and thus degraded version of the own voice by the speaker. Transferring this to the results of the MDS experiment, the identified dimension shows that stronger degradations lead to a more degraded perception of the own voice than weaker degradations. Hence, the scale of dimension two (from bottom-low to top-high) thus seems to describe the degree of degradation of the own voice the speaker perceives hearing one's own voice.


4.3.7 Discussion
The results of the SD (see Sect. 4.3.3) and the MDS (see Sect. 4.3.5) experiment reveal a high degree of similarity. In the SD experiment, the first resulting dimension covers APs that describe the impact of the own heard voice on the speaker while speaking. The same properties can be seen in the results of the MDS experiment where the first dimension describes from low to high the characteristics (weak to strong echo/sidetone) of the conditions. In both cases the resulting dimensions seem to represent the impact of the degraded transmission system on the speaker while speaking.
The second resulting dimension in the SD experiment covers attributes that describe the amount of degradation of the conditions ("distorted—undistorted", "unclear—clear", "reverberant—anechoic"). In the MDS experiment the second identified dimension is also describing the same effects starting with the reference conditions ending with highly degraded conditions (strong echo/sidetone). Following from this, in both experiments the two identified dimensions seem to portray the degradation of one's own voice perceived by the speaker.
In sum, the result of the multidimensional analysis in terms of two subjective tests identified two perceptual dimensions. In Sect. 3.​4.​1, the effects that might occur due to a back coupling of one's own voice in a telephone conversational situation are discussed. It was mentioned that a loud sidetone might decrease the voice of a speaker and that a back coupled and delayed version of one's own voice is perceived as a coloration in the sound of the own voice by the user. These two effects match the two dimensions identified in the multidimensional analysis. One dimension describes the impact on the speaker a back coupling might have (for example decreasing the voice) and the other dimension describes the degraded perception of the own voice (for example a colored sound).
However, it has to be mentioned again that the two identified dimensions might depend on each other in terms of their presence. While a degradation of one's own voice is only perceived when the own voice has also an impact on the speaking, a back coupling of the own voice might only have an impact on the speaking without perceiving a degradation of the own voice. Until now, this is just an assumption and has to be verified in an additional experiment (see Chap. 6).
Following from the results of the multidimensional analysis and the review of the Speaking Phase in Sect. 3.​4.​1, it is proposed to call the two perceptual dimensions of the Speaking Phase:1.The Impact of one's own voice on speaking (scaled from "no impact on speaking" to "high impact on speaking"). 2.The Degradation of one's own voice (scaled from "own voice not degraded" to "own voice degraded"). 




4.4 Uncovering the Perceptual Quality Space in the Interaction Phase
To uncover the perceptual dimensions of the Interaction Phase, again both methodologies (MDS and SD) are applied. Interactive experiments are especially sensitive to the quality element delay (see Chap. 3) which impairs the interaction of two interlocutors. So, for both experiments a conversation test was carried out to investigate how the user perceives the interaction in a call that is affected by varying amounts of transmission delay.

4.4.1 Technical Setup
For the experiments a test system based on Pure Data (PD [153]), a graphical programming language for signal processing, was used. It allows manipulating audio effects in real-time and thus enables to simulate acoustical degradations like echo, transmission delay, as well as non-stationary degradations. Additionally, the system was extended with multiple speech codecs including G.711 or LPC-10, using open-source implementations. The codec components also introduce effects like packet-loss on request. The test system is called The Telephone and is available open source at [154]. This setup is also used in the validation experiments presented in Chap. 6.
The sound signal was presented via a Beyer Dynamic DT770 stereo headset. The two headsets were connected to the processing computer (DELL Optiplex 790) with an Edirol UA-25EX sound card. The signal of each microphone was amplified with an RME QuadMic II microphone preamplifier to counter potential signal loss due to the cable length. Before starting the experiment, the output was once calibrated to a comfortable listening level by the test supervisor. In both setups the test subjects were located in two sound-insulated test rooms which met the requirements according to [35].


4.4.2 Test Design
For the conversational tasks, SCTs (see Sect. 3.​5.​2 and Appendix A) were used and modified by updating dates and currencies. The SCTs were selected because their tasks represent everyday-life situations and provide a reasonable degree of interaction while being limited to an acceptable test duration. Also, the SCTs were developed in a way that each scenario consists of a short section similar to RNVTs (for example check credit card number) making them also more delay-sensitive (see Sect. 3.​5.​2 and [6]).
In both experiments, each pair of test subjects first conducted one introduction SCT scenario to get familiar with the test design. In the SD experiment the test subjects both were asked to give their rating on the APs for each condition and each SCT (see Sect. 4.4.3). In the MDS experiment only one of the two test subjects was able to switch between two conditions. The one test subject was asked to rate the comparison of two conditions with regard to the interaction between both interlocutors (see Sect. 4.4.5).


4.4.3 SD Experiment
Again, to conduct the SD experiment a predefined set of APs has to be found. To find suitable attributes, two pre-tests were conducted (similar to the SD experiment of the Speaking Phase in Sect. 4.3.3).
In the first test, as many descriptions as possible were collected by six experts, resulting in a list of 42 different APs. In the second test, 15 naïve test subjects were asked to select five of the 42 attributes they think describe the system best. Based on the overall frequency of selection, a set of 10 APs were finally selected: not exhausting—exhausting; easy—hard; unpleasant—pleasant; not frustrating—frustrating; effective—ineffective; does not require concentration—requires concentration; lazy—agile; clear - confusing; relaxing - annoying; distracting—not distracting.Fig. 4.7Test setup for the SD experiment in the Interaction Phase


The actual experiment was carried out by 32 naïve test subjects (8 female, 24 male) aged between 19 and 31 years paired in 16 groups of two interlocutors. The test-system was distorted by eight different values of one-way end-to-end transmission delay (0, 300, 600, 900, 1300, 1700, 2100, and 2500ms) resulting in eight conditions. The basic test setup can be seen in Fig. 4.7. For each condition the test subjects were asked to play through one SCT scenario and then first rate the overall quality for a sanity check, and second the APs introduced before. Again, the same scales as in the SD experiment for the Speaking Phase were used (compare Figs. 4.2 and 4.3).


4.4.4 Results
The results of the conducted SD experiment are again structured in two groups: First, the results of the overall quality as a sanity check are analyzed, and second the results of the SD experiment are presented.
After averaging the ratings of the overall interaction quality over the conditions, a repeated measure ANOVA between the conditions and the overall quality ratings (MOS
) as dependent variables was carried out. The result shows that the amount of delay has a significant impact on the judgment of the test subjects . This data indicates that the different degradation levels worked as intended (short delay—high overall quality/long delay—low overall quality).
The judgments show that the addressed 10 attributes highly correlate with each other (average ). The results of the following PCA indicate, that the 10 APs can be described by one dimension, covering 96.12% of the variances of the 10 one-dimensional features. The resulting factor loadings for each of the 10 APs can be seen in Table 4.5.
The outcome shows that all features are covered by one dimension with high loadings above .9. Regarding the ten features, the resulting dimension seems to describe the convenience or the challenge of interacting. But a final interpretation (see Sect. 4.4.7) of the dimension is again only possible after analyzing the MDS experiment.Table 4.5Factor loadings of the PCA on the SD experiment in the Interaction Phase—VARIMAX rotatedAntonym-pairDimension 1Distracting—not distracting.971Exhausting—not exhausting.988Concentration—no concentration.979Unpleasant—pleasant.981Clear—confusing.960Lazy—agile.995Easy—hard.993Relaxing—annoying.979Not frustrating—frustrating.982Effective—ineffective.977



4.4.5 MDS Experiment
In the case of the Interaction Phase the task in the MDS experiment is to judge the preference of two pairwise presented amounts of transmission delay. The eight conditions used in the SD experiment would lead to 28 comparisons and thus SCTs. Again, this would be too much for one experimental session. Therefore, only five conditions (0, 500, 1000, 1500, and 2000ms) were used leading to 10 comparisons (see Sect. 4.3.5).
As done for the MDS experiment in the Speaking Phase, one half of the test subjects judged the preference between condition A and condition B and the other half the preference between condition B and condition A to create the complete distance matrix for the ordinal MDS. As an exception for this experiment, only one of the two test subjects was asked to judge whether he or she prefers condition A over B, the other test subject acted as a dummy. This procedure was followed because only one of the test subjects was able to change the condition and thus was able to judge his or her preference. The test setup for the MDS experiment can be seen in Fig. 4.8. Test subject 1 has a "switch" to change between two transmission delay conditions. Hence, the paired comparison test paradigm was only done by one of the two test subjects. This is a new approach for a multidimensional analysis of an interactive situation. The rating was again done on the scale shown in Fig. 4.4.Fig. 4.8Test setup for the MDS experiment in the Interaction Phase


The MDS experiment was carried out by 52 test subjects grouped in 26 pairs. Thus, the results are based on the ratings of 26 test subjects (10 female, 16 male) aged between 20 and 32 years (different from the SD experiment).


4.4.6 Results
The MDS reveals a stress below .5 showing that the resulting space is one-dimensional. The space can be seen in Fig. 4.9.
The figure shows that the resulting dimension starts with the highest delay (2000 ms) and then covers stepwise the conditions with lower delay until reaching the lowest value (0 ms). The scale of the dimension (from bottom-high to top-low) thus seems to describe the effort or difficulty to interact with the interlocutor.Fig. 4.9Test setup for the MDS experiment in the Interaction Phase




4.4.7 Discussion
Again, the results of the SD (see Sect. 4.4.3) and the MDS (see Sect. 4.4.5) experiment reveal a high degree of similarity. In the SD experiment, the resulting dimension covers APs that describe the convenience or the difficulty of interacting. The same characteristics can be seen in the results of the MDS experiment where the resulting dimension describes from low to high the effort or difficulty to interact (long to no delay). Thus, in both cases the resulting dimension seems to represent the degree of facility/difficulty to interact.
The effects of a delayed speech transmission on the user's perception was discussed and reviewed in Sect. 3.​5.​1. It was mentioned that a transmission delay may lead to passive and active interruptions that shift the natural interactive rhythm in a conversation. These interruptions also lead to a different perception (in terms of the two interlocutors) of the conversational structure. In addition, too high amounts of delay are related to an increasing user dissatisfaction. The results of the two conducted multidimensional analyses combine these findings of the user perception as the identified dimension seems to cover the effects of a delayed speech transmission (see Chap. 3). The resulting dimension can be described with used APs (see Table 4.5) and the characteristics of the dimension is depended on the amount of transmission delay.
Following from the results of the multidimensional analysis and the review of the Interaction Phase in Sect. 3.​5.​1, it is proposed to call the identified perceptual dimension of the Interaction Phase:1.The Interactivity (scaled from "easy to interact" to "hard to interact"). 




4.5 Conclusion

Table 4.6Overview of the seven identified and proposed perceptual quality dimensions for a conversational situationConversational phasePerceptual dimensionDescriptionPossible sourceListening phaseNoisinessBackground noise, circuit noise, coding noiseCoding, background noiseDiscontinuityIsolated and non-stationary distortionsPacket-lossColorationFrequency response distortionsBandwidth limitations and codingLoudnessImportant for the overall quality and intelligibilityAttenuationSpeaking phaseImpact of one's own voice on speakingHow is the back coupling of one's own voice perceivedSidetone and echoDegradation of one's own voiceHow is the back coupling of one's own voice degradedColoration of the sidetone and echo pathInteraction phaseInteractivityDelayed and disrupted interactionDelay

In memory of the aforementioned two limitations and the research question to overcome these limitations (see Sect. 3.​6), now a set of seven perceptual quality dimensions for an entire conversation is proposed. While the Listening Phase was already part of different studies and revealed four perceptual dimensions (see Sect. 3.​3.​1), two additional perceptual dimensions for the Speaking Phase and one perceptual dimension for the Interaction Phase were identified. An overview of the perceptual quality spaces resulting from the multidimensional analysis can be seen in Table 4.6. The seven perceptual dimensions are proposed to be called:
Coloration

Noisiness

Discontinuity

Loudness

Impact of one's own voice on speaking

Degradation of one's own voice

Interactivity


The two identified dimensions for the Speaking Phase, the Impact of one's own voice on speaking and Degradation of one's own voice seem to cover the space spanned by the degradations sidetone and echo. However, also other degradations (e.g., loud background noise) might not only affect the Listening Phase, but also the Speaking phase (see Sect. 3.​4.​1).
For the Interaction Phase, the perceptual dimension Interactivity was identified. Mainly two explanations for this result are considered: First, the perceptual dimension was identified with the help of an SD experiment that is based on prior determination of APs. In this case, two separate pre-tests with naïve test subjects and with experts were conducted. However, the high correlation of the attributes suggests that the attributes only cover a certain limited space. This is due to the fact that the stimuli that were presented varied only with respect to transmission delay. This brings up the second explanation: The only quality element varied was delay. Quality elements of the Listening Phase or the Speaking Phase, which might have provoked other dimensions, were not considered.
So far, the three phases were treated mostly independent. It is not known and has to be analyzed if the results of the multidimensional analysis for the Speaking Phase and Interaction Phase would be different when quality elements of all phases are considered in one single tests. In particular, it has to be verified if the separately identified dimensions can still be uncovered in a real conversational situation. Also, it is not known yet how the presence of multiple degradations affects the characteristics of the seven perceptual dimensions. For example, in [67] or [155] it was found that the conversational quality is rated more critically for echo than for transmission delay. Whether this could be adapted for the identified dimensions is unclear. For this, additional studies to investigate and identify the conversational quality profile are necessary. A proposal of a conversational quality profile based on conversational tests is presented in Chap. 7.
The multidimensional analysis revealed the perceptual quality spaces for each phase of a conversation that in sum is composed of seven perceptual dimensions. This set of perpetual dimensions allows diagnosing conversational speech quality in future work. However, this set of perceptual dimensions still has to be validated and their characteristics in a conversational test (and not in separate SOTs or LOTs) have to be investigated. For this, at first a new subjective test method that allows considering all three conversational phases and their perceptual dimensions has to be developed (see Chap. 5). Using the developed test method then enables the verification of the proposed perceptual spaces (see Chap. 6).












© Springer Nature Singapore Pte Ltd. 2018


Friedemann Köster



Multidimensional Analysis of Conversational Telephone Speech


T-Labs Series in Telecommunication Services


https://doi.org/10.1007/978-981-10-5224-8_5





5. Direct Scaling of Perceptual Dimensions in a Conversational Situation




Friedemann Köster
1  




(1)
Quality and Usability Lab, Technical University of Berlin, Berlin, Germany

 



 

Friedemann Köster


Email: 
friedemann.koester@tu-berlin.de







5.1 Introduction and Scope
In the previous chapter, the perceptual quality spaces of two conversational phases, namely the Speaking and the Interaction Phase, have been explored and identified. These phases have not been part of multidimensional research in the related literature, yet. Thus, methods for quantifying the resulting seven perceptual quality dimensions, and thus for diagnosing conversational speech quality, are so far not available. In this chapter, a new subjective test method is presented for assessing and scaling the resulting seven perceptual quality dimensions of conversational quality directly by a test subject. The work presented in the following is addressing the second research topic (Quantification) stated in Sect. 3.​6.
The term directly corresponds to the quality assessment as it is presented in Sect. 2.​3.​4. Instead of gathering data with a comparison test or an SD and analyzing the results with an MDS or an PCA, the resulting perceptual quality dimensions from the multidimensional analysis are rated by the subjects. Thus, the seven perceptual dimensions are directly rated on seven individual scales.
In addition to directly scaling the identified perceptual dimensions, the proposed test procedure provides a method to quantify the quality perception of each individual phase of a conversation. The test subjects thus have to perceive each phase individually, to allow a separate rating. Finally, besides the rating for the perceptual quality dimensions and the conversational phases, the test subjects are also asked to give an overall conversational quality rating.
The subjective test method and the gathered ratings are new to the quality research community and provide fundamental advantages in terms of research and applicability:The new test method gives the possibility to diagnose conversational quality based on the subjective ratings of the proposed perceptual quality dimensions.Apart from the fact that the SD and MDS methodologies are necessary to extract the perceptual dimensions, they comprise one major drawback: Due to the relatively large number of attributes (SD) and pairwise comparisons (MDS) both methods are time-consuming. Thus, the number of conditions to be assessed is limited due to the enormous experimental effort. The direct scaling of the perceptual quality dimensions introduced by the new test method reduces the experimental effort and allows to increase the number of conditions under test or to decrease the required time.In addition, gathering the ratings for the perceptual quality dimensions, the three conversational phases, and the overall conversational quality ratings, allow to formulate new research topics concerning the perceptual quality dimensions. For example, it can be researched how the overall conversational quality can be modeled on the basis of the dimension ratings. Or, based on the assumption stated in Sect. 2.​3.​3 and proved in [2], the quality values of each individual phase can be modeled with the ratings of its underlying perceptual dimensions (see also Chap. 7).Based on the requirements and the demand of the test designer, the new test method can be adapted. For example, if the test designer is only interested in the overall conversational quality and the quality of its three phases, the test supervisor can leave out the assessment of the perceptual quality dimensions and can only ask for the demanded ratings.The new test method allows validating the identified set of perceptual dimensions (see Chap. 6).Finally, the test method gives the possibility to gather the subjective ground truth to develop instrumental diagnostic conversational quality models (see Chap. 8).

The new test method is developed to provide all these advantages. As a first step of the development process, the scope of the new test method is defined (based on [156]):
The subjective test methodology is able to asses and diagnose the quality of speech in a "telephone conversation" scenario. Common conversation tests, as described in [35, 134], provide valid methods for the overall conversational quality, but do not give insights into reasons for possible quality losses. In addition, common conversational tests lack analytic ability, since naïve test subjects concentrate on the conversation flow. To circumvent these problems, this test method specifically allows the test subjects to perceive each phase of a conversation separately, in addition to a natural conversation, and yields overall conversational quality scores as well as quality scores for each phase (the Listening Phase, the Speaking Phase, and the Interacting Phase). In addition, scores for seven underlying perceptual dimensions of conversational speech quality are provided. These scores enable an analysis of conversational speech quality for diagnosis and optimization.
The design of the used rating scales is presented in Sect. 5.2. In Sect. 5.3, the test procedure is described in detail. The setup of the test method in terms of test rooms and instructions is given in Sect. 5.4. The chapter closes with a conclusion in Sect. 5.5. The developed new test method is applied in two conversational tests. The results are presented in Chap. 6. The work illustrated in this Chapter is an extended and modified version of the former contributions [156-158].


5.2 Rating Scales

Overall Quality Rating Scales

As stated in the scope of the new test method, the method provides means for quantifying the overall conversational quality as well as the quality of the three conversational phases, the Listening, Speaking, and the Interaction Phase. The same rating scale as presented in the SD experiments is used to gather the overall quality ratings (see Chap. 4 and Fig. 4.1). Other than the traditional ACR 5-point MOS scale (Sect. 3.​3.​2.​1) the continuous scale was chosen because it avoids scale-end effects and showed to be more sensitive (see Sect. 2.3.4.1 and [57]).

Dimension Rating Scales

The new subjective test method provides means for quantifying the seven quality relevant perceptual dimensions in a conversational situation (Noisiness, Discontinuity, Coloration, Loudness, Impact of one's own voice on speaking, Degradation of one's own voice, and Interactivity, see Sect. 4.​5) directly on seven descriptive scales. Thus, each scale is dedicated to one particular dimension. The poles of each scale are labeled with the APs describing the corresponding dimension, "uncolored—colored" (for the Coloration dimension), "continuous—discontinuous" (for the Discontinuity dimension), "not noisy—noisy" (for the Noisiness dimension), "optimal loudness—sub-optimal loudness" (for the Loudness dimension), "no impact on speaking—high impact on speaking" (for the Impact of one's own voice on speaking dimension), "own voice not degraded—own voice degraded" (for the Degradation of one's own voice dimension), and "easy to interact—hard to interact" (for the Interactivity dimension). This enables to directly quantify separate scores for each perceptual dimension present in a conversational situation.
Figure 5.1 shows the graphical scale layout. The scales are similar to the scales used for the SD experiments in Chap. 4 (see Fig. 4.​2). Again, the continuous scales were chosen over traditional ACR scales because they showed to be more sensitive [57]. In addition, the extended extreme positions avoid contraction bias and saturation effects (see Sect. 2.​3.​4.​1). While the labels on the left of the scales describe no impairment in the relating dimension, the labels on the right describe the maximum impairment. Thus the scales are considered to be unipolar following the vector model (see Sect. 2.​3.​3).Fig. 5.1Dimension scale design



5.3 Test Procedure
This section will give an overview over the test procedure of the new test method. As the test method is supposed to allow the test subjects to perceive each conversational phase separately, the test is split into three sessions. Each session addresses specific components of a conversation and is therefore necessary for analyzing the whole conversation. Section 5.3.1 introduces the general test procedure and its sessions. To avoid order effects, the presentation of the rating scales follows a systematic scheme. The dimension rating scheme is presented in Sect. 5.3.2. In Sect. 5.3.3, a set of reference conditions is introduced to ensure a comparability of the new test method. Finally, a calculation of the estimated test duration is depicted in Sect. 5.3.4.

5.3.1 General
The new test method is supposed to provide diagnostic information for a conversational situation. Therefore, the method follows common means for subjective conversational tests as described in Sect. 3.​5.​2. For each condition, or transmission system characteristic under test, two test subjects in two separate rooms according to [35] are required. The basic test setup is similar to the one used for the SD interaction test described in Sect. 4.​4.​3. The setup can be seen in Fig. 4.​7.
It is assumed that with traditional conversation scenarios like the SCT or the RNVT alone, test subjects are not capable of identifying all of the seven perceptual dimensions. This is because too many cognitive resources may be bound by these tasks due to the fact that the attention of the test subjects is rather on the content of the conversation, and on the dialogue flow. This assumption is not proven yet, but will be part of the research presented in Sect. 6.​2. Thus, it is important to establish a test method that specifically allows the test subjects to perceive each phase separately, in addition to a natural conversation test. Therefore, the new test method to assess one condition is composed of three sessions:

(I) In the first session, the task of the two test subjects is to conduct a SCT scenario according to [134]. The SCTs were used because their tasks represent everyday-life situations and provide a reasonable degree of interaction while being limited to an acceptable test duration. Thus, this session represents a regular everyday-life conversational scenario of about 2-4 min length. After each scenario, the test subjects are asked to judge the overall conversational quality (according to [35]), and then the seven perceptual dimensions representing all phases of a conversation.1


(II) The second session addresses the Listening and Speaking Phases. One of the test subjects is asked to read out two sentences while the other participant listens to what is read out. The sentences and procedures of the speaking part are similar to SOTs introduced in Sect. 3.​4.​2 and to the tests conducted in Sect. 4.​3. In turn, the listening part is analog to LOTs introduced in Sect. 3.​3.​2. After the first sequence, the test subjects change roles so that each test subject has to speak and listen for each condition under test. For each sequence, the test subjects are asked to judge the overall quality of the speaking as well as the two dimensions for the Speaking Phase and the overall quality of the listening as well as the four dimensions for the Listening Phase. The detailed rating scheme is presented in Sect. 5.​3.​2.

(III) The third session addresses the Interaction Phase. This task is supposed to be sensitive for possible delays in the transmission system. It was decided to use the RNVT as introduced in Sect. 3.​5.​2. The RNVT was chosen because it is limited in time and lets naïve test subjects perceive even small amounts of transmission delay. After the RNVT the test subjects are asked to judge the overall quality of the interaction and the Interactivity dimension representing the Interaction Phase.
An overview of the test procedure for one condition under test and for both test subjects can be seen in Fig. 5.2.Fig. 5.2Overview of the test procedure: SCT—Short Conversation Test, RNVT—Random Number Verification Task



5.3.2 Dimension Rating Scheme
The dimension rating scheme of the new test method is comparable to the scheme for diagnosing the listening phase (see Sect. 3.​3.​2.​2 or [2]) or for analyzing noisy signals (see Sect. 3.​2.​6) or [79]). Each of the three separate sessions of the new test method includes an assignment (speaking, listening, SCT, or RNVT) as well as an overall quality and a dimension rating task. As these rating tasks are similar, the rating task for the speaking part in Session II is explained in detail as a representative session.
The dimension rating scheme is used to reduce the bias due to the presentation order (see Sect. 2.​3.​4.​1). Before the test subjects are asked for their ratings, they are asked to conduct the given task once. Afterwards, the test subjects first give their ratings on the overall quality and second on the two perceptual dimensions for the Speaking Phase. After the overall quality rating according to [35], the dimension scales (see Fig. 5.1) are presented separately and consecutively. The detailed rating schema for the speaking part of Session II can be seen in Fig. 5.3.
The conditions to be assessed are presented in randomized order. Additionally, the order of the dimension scales is permuted for each test subject. The schema can be seen in Table 5.1. For each test subject the order of the scales is held constant to avoid confusion of the scales.Fig. 5.3Condition, scale presentation, and rating for the speaking part of Session II
Table 5.1Presentation order of the dimensions scales. ios—Impact of one's own voice on speaking and dos—Degradation of one's own voice
Test subjectDim scale 1Dim scale 21iosdos2dosios3iosdos4dosios.........



5.3.3 Reference Conditions
It is common practice to include standard reference conditions in subjective tests (see for example, [35, 79]) to provide subjects with a frame of expectation within the test. In addition, a set of reference conditions gives test supervisors of different labs the possibility to compare their results. This is especially important for the new test method where the test subjects are asked to rate a telephone conversation on multiple dimensions.
For the proposed new test method, the concept of Exemplar Conditions introduced in [102] is adapted. Each exemplar condition exhibits a high degree of degradation in a single perceptual quality dimension that is a distinct example of that dimension. Each test of the new test method should include at least one exemplar condition for each of the seven perceptual dimensions described in Sect. 4.​5. These exemplar conditions should be designed in a way that the test subjects are provided with at least one condition within each test where a distinct example of a degradation in the specific quality dimension is exhibited. This means that the quality dimension for which the exemplar condition is designed for, is the dominant degradation while the other six quality dimensions are not triggered. Having these exemplar conditions in a test provides the test subjects with a possibility to exercise every dimension scale inside the test, independent of the context and the conditions under test.
Beside the seven exemplar conditions, it is also common practice to introduce so-called Source Conditions in subjective tests. The source conditions provide an example of a condition with no degradation. For the new proposed test method, this means that a source condition is a "clean" telephone conversation with no degradation in any of the seven perceptual quality dimensions. If the test supervisor plans to involve multiple bandwidths, the source conditions should include more than one bandwidth, for example S-WB and WB.Table 5.2Reference conditions to be used in the new test methodCon.DegradationPerceptual dimension1Clean SWB PCMSource condition2Sidetone  dB attenuationImpact of one's own voice on speaking3Delay 1000 msInteractivity4Echo 100 msDegradation of one's own voice5Packet-loss 10% (no PLC)Discontinuity6White noise 30 dB attenuation (SNR 40 dB)Noisiness7Attenuation 15 dBLoudness8Codec LPC-10Coloration

The exemplar and the source conditions form the reference conditions to be used in the new test method. Table 5.2 gives an overview of the processing that could be used for the source condition (1) and for the exemplar conditions (2-8) for each of the seven perceptual quality dimensions. The reference conditions (as described in Table 5.2 or with adapted characteristics) may also be used to train or anchor the test subjects (regarding the dimension scales) for the new test (see Sect. 5.4.2).


5.3.4 Test Duration
The overall test duration of the new test method is dependent on the conditions under test. The average duration for rating one condition under test is divided in separate durations to provide an estimation of the average test duration:Average duration of a SCT according to [134]: 3 min or 180 sAverage duration of the speaking part in session II: 30 sAverage duration of the listening part in session II: 30 sAverage duration of a RNVT: 70 sAverage duration for an overall quality rating interval: 5 sAverage duration for a dimension rating interval: 5 s

These values add up (for the number of overall quality and dimension ratings) for one condition. Table 5.3 shows the added estimations for the test duration of one condition. The average 400 s (or 6.6 min) can vary depending on the delay the system uses, resulting in longer or shorter durations (duration one sequence ).Table 5.3Average test duration for one conditionSectionTaskDuration [s]Session 1SCT180Rating (overall quality  7 dimensions)40Session 2Speaking30Rating (overall quality  2 dimensions)15Listening30Rating (overall quality  4 dimensions)25Session 3RNVT70Rating (overall quality  1 dimension)10Overall duration 400

In addition to the test duration of one condition, the duration of a possible training and the instructions (see Sect. 5.4.2) must also be considered when estimating an overall test duration. The training and the introduction together take up to 30 min until the procedure and the scales are understood (training and introduction ).
Assuming the test supervisor plans to test 15 different telephone system network settings (conditions ), the total duration of the experiment using the new test method would then be approximately 130 min (compare (5.1)). (5.1)To avoid test subjects fatigue the experiment should then be divided into two 65 min sessions.



5.4 Setup
For actually conducting a conversation test using the new test method a number of recommendations should be respected. This section will give an overview about the main setup recommendations when using the proposed test method. First, recommendations about the test facilities and the test subjects are given in Sect. 5.4.1. Second, Sect. 5.4.2 will briefly discuss recommendations concerning the instructions and the training of the test subjects.

5.4.1 Test Rooms and Test Subjects
The test should be conducted with a test setup presented in Fig. 4.​7. The test rooms of the two test subjects should be selected according to the requirements regarding background noise and reverberation stated in [35]. Sound presentation should be diotic by using headphones, for example the one used in the interaction test presented in Sect. 4.​4.
The selection of the test subjects is dependent on the target group the test designer wants to evaluate. However, the test was developed for naïve test subjects. As mentioned in Sect. 2.​3.​4.​1, the number of test subjects should not be smaller than 30 and the portions of male and female test subjects should be balanced.


5.4.2 Introduction and Training
For the introduction, a detailed written description of the test method should be given to the test subjects to ensure an equal level of knowledge. The instructions first give an overview over the scales and how they should be used. It should be explained that in the test the characteristics of a conversation are supposed to be judged and that this judgment is done on eight scales. Regarding the dimension scales, each scale is labeled with an attribute at each end that describes the characteristic to be judged. The scales are described in detail using the highly correlated attributes according to the SD experiment conducted to identify the perceptual dimensions (see Chap. 4). For example for Interactivity, "easy to interact" means that the interaction between the two interlocutors is easy, effective, pleasant, and agile. In turn, "hard to interact" means that the interaction is ineffective, unpleasant, hard and lazy.
Second, the test procedure as presented in Sect. 5.3 is introduced. The introduction introduces each session and its relating assignments to the test subjects. An exemplary introduction for the new test method can be found in Appendix C.
An optional training should be conducted to ensure that the test subjects get to know the test procedure as well as get familiarized with the usage of the scales and the test method. For this, the test procedure as well as the ratings (overall quality and dimensions) should exemplarily be run through. Thus, one possible training could look like this:
The test subjects run through the test procedure (as described in Fig. 5.2) twice. In the first run, the first session (SCT) is degraded with a condition related to the dimension Noisiness. The second session (speaking and listening) is alternatingly degraded with conditions related to the dimensions Discontinuity and Impact of one's own voice. In the third session (RNVT), the test subjects will not be confronted with a degradation. In the second run, the first session is degraded with a condition related to the dimension Coloration. In the second session, the subjects will again be confronted with two alternating conditions, one related to the dimension Loudness and on related to the dimension Degradation of one's own voice. Finally, in the third session, the transmission system will introduce delay to trigger the dimension Interactivity. The scheme of the training is also illustrated in Table 5.4.
With this possible training, the two test subjects are introduced to the test procedure and the seven perceptual dimensions. In addition, the test subjects get to know the characteristics of all perceptual dimensions and train the usage of the rating scales. The training of the third session (no degradation vs. Interactivity) is in particular useful to ensure the test subject's sensitivity for a transmission delay. As possible conditions, the reference conditions introduced in Sect. 5.3.3 could be used. If the test supervisor plans to use the reference condition in the actual test, it is also possible to adapt the reference conditions. However, the training is just a recommendation, it might also be possible to just run through the test procedure once to ensure that the test subjects understand their tasks.Table 5.4Scheme of a possible training for the proposed test method SessionPerceptual dimension Test subject 1Perceptual dimension Test subject 2Training run 11 (SCT)NoisinessNoisiness2 (listening/speaking)DiscontinuityImpact of one's own voice on speaking2 (speaking/listening)Impact of one's own voiceDiscontinuity3 (RNVT)nonenoneTraining run 21 (SCT)ColorationColoration2 (listening/speaking)LoudnessDegradation of one's own voice2 (speaking/listening)Degradation of one's own voiceLoudness3 (RNVT)InteractivityInteractivity




5.5 Conclusion
In this chapter, a method is presented for subjectively rating the introduced perceptual quality dimensions of a conversation (see Chap. 4) in a direct way. The method allows naïve test subjects to perceive each conversational phase separately and to directly quantify the proposed seven dimensions. Thus, the method forms the basis to diagnose the overall conversational quality in an efficient way. In addition, the method follows the recommendations of a conversation test as stated in Sect. 3.​5.​2.
The introduced method meets the scope and exhibits the named advantages discussed and presented in Sect. 5.1. However, it has to be validated if the new test method works in a meaningful and reliable way. In particular, it has to be validated if the dimension scales measure what they were designed for. The validation of the new test method is presented in Chap. 6.
The introduced method was made available to the ITU-T SG 12 [158]. Based on this contribution, Question 7 of SG 12 decided to start a new work item called P.CQS to provide the subjective basis for a potential instrumental conversational model P.CQO [139]. It is planned, that the P.CQS work item results in a new recommendation, named Subjective Diagnostic Test Method for Conversational Speech Quality Analysis. The presented new test method is supposed to provide the foundation for the new recommendation. However, before a standardization of the method, the method has to be approved in terms of validation and inter-test reliability if applied by independent research laboratories.


Footnotes


1


Note that here the assessment of the seven perceptual dimensions is not mandatory. Depending on the requirements of the test designer it is also possible to only gather the overall conversational quality. Asking for the dimension ratings at this point mostly serves for research purposes (see Chap. 6).

 













© Springer Nature Singapore Pte Ltd. 2018


Friedemann Köster



Multidimensional Analysis of Conversational Telephone Speech


T-Labs Series in Telecommunication Services


https://doi.org/10.1007/978-981-10-5224-8_6





6. Conversational Validation Experiments




Friedemann Köster
1  




(1)
Quality and Usability Lab, Technical University of Berlin, Berlin, Germany

 



 

Friedemann Köster


Email: 
friedemann.koester@tu-berlin.de







6.1 Introduction
In the two previous chapters, the perceptual quality space in a telephone conversation (Chap. 4) and a new test method for directly scaling the identified perceptual quality dimensions in a conversational situation (Chap. 5) were presented. At this point, the work presented in both chapters has not been validated yet.
More precisely, regarding the identified perceptual quality space, the three conversational phases were so far only analyzed independently. It is not researched and analyzed yet, whether the identified perceptual dimensions of all three phases would also result in a multidimensional analysis of a single conversational test considering quality elements of all three phases. Thus, the perceptual quality space of a telephone conversation is validated by verifying if the separately identified dimensions can still be uncovered in a real conversational situation.
Regarding the proposed new conversational test method, it theoretically provides a meaningful approach to scale the identified perceptual dimensions in a direct way by test subjects. However, on a practical level it has to be verified if the new test method works reliably. In particular, a conversational experiment using the new test method has to be conducted to validate whether the dimension scales measure what they were designed for.
In this chapter, two sophisticated conversational experiments and their results are presented. The first experiment addresses the validation of the perceptual quality space in a telephone conversation. The second experiment is focused on the validation and the verification of the new proposed test method. Thus, this chapter concentrates on the third research topic (Validation) stated in Sect. 3.​6.
In Sect. 6.2, the validation of the perceptual quality space in a telephone conversation is presented. The section is subdivided into a description of the test design (Sect. 6.2.1), a presentation of the results of the conversational test (Sect. 6.2.2), and a discussion of the results (Sect. 6.2.3). The conversational experiment to validate the new test method is presented in Sect. 6.3. Again, the section is subdivided into instructions regarding the test design (Sect. 6.3.1), a demonstration of the results (Sect. 6.3.2), and a discussion of the results (Sect. 6.3.3). Following, the two experiments are compared in terms of the overall quality ratings in Sect. 6.4. The chapter closes with a summary and a conclusion in Sect. 6.5. Parts of the work illustrated in this chapter are based on the data presented in a former ITU contribution [158] and in a former publication [159].


6.2 Validation of the Perceptual Quality Space
To verify the identified perceptual quality space and its underlying perceptual dimensions, a conversational experiment using an adapted version of the new test method (see Chap. 5) was conducted. The approach of the validation experiment is based on the hypothesis that the resulting dimensions of the separately conducted listening, speaking, and interaction experiments can also be identified using the new test method. To do so, it was decided to conduct an additional SD experiment (see Sect. 4.​2.​2) to analyze the identification of the dimensions. As mentioned before, the new test method was slightly adapted for this, however, in future the test method will and should be used as recommended in Chap. 5. In the following, the test design and the results of the test are presented in detail. Subsequently, the outcome of the validation test will be discussed.

6.2.1 Test Design
As mentioned before, the experiment conducted to validate the identified perceptual quality space is using a test design that is a mixture of an SD experiment and an adapted version of the new proposed test method. The experiment is motivated by the hypothesis that a PCA on ratings stemming from an SD experiment of a conversation results in the same perceptual dimensions as identified in the separate listening, speaking, and interaction tests. Thus, instead of directly scaling the perceptual dimensions, the new test method was adapted in a way that in each session only the corresponding APs had to be rated. In the first session, all APs (see Table 6.3) of all three phases have to be rated to also analyze if test subjects can perceive all seven perceptual dimensions during a structured conversation. In sum, the new test method and its three sessions were adapted as follows:

(I) After each SCT, the test subjects first have to rate the overall conversational quality and second the 28 APs representing (and used in) all phases of a conversation.

(II) For each sequence, the test subjects are asked to rate the 11 APs for the Speaking Phase (see Sect. 4.​3.​3) and the 14 APs for the Listening Phase [99].

(III) After the RNVT the test subjects judge the 10 APs representing the Interaction Phase (see Sect. 4.​4.​3).
Table 6.1 illustrates again the described experimental procedure and structure. The test subjects were asked to communicate using a transmission system (see Sect. 4.​4.​1) that was distorted by eleven different degradations (see Table 6.2). The degradations use the eight reference conditions plus three conditions with mixed degradations. The conditions are analogous to the conditions used in the separate tests described in Chap. 4.
The experiment was carried out by 40 test subjects (23 female, 17 male) grouped into 20 pairs, aged between 18 and 53 years (there is no overlap between the test subjects of the experiments presented in Chap. 4 and the validation experiments). Each pair of test subjects first conducted one introduction dry-run to get familiar with the test, and then eleven runs for each degradation. The order of degradations was randomized between the test subjects. Keep in mind that the rating of all APs takes up to ten minutes per condition. Therefore, the experiment was split into two sessions per 60 min to avoid test subjects' fatigue.Table 6.1Overview of the experimental procedure. (I) Conversation, (II) Listening and Speaking, (III) Interaction. T—Test subject, APs—antonym-pairs, SCT—Short Conversation Test, RNVT—random number verification tasksTest sectionTask T1Task T2Rating T1 [APs]Rating T2 [APs]ISCTSCT2828IIListeningSpeaking1411SpeakingListening1114IIIRNVTRNVT1010
Table 6.2Conditions used for the validation of the perceptual quality space in a telephone conversation. Here, the eight reference conditions (see Sect. 5.​3.​3) plus three mixed conditions were usedCon.Degradation1clean SWB PCM2Sidetone  dB attenuation3Delay 1000 ms4Echo 100 ms, no attenuation5Packet-loss 10 % (no PLC)6White noise 30 dB attenuation (SNR 40 dB)7Attenuation 15 dB8Codec LPC-109Noise(6)  Echo(4)10Codec LPC-10(8)  Sidetone(2)11Delay(3)  Packet-loss(5)



6.2.2 Results
The results of the conducted experiment are structured in five groups: First, the results of the overall conversational quality ratings are analyzed, second, the results of the third session (Interaction Phase), third and fourth, the results of the second session (Listening Phase as well as Speaking Phase), and finally, the results of the first session (Conversation Test) of the SD experiment are presented.

Overall quality

After averaging the ratings of the overall conversational quality over the conditions, a repeated measure ANOVA between the conditions as independent and the overall conversational quality ratings as dependent variables was carried out, showing that the conditions have a significant impact on the judgment of the test subjects (). With this it is proved that the different degradation levels worked as intended (decreasing quality—lower rating/increasing quality—higher ratings).

Session III—Interaction Phase

The results of the following PCA indicate that the 10 attributes can be described by one dimension, covering 85.4% of the variance of the 10 one-dimensional features. The resulting factor loadings can be seen in Table 6.3. This result is similar to the one of the previously conducted separate interaction experiments. However, the AP "unpleasant—pleasant" shows a lower correlation than in the separate interaction experiment (see Chap. 4). A possible explanation could be that the RNVT does not trigger this AP in a similar way as the SCT. While in a RNVT the test subjects just exchange numbers without being "pleasant", in a SCT the two subjects have a real conversation triggering the AP "unpleasant—pleasant". Nevertheless, the results show that the proposed dimension that were identified in a separate interaction test can also be identified in session III of the new test method.Fig. 6.1Scree plots for the PCA (validation experiment); a—Listening phase (II); b—Speaking phase (II); c—Conversation test (I)


Session II—Listening Phase

The Scree Plot (see Fig. 6.1a) of the PCA shows that only three potential dimensions result for the Listening Phase in session II. The three dimensions are determined, covering 96.9 % of the variance of the 14 APs. In separate LOTs, however, four dimensions were proposed.
An explanation for this can be found by analyzing the factor loadings for each AP to the determined three dimensions in Table 6.3. Dim 3 describes the dimension Loudness ("loud—quiet" (.972)) and Dim 2 describes the dimension Noisiness ("not hissing—hissing" (.831), "not noisy—noisy" (.862), and "crackling—not crackling" (.866)), whereas Dim 1 seems to cover both dimensions Coloration and Discontinuity, correlating with the remaining 10 APs.
In the validation experiment the two dimensions Discontinuity and Coloration have individually only been triggered by two conditions (Condition 5 and 8). Additionally, for each dimension (Discontinuity and Coloration) one of the two conditions is combined with a different degradation that might mask the Discontinuity and Coloration degradation (Condition 10 and 11). Also, in [160] it was observed in a diagnostic listening experiment that subjects reflect in the Coloration scale distortions that are not clearly classified to any of the other three dimensions. Thus, it might be possible that in this experiment the test subjects also related APs to Coloration when they were not sure about their origin. These facts could be the reason of the result that the PCA of the validation experiment results in one dimension that covers the APs for Discontinuity and Coloration.
Thus, the reason for the reduction of the dimensionality of the Listening Phase perceptual quality space from four (found in the identification experiments) to three (found in the validation experiment) is probably due to (a) the limited number of conditions which could trigger these perceptual dimensions and (b) an uncertainty of test subjects on which scales distortions should be classified if they are not sure. The latter point will also be reflected in the validation experiment of the new test method (see Sect. 6.3).

Session II—
Speaking Phase

The Scree Plot (see Fig. 6.1b) of the PCA shows that two potential dimensions result for the Speaking Phase in session II. These two dimensions are determined, covering 96.5% of the variance of the 11 one-dimensional features.
Two dimensions have also been discovered in the separate speaking test, termed Impact of one's own voice on speaking (covering APs like "not helpful—helpful", "irritating—not irritating", "exhausting—not exhausting", "distracting—not distracting" or "not fluent—fluent") and Degradation of one's own voice (covering APs like "reverberant-anechoic", "clear—unclear", "thin—thick" and "distorted—undistorted"). Looking at the factor loadings for the Speaking Phase (see Table 6.3), it can be seen, that Dim 1 covers the same APs as in the previous individual speaking tests. Dim 2 explicitly only covers the APs "thin—thick", and with lower values "clear—unclear" (.401) and "distorted—undistorted" (.280). These two APs are also covered by Dim 1.
Additionally, the AP "reverberant—anechoic", intended for Dim 2, is only respected by Dim 1. An explanation for this result might be found by looking at condition 9, where the echo is mixed with noise. In the perception of the test subjects, the noise seems to mask the echo degradation. Thus, only condition 4 covers pure reverberation, which potentially led to the presented outcome.
In sum, the findings of the validation experiment are similar to the previous individual speaking tests to identify the perceptual quality space of the Speaking Phase. Again, the second dimension Degradation of one's own voice is rather weak in comparison to the other identified dimension Impact of one's own voice on speaking. The limited coverage of the second dimension (this experiment) in comparison to the interpretation of the two proposed dimensions (previous experiment) might again be (a) due to the number of conditions triggering the dimensions and (b) due to the singularity of the second dimension being only present when the first dimension is also present (see Sect. 4.​3.​7). Again, the latter point will also be addressed in the validation experiment regarding the new test method (see Sect. 6.3).Table 6.3PCA results—VARIMAX rotated; Factor loadings (; except Speaking Phase ). Boldface printed values are used for identifying the Dimension (Dim) Session I: Conversation (SCT)Session II: ListeningSession II: SpeakingSession III: InteractionAntonym-pairDim 1Dim 2Dim 3Dim 1Dim 2Dim 3Dim 1Dim 2Dim 1Interrupted—continuous
.760
  
.939
    Distant—close
.892
  
.876
    Crackling—not crackling  
.901
 
.866
   Not noisy—noisy  
.901
 
.862
   Muffled—not muffled
.738
  
.913
    Shaky—steady
.746
  
.866
    Indirect—direct
.827
  
.904
    Dark—bright
.821
  
.928
    Unintelligible—intelligible
.792
  
.929
    Not hissing—hissing  
.913
 
.831
   Clear—unclear
.717
  
.863
  .869
.401
 Thin—thick
.827
  
.832
   
.994
 Distorted—undistorted
.720
  
.884
  .942
.280
 Loud—quiet 
.975
   
.972
.932

 Not fluent—fluent
.736
    
.983
  Not helpful—helpful.632
.665
   
.990
  Reverberant—anechoic 
.826
   
.971
  Irritating—not irritating 
.767
   
.985
  Distracting—not distracting 
.760
   
.987
 
.834
Exhausting—not exhausting.662
.664
   
.991
 
.984
Concentration—no concentration.645
.712
   
.990
 
.970
Unpleasant—pleasant.621
.708
    Clear—confusing.619
.706
   
.980
Lazy—agile
.772
    
.878
Easy—hard.651
.669
   
.983
Relaxing—annoying 
.685
   
.986
Not frustrating—frustrating.649
.688
   
.994
Effective—ineffective.710
.617
   
.976



Session I—Conversation Test (SCT)

The Scree Plot (see Fig. 6.1c) of the PCA shows that three potential dimensions result for the SCT conversation test in session I. These three dimensions are determined, covering 96.6 % of the variance of the 28 one-dimensional AP space. It was intended that the results of the PCA show that all seven dimensions are perceived in the conversation test.
However, it seems that only a limited number of dimensions can be perceived in a test-paradigm like the SCT that requires the full attention of the test subjects on the flow of the conversation, and not on the rating task. The factor loadings (Table 6.3) point out, that only the proposed dimensions Noisiness is distinct enough to be perceived separately in Dim 3 ("not hissing—hissing" (.913), "not noisy—noisy" (.901), "crackling—not crackling" (.901)).
The other two assigned dimensions Dim 1 and Dim 2 represent a mix of the remaining 6 dimensions of the individual phases. Dim 1 represents the proposed Dimensions Coloration ("muffled—not muffled" (.738), "dark—bright" (.821), "indirect—direct" (.827), "clear—unclear" (.717), "distant—close" (.892)) and Discontinuity ("interrupted—continuous" (.760), "shaky—steady" (.746), "distorted—undistorted" (.720)) and could be related to the intelligibility. Dim 2 might describe the cognitive load of the test subject representing the dimensions Loudness ("loud—quiet" (.975)) and the Impact of one's own voice on speaking ("not helpful—helpful" (.665), "reverberant—anechoic" (.826), "distracting - not distracting" (.760)). The remaining two dimensions Interactivity and Degradation of one's own voice are fused in Dim 1 and Dim 2.
The results show that a distinct identification of the seven perceptual dimensions (this experiment) in a pure conversational situation is difficult in comparison to the previously conducted separate experiments. One possible explanation for this is that the cognitive resources of the test subjects are bound by the conversation task of the SCT. More precisely, it seems to be difficult for naïve test subjects to concentrate on the conversational task, the rating, and the degradations—at least if the degradations show different and complex characteristics and the subjects have to rate 28 scales. Thus, this result points out the importance of the new test method where the test subjects only rate seven sales and perceive each conversational phase separately.
The results also show a similar behavior of the two dimensions Coloration and Discontinuity as in session II (Listening Phase). Both dimensions seem to be covered by one single dimension. Possible explanations are similar to the explanation made for session II. Again, this point will be addressed in the validation experiment regarding the new test method (see Sect. 6.3).
In sum, it is argued that the results of the sessions II and III of the experiment show that the seven proposed dimensions are still valid for a proper diagnosis of the quality of transmitted speech in a conversational situation if the new test method is used. The results of session I show that the seven proposed dimensions can only be identified if the new test method is used, indicating the necessity of the new test method. The resulting three dimensions of session I show to be a combination of the seven proposed dimensions. Thus, no new dimensions were identified in the SCT, indicating that the seven proposed dimensions are valid.


6.2.3 Discussion
The results of the validation experiment show that the proposed dimensions are difficult to identify in a realistic conversational situation, where the attention of the test subjects is rather on the content of the conversation, and on the dialogue flow. It seems that too many cognitive resources are bound by this task, reducing the number of separately perceivable dimensions in this session. Thus, in subsequent experiments the presented test method (see Chap. 5) that specifically allows the test subjects to perceive each phase separately, in addition to a natural conversation, should be used.
Additionally, the results of session II Listening Phase and session I show that the two dimensions Coloration and Discontinuity seem to merge. This finding is explained with the peculiarities of the conducted experiment. In two conditions the degradations triggering both dimensions might be masked, and the size of the experiment did not allow for more than one additional condition for each dimension. However, this finding has to be investigated in follow-up studies. More precisely, when designing test conditions, care should be taken that each expected perceptual dimension is separately covered by a sufficient number of technical conditions.



6.3 Validation of the Direct Scaling Test Method
The second part of this chapter covers the validation of the new test method proposed in Chap. 5. The results of the validation experiment concerning the identified perceptual quality space (Sect. 6.2) already showed that for a detailed diagnosis of a conversation the proposed test method is necessary, as it allows the test subjects to perceive each conversational phase separately. In addition, the results revealed that the seven identified perceptual quality dimensions are valid for a diagnostic analysis of speech quality in a conversational situation. However, the dimension scales proposed in Chap. 5, the ratings scheme, as well as the estimated test duration have so far not been validated. In detail, it has to be validated if the dimension scales measure what they were designed for, and if the test method works in a meaningful and reliable way.
Thus, to check the applicability of the proposed test method an initial pilot test was conducted. For this, a conversation test using the new test method and triggering the seven proposed perceptual quality dimensions was incorporated.

6.3.1 Test Design
The test to validate the new test method was designed strictly according to the instructions made in Chap. 5. The recommended overall conversational quality rating scale and the dimension rating scales were used. The test procedure followed the outline presented in Fig. 5.​2. The scale presentation and the rating intervals were done according to Table 5.​1 and Fig. 5.​3. In addition, the introduction attached in Appendix C was given to the test subjects prior. However, for the training the recommendations proposed in Sect. 5.​4.​2 were not followed one-to-one. Instead of having two training runs with different degradations, the test subjects were asked to only perform one training run with no degradations (to save time) to get familiar with the test procedure.
The test subjects were asked to communicate using the same transmission system as in the previous identification and validation experiments (see Sect. 4.​4.​1). Again, the system was distorted by eleven different degradations (see Table 6.2). The degradations use the eight reference conditions plus three conditions with mixed degradations. All eleven conditions were the same conditions as in the experiment to validate the perceptual quality space (see Sect. 6.2).
The conversational validation experiment was carried out by 36 test subjects (18 female, 18 male) grouped into 18 pairs, aged between 18 and 51 years. Each pair of test subjects first conducted the training run to get familiar with the test, and then eleven runs for each degradation. The order of degradations was randomized between the test subjects.


6.3.2 Results
The test subjects took an average of 1 hour and 31 min to complete the test including training, instructions, and rating tasks. Compared to (5.​1) the test method with eleven condition () was expected to have a duration of  min. This corresponds to 1 h and 41 min and is thus 10 min more than the actual test duration. An explanation for the discrepancy between the actual and the expected test duration might be that the test subjects get used to the test procedure and act faster for the later conditions in the test. However, with respect to the overall test duration a discrepancy of ten minutes is rather small. Therefore, when planning a test with the new test method the estimated duration according to (5.​1) should be respected.
Next, the results of the validation experiment will be analyzed. The results of the experiment are based on the 36 ratings of the test subjects for each condition. The continuous ratings (0-6) (see the dimension scales in Fig. 5.​1) were transformed and averaged to discrete ACR (1-5) ratings according to [57]. For the analysis of the results, first, the overall conversational quality ratings, and second, the dimension ratings for all sessions are presented and discussed.Fig. 6.2Subjective quality ratings resulting from the validation experiment; the overall conversational quality (), and the quality of the three conversational phases (, , and ). The error-bars display the 95% confidence intervals


6.3.2.1 Overall Quality Ratings
In each session of the test, the subjects are asked to give an overall quality rating () regarding the overall conversation quality (CO) (session I), the listening () and speaking () overall quality (session II for the Listening Phase (LI) and the Speaking Phase (SP)), and the interaction overall quality () (session III for the Interaction Phase (IN)).Table 6.4Statistics for the overall quality ratings obtained from the validation test. StdDev—standard deviationConditionOverall Quality Session IListening Quality Session IISpeaking Quality Session IIInteraction Quality Session III1Mean3.804.184.004.26StdDev.81.69.94.592Mean2.143.382.252.77StdDev.811.10.91.953Mean3.054.073.752.60StdDev1.02.71.84.844Mean1.773.031.772.27StdDev.73.97.69.855Mean3.353.124.003.61StdDev.80.88.74.936Mean2.322.602.522.81StdDev.68.81.88.967Mean3.723.823.774.07StdDev.65.71.87.738Mean2.181.953.412.57StdDev.84.79.88.759Mean1.722.131.692.15StdDev.59.77.78.8210Mean1.771.821.682.14StdDev.63.67.74.8911Mean2.662.773.622.54StdDev.93.84.89.88

Table 6.4 shows the statistics mean (Mean) and standard deviation (StdDev) for all four ratings according to the conditions under test. It can be seen that the results show a standard deviation below one for all ratings except for the overall quality ratings for condition three (delay) and the listening quality ratings for condition two (sidetone), respectively. However, here the standard deviations are only slightly above one. The average standard deviations for all four ratings are presented in Table 6.5. The results show that the average standard deviations for all four ratings are below .83. These values lie within the range of standard deviations as typically also obtained in standard ACR experiments [6]. Thus, the low standard deviations validate that the ratings show a high reliability.
In addition, a repeated measure ANOVA between the conditions and the four quality ratings as dependent variables was carried out. The results are given in Table 6.5. The terms  and  denote the degrees of freedom of the numerator and denominator of the F-test, respectively. The results show that the used conditions have a significant influence on all four quality ratings ().Table 6.5Statistical analysis of the ratings gathered in the conversational experiment; the overall conversational quality (), and the quality of the three conversational phases (, , and ) Mean stdANOVA






F

p


.776.8238.145.85



.815.3186.747.01



.835.1175.865.71



.836.2216.137.53



In Fig. 6.2, the results presented in Table 6.4 are illustrated and in addition the 95% Confidence Intervals (CI) are added. It can be seen that for the seven conditions (2-8) in which one degradation is intended to trigger one proposed dimension (see reference condition in Sect. 5.​3.​3) the overall quality () of session I is anchored to the quality ratings of the corresponding phase. In detail, see for example condition two that is degraded by sidetone. Here, the  rating for the overall conversational quality is anchored to the  rating of the Speaking Phase. The three remaining conditions nine, ten, and eleven (mixed degradations) show similar ratings, except that here the ratings for two conversational phases mask the overall quality rating. See for example condition ten degraded by a codec and sidetone. The overall conversational quality  is anchored to the two ratings for the Listening  and the Speaking Phase . A detailed analysis about the relation between the overall conversational quality and the ratings for its underlying three conversational phases will be given in Sect. 7.​4.
Finally, the correlations between the four ratings will be analyzed. Table 6.6 shows the calculated correlation that are all significant at a  level. It can be seen that the ratings for the individual phases show a significant correlation with the overall conversational quality (above .6). Also, the speaking and listening ratings significantly correlate with the Interaction Phase (slightly below .6). This was expected, since the Interaction Phase describes the frequent change from speaking to listening and thus is connected to both phases. In turn, the ratings for the Speaking and Listening Phase have a low (but significant) correlation (a little above .4). In sum, while the Speaking and the Listening Phase seem to be more independent of each other, there is a significant correlation between the overall conversational quality and the three individual phase qualities as well as between the Interaction, the Speaking, and the Listening Phase.Table 6.6Correlations between the overall conversational quality () and the quality of the three conversational phases (, , and ). The correlations are significant at a  level 









1.602.651.657

.6021.444.558

.651.4441.584

.657.558.5841



6.3.2.2 Dimension Quality Ratings Session I—Conversation Task (SCT)
Table 6.7 shows the statistics mean and standard deviation for the dimension scales rated in Session I (Noisiness (Noi), Discontinuity (Dis), Coloration (Col), Loudness (Lou), Impact of one's own voice on speaking (Ios), Degradation of one's own voice (Dos), or Interactivity (Int)). Again, it can be seen that the results mostly show a standard deviation below one for all ratings. In comparison to the overall ratings presented in Sect. 6.3.2.1, standard deviations above one occur more often. However, in these cases the values are again only slightly above one. The average standard deviations for all seven ratings are presented in Table 6.8 and show a maximum of 1.0 for Coloration. Thus, the low standard deviations validate that the dimension ratings show a high reliability.Table 6.7Statistics for the dimension ratings in Session I, obtained from the validation test. StdDev—standard deviationConditionNoisinessDiscontinuityColorationLoudnessImpact of one's own voiceDegradation of one'sown voiceInteractivity1Mean4.104.374.164.154.143.934.22StdDev.88.47.75.70.92.99.562Mean3.603.373.333.951.922.432.60StdDev1.141.281.21.84.831.311.143Mean3.883.613.574.033.903.773.36StdDev.951.061.06.781.061.101.084Mean3.763.032.703.931.531.741.91StdDev1.121.381.41.83.38.83.695Mean3.603.613.804.214.094.143.64StdDev1.151.021.01.63.97.79.886Mean1.583.983.823.914.214.043.58StdDev.43.861.08.86.74.93.957Mean4.354.384.213.334.354.184.08StdDev.62.40.701.11.67.86.688Mean2.592.852.133.344.174.192.58StdDev1.07.99.87.93.87.741.019Mean1.813.042.803.871.871.962.12StdDev.791.331.391.01.82.94.8810Mean2.512.492.413.832.352.422.37StdDev1.131.081.14.851.191.121.0011Mean3.922.843.823.983.994.042.76StdDev.90.97.98.82.96.90.94

Again, a repeated measure ANOVA between the conditions and the seven dimension ratings as depended variables was carried out. The results are given in Table 6.8. The results show that the used conditions have a significant influence on all seven dimension ratings ().
In Fig. 6.3, the results (presented in Table 6.7) and the 95% CI of the dimension ratings are illustrated. The results show that the degradations triggering specific dimensions mostly provoke a lower rating in that specific dimension. Regarding the Speaking Phase (condition two degraded by sidetone and condition four degraded by echo), the degradations trigger the proposed speaking dimensions. In addition, the ratings show that the two listening dimensions Discontinuity and Coloration also are slightly affected by sidetone and echo. The results also reveal that Interactivity is also rated lower when the speaking is degraded. Regarding the Listening Phase, the triggering degradations mostly worked as intended. Especially condition six (noise) and seven (attenuation) evoke lower ratings for Noisiness and Loudness, respectively. Only for condition five (intended to trigger Discontinuity with a packet-loss degradation), a distinctly lower rating of Discontinuity cannot be observed. A similar observation shows condition three (intended to trigger Interactivity with a delay degradation) where delay is only rated slightly worse than the other dimensions. It is interesting, thus, that condition ten (degraded by packet-loss and delay) shows a significant lower rating in both dimensions. This finding has to be further analyzed when looking at the separate phases. In addition, the condition using the LPC-10 codec (condition eight, intended to trigger Coloration) shows a low rating for all listening dimensions. Indeed, the Coloration rating is the lowest, but Noisiness and Discontinuity seem also to be affected by this codec. This could be explained with the low overall quality the codec provides. As it is a parametric codec, it only archives a POLQA  rating of 1.9, indicating that more than one listening dimension might be triggered. However, this observation will also be further analyzed when looking at the separate sessions of the experiment.
Table 6.9 shows the correlations between all used dimension scales. The scales seem to trigger ratings which are not completely independent (significant correlation), but basically measure different constructs (low correlation values). However, the dimension Interactivity is a little higher correlated (around .5) with the two speaking and two listening dimensions. Again, this could be explained with the fact that the Interactivity is dependent of the frequent change between speaking and listening. Thus, the dimension is connected to the dimensions of the Listening and the Speaking Phases.Table 6.8Statistical analysis of the dimension ratings gathered in Session I of the validation experiment; Noisiness (), Discontinuity (), Coloration (), Loudness (), Impact of one's own voice (), Degradation of one's own voice (), and Interactivity () Mean stdANOVA






F

p


.926.3208.047.96



.986.4210.214.79



1.007.2239.122.20



.855.1167.24.93



.863.7121.883.98



.953.9131.153.77



.895.9193.133.53




Table 6.9Correlations between the dimension ratings for Noisiness (), Discontinuity (), Coloration (), Loudness (), Impact of one's own voice (), Degradation of one's own voice (), and Interactivity (). The correlations are significant at a  level 















1.244.391.135.210.220.306

.2441.541.071.262.264.564

.391.5411.196.365.392.540

.135.071.1961.085.079.144

.210.262.365.0851.873.557

.220.264.392.079.8731.555

.306.564.540.144.557.5551

In the first validation experiment (Sect. 6.2), it was observed that the two dimensions Coloration and Discontinuity seem to merge into one dimension. Here, the correlation between both dimensions result in a value of .541. This medium correlation assumes that there is a certain degree of dependency between these two dimensions. As this finding is conform to the results of the first validation experiment, a final interpretation of the dependency between Coloration and Discontinuity will be given when separately analyzing the Listening Phase in Session II (see Sect. 6.3.2.3).
The only dimensions that show a high correlation are the two speaking dimensions. It seems as if both dimensions are equally triggered whenever the speaking is somewhat degraded. It was already mentioned in Sect. 4.​3.​7 that the two dimensions might be dependent on each other in terms of their presence. The test subject can only perceive a degraded own voice if he or she hears the own voice, that also has an impact on the speaking. Still both dimensions were extracted within separate experiments (see Sect. 4.​3). Thus it needs to be investigated if this is due to the interpretation of the resulting dimensions or to the degradations used to trigger the dimensions. This finding will also be discussed when analyzing the speaking session of the experiment in Sect. 6.3.2.4.Fig. 6.3Subjective dimension ratings for Session I resulting from the validation experiment; Noisiness (), Discontinuity (), Coloration (), Loudness (), Impact of one's own voice (), Degradation of one's own voice (), and Interactivity (). The error-bars display the 95% confidence intervals



6.3.2.3 Dimension Quality Ratings Session II—Listening Phase

Table 6.10 shows the statistics mean and standard deviation for the dimension scales rated in Session II for the Listening Phase. The results mostly show a standard deviation below one. Again, compared to the overall conversational ratings presented in Sect. 6.3.2.1, standard deviations (slightly) above one occur more often. The average standard deviations for all four ratings are presented in Table 6.10. The results show that the average standard deviations for all four ratings are below .93. Thus, the low standard deviations validate that the dimension ratings show a high reliability.
As the second step, again a repeated measure ANOVA between the conditions and the four dimension ratings as dependent variables was carried out. The results are given in Table 6.11. The results show that the used conditions have a significant influence on all four dimension ratings ().Table 6.10Statistics for the dimension ratings in session II—Listening, obtained from the validation test. StdDev—standard deviationConditionNoisinessDiscontinuityColorationLoudness1Mean4.334.544.274.47StdDev.59.31.64.522Mean3.903.643.694.22StdDev.961.121.05.553Mean4.214.404.234.28StdDev.70.49.76.684Mean4.203.403.294.12StdDev.781.211.37.825Mean3.802.823.754.31StdDev1.031.201.02.516Mean1.594.223.904.17StdDev.42.68.96.697Mean4.424.454.283.55StdDev.55.30.59.988Mean2.572.602.083.44StdDev1.071.05.861.029Mean1.723.353.254.11StdDev.561.161.12.6110Mean2.562.652.153.56StdDev1.071.11.95.9411Mean3.842.873.814.24StdDev.911.21.97.56
Table 6.11Statistical analysis of the dimension ratings gathered in session II—Listening of the validation experiment; Noisiness (), Discontinuity (), Coloration (), and Loudness () Mean StdANOVA






F

p


.786.2204.471.52



.895.3173.825.78



.935.9196.131.11



.715.1165.810.17




Fig. 6.4Subjective dimension ratings for Session II—Listening resulting from the validation experiment; Noisiness (), Discontinuity (), Coloration (), and Loudness (). The error-bars display the 95% confidence intervals

In Fig. 6.4, the results presented in Table 6.10 and the corresponding 95% CI are illustrated. The figure shows that the four dimensions proposed for the Listening Phase are in particular triggered when degradations concerning the listening are applied. For example, in condition five (degraded by packet-loss) Discontinuity is rated significantly worse than the other dimensions. The same can be seen for condition six (degraded by noise and triggering Noisiness) and condition seven (degraded by attenuation and triggering Loudness). In condition eight (degraded by a codec and triggering Coloration), similar ratings as in Session I can be seen. While Coloration still is the dimension with the lowest rating, all other three dimensions of the Listening Phase are affected by the LPC-10 codec. Again, it seems that the codec is providing a too bad overall quality that has an impact on all four dimensions. In future experiments it should be considered to use a bandwidth limitation to trigger Coloration instead of a low quality parametric codec.
Figure 6.4 also shows that the two conditions that were supposed to only affect the speaking dimensions have a slight impact on the listening dimensions. For condition two and four, it can be seen that in both cases Coloration and Discontinuity get slightly lower ratings. This was already observed in Session I of the experiment. It is interesting, thus, that the four dimensions (Coloration, Discontinuity, Impact of one's own voice, and Degradation of one's own voice) only show a low correlation (see Table 6.9) while they seem to be triggered if the speaking is degraded. One explanation for this could be that the naïve test subjects hear a degraded version of their own voice and rate both, the listening dimensions and the speaking dimension, worse. This might be overcome when applying the proposed training presented in Sect. 5.​4.​2.
The ratings for the conditions with mixed degradation (condition nine, ten, and eleven) show similar ratings as the conditions with only single degradations. Looking for example at condition nine (degraded with noise and echo), it can be seen that Noisiness is the lowest rated dimension and that the other three dimensions almost get the same ratings as for the single echo degradation (see condition four). The same applies for condition ten, where the bad codec provokes similar ratings as in condition eight with the single codec degradation. Finally, comparing condition eleven and five, a similar observation can be made. In both cases the packet-loss provokes same ratings for the listening dimensions. In sum, the results show that the used scales for the Listening Phase work as intended and gather reliable and valid ratings.Table 6.12Correlations between the dimension ratings for Noisiness (), Discontinuity (), Coloration (), and Loudness (). The correlations are significant at a  level 









1.283.434.227

.2831.587.173

.434.5871.352

.227.173.3521

The correlation between the four listening dimension scales can be seen in Table 6.12. The values show that the used scales measure different constructs. However, the correlation between Discontinuity and Coloration (almost .6) again shows a tendency to be dependent on each other. The same observation was made in the first validation experiment and in Session I of this validation experiment. In future experiments, it has to be investigated if this is (a) due to the conditions used in the experiment or (b) due to a principle problem with the two dimensions. The first argument requires analyzing whether a packet-loss of 10% is distinct enough for naïve test subjects, or whether in future experiments it would be better to choose a different codec than LPC-10 to trigger Coloration. As mentioned before, LPC-10 seems to trigger more than one listing dimensions and thus might support a merge of the dimension ratings for Discontinuity and Coloration. The second point supports the findings made in [160] that test subjects tend to rate Coloration worse when they are not sure about the perceived degradation. However, the four listening dimensions were identified in separate experiments in [99] and proved to be independent. Thus, the relation between Discontinuity and Coloration should be further analyzed in additional experiments.Table 6.13Statistics for the dimension ratings in session II—Speaking, obtained from the validation test. StdDev—standard deviationConditionImpact of one's own voiceDegradation of one's own voice1Mean4.274.09StdDev.73.972Mean1.912.71StdDev.791.253Mean4.083.90StdDev.91.934Mean1.571.64StdDev.41.715Mean4.344.29StdDev.72.676Mean4.123.78StdDev.961.107Mean4.214.13StdDev.89.928Mean4.194.19StdDev.69.639Mean1.601.77StdDev.47.8610Mean1.831.96StdDev.76.9011Mean4.204.08StdDev.80.85



6.3.2.4 Dimension Quality Ratings Session II—Speaking Phase

Table 6.13 shows the statistics mean and standard deviation for the dimension scales rated in Session II for the Speaking Phase. The results show a standard deviation below one for all except two ratings (Degradation of one's own voice for condition two and six). The average standard deviations for the two ratings are presented in Table 6.14. The results show that the average standard deviations for the two ratings are below .80. Thus, the low standard deviations validate that the dimension ratings show a high reliability.
Second, again a repeated measure ANOVA between the conditions and the two dimension ratings as dependent variables was carried out. The results are given in Table 6.14. The results show that the used conditions have a significant influence on the two dimension ratings ().Table 6.14Statistical analysis of the dimension ratings gathered in session II—Speaking of the validation experiment; Impact of one's own voice () and Degradation of one's own voice () Mean stdANOVA






F

p


.732.891.8154.42



.883.8125.471.38




Fig. 6.5Subjective dimension ratings for session II—Speaking resulting from the validation experiment; Impact of one's own voice () and Degradation of one's own voice (). The error-bars display the 95% confidence intervals

In Fig. 6.5, the results of the speaking part in session II for the validation experiment and the 95% CI of the dimension ratings are illustrated. The first observation that can be made is that the two dimensions of the Speaking Phase are only triggered if the speaking is degraded. Thus, the dimension ratings for condition one, three, five, six, seven, eight, and eleven are almost the same. Only for condition six (degraded by noise), a slight effect of noise on the two speaking dimensions can be seen. Thus, it seems that either a strong noise might also have a small effect on the speaking (see the Lombard Effect introduced in Sect. 3.​4.​1), or that the noise masks the speaking degradations.
The results become more interesting when looking at the four conditions (two, four, nine, and ten) in which the speaking was degraded. Condition two was degraded by a sidetone that resulted in a very low dimension rating for the Impact of one's own voice. The dimension Degradation of one's own voice here also receives a low rating, but not as low as the one for Impact of one's own voice. However, for the second condition degraded by a sidetone (condition ten), the ratings for Impact of one's own voice and Degradation of one's own voice are almost equal. This is due to the fact that the back coupled own voice is also coded with the LPC-10 codec and thus is strongly degraded. In sum, it can be concluded that a sidetone has a strong impact on the speaking but only a moderate impact on the perceived degradation of the own voice if this is not degraded by a bad codec.
This is different for the conditions degraded by echo (condition four and nine). Here, both speaking dimensions, Impact of one's own voice and Degradation of one's own voice, receive a similarly low rating. Thus, it seems that for echo the test subjects rate the impact on the speaking and the degradation of the own voice as equally affected. In addition, for the echo conditions the Degradation of one's own voice is more affected than for the sidetone conditions. This is conform to the review made in Sect. 3.​4.​1, where it was stated that a delayed back coupling of the own voice is perceived as a colored version of the own voice. This could also be an explanation why the listening dimension Coloration is also provoked by these conditions (see Sect. 6.3.2.2)Table 6.15Correlations between the dimension ratings for Impact of one's own voice () and Degradation of one's own voice (). The correlations are significant at a  level 





1.846

.8461

The correlation between the two speaking dimensions scales can be seen in Table 6.15. The correlation between both dimensions is almost .85 and shows a strong dependency on both dimensions. This result is partly surprising and partly expected. It is surprising because the two dimensions were identified in two separate experiments with a subsequent multidimensional analysis. The results of the multidimensional analysis indicate that the identified dimensions are supposed to be independent. In addition, in the first validation experiment the two dimensions were again identified in session II. It was expected since the two dimensions are dependent on each other in terms of their presence (see Sect. 4.​3.​7). More precisely, the Degradation of one's own voice dimension can only be perceived if also the Impact of one's own voice dimension is triggered. Thus, the ratings result in different ratings if the own voice is not degraded (condition two) and in similar ratings if both dimensions are triggered (condition four, nine, and ten)
Another explanation for the high correlation and the low variety of the two speaking dimensions is the low number of conditions triggering the dimensions. In only four conditions the dimensions were triggered. In addition, the characteristics of the sidetone and the echo were not varied. In future experiments, new conditions with for example low, medium, and strong characteristics of echo and sidetone should be tested. The results of these experiments are then expected to show a lower correlation and a higher variation of the dimension ratings for Degradation of one's own voice and Impact of one's own voice.
In sum, the results show that the used scales for the Speaking Phase work as intended and gather reliable and valid ratings. However, in future experiments it should be analyzed if the high correlation between the two dimensions is due to the degradation in the used conditions or if there is a general problem for naïve test subjects to separate the two dimensions.Table 6.16Statistics for the dimension ratings in session III—Interactivity, obtained from the validation test. StdDev—standard deviationCondition1234567891011Mean4.483.172.572.904.113.784.473.472.852.762.65StdDev.361.05.961.04.851.02.28.911.051.011.01
Table 6.17Statistical analysis of the dimension ratings gathered in session III—Interaction of the validation experiment; Interactivity () Mean stdANOVA






F

p


.865.4176.928.17
.01



6.3.2.5 Dimension Quality Ratings Session III—Interaction Phase

Table 6.16 shows the statistics mean and standard deviation for the dimension scale rated in session III. The results show a standard deviation below one or slightly above one for all ratings. The average standard deviation for all ratings is presented in Table 6.17. The results show that the average standard deviation for the dimension ratings is .86. The low standard deviation validates that the dimension rating shows a high reliability.
As the second step of the analysis, again a repeated measure ANOVA between the conditions as independent and the dimension rating as dependent variable was carried out. The results are given in Table 6.17. Again, the results show that the used conditions have a significant influence on the Interactivity quality rating ()
The ratings of the perceptual quality dimension Interactivity are illustrated in Fig. 6.6 together with the 95% CIs. It can be seen that it seems to be difficult for naïve test subjects to adequately assess the dimension Interactivity. While the conditions three and eleven were degraded with a one-way delay of 1000 ms the ratings only show a slight difference to the other conditions. Indeed, the ratings for these two conditions are low, but the ratings show that in particular speaking degradations also affect the Interactivity ratings. While the ratings for the clean condition one and for the conditions triggering the dimensions of the Listening Phase (condition five, six, seven, and eight) are all high (3.5 and more), the conditions triggering the dimensions of the Speaking Phase also provoke a lower Interactivity rating. Thus, this observation indicates that a sidetone and/or an echo are also responsible for a shift of the natural conversation rhythm in terms of Interactivity.Fig. 6.6Subjective dimension ratings for session III—Interaction resulting from the validation experiment; Interactivity (). The error-bars display the 95% confidence intervals

Two possible explanations are seen for this observation. Firstly, the same as for the dimensions ratings concerning the Speaking Phase applies. Interactivity ratings are only triggered by a low number of two conditions. In future experiments more conditions with varying delay, for example a low, medium, and a strong delay, should be tested to verify this observation. Secondly, it is also possible that the presence of a transmission delay is generally difficult to perceive for naïve test subjects. They perceive a degradation in the transmission system but cannot link it to the interactivity or adapt their interaction behavior to minimize the perceived degradation (see Sect. 3.​5.​1). Actually, the RNVT was applied to minimize the difficulties in perceiving a transmission delay. Therefore, more prominent delay degradations should be applied in future tests to uncover the sensitivity of the test subjects for transmission delay.
In sum, the results show that the used scale for the Interaction Phase works as intended and gathers reliable and valid ratings. However, in future experiments it should be analyzed if the naïve test subjects provide similar ratings when more varying conditions concerning transmission delay and the Speaking Phase are tested.



6.3.3 Discussion and Conclusion
The results of the experiment to validate the new proposed test method show that the dimension scales, their rating scheme, as well as the estimated test duration work as introduced in Chap. 5. Especially, the dimension scales measure what they were designed for and the test method works in a meaningful and reliable way. However, the results also revealed three issues that should be addressed in future experiments.
Firstly, for the perceptual quality dimensions regarding the Listening Phase it was observed that the two dimensions Coloration and Discontinuity seem to depend on each other. It was discussed whether this is due to the conditions used in the test or if there is a principle problem with the two dimensions. Their relation should be analyzed in further experiments.
Secondly, for the Speaking Phase, the results showed that the two perceptual dimensions Degradation of one's own voice and Impact of one's own voice depend on each other in terms of their presence and highly correlate. Again, this observation might be due to the particularities of the conducted experiment or due to the characteristics of the two dimensions. In future experiments more distinct and varying conditions triggering the two perceptual dimensions should be tested to verify the findings made.
Thirdly, the dimension of the Interaction Phase shows low ratings for conditions triggering the Interaction Phase and the Speaking Phase. It has to be verified, if this is due to the prominence of the applied degradations or if there is a general problem for test subjects to perceive this dimension as intended.
Apart from these issues, the proposed test method promises to provide a valid, meaningful, time as well as cost saving, and feasible method for analyzing and optimizing telecommunication systems.

For the first time, it is validated that it is possible to analyze all aspects of a conversation (
Listening
,
Speaking
and
Interaction Phase
) with one single test method.

However, the test method must be validated in further experiments testing other and more distinctive conditions. In addition, the training proposed in Sect. 5.​4.​2 should be applied in future experiments using the new test method.



6.4 Comparison of the Two Validation Experiments
As the last part of this chapter, the experiments to validate the identified perceptual quality space in a conversational situation (first validation experiment, see Sect. 6.2) and to validate the new proposed test method (second validation experiment, see Sect. 6.3) are compared. This comparison is done to verify that in both experiments the test subjects perceived the presented degradation in a similar way. The comparison of the experiments is possible since in both experiments the same degradations were presented in the same conditions under test.
It would be interesting to compare the ratings of the new proposed test method as it was also used in both experiments. As a matter of fact, in the first validation experiment an adapted version of the new test method was used. Instead of directly scaling the identified perceptual quality dimensions, the test subjects were asked to rate the APs used in the identification experiments presented in Chap. 4. Thus, the comparison of both experiments based on the dimension ratings is not possible. The comparison will therefore be limited to the overall conversational quality ratings.Fig. 6.7Subjective overall quality ratings from the experiment to validate the perceptual quality space () and the experiment to validate the new test method (). The error-bars display the 95% confidence intervals

It was already shown that in both experiments the conditions under test had a significant influence on the overall quality ratings, see Sect. 6.2.2 and 6.3.2.1, respectively. Figure 6.7 shows the overall quality ratings for both experiments for each condition under test. It can be seen that the overall conversational quality ratings are in principle conform for both experiments. This is confirmed by the correlation between both ratings that is .
The only discrepancy that can be seen in Fig. 6.7 are the overall quality ratings for condition five and seven. It seems that for these two conditions the test subjects in the second validation experiment tend to give higher ratings. However, this trend cannot be seen for the other nine conditions. Thus, the discrepancy is explained by regular rating variations in two experiments.
In sum, the comparison of the overall conversational quality ratings of both validation experiments shows that the conditions under test worked as intended in both experiments. For all eleven conditions under test the (different group of) test subjects rated the overall conversational quality in the same way. A future experiment with dimension ratings could allow performing a similar comparison on the dimension ratings. Having this comparison at hand would finally validate the identified perceptual quality dimensions and the proposed test method.


6.5 Conclusion
In the two previous Chaps. 4 and 5, the perceptual quality space in a conversational situation and a new test method for directly scaling the identified perceptual quality dimensions were presented. In this chapter, the presented work of both chapters was validated. Regarding the identified perceptual quality space, the identified perceptual dimensions of all three phases were identified in a multidimensional analysis of a single conversational test considering quality elements of all three phases. The results showed that in a solely conversational task the test subjects have difficulties to identify all seven proposed dimension. Thus, the proposed test method that specifically allows the test subjects to perceive each phase separately should be used when diagnosing a telephone conversation. The second experiment to validate the new proposed test method revealed that the test method provides a meaningful approach to scale the identified perceptual dimensions in a direct way by test subjects. It was validated that the dimension scales measure what they were designed for, that the test procedure works as intended, and that the estimated test duration is true for the first pilot test.
However, the results of the two validation experiments also showed that particular issues should be analyzed in future experiments. The dependency of the two listening dimensions Coloration and Discontinuity as well as of the two speaking dimensions Degradation of one's own voice and Impact of one's own voice should be addressed in future studies. In addition, the characteristics and the ratings of the dimension Interactivity should be analyzed if the test method is used again.
The named issues are not considered to be a problem of the identified perceptual quality space or the test method, but rather of the particularities of the conducted experiments. In future test, care should be taken that each expected perceptual dimension is separately covered by a sufficient number of technical conditions. For example, for the perceptual dimensions that should be further analyzed, three distinct conditions with three different characteristics of a technical degradation should be applied. In addition, the training proposed in Sect. 5.​4.​2 should be applied for future experiments using the new test method.
In sum, the proposed perceptual quality space and the test method work as intended. As the next step, the proposed test method should be used for further experiments to gather additional ratings and to finish the validation process of the new test method. Especially, the dimension ratings of two independently conducted experiments using the test method should be compared (see Sect. 6.4). Apart from that, the test method should also be tested by other independent research laboratories to advance the standardization process of the ITU work item P.CQS (see Sect. 5.​5).












© Springer Nature Singapore Pte Ltd. 2018


Friedemann Köster



Multidimensional Analysis of Conversational Telephone Speech


T-Labs Series in Telecommunication Services


https://doi.org/10.1007/978-981-10-5224-8_7





7. Resulting Quality Profile in a Telephone Conversation




Friedemann Köster
1  




(1)
Quality and Usability Lab, Technical University of Berlin, Berlin, Germany

 



 

Friedemann Köster


Email: 
friedemann.koester@tu-berlin.de







7.1 Introduction
Based on the results of the experiments conducted in Chap. 6, it is possible to analyze the relation between the overall conversational quality ratings, the overall phase quality ratings, and the dimension ratings. Especially the ratings obtained from the second validation experiment (to validate the new proposed test method, see Sect. 6.​3) aim at identifying the relation between the three different rating types. Thus, based on these ratings, the relation between all the gathered ratings of the second validation experiment will be identified in this chapter. The work presented in the following is addressing the fourth research topic (Modeling) stated in Sect. 3.​6.
The underlying idea—that has already been proven in [2] and was introduced in Sect. 2.​3.​3—is that the dimensions, as they are orthogonal, can be combined to a quality rating for each conversation phase, and that the quality ratings for each phase, in turn, can be used to determine the overall conversational quality. To follow this approach, the weights of the individual phases for the overall conversational quality, and the weights of the perceptual quality dimensions for the quality of each individual phase have to be identified.
Based on the approach of a vector model (see Sect. 2.​3.​3), it was decided to apply a multiple linear regression to identify the relation between the different rating types. Linear regression was chosen (i) for its simplicity and (ii) by its similarity to the estimation of audiovisual quality, where two dimensions (audio and video) are estimated with linear models [161]. Hence, the estimated quality values (overall conversation quality or the overall quality of a specific phase) are estimated according to the following regression equation: (7.1)Here, Over corresponds to either the overall conversation quality (CO) or the overall quality of a specific phase, the Listening Phase (LI), the Speaking Phase (SP), or the Interaction Phase (IN). In addition, the J in the sum is dependent on what quality value is estimated and what dimension or phase ratings are used for the linear regression model. This could either be the dimension ratings (Noisiness (Noi), Discontinuity (Dis), Coloration (Col), Loudness (Lou), Impact of one's own voice on speaking (Ios), Degradation of one's own voice (Dos), or Interactivity (Int)) or the ratings of a specific conversational phase (the Listening Phase (LI), the Speaking Phase (SP), or the Interaction Phase (IN)). Thus,  and  if the relation between the dimension ratings and an overall phases quality rating is analyzed or  if the relation between the overall conversational quality and the ratings for the conversational phases are analyzed.
The performance of the developed regression models (and of the models presented in Chap. 8) is evaluated by two common statistical measures. These two measures are per-condition measures. Thus, the two statistical measures are calculated after averaging the individual (subjective or instrumental) scores into MOS values for each condition under test. The first statistical measure is calculating the consistency of the developed model by measuring the linear relationship between the subjective and the predicted scores. This statistical measure is called Pearson correlation coefficient (r) and is calculated as follows: (7.2)where  (or ) is a subjective (or estimated) MOS value for condition ;  (or ) is the mean subjective (or estimated) MOS value over all conditions.
While the correlation coefficient is a meaningful measure for the consistency of the developed model, it does not provide information about the model's accuracy [3]. Thus, the accuracy of the developed instrumental models is evaluated using the Root Mean Square Error (RMSE), which is the standard deviation of the prediction error. The RMSE is calculated as follows: (7.3)These analyses and the identification of the relation between the perceptual quality dimensions and the overall quality values are essential for a possible instrumental estimation of the overall conversational quality based on the perceptual quality dimensions. Thus, the work presented in the following forms the basis for a potential new conversational instrumental quality estimator as demanded by the ITU-T in the work item P.CQO. A first approach for such an estimator that is based on the findings made in this chapter is presented in Chap. 8.
In this chapter, the relation between the ratings obtained in the second validation experiment will be analyzed in three steps. First, the relation between the dimension scores and the overall conversational quality will be analyzed in Sect. 7.2. Second, the relation between the dimension scores and the quality of individual conversational phases will be identified in Sect. 7.3. In Sect. 7.4, the relation between the overall conversational quality and the quality of individual phases will be presented. This results in a final recommended quality profile. The chapter closes with a conclusion in Sect. 7.5.
Please note that the following analyses of the relations between the gathered ratings are exclusively based on the one conducted experiment presented in Sect. 6.​3. The ratings are averaged for each condition under test (eleven data points). Thus, all models presented in the following are based on these averaged values for each rating. Regarding the maximum number of predictors to be used in a regression model, no strict rule is available, but it is a rule of thumb to use at least fewer predictors than data points [162]. In the following analyses this rule is always respected. In addition, in [163] guidelines for applying regression models are given. It is recommended to have at least 40 data points for a regression model with two to seven predictors. However, for these analyses only eleven data points are available. Therefore, the relations and analyses are true for the conducted experiment, but it is not guaranteed that they are also true for all other experiments using the new test method and the new perceptual quality space. So, this is a first step to identify the relation between the perceptual quality dimensions and the overall quality values. A final interpretation is only possible if more data gathered with the new test method is available. Parts of the work illustrated in this chapter are based on the ideas and the data presented in the former publication [164].


7.2 Relation Between the Dimension Scores and the Overall Conversational Quality
The analysis of the relation between the dimension ratings and the overall conversational quality is based on the ratings gathered in session I of the second validation experiment (see Sect. 6.​3.​2.​2). Thus, the relation between the overall conversational quality  and the ratings for all seven perpetual dimensions (Noisiness (), Discontinuity (), Coloration (), Loudness (), Impact of one's own voice (), Degradation of one's own voice (), and Interactivity ()) is analyzed with a linear regression model.
The analysis of the linear regression is given in Table 7.1. The regression reaches a  value of .96 and a RMSE of .25. The significance test reveals that the seven predictor coefficients are not statistically significant different from zero (). An explanation for this is the high collinearity (Variance Inflation Factor ) of the seven predictors and their shared variances. This can also be seen in Table 6.​3, that shows the correlations between the seven perceptual dimensions. Especially the perceptual dimension Interactivity is correlated with the other six dimensions. In addition, the table shows a slight dependency between the other perceptual dimensions. If the predictors are correlated, they are interchangeable in the regression model. Thus, in this case, all seven perceptual dimensions are not unavoidably necessary for a regression model with an equal performance. However, in this particular case, all seven predictors are used as the aim was to analyze the relation between the overall conversational quality and all seven perceptual dimensions. An additional explanation for the low significance of the predictors is the low number of available data points (see Sect. 7.1). However, the ANOVA of the regression model shows that it is significant ().
Table 7.1 shows also the weight of each perceptual dimension for the regression model to estimate the overall conversational quality. The standardized  coefficients reveal whether a perceptual dimension has a high or a low impact on the overall conversational quality. It can be seen that the Interactivity has the by far highest impact on the overall conversational quality. This was expected since the Interactivity of the Interaction Phase is an important part of the conversation as it describes how the two interlocutors interact with each other. As the second highest impact on the overall conversational quality the three perceptual dimensions Impact of one's own voice, Degradation of one's own voice, and Noisiness follow. However, one speaking dimension has a positive impact (Impact of one's own voice), while the second speaking dimension has a negative impact (Degradation of one's own voice). As both dimensions correlate (see Chap. 6), the impact of the two dimensions might compensate each other which leads to a lower impact than Noisiness. This, however, has to be validated in further experiments. Just looking at the data of Table 7.1, it seems that the Speaking Phase with its two underlying perceptual dimensions is besides the Interactivity of high importance for the overall conversational quality. Regarding the Listing Phase, only Noisiness seems to have an impact of the overall quality. Discontinuity, Coloration, and Loudness show no impact in this regression model.Table 7.1Multiple linear regression analysis for predicting the overall conversational quality () on the basis of its seven underlying perceptual quality dimensions; Noisiness (), Discontinuity (), Coloration (), Loudness (), Impact of one's own voice (), Degradation of one's own voice (), and Interactivity ()PredictorStandardized  coefficientT-stat



.3893.04.05

−.020−.06.95

−.025−.10.92

.032.23.83

.464.52.64

−.327−.39.72

.6951.50.23


Fig. 7.1Estimated  versus subjective 


The regression model allows to replace the coefficients from (7.1) () with values that enable an estimation of the overall conversational quality. This leads to the following equation: (7.4)Applied to the subjective ratings for the seven dimensions, the regression model estimates the subjective  values with a correlation of  and a RMSE of .13. Figure 7.1 displays the regression between the estimated  values and the subjective  values. The figure shows that the regression model estimates the overall conversational quality with high reliability and accuracy. However, by using seven predictors that are partly correlated (and thus not significant) the regression model seems to be over-fitted. Besides gathering more data points, it should be considered to analyze each conversational phase separately and then map the overall conversational quality based on the three conversational phases and its underlying perceptual dimensions. This way, the significance of the regression predictors should be restored and the over-fitting should be minimized. The proposed changes are presented in following sections.


7.3 Relation Between the Dimension Scores and the Quality of Individual Phases
As the regression model to estimate the overall conversational quality on the basis of the seven identified perceptual dimensions showed to be over-fitted and the predictors were not significant, in this section, the weights of the perceptual quality dimensions for the quality of each individual phase are identified. Again, multiple linear regression based on the vector model is applied. Based on the outcome of the following analyses, the overall conversational quality can be estimated based on the estimations of the three conversational phases (see Sect. 7.4). In this section, first the Listening Phase, second the Speaking Phase, and finally the Interaction Phase are analyzed.Table 7.2Multiple linear regression analysis for predicting the overall listening quality () on the basis of its four underlying perceptual quality dimensions; Noisiness (), Discontinuity (), Coloration (), and Loudness ()PredictorStandardized  coefficientT-stat



.5597.06.00

.4724.05.01

.110.69.51

.1301.38.21


Listening Phase

The analysis of the relation between the dimension ratings and the overall quality of the Listening Phase is based on the ratings gathered in session II (listening) of the second validation experiment (see Sect. 6.​3.​2.​3). Thus, the relation between the overall listening quality  and the ratings of its four underlying perceptual dimensions (Noisiness (), Discontinuity (), Coloration (), and Loudness ()) is analyzed with a linear regression model.
The analysis of the linear regression is given in Table 7.2. The regression reaches a  value of .97 and a RMSE of .17. The significance test reveals that two of the four predictor coefficients are not statistically significantly different from zero (). This can again be explained with a high collinearity () of the two predictors and their shared variances. The low significance for Coloration can be explained with the high correlation between Coloration and Discontinuity (see Table 6.​12). It was already mentioned in Chap. 6 that their dependency should be further analyzed in future experiments. The high correlation makes the two predictors (for Coloration and Discontinuity) interchangeable and thus one of them not significant. In addition, Loudness shows to have no significant impact on the overall listening quality. Again, this result can be explained with the low number of data points. Testing more conditions triggering the Loudness in future experiments should make the Loudness predictor significant.
In similar studies presented in [2], the relation between the perceptual quality dimensions of the Listening Phase and the overall listening quality was analyzed in a LOT. It was shown that Discontinuity and Noisiness have the highest impact on the overall listening quality. Thus, the results presented in [2] are analogue to the results present in Table 7.2 (see the standardized  coefficients).Fig. 7.2Estimated  versus subjective 


Compared to the regression model applied in Sect. 7.2, the model to estimate the overall listening quality based on its four underlying perceptual quality dimensions shows to be statistically more robust. In addition, the ANOVA of the regression model shows that it is significant (). Again, the regression model allows replacing the regression coefficients from (7.1) with values that enable to estimate the overall listening quality as follows: (7.5)Applied to the subjective ratings for the four dimensions, the regression model estimates the subjective  values with a consistency of  and an error of . Figure 7.2 displays the regression between the estimated  values and the subjective  values. The figure shows that the regression model estimates the overall conversational quality with high reliability. The model is not over-fitted, but Coloration and Loudness seem to have a rather low impact on the overall listening quality. Gathering more data points and analyzing the dependency between Coloration and Discontinuity in future experiments should provide significant predictors for Coloration and Loudness.Table 7.3Multiple linear regression analysis for predicting the overall speaking quality () on the basis of its two underlying perceptual quality dimensions; Impact of one's own voice () and Degradation of one's own voice ()PredictorStandardized  coefficientT-stat



.033.05.95

.9031.47.18


Speaking Phase

The analysis of the relation between the dimension ratings and the overall quality of the Speaking Phase is based on the ratings gathered in session II (speaking) of the second validation experiment (see Sect. 6.​3.​2.​4). Thus, the relation between the overall speaking quality  and the ratings of its two underlying perceptual dimensions (Impact of one's own voice (Ios) and Degradation of one's own voice (Dos)) is analyzed with a linear regression model.Fig. 7.3Estimated  versus subjective 


The analysis of the linear regression is given in Table 7.3. The regression reaches a  value of .87 and a RMSE of .38. The significance test reveals that the two predictor coefficients are not statistically significantly different from zero (). Again, this can be explained with a high collinearity () of the two predictors and their high correlation (see Table 6.​15). As mentioned before, the dependency of both perceptual dimensions should be analyzed further, while their peculiarities in terms of their presence have already been discussed in Sect. 6.​3.​2.​4. At this point, a definite interpretation of their impact on the overall speaking quality is difficult as their predictors are interchangeable. The ANOVA of the regression model shows that it is significant (). To estimate the overall speaking quality, the regression coefficients from (7.1) are replaced with the regression predictors resulting from the regression model: (7.6)
Table 7.4Multiple linear regression analysis for predicting the overall interaction quality () on the basis of its one underlying perceptual quality dimension; Interactivity ()PredictorStandardized  coefficientT-stat



.9116.62.00

Applied to the subjective ratings for the two dimensions, the regression model estimates the subjective  values with a correlation of  and a RMSE of .33. Figure 7.3 displays the regression between the estimated  values and the subjective  values. The figure shows that the regression model estimates the overall conversational quality with high accuracy. Again, more data points and more analyses are necessary to provide a robust modeling of the speaking quality based on its two perceptual quality dimensions. However, for the available data, the applied regression model provides reliable results with a high correlation and a small error.

Interaction Phase

The analysis of the relation between the dimension rating and the overall quality of the Interaction Phase is based on the ratings gathered in session III of the second validation experiment (see Sect. 6.​3.​2.​5). Thus, the relation between the overall interaction quality  and the ratings of its underlying perceptual dimensions Interactivity is analyzed with a linear regression model.
The analysis of the linear regression is given in Table 7.4. The regression reaches a  value of .83 and a RMSE of .32. The significance test reveals that the predictor coefficient is statistically significantly different from zero (). The ANOVA of the regression model shows that it is significant (F(1, 9) = 43.867, ). The regression allows replacing the regression coefficients from (7.1) with the regression predictors as follows: (7.7)Applied to the subjective ratings for the one dimension, the regression model estimates the subjective  values with a consistency of  and an error of . Figure 7.4 displays the regression between the estimated  values and the subjective  values. It can be seen that the regression model provides reliable results with a high correlation and a small error. However, more data points are again demanded to provide a robust model that is also valid for conditions with different characteristics triggering the Interaction Phase (see discussion in Sect. 6.​3.​2.​5).Fig. 7.4Estimated  versus subjective 

Table 7.5Multiple linear regression analysis for predicting the overall conversational quality () on the basis of its three conversational phases; the Listening Phase (), the Speaking Phase (), and the Interaction Phase ()PredictorStandardized  coefficientT-stat



.1992.26.05

.4424.75.00

.4574.38.00



7.4 Relation Between the Overall Conversational Quality and the Quality of Individual Phases
Knowing the relations between the perceptual quality dimensions and the three conversational phases allows modeling the ratings for each conversational phase. Now, to estimate the overall quality, the weights of the three individual conversational phases for the overall conversational quality have to be identified.
The analysis of the relation between the three conversational phases ratings and the overall conversational quality is based on the ratings gathered in all three sessions of the second validation experiment (see Sect. 6.​3.​2.​1). Thus, the relation between the overall conversational quality  and the ratings of its three conversational phases (the Listening Phase (LI), the Speaking Phase (SP), and the Interaction Phase (IN)) is analyzed with a linear regression model.
The analysis of the linear regression is given in Table 7.5. The regression reaches a  value of .97 and a RMSE of .15. The significance test reveals that one of the three predictor coefficients is not statistically significantly different from zero (). Again, an explanation for this is the low number of available data points. However, the p value is not below but equal .05 (). Thus, all predictors of the applied regression model have a significant impact for the model. In turn, this means that all three conversational phases make a significant contribution for estimating the overall conversational quality. The ANOVA of the regression model shows to be significant ().
The standardized  coefficients allow to draw a conclusion about the relation between the overall conversational quality and its three conversational phases. It can be seen, that the Interaction Phase seems to have the biggest impact on the overall conversational quality. This is proven by the high correlation between the ratings of the phase and the overall quality (see Table 6.​6) as well as by the high weighting in the regression model (see Table 7.5). A similar observation has also been made in [67], where the quality element delay (triggering the Interaction Phase as introduced in Chap. 3) showed to have a significant impact on the overall quality. This finding is explained with the high importance of the Interaction Phase in a conversation: On the one hand, a conversation is always connected with a certain degree of interaction that typically affects the overall impression of a conversation, on the other hand, the Interaction Phase is connected to the Speaking and Listening Phase (see high correlation between the three phases in Table 6.​6) and thus, interaction is affected by speaking and listening, and indirectly affects the overall conversational quality.
For the overall conversational quality, the Speaking Phase has a higher impact than the Listening Phase (see Table 7.5). From this it follows, that degradations that affect the Listening Phase (e.g. attenuation) only partly affect the overall conversational quality. Degradation concerning the Speaking Phase (e.g. echo), however, show to have a high impact regarding the overall conversational quality. These findings are in line with the observations made in Sect. 7.2. Here the relation between the overall conversational quality and its underlying seven perceptual dimensions were presented. The results showed that Interactivity (from the Interaction Phase) has the highest impact on the overall conversational quality, while the perceptual dimensions of the Speaking Phase have a higher impact than the perceptual dimensions of the Listening Phase. However, as described in Sect. 7.2, it has to be further investigated how the impact of the two speaking dimension can be seen in relation to each other, and what conclusions could be drawn from these investigations in the context of the conversational phases.
Again, the multiple regression model reveals the regression coefficients from Eq. 7.1 to estimate the overall conversational quality based on its three conversational phases: (7.8)Equation (7.8) is applied to the subjective ratings for the overall quality of the three conversational phases. The regression model estimates the subjective overall conversational quality  with a correlation of  and a RMSE of .13. An overview of the estimations can be seen in Fig. 7.5, that displays the regression between the estimated  values and the subjective  values. It can be seen that the developed model provides reliable results with a high correlation and a small error.Fig. 7.5Estimated  versus subjective 



Resulting Quality Profile

The models presented in Sect. 7.3 and the regression model to estimate the overall conversational quality based on the three conversational phases can be combined. This results in a quality profile and a model to estimate the overall conversational quality based on the seven perceptual quality dimensions of a conversational situation. The resulting quality profile is formed in two consecutive steps:1.The quality of the three conversational phases (, , and ) is estimated based on their underlying perceptual dimensions according to (7.5), (7.6), and (7.7). 2.The overall conversational quality  is estimated based on the estimations of the conversational phases in step 1 according to (7.8). 

Executing the two combination steps leads to the following equation to estimate the overall conversational quality based on its seven underlying perceptual dimensions: (7.9)Applying (7.9) on the available ratings for the seven perceptual dimensions results in an estimation with a correlation of  and an error of . Figure 7.6 shows an overview of the estimated  values and the subjective  values for the eleven data points. It can be seen that the developed model provides reliable results with a high correlation and a small error.
Compared to the estimation model presented in Sect. 7.2 (estimating the overall conversational quality directly from the seven perceptual dimensions, see (7.4)) the new quality profile provides a little lower correlation and little higher error. However, the proposed quality profile provides three major advantages in comparison to the estimation approach presented in Sect. 7.2:It estimates the overall conversational quality and the quality of the three conversational phases. Thus it gives more information than the approach of Sect. 7.2.It is significant and not over-fitted.It allows to analyze the relation and the dependencies between the perceptual dimensions, the three conversational phases, and the overall conversational quality.

In sum, the presented resulting quality profile fulfills the requirements of a quality profile (see Sect. 2.​3.​3) and gives additional and diagnostic information about the three conversational phases, and thus, about a telephone conversation.Fig. 7.6Estimated  versus subjective  based on the new quality profile



7.5 Conclusion
In this chapter, the resulting quality profile in a telephone conversation was presented. For this, the relations and weights between the seven identified perceptual quality dimensions, the three conversational phases, and the overall conversational quality have been analyzed and identified. In sum, five regression models were developed. The resulting quality profile uses three of the developed models to estimate the quality of each of the three conversational phases based on their underlying perceptual quality dimensions. To estimate the overall quality, a fourth developed model that is based on the quality values of the three conversational phases, is used. The new quality profile thus gives information about the overall conversational quality and the quality of the three conversational phases based on the seven perceptual quality dimensions. The developed model provides reliable results with a high correlation and a small error.
However, the analyses showed that more data for more conditions under test are needed to prove the robustness of the new quality profile. As mentioned in the introduction (see Sect. 7.1) of this chapter, the presented models are based on the second validation experiment (see Sect. 6.​3) that tested eleven conditions. Thus, more varying conditions with different characteristics should be tested in the future to provide more data points to train and validate the proposed quality profile.
In sum, the new quality profile allows analyzing, diagnosing, and estimating the quality in a telephone conversion. In addition, the quality profile forms the fundamental base for future instrumental quality models. Based on the needs and the requirements the model should fulfill, the quality profile gives the possibilities to estimate the overall conversational quality either on the base of its seven perceptual quality dimensions or on its three conversational phases. A first approach towards such an instrumental conversational quality model is given in the next chapter.












© Springer Nature Singapore Pte Ltd. 2018


Friedemann Köster



Multidimensional Analysis of Conversational Telephone Speech


T-Labs Series in Telecommunication Services


https://doi.org/10.1007/978-981-10-5224-8_8





8. Instrumental Diagnostic Conversational Quality Modeling




Friedemann Köster
1  




(1)
Quality and Usability Lab, Technical University of Berlin, Berlin, Germany

 



 

Friedemann Köster


Email: 
friedemann.koester@tu-berlin.de







8.1 Introduction
The work presented in this book, so far, was conducted with the final goal to develop an instrumental diagnostic conversational quality model. The identification of the perceptual quality space and its corresponding perceptual dimensions in a conversational telephone conversation (see Chap. 4), the test method to gather subjective ratings of these perceptual dimensions (see Chap. 5), the validation of the perceptual quality space and the test method (see Chap. 6), and finally the identification of the relations between overall conversational quality, its three phases, and the seven perceptual dimensions (see Chap. 7), forms the necessary basis to develop such a model. Thus, a first approach to develop an instrumental diagnostic conversational quality model is presented in this chapter. The work presented in the following is addressing the fifth research topic (Estimation) stated in Sect. 3.​6. In addition, the presented approach may be used as a potential starting point for the instrumental conversational model demanded by the ITU work item P.CQO.
As the first step of this chapter, the general approach in terms of technical requirements and specifications is introduced in Sect. 8.2. The presented instrumental model is targeting at estimating the overall conversational quality based on its seven underlying perceptual quality dimensions. For the four perceptual dimensions of the Listening Phase, an instrumental diagnostic model, called DIAL (see Sect. 3.​3.​3), already exists and is thus used to estimate the perceptual dimensions of the Listening Phase. Therefore, three separate dimension estimators for the three remaining perceptual dimensions grouped by the two remaining conversational phases have to be developed. The separate estimators are presented according to their conversational phases. The results of the DIAL model for the Listening Phase are presented in Sect. 8.3, the estimators for the Speaking Phase are introduced in Sect. 8.4, and in Sect. 8.5, the dimension estimator for the Interaction Phase is explained. These three sections are all structured in the same way: first the development and evaluation of the separate dimension estimators are introduced, and second, based on these estimations, the modeling of the overall phase quality estimations is presented. These estimations are finally used to model the overall conversational quality in Sect. 8.6. The chapter closes with a conclusion in Sect. 8.7.
Please note that the following development and evaluation of the instrumental models are based on the one conducted experiment presented in Sect. 6.​3. Again, the evaluation is based on the eleven data points available. Therefore, the estimations and the results are considered to be true for the available data, but it is not guaranteed that they are also true for all other experiments using the new test method and the new perceptual quality space. A final recommendable instrumental diagnostic conversational-quality model can only be developed if more independent data is available. Therefore, the work presented in this chapter is considered as a first approach towards such a model, but not as a final model.


8.2 General Approach
The new instrumental diagnostic conversational-quality model is targeting at providing estimations for the overall conversational quality, for the three conversational phases, and for the seven conversational perceptual quality dimensions. Thus, the model provides more detailed information about the overall conversational quality and allows diagnosing the source of a possible degradation. The model is designed to work in the Super-Wideband operational mode. In this model, the input speech samples are scored against a S-WB reference signal to predict the perceptual dimension and overall quality scores on a corresponding scale. The model is based on the subjective scores gathered with the new test method presented in Chap. 5.

Model Classification

The new model is a full-reference signal-based instrumental model. Thus, the model requires reference speech signals and corresponding degraded speech signals.

Model Input and Output

The model requires four input speech signals sampled at 48 kHz. These four input speech signals are divided into two digital reference ( and ) and two digital degraded speech signals ( and ). The reference signals are the clean, non-degraded, speech signals. They are captured at the microphones of the user terminals of both subjects participating in a conversation. The degraded signals are the speech signals degraded or impaired by the transmission system. They are captured at the speakers of the user terminals of both subjects participating in a conversation. An illustration of capturing the model input signals is given in Fig. 8.1. The four input signals allow estimating the subjective ratings given by both test subjects. In sum, for each transmission-system condition under test, the four signals will be captured for all three sessions of the test method (see Chap. 5). Depending on the dimensions to be estimated, particular parts of the captured signals of each session will be isolated. A detailed description of the used signals will also be given in the following subsections.
The model will output eleven scores for each test subject and each condition:Estimated perceptual dimension value for Noisiness 
Estimated perceptual dimension value for Discontinuity 
Estimated perceptual dimension value for Coloration 
Estimated perceptual dimension value for Loudness 
Estimated perceptual dimension value for Impact of one's own voice on speaking 
Estimated perceptual dimension value for Degradation of one's own voice 
Estimated perceptual dimension value for Interactivity 
Estimated phase quality value for the Listening Phase 
Estimated phase quality value for the Speaking Phase 
Estimated phase quality value for the Interaction Phase 
Estimated overall conversational quality value .

Each perceptual quality dimension is estimated with an individual dimension estimator. The overall quality values are modeled based on the dimension estimations and their relations to the overall quality values according to Chap. 7. The estimations are again evaluated with the statistical measures correlation and RMSE (see Sect. 7.​1). An overview of the structure of the new instrumental model is given in Fig. 8.15.Fig. 8.1Reference and degraded speech signals that serve as input for the new instrumental diagnostic conversational-quality model



8.3 Modeling Perceptual Dimension Scores of the Listening Phase
As mentioned before, the four perceptual quality dimensions of the Listening Phase will be estimated with the DIAL model [3]. DIAL was already introduced in Sect. 3.​3.​3 as a full-reference signal-based diagnostic instrumental model for the Listening Phase. An overview of the DIAL model can be seen in Fig. 8.2. DIAL is composed of four individual dimension estimators for each of the four perceptual quality dimensions of the Listening Phase. Each dimension estimator is based on two to three indicators that will be explained for each estimator in detail. In addition, the model is composed of a core model that estimates the overall listening quality. However, for the new conversational model, only the dimension estimators will be used.Fig. 8.2Overview of the DIAL model [3]

As DIAL is a full-reference signal-based model, it requires a clean reference signal (x(k)) and a degraded signal under test (y(k)). To provide input for the four dimension estimators for the new conversational model, the captured signals of the listening part of the second session of the new test method are isolated. By doing that, only signals that are directly connected to the Listening Phase are provided. As the input for the dimension estimators, the system input and the system output signals, depending on the subject's ratings that should be estimated, are used (see Fig. 8.1). Thus, if the subjective ratings of subject one should be estimated, the system input at subject two () is used as the reference signal (x(k)) and the system output at subject one () is used as the degraded signal (y(k)).
The DIAL model and its four dimension estimators work in an S-WB operation mode and require input signals with a sampling frequency of 48 kHz. This meets the specifications of the new conversational model. In the following, the four dimension estimators and their evaluation on the available data is presented. For detailed information about the indicators used by the dimension estimators see [3].

Discontinuity

The Discontinuity estimator of the DIAL model is based on three indicators to map the subjective Discontinuity ratings (see Fig. 8.2). The level variation () describes variation in the level of the speech signal. If for example a PLC with a ZI is applied in a transmission system, a level attenuation is produced. This is captured by the () indicator. If the PLC algorithm is not using a ZI, the lost frames may be interpolated from the previous frames. This leads to spectral distortions in the interpolated frames in the degraded signal. To cover these distortions, the artifact rate () is computed and used for the dimension estimator. The third indicator is called the interruption rate () and describes a long level attenuation triggered by long speech cut-outs due to for example high packet-loss. The three indicators are combined in a linear model to estimate the Discontinuity .Fig. 8.3Estimated  versus subjective  using the Discontinuity estimator of the DIAL model. The numbers indicate the conditions (see Tables 6.​2 and 6.​10)

The Discontinuity estimator is applied to the available signals for all 36 test subjects and for all eleven conditions under test (see Sect. 6.​3). For the evaluation the estimations and the subjective ratings are averaged over all test subjects to provide per-condition values. In relation to the subjective Discontinuity ratings the estimator achieves a correlation of  and an error of . Figure 8.3 shows an overview of the estimated  values and the subjective  values for the eleven data points. It can be seen that the Discontinuity estimator provides accurate estimations. However, subjectively low rated conditions seem to be slightly underestimated. In addition, for conditions with subjective Discontinuity ratings between three and four the estimator shows to have difficulties to provide precise estimations. This finding should be investigated further if more data with equal subjective ratings is available. In sum, the Discontinuity estimator provides reliable results with a high correlation and a small error.

Noisiness

As can be seen in Fig. 8.2, the Noisiness estimator of the DIAL model is based on two indicators to map the subjective Noisiness ratings. The first indicator is called Noise on Speech (NoS). It captures additive noise parts in active speech frames that appear due to background noise. The second indicator tries to capture discontinuities in the background noise. Usually, background noise, such as street or cafeteria noise, varies only in a small dynamic range. However, sometimes abrupt level variations may occur, these are considered as discontinuities. To capture these discontinuities in the Noisiness estimator, the total noise loudness (Ln) indicator is used. The two indicators are used to calculate Noisiness impairment factors with a polynomial function. The maximum of the two impairment factors is used to map the subjective Noisiness ratings.Fig. 8.4Estimated  versus subjective  using the Noisiness estimator of the DIAL model. The numbers indicate the conditions (see Tables 6.​2 and 6.​10)

Again, the Noisiness estimator of the DIAL model is applied to the available signals for all 36 test subjects and for all eleven conditions under test. Based on the average subjective and instrumental values, the Noisiness estimator achieves an estimation accuracy of  and an error of . Figure 8.4 shows an overview of the estimated  values and the subjective  values. It can be seen that the Noisiness estimator provides accurate estimations for conditions that are subjectively rated high. The estimator strongly overestimates conditions that are subjectively rated below three. This results in a rather low accuracy and a higher error. However, the performance of the Noisiness should again further be evaluated if a larger data set is available that includes more and different noise conditions. In sum, the Noisiness estimator provides acceptable results with a moderate correlation and a moderate error.

Coloration

In general, Coloration is influenced by frequency-response distortions that are introduced by the bandwidth of the used codec and/or transmission network. To capture these distortions, the Coloration estimator uses two individual indicators to map the subjective Coloration ratings (see Fig. 8.2). The two indicators are based on the gain function of the condition under test, that is the logarithmic frequency response magnitude of the transmission system. The first indicator is called Equivalent Rectangular Bandwidth (ERB). The ERB represents an ideal rectangular filter which has the same perceptual characteristics as the bandwidth of the gain function. The second indicator is called center frequency (). This indicator is representing the center of the gain function. Both indicators are used to calculate a bandwidth impairment factor according to [21]. Finally, Coloration ratings are estimated using the transformation described by the E-Model [129] (see Sect. 3.​5.​3).Fig. 8.5Estimated  versus subjective  using the Coloration estimator of the DIAL model. The numbers indicate the conditions (see Tables 6.​2 and 6.​10)

For the average subjective ratings of all 36 test subjects and for all eleven conditions under test the Coloration estimator provides estimations with a correlation of  and an error of . Again, Fig. 8.5 shows an overview of the estimated  values and the subjective  values for the eleven data points. The figure shows that most of the conditions under test are estimated with a high  value. If no frequency distortions are present in the speech signal, the estimator predicts a  of 4.5. In contrast, if frequency distortions are present in the speech signal (only two conditions were used with the same parametric NB codec), the estimator is accurate (see the two low-rated conditions in Fig. 8.5). However, due to the high estimations for the conditions with no frequency distortions the error of the estimations raises. Still, the Coloration estimator in sum provides accurate and consistent results for the available data set.

Loudness

The Loudness estimator of the DIAL model quantifies the degradation for speech heard at a non-optimum listening level [3]. Figure 8.2 shows that the Loudness estimator uses two indicators to map subjective Loudness ratings. The Long-Term Loudness (LTL) corresponds to the perceived loudness of the entire speech signal. To calculate the LTL indicator, an algorithm based on [165] was used and retrained to match the scores of databases gathered according to [35]. In addition, the indicator Equivalent Continuous Sound Level () measures the mean energy of the degraded signal over all speech frames. The two indicators are used to calculate a Loudness impairment factor with a third order polynomial function. Again, the Loudness ratings are estimated using the E-Model transformation.Fig. 8.6Estimated  versus subjective  using the Loundess estimator of the DIAL model. The numbers indicate the conditions (see Tables 6.​2 and 6.​10)

The Loudness estimator is used to estimate the average subjective ratings for all 36 test subjects and eleven conditions. The estimator achieves a consistency of  and an accuracy of . Figure 8.6 gives an overview of the estimated  values and the subjective  values. The figure and the RMSE indicate that the estimator provides a high accuracy. However, the low correlation indicates a low consistency. The significance test of the correlation showed that the correlation is not significant. This is explained by the low variation of the Loudness ratings. All estimations and all subjective ratings are above a  value of three. This low variation results in a per chance relation and thus in a not significant and low correlation. In future studies, additional conditions triggering the Loudness should be introduced to provide a higher and significant correlation. However, the high consistency of the estimations allows using the estimated values to map the overall listening quality.

Overall Listening Quality

Based on the estimations of the four perceptual quality dimensions of the Listening Phase, the overall listening quality  can be modeled using the relation presented in Sect. 7.​3. Thus, (7.​5) adapts to the following: (8.1)Here, the values for the perceptual dimensions, Noisiness, Discontinuity, Coloration, and Loudness are the results of the individual dimension estimations , , , and .Fig. 8.7Estimated  versus subjective  using the dimension estimators of the DIAL model. The numbers indicate the conditions (see Tables 6.​2 and 6.​4)

Applied to the averaged subjective phase quality rating the model provides estimation with a consistency of  and an accuracy of . Figure 8.7 gives an overview of the estimated  values and the subjective  values. The figure shows that the model developed in Sect. 7.​3 also provides acceptable results if the dimension values are estimated. The only major deviations the model shows are for conditions that subjectively are rated below three. The model slightly overestimates the subjective ratings for these conditions. However, for the conditions that are subjectively rated above three, the model provides very accurate estimations. In sum, the results show that the overall listening quality  can be estimated using the dimension estimators of the DIAL model and the relation presented in Sect. 7.​3 with a high correlation and a low error.
Nevertheless, more data using the new test method (Chap. 5) should be gathered. Having more varying system conditions can help to further validate the used estimators and the developed models. Especially more conditions regarding the perceptual quality dimension Loudness are demanded to provide a significant correlation of the estimations. In sum, the results presented in this section show that the developed modeling of the perceptual dimension scores of the Listening Phase, and the scores for the overall quality of the Listening Phase based on these dimension estimations, is valid and reliable.


8.4 Modeling Perceptual Dimension Scores of the Speaking Phase
Other than for the Listening Phase, no dimension estimators for the perceptual quality dimensions of the Speaking Phase have been available. Thus, two new dimension estimators have to be developed to model the perceptual dimension scores of the Speaking Phase. For these two estimators, the approach of a full-reference signal-based model is used again. The demanded signals are provided by isolating the signals from the speaking part of the second session of the new test method from the recordings. This assures that only signals that are related to the Speaking Phase are used for the new dimension estimators. The two new estimators use the system input and the system output signals at one test subject's side as input (see Fig. 8.1). More precisely, if the subjective dimension scores of subject one should be estimated, the system input of subject one () is used as the reference signal and the system output of subject one () is used as the degraded signal. This approach is similar, but not equal, to how the PESQM model is provided with reference and degraded signals (see Sect. 3.​4.​3)
The reference signal x(k) and the degraded signal y(k) are used to calculate two indicators. Both indicators are used by the two developed estimators to estimate the two perceptual quality dimensions Impact of one's own voice on speaking and Degradation of one's own voice.
The first indicator is called attenuation (ATT). The indicator describes the average level differences between the spoken signal, the reference signal x(k), and the back coupled signal, the degraded signal y(k). It is assumed that the level difference between the two signals is directly connected to the impact of the back coupled signal on the speaking. Figure 8.8 illustrates how the ATT indicator is calculated for an example condition. ATT is expressed in dB. For N samples of the reference x(k) and the degraded signal y(k) the indicator is calculated according to: (8.2)
Fig. 8.8Calculation of the ATT indicator for an example condition

The second indicator is called back coupling delay (). The indicator describes the shift between the spoken signal, the reference signal x(k), and the delayed back coupled signal, the degraded signal y(k). It is assumed that the delay between the two signals is connected to the impact of the back coupled signal on the speaking and to the degradation of the back coupled signal. The latter is explained with the comb-filtered version of the signal and the thereby perceived coloration (see Sect. 3.​4.​1). Figure 8.9 illustrates how the  indicator is calculated for an example condition.  is expressed in ms. To calculate , the cross-correlation between the reference x(k) and the degraded signal y(k) at all possible lags  is calculated. The cross-correlation indicates at what lag the two signals are most similar. The estimated delay is given by the value where the absolute cross-correlation has the largest absolute value. Thus,  is calculated according to: (8.3)The two indicators serve as input for the two dimension estimators. However, it has to be mentioned at this point that the two indicators are initial approaches to provide meaningful input for the estimators. For future extensions and improvements of the two estimators, more indicators are necessary. For example, both indicators are calculated from the time domain of the signals. Further indicators could be extracted from the frequency domain of the signals. These indicators might in particular be useful for the Degradation of one's own voice estimator as they provide meaningful measures of the coloration (see the Coloration estimator for the Listening Phase in Sect. 8.3). Nevertheless, the two available indicators are used for the Impact of one's own voice on speaking and Degradation of one's own voice estimators for now.Fig. 8.9Calculation of the  indicator for an example condition


Impact of one's own voice on speaking

The Impact of one's own voice on speaking estimator is based on the two previously introduced indicators ATT and . Both indicators are used in a multiple linear regression model to estimate the subjective perceptual dimension scores. The model is developed based on the subjective per-file scores.Table 8.1Multiple linear regression analysis for estimating the Impact of one's own voice on speaking () on the basis of the two introduced indicators ATT and 
PredictorStandardized  coefficientT-stat


ATT
−.54−12.11.00

−.27−6.15.00

The analysis of the linear regression is given in Table 8.1. The regression reaches a  value of .55 and a RMSE of 1.18. The significance test reveals that the two predictor coefficients are statistically significantly different from zero (). Thus, both indicators have a significant impact on the regression model. The ANOVA of the regression model shows that it is significant (). The regression analysis allows developing an equation to estimate the Impact of one's own voice on speaking as follows: (8.4)The Impact of one's own voice on speaking estimator (8.4) is applied to the available recordings. The results are compared to the per-condition subjective perceptual dimension scores. The estimator provides a consistency of  and an accuracy of . Figure 8.10 shows an overview of the estimated  values and the subjective  values for the eleven conditions under test. The figure and the low achieved correlation show that the developed Impact of one's own voice on speaking estimator is still at an early stage. The estimator only provides acceptable estimations for subjectively high rated conditions. For the four conditions that are supposed to trigger the Impact of one's own voice on speaking only two conditions are estimated accurately. These results are explained with two disadvantages of the developed estimator: First, the estimator uses the two presented indicators ATT and . The results show that these two indicators are not enough input to accurately estimate the Impact of one's own voice on speaking. Thus, more meaningful indicators are required. Second, the estimator is developed on limited data. As already mentioned for the models presented in Chap. 7, more varying data is required to develop a robust estimator. In addition, other than linear regression models should improve the performance of the two estimators (see for example the models used in the E-Model [129]).Fig. 8.10Estimated  versus subjective  using the new developed Impact of one's own voice on speaking estimator. The numbers indicate the conditions (see Tables 6.​2 and 6.​13)

However, as mentioned in Sect. 8.1, the developed model is meant as a first approach towards a final conversational model. Thus, the presented model reveals first possibilities how a robust Impact of one's own voice on speaking estimator may look like. In addition, the results highlight that such a final estimator should use an adequate number of indicators and should be developed on a sufficient amount of data.Fig. 8.11Estimated  versus subjective  using the new developed Degradation of one's own voice estimator. The numbers indicate the conditions (see Tables 6.​2 and 6.​13)


Degradation of one's own voice

Again, the Degradation of one's own voice estimator is based on the two presented indicators ATT and . As for the Impact of one's own voice on speaking estimator, the two indicators are used in a multiple linear regression model to estimate the subjective perceptual dimension scores. The model is developed based on the subjective per-file scores.
The analysis of the linear regression is given in Table 8.2. The regression reaches a  value of .42 and a RMSE of 1.23. The significance test reveals that the two predictor coefficients are statistically significantly different from zero (). Thus, both indicators have a significant impact on the regression model. The ANOVA of the regression model shows that it is significant (). The regression analysis allows developing an equation to estimate the Degradation of one's own voice as follows: (8.5)
Table 8.2Multiple linear regression analysis for estimating the Degradation of one's own voice () on the basis of the two introduced indicators ATT and 
PredictorStandardized  coefficientT-stat


ATT
−.40−8.31.00

−.26−5.34.00

The estimator for the perceptual dimension Degradation of one's own voice (8.5) is applied to the available recordings. The estimations are averaged to per-condition values and are compared to the subjective per-condition scores. The estimator provides a correlation of  and an error of . Figure 8.11 shows an overview of the estimated  values and the subjective  values for the eleven tested conditions. Again, the developed estimator is not providing acceptable results. In particular, subjectively low rated conditions are difficult to estimate for the developed model. The low performance of the estimator can also be explained with the two disadvantages introduced for the Impact of one's own voice on speaking estimator. Especially the disadvantage regarding the used indicators should be respected for the Degradation of one's own voice estimator. As mentioned before, indicators to measure the frequency response of the transmission system may improve the developed indicator.
Again, the developed estimator is meant as a first approach towards a final conversational model. Having more indicators and data should enhance the presented estimator.

Overall Speaking Quality

Based on the estimations of the two perceptual quality dimensions of the Speaking Phase, the overall speaking quality  can be modeled using the relation presented in Sect. 7.​3. Thus, (7.​6) adapts to the following: (8.6)
Fig. 8.12Estimated  versus subjective  using the developed dimension estimators for Impact of one's own voice on speaking and Degradation of one's own voice. The numbers indicate the conditions (see Tables 6.​2 and 6.​4)

Here, the values for the perceptual dimensions, Impact of one's own voice on speaking and Degradation of one's own voice, are the results of the individual dimension estimations , and . Applied to the averaged subjective phase quality ratings the model provides estimations with a consistency of  and an accuracy of . Figure 8.12 gives an overview of the estimated  values and the subjective  values. The figure and the accuracy show that the model developed in Sect. 7.​3 cannot provide acceptable results if the dimension values are estimated with the two developed dimension estimators. In future work, it should be analyzed whether this is due to the low performance of the two dimension estimators, or if there is a general problem with the developed model. For both cases the developed model must be evaluated on more independent data.


8.5 Modeling Perceptual Dimension Scores of the Interaction Phase
The final part of the new instrumental diagnostic conversational quality model is a dimension estimator for the last remaining perceptual dimensions Interactivity. Again, the approach of a full-reference signal-based model is used for the Interactivity estimator. The required signals are isolated from the third session of the new test method. Thus, only signals that are related to the Interaction Phase are used for the new dimension estimators. The new estimator uses the system input signals of test subject one and the system output signals of the test subject two. In detail, if the subjective dimension scores of subject one should be estimated, the system input of subject one () is used as the reference signal and the system output of subject two () is used as the degraded signal (see Fig. 8.1).
The reference signal x(k) and the degraded signal y(k) are used to calculate one indicator. The indicator is used by the dimension estimator to model the perceptual quality dimension Interactivity. The indicator is called overall delay ().  is calculated in the same way the indicator back coupling delay () is determined. Thus, again the largest value of the absolute cross-correlation of the reference and the degraded signal is used to calculate the value  (8.3). The difference of the two calculations is that the degraded signal is a different one. For  the back coupled signal  is used while for  the transmitted signal  is used. The  value is assumed to represent a value that measures the Interactivity in terms of overall transmission delay that might results in active or passive interruptions (see Sect. 3.​5.​1).
The  indicator is used as input for the new Interactivity estimator. Here, the same applies as for the two estimators developed for the Speaking Phase: the indicator is an initial approach to provide meaningful input for the estimator. For future extensions and improvements of the Interactivity estimator more indicators are necessary. Other possible indicators are for example the introduced conversational parameters SAR or the conversational temperature (see Sect. 3.​5.​4). However, only the one available indicator is used for the Interactivity estimator for now.

Interactivity

The Interactivity estimator is based on the introduced indicator . The indicator is used in a linear regression model to estimate the subjective perceptual dimension scores. Again, the model is developed based on the subjective per-file scores.
The analysis of the linear regression is given in Table 8.3. The regression reaches a  value of .32 and a RMSE of 1.07. The significance test reveals that the predictor coefficient is statistically significantly different from zero (). Thus, the indicator has a significant impact on the regression model. The ANOVA of the regression model shows that it is significant (). The regression analysis allows developing an equation to estimate the Interactivity as follows: (8.7)
Fig. 8.13Estimated  versus subjective  using the new developed Interactivity estimator. The numbers indicate the conditions (see Tables 6.​2 and 6.​16)


Table 8.3Multiple linear regression analysis for estimating the Interactivity () on the basis of the introduced indicator 
PredictorStandardized  coefficientT-stat



−.321−6.54.00

The Interactivity estimator (8.7) is applied to the available recordings. Again, the evaluation of the dimension estimator is done on per-condition scores. The estimator provides an accuracy of  and an error of . However, the correlation of the estimated and the subjective scores is slightly not significant (). Figure 8.13 shows an overview of the estimated  values and the subjective  values for the eleven test conditions. The figure and the not significant and rather low correlation show that there is still room for improvement regarding the developed Interactivity estimator. The non-significant correlation is explained with the low amount of available test data. Only two test conditions introduced delay to the test subjects. Thus, the variations of the Interactivity estimations and ratings are too low to provide a significant correlation. This is a similar result as for the Loudness estimator presented in Sect. 8.3. To provide a significant correlation, more varying conditions introducing transmission delay are required. The low accuracy of the Interactivity estimator is explained with the single indicator used for the linear regression model. As mentioned before, further indicators are required to improve the performance of the Interactivity estimator.

Overall Interaction Quality

The results of the developed Interactivity estimator are now used to model the overall interaction quality of the Interaction Phase (). For this, the model presented in Sect. 7.​3 is used. Therefore, (7.​7) is modified to the following: (8.8)
Fig. 8.14Estimated  versus subjective  using the developed dimension estimator for Interactivity. The numbers indicate the conditions (see Tables 6.​2 and 6.​4)

In (8.8), the values for the perceptual dimension Interactivity are the results of the Interactivity estimations . Applied to the averaged subjective phase-quality rating the model provides estimations with a correlation of  and an error of . Figure 8.14 gives an overview of the estimated  values and the subjective  values. The figure and the accuracy show that the model developed in Sect. 7.​3 cannot provide acceptable results if the dimension values are estimated with the developed Interactivity estimator. This is explained with the low consistency and the not significant accuracy of the Interactivity estimator. If  strongly deviates from the subjective  values, the estimations of the overall interaction quality cannot reach a high accuracy. If more data and further indicators are available for an extended version of the Interactivity estimator, the model (8.8) should provide improved estimations for the overall interaction quality.


8.6 Modeling the Overall Conversational Quality
Finally, the overall conversational quality is modeled based on the developed and presented dimension estimators. Just to clarify the approach of the new instrumental diagnostic conversational quality model again: First, the seven perceptual quality dimensions are estimated with the introduced dimension estimators. Second, the phase quality values are modeled based on the dimension estimations (see Sects. 8.3, 8.4, and 8.5). Third, the overall conversational quality is estimated based on the quality profile illustrated in Sect. 7.​4. The structure of the new instrumental diagnostic conversational quality model can be seen in Fig. 8.15.
Thus, the results of the estimated phase quality values are applied to the quality profile according to (7.​9). In comparison to the subjective overall conversational quality scores, the instrumental model achieves a consistency of  and an accuracy of . Figure 8.16 gives an overview of the estimated  values and the subjective  values.
The low correlation and Fig. 8.16 indicate that the estimations of the overall conversational quality based on the seven dimension estimators is not accurate. While the dimension estimators for the Listening Phase (see Sect. 8.3) provide estimations with an acceptable accuracy, the performance of the developed dimension estimators for the Speaking Phase is just acceptable and for the Interaction Phase not acceptable. Thus, the discrepancy of the estimations provided by the three new developed estimators is send through the whole conversational quality model. As they provide a low accuracy, the estimations for the overall conversational quality cannot provide a higher accuracy. As already mentioned in Sects. 8.4 and 8.5, more data and further indicators are necessary to improve first the dimension estimators, and second the whole instrumental diagnostic conversational quality model.Fig. 8.15Structure of the new instrumental diagnostic conversational quality model for estimations of one test subject
Fig. 8.16Estimated  versus subjective  using the developed dimension estimators and the developed quality profile presented in Sect. 7.​4. The numbers indicate the conditions (see Tables 6.​2 and 6.​4)



8.7 Conclusion
In this chapter, a first approach towards an instrumental diagnostic conversational quality model was presented. For this, first, the technical requirement specifications in terms of the model classification, its input, and its output parameters were defined. Second, seven individual dimension estimators, one for each perceptual quality dimension of a conversation, were introduced and evaluated. For each conversational phase, the estimated scores of the underlying perceptual quality dimensions were used to model the overall phase-quality scores according to the relations presented in Chap. 7. Finally, the estimated overall phase-quality scores provide the necessary input to model the overall conversational quality.

For the first time, an instrumental quality model that provides diagnostic information of a telephone conversation and thus allows analyzing and optimizing a complete telephone transmission system is available.

However, the evaluation of the constructed dimension estimators showed that the model is still at an early stage of development. While the dimension estimators for the Listening Phase were already available, the dimension estimators for the Speaking and the Interaction Phase had to be developed. The four dimension estimators for the Listening Phase were taken from the DIAL model and provide acceptable results. For the two dimension estimators regarding the Speaking Phase, two new indicators were extracted from the captured signals and combined in a linear regression model. The estimators provide just acceptable estimations, but further improvements and additional indicators are required to provide recommendable estimators. The developed estimator for the perceptual quality dimension of the Interaction Phase uses one indicator to estimate the subjective dimension scores with a linear model. Unfortunately, the developed estimator does not provide acceptable estimations. Again, more indicators are necessary to raise the accuracy and the consistency of the dimension estimators. In addition, the dimension estimators were evaluated on the eleven available data points. For further improvements of the estimators more data gathered with the new test method (see Chap. 5) is needed. Another potential point for improvement is using linear regression models. Applying other, non-linear models, might also improve the performance of the developed dimension estimators.
The new instrumental diagnostic conversational quality model estimates the overall conversational quality on the basis of the seven dimension estimators. As some of the estimators provide varying estimations, the accuracy of the overall conversational quality estimations is only mediocre. The overall conversational quality is modeled with the overall phase-quality scores, which are in turn modeled by the estimations provided by the seven dimension estimators. This three-step approach leads to low overall conversation-quality estimations due to deviations of the dimension estimators that are carried though all three steps. The two-step approach without estimating the phase-quality scores (see Sect. 7.​2) does not provide significant results yet, and is therefore not recommended to be used for an instrumental model. Thus, to provide more accurate and consistent overall conversational quality estimations, the dimension estimators need to be improved. In addition, a possible improved performance of the overall conversational quality estimation might be achieved by integrating a core model in addition to the dimension estimators (similar to the DIAL model).
However, while the new instrumental diagnostic conversational quality model only provides overall conversational quality estimation with a mediocre accuracy, it is not known how the performance can be judged relatively to other instrumental quality models. The peculiarity of the new quality model allows evaluating its performance in comparison to numerous different models. For example, the estimations of the overall listening quality could be compared to the recommended models POLQA, PESQ, or even DIAL. In turn, the performance of the dimension estimators and the resulting overall quality of the Speaking Phase could be compared to the estimations of the PESQM model. The overall conversational quality should be compared to the results of the E-Model or of the model proposed in [67]. Having such an evaluation at hand would highlight the performance of the new instrumental diagnostic conversational quality model in comparison to other models. In addition, such an evaluation might also give suggestions how the developed conversational model could be further improved.
Nevertheless, at this point, the developed model was not intended to be a final recommendable model. In fact, the presented work is targeting at providing first ideas and solutions to come up with a potential instrumental diagnostic conversational quality model. In addition, as already mentioned before, the developed model could be seen as a starting point for the conversational quality model demanded by the ITU in its study item P.CQO.












© Springer Nature Singapore Pte Ltd. 2018


Friedemann Köster



Multidimensional Analysis of Conversational Telephone Speech


T-Labs Series in Telecommunication Services


https://doi.org/10.1007/978-981-10-5224-8_9





9. Conclusions and Future Work




Friedemann Köster
1  




(1)
Quality and Usability Lab, Technical University of Berlin, Berlin, Germany

 



 

Friedemann Köster


Email: 
friedemann.koester@tu-berlin.de






The quality of transmitted speech is a major indicator for telecommunication system providers to evaluate their services. However, traditional methods to assess and estimate the quality of transmitted speech exhibit two inherent limitations: on the one hand, the methods only provide an overall quality score without diagnostic information, on the other hand, if diagnostic information are provided, only the passive listening situation is considered. This leads to a trade-off between either providing diagnostic information or taking into account an entire conversation. In sum, diagnosing a complete conversational situation is not possible with traditional methods.
To address this trade-off, the work conducted to provide diagnostic information of a conversational situation based on perceptual quality dimensions is presented in this book. For this, the main research question "What are the quality relevant perceptual dimensions that an interactive conversational situation is composed of?" is formulated and systematically answered. The research question is answered by successively addressing five research topics regarding the perceptual dimensions of a conversational situation—Identification, Quantification, Validation, Modeling, and Estimation of the perceptual quality dimensions underlying the conversational speech quality. The presented work answers the stated research question and leads to a preliminary new instrumental diagnostic conversational speech-quality model.
Chapter 2 introduces the basic research scenario and the fundamentals of human speech production, transmission, and perception. In addition, the chapter defines the term quality of transmitted speech, its assessment methods, as well as analyzing and diagnosing concepts, used throughout the book. The introduced concepts are transferred to the context of a telephone conversation in Chap. 3. For this purpose, the approach of separating a conversation in three conversational phases, the Listening, the Speaking, and the Interaction Phase, is introduced. Each conversational phase is reviewed in terms of related work regarding its perceptual quality spaces as well as state of the art subjective and instrumental quality-assessment methods. Thus, Chaps. 2 and 3 provide a review of related work, the fundamentals, and the knowledge required for the conducted research. In conclusion, Chap. 3 defines the research question and enumerates the five research topics covered in this book.
Chapter 4 addresses the identification of the perceptual quality space and its perceptual quality dimensions in a conversational situation. While the perceptual dimensions for the Listening Phase are already known, the perceptual quality space of the Speaking and the Interaction Phase is explored. Four subjective experiments were conducted following the paradigms of pairwise scaling with subsequent Multidimensional Scaling and Semantic Differential with subsequent Principal Component Analysis. In these experiments, quality elements regarding the Speaking and the Interaction Phase were considered. Together with the work already conducted for the Listening Phase, the perceptual quality space of conversational speech quality was identified:

Identification: The perceptual quality space in a conversational situation is composed of seven perceptual quality dimensions, structured according to their conversational phase:
Listening Phase
Coloration

Discontinuity

Noisiness

Loudness


Speaking Phase
Impact of one's own voice on speaking

Degradation of one's own voice


Interaction Phase
Interactivity


The application of the multidimensional test paradigms requires an enormous experimental effort. Thus, a test method that allows directly quantifying the identified perceptual dimensions is introduced in Chap. 5. In this regard, seven dimension scales, each dedicated to one perceptual dimension, were presented. The test method is following a detailed procedure to assure that the test subjects can perceive each conversational phase separately. Thus, the method gathers subjective ratings for the overall conversational quality, the overall conversational phase qualities, and the perceptual dimensions. In addition, the recommended test setup in terms of training and introductions is introduced. The new test method is supposed to provide the foundation for a new ITU recommendation resulting from the work item P.CQS.

Quantification: A sophisticated test method, which allows the test subjects to perceive each conversational phase separately, has been developed in order to subjectively rate the seven perceptual quality dimension in a direct way.
In Chap. 6, two conversational experiments to validate the identified perceptual quality space in a conversational situation and the developed test method are presented. In Chap. 4, the perceptual dimensions were identified in separate experiments regarding the three conversational phases. The results of the conducted conversational experiment show that the identified perceptual dimensions are valid if the test subjects perceive each conversational phase separately. The second experiment validates the new test method. The results show that the developed method provides meaningful and reliable results.

Validation: The results of two sophisticated conversational experiments show that the identified perceptual quality dimensions are valid in a conversational situation and that the developed test method measures what it was designed for.
The results of the second validation experiment are used to model the overall conversational quality based on the perceptual dimension scores. Thus, in Chap. 7, multiple linear regression models are used to identify the weights of the overall conversational quality scores, the overall conversational phase quality scores, and the dimension scores. The resulting quality profile defines the relations to model the overall conversational quality based on the quality ratings for each conversational phase, and in turn, to model the quality of each conversational phase based on its underlying perceptual dimensions.

Modeling: The relations between the overall conversational quality, the overall conversational phase qualities, and the perceptual dimensions, form a new quality profile to analyze and diagnose conversational speech quality.
Finally, the conducted studies and analyses merge to the development of a new instrumental diagnostic conversational quality model that is presented in Chap. 8. The model is composed of seven individual dimension estimators for each perceptual quality dimension. For this, four already available dimension estimators for the perceptual dimensions of the Listening Phase are used together with three newly developed dimension estimators for the perceptual dimensions of the Speaking and the Interaction Phase. The overall conversational quality and the overall conversational phase qualities are estimated based on the dimension estimations according to their relations identified in Chap. 7. The model and the dimension estimators are trained and evaluated on the data gathered in Chap. 6. The results show that the overall conversational quality estimations only provide a low accuracy due to the preliminary development status of the new dimension estimators for the Speaking and the Interaction Phase. However, the model is seen as a first step to provide ideas and solutions for a conversational quality model demanded in the ITU study item P.CQO.

Estimation: A new instrumental diagnostic conversational quality model based on seven individual dimension estimators is developed. The model gives estimations for the overall conversational quality, the overall conversational phase qualities, and the perceptual dimensions. As the model is still in an early development stage, it can be seen as a first fundamental contribution for a final and robust diagnostic conversational quality model.
In sum, this book provides fundamental research towards the Multidimensional Analysis of Conversational Telephone Speech. For this, the stated research question "What are the quality relevant perceptual dimensions that an interactive conversational situation is composed of?" is answered by addressing five research topics. Thus, this book results in the following four outputs that are new to the quality community:

Final output:1.Validated perceptual quality space in a conversational situation 2.Validated test method to quantify the identified perceptual dimensions 3.Quality profile of a conversational situation 4.New instrumental diagnostic conversational quality model 

Nevertheless, the conducted research still leaves room for future work. First of all, more data gathered with the new test method is required. This includes more test conditions and conditions triggering one specific perceptual dimension with varying characteristics (no, medium, and high degradations). Having more data allows advancing the analyses and further validating the conducted research in four directions.
Secondly, the relation between the two listening dimensions Coloration and Discontinuity should be researched further. For now, the dimensions have only been triggered with a low number of conditions. The results showed that there seems to be a dependency between both dimensions. In addition, the particularities of the Coloration dimension—it is rated low if the test subject is not sure about the origin of the perceived degradation—have already been discussed. Having more data available should give more insights into their relation and may clarify whether there is a principle problem with the two dimensions or if their dependency results from the used test conditions.
Thirdly, the two speaking dimensions Degradation of one's own voice and Impact of one's own voice seem to depend on each other in terms of their presence and highly correlate. Here, especially conditions with varying characteristics triggering independently the two dimensions should be analyzed in future. Besides, it has to be investigated if there is a general problem for test subject to distinguish between the two dimensions. If this is true, the new test method should be adapted and/or the identification of both dimensions could be revised.
Fourthly, the dimension of the Interaction Phase shows low ratings for conditions triggering the Interaction Phase and the Speaking Phase. Having more varying data at hand allows verifying if this due to used degradations or if there is a general problem for test subjects to perceive this dimension as intended. In addition, it has to be investigated how the dimensions of the two phases are connected. More precisely, if the speaking is degraded the interaction should also be degraded. In turn, it is not clear whether the speaking is degraded if the interaction is degraded. These assumptions have to be validated in future experiments with more varying degradations. For now, only one characteristic of transmission delay was applied. In future, more varying amounts of delay should give insights into the observed findings. Also, combining degradations triggering the Interaction Phase and the Speaking Phase might reveal further knowledge about the relation between the two phases and their dimensions.
Fifthly, more data gives the possibility to further validate the models developed in Chap. 7. The identified relations between the overall conversational quality, the overall conversational phase qualities, and the perceptual dimensions are based on eleven data points. More data points should raise the significance and the robustness of the resulting quality profile. In addition, the development of the new instrumental diagnostic conversational quality model is also based on the limited available data. More data would allow to revise the developed estimator and to raise its accuracy.
This leads to a next major point for future work. The developed estimators for the three dimensions Degradation of one's own voice, Impact of one's own voice, and Interactivity are at an early stage of development. For all three estimators more indicators are necessary. Especially the dimension estimator for the Interactivity cannot provide results with an acceptable accuracy. It might also be interesting to study the influence of using linear regression models for the estimators. The performance of different linear and non-linear models should be researched in future work. Having more data, more indicators, and different models to estimate the dimension scores should improve the performance of the overall conversational quality estimations. Additionally, the developed estimator has to be evaluated on new unknown data and in comparison to other instrumental quality models. However, the development of a final robust instrumental diagnostic conversational quality model is a topic for a single book and thus gives multiple directions for future work.
Besides the named points of future work, the standardization of the developed test method (P.CQS) and the instrumental diagnostic conversational quality model (P.CQO) should be advanced in future. This includes further contributions to ITU SG12 and the need of independent research laboratories to use, test, and validate the developed methods and models.













Appendix A



Short Conversation Test (SCT)
Scenario: British Rail Travel Information

Your name
                :
                Thompson






Scenario 1: British Rail Travel Information

Your name
                :
                British Rail travel service











Appendix B



Random Number Verification Task (RNVT)

Example scenarios for random number verification tasks (RNVT)


Test subject 1

Instructions: "Your conversation partner is also provided with such a list. Some of the numbers in your list do not correspond with those of your conversation partner. Find the wrong numbers as quickly as possible by taking turns reading them line by line. Acknowledge by saying "yes" or "no", and cross out the wrong numbers. You will read the bold red numbers and your conversation partner will read the non-bold blue ones".






Example scenarios for random number verification tasks (RNVT)


Test subject 2

Instructions: "Your conversation partner is also provided with such a list. Some of the numbers in your list do not correspond with those of your conversation partner. Find the wrong numbers as quickly as possible by taking turns reading them line by line. Acknowledge by saying "yes" or "no", and cross out the wrong numbers. You will read the bold blue numbers and your conversation partner will read the non-bold red ones".










Appendix C



Test Instructions

Test instructions—translated from german


Analysis of speech quality in a Conversational situation

Thank you very much for taking part in this experiment! Please take the time to read the instructions thoroughly. Should you have any questions please do not hesitate to ask the experiment supervisor.
You are taking part in a conversational experiment, in which the properties and the perception of a conversation are to be evaluated. To do this you and you conversational partner will be put into a conversational situation. In this situation different conditions will be presented in three phases. The phases are the following: (1.) a short conversational scenario, (2.) speaking and listening and (3.) the interaction. After every phase you are asked to evaluate your perception and the properties of the phase. The exact procedure of the individual phases will be described in detail later, and will be made clear in a test run.
The characteristics of each condition are to be evaluated with the help of different scales. Please familiarize yourself with the scales and how to use them now:
Each scale has a term at each end (e.g. not noisy/noisy). You are to evaluate to what extent the characteristics of a condition can be described by the terms on the scale. There are two different kinds of scales. The scale for the overall quality has describing terms for every point while the scales for the characteristics (e.g. not noisy/noisy) only have terms at their endpoints. The usage of these scales is analogous and is explained in detail for the overall quality.

                The
                overall quality
                of a condition is to be evaluated. If you are of the opinion the condition is overall bad, put down your cross at the following position:
              





If you think the overall quality of the condition is excellent, put down your cross at the position "excellent":





For your evaluation you can use the whole scale freely. The markings on the scale are meant to provide points of reverence for you and to support you in your evaluation. You can even use the spaces in between the markings if you do not wish to settle for one of the markings.
You can always use the "overflow areas" beyond the terms if you feel the terms are not sufficient for your evaluation:





The scales are used in an analogue way for the different characteristics. Overall there are seven characteristics to evaluate.

1. Noisiness

The first scale has the terms "not noisy" and "noisy" and looks the following:






                With this scale you are to evaluate the
                noisiness
                of what you heard in a condition. The terms "not noisy" and "noisy" can be described with the terms
                noisless
                and
                not hissing,
                and
                noisy
                and
                hissing
                respectively.
              

2. Discontinuity


                The
                discontinuity
                of the heard sound in a condition is to be evaluated with the second scale:
              






                The term "continuous" means that the heard sound in a condition is completely
                even
                ,
                firm
                ,
                not chopped
                and
                not frayed.
                "Discontinuos" can be describes with terms like
                uneven
                ,
                wobbly
                ,
                chopped
                or
                frayed.


3. Coloration


                The
                coloration
                of the heard sound in a condition is described by the third scale:
              






                "Uncolored" means that the heard sound in a condition is
                direct
                ,
                close
                ,
                full
                and
                not nasally
                . "Colored" means the heard sound is
                indirect
                ,
                far
                ,
                thin
                and
                nasally
                .
              

4. Loudness


                The fourth scale describes the
                Loudness
                of the heard sound in a condition:
              





If the heard sound is neither too loud nor too quiet then the volume is optimal. If that is not the case then the volume is not optimal.

5. Impact of one's own voice


                The
                impact on your speaking through the hearing of your own voice
                is to be evaluated with the fifth scale:
              






                In some of the conditions you will be confronted with back coupling of your own voice. This means that you will hear your own voice. With this characteristic you are to evaluate if this does or doesn't negatively impact your speaking. More to the point you are to evaluate if speaking while hearing yourself is
                not distracting
                ,
                not irritating, fluid
                and
                doesn't take concentration
                or if it is
                distracting
                ,
                irritating
                ,
                not fluid
                and
                takes concentration.


6. Degradation of one's own voice


                The sixth scale is for the evaluation of the
                degradation of the own voice
                while having back coupling:
              






                "Own voice not degraded" means that you hear your own voice unaltered e.g. you hear your voice
                not distorted, echofree
                and with
                optimal volume.
                "Own voice degraded" can be described with terms like
                distorted, echoy, thin
                or
                not optimal volume


7. Interactivity


                The seventh scale is used to evaluate the
                interactivity
                in a condition:
              






                "Easy to interact" means that the interaction between you and your conversational partner is easy. That means you have an
                effective, pleasant, easy,
                and
                agile
                interaction. "Hard to interaction", on the other hand, means that the interaction is
                ineffective
                ,
                unpleasant
                ,
                hard
                and
                sluggish
                .
              
For each scale applies: Use as described for the scale for "overall quality" (see above).
Now that you have familiarized yourself with the meaning of the characteristics, the phases and the procedure of the test will be described.

Phase 1—Conversation


Explanation
                :
              
In this phase you and your partner simulate a telephone conversation. One of you will be the caller, who wants something and calls a company/organization/institution. The other one will be the company/organization/institution.

Explanation of symbols
                :
              

As the caller you have the following symbols:


This symbol means: You are the callerPlease wait until the experiment supervisor asks you to start the first conversation

Next to this symbol is the reason for your call
e.g.: I want to buy a ticket!


Next to this symbol are the conditions that should be incorporated into the exchange of information
e.g.: I want to buy a ticket!

BUT if possible cheap!


Next to this symbol you are to note down all information that you need from your telephone partner

Next to this symbol are all the information that your partner needs and that you should give him at some point during the conversation

Next to this symbol is a question to which neither you nor your conversational partner have any information. You are to discuss this question briefly and come to a satisfactory conclusion together


If you get called you have to following symbols
                :
                

This symbol means: You are getting called. Wait until you hear the ringtone and and then pick up

Next to this symbol is information from which you are to sort out the information that your partner needs to have
e.g.: Prices for train tickets for adults, students, children, seniors, etc.


Next to this symbol you are to record all information that you need from your conversational partner


Procedure
                :
              
Read the Information that you are given once before starting the conversation.
Are you the caller, call your partner. Play through the scenario and hang up the conversation. Now click "Next". First you evaluate the overall quality of the conversation and then the conversation regarding the seven characteristics.
Are you the one who gets called, please wait until you hear the ringtone. When you do, pick up. Play through the scenario with your partner and wait until they hang up the conversation.
Click on "Next". First you evaluate the overall quality of the conversation and then the conversation regarding the seven characteristics.

Phase 2—Listening and Speaking
                :
              

Explanation
                :
              
In this phase either you read two sentences to your partner or your partner reads two sentences to you. Afterwards you swap around.

Procedure
                :
              
Should you have two sentences before you: Call your partner and read both sentences. Hang up the conversation. Click "Next". Now you need to evaluate the overall quality of your speaking experience. Afterwards you need to evaluate your speaking pertaining the two characteristics "Impact of the own voice" and "degradation of the own voice".
Should you have no sentences to read: Wait until you are called and pick up the conversation. Listen to the two sentences and wait until your partner hangs up. Click "Next". Evaluate the "overall quality" of your listening experience first, followed by the four conditions "noisiness", "coloration", "continuity" and "volume".

Phase 3—Interaction
                :
              

Explanation
                :
              
In this phase you and your partner are to do a number verification.

Procedure
                :
              

                You will see four series of numbers before you. Two are
                bold
                and two are not. You are to read the bold number sequences to your partner. Should the first of the four sequences on your screen be bold, please call your partner. Do the number verification in an alternating fashion and when all four sequences have been read hang up the conversation. Wait after every number in the sequence (e.g. 24) for a confirmation of your partner in form of a "yes" when they have the same number or a "no" if they should have a different number. After the conversation, click "Next". Please evaluate the "overall quality" of the interaction and afterwards evaluate the characteristic "interaction".
              

Overall procedure
                :
              
Summarized the test goes for every condition the following way (eleven conditions in total):

                call
                
                phase 1
                
                hang up
                
                Next
                
                overall quality
                
                evaluation 7 characteristics
                
                call
                
                phase 2 (speaking/listening)
                
                hang up
                
                Next
                
                overall quality
                
                2/4 characteristics
                
                call
                
                phase 2 (speaking /listening)
                
                hang up
                
                Next
                
                overall quality
                
                2/4 characteristics
                
                call
                
                phase 3
                
                hang up
                
                Next
                
                overall quality
                
                interaction.
              
With a few of the conditions you could have the feeling that you have evaluated them before. This is not the case. Please evaluate every condition independently from all your other evaluations. Try not to remember how you evaluated other "similar" evaluations before, but evaluate every characteristic of every condition individually.

                Please evaluate the scales quickly and intuitively. This experiment is purely subjective in its nature. There are no right or wrong answers.
                Not you but the system is being tested
                . Only your personal opinion matters for this experiment.
              

                If you have any more questions please don't hesitate to ask the experiment supervisor. Have fun!
                




References


1.
Köster F, Möller S, Antons J-N, Arndt S, Guse D, Weiss B (2014) Methods for assessing the quality of transmitted speech and of speech communication services. Acoust Aust 42(3):179-184


2.
Wältermann M (2012) Dimension-based quality modeling of transmitted speech. Springer, Berlin


3.
Côté N (2011) Integral and diagnostic intrusive prediction of speech quality. Springer, BerlinCrossref


4.
Lyons J (1977) Semantics, vol 2. Cambridge University Press, Cambridge. Cambridge Books Online


5.
Denes P, Pinson E (1993) The Speech Chain. Ser. Anchor books. Worth Publishers, New York


6.
Möller S (2000) Assessment and prediction of speech quality in telecommunications. Kluwer, BostonCrossref


7.
Richards D (1973) Telecommuncation by speech: the transmission performance of telephone networks. Butterworths, London


8.
Vary P, Heute U, Hess W (1998) Digitale sprachsignalverarbeitung. Teubner, Stuttgart


9.
Peterson GE, Barney HL (1952) Control methods used in a study of vowels. J Acoust Soc Am 24(2):175-184Crossref


10.
O'Shaughnessy D (2000) Speech communications: human and machine. Institute of Electrical and Electronics Engineers, New York


11.
Association IP (1999) Handbook of the international phonetic association: a guide to the use of the international phonetic alphabet. ser. A Regents publication. Cambridge University Press, Cambridge


12.
Hess W (1976) A pitch-synchronous digital feature extraction system for phonemic recognition of speech. IEEE Trans Acoust Speech Sig Process 24:14-25Crossref


13.
Deng L, O'Shaughnessy D (2003) Speech processing: a dynamic and optimization-oriented approach. Ser. Signal Processing and Communications. Taylor & Francis, London


14.
Jekosch U (2005) Voice and speech quality perception: assessment and evaluation. Springer Science & Business Media, Berlin


15.
Berger J (1998) Instrumentelle Verfahren zur Sprachqualitätsschätzung: Modelle auditiver Tests. Shaker Verlag, Kiel


16.
ITU-T Recommandation I.430 (1995) Basic user-network interface—Layer 1 specification. International Telecommunication Union, Geneva


17.
Lewcio B (2013) Management of speech and video telephony quality in heterogeneous wireless networks. Springer Publishing Company, Incorporated, Berlin


18.

                3GPP TS 45.-series 3rd generation partnership project.
                http://​www.​3gpp.​org/​DynaReport/​45-series.​htm



19.

                3GPP TS 25.-series 3rd generation partnership project.
                http://​www.​3gpp.​org/​DynaReport/​25-series.​htm



20.

                3GPP TS 36.-series 3rd generation partnership project.
                http://​www.​3gpp.​org/​dynareport/​36-series.​htm



21.
Raake A (2006) Speech quality of VoIP assessment and prediction. Wiley, ChichisterCrossref


22.
Zwicker E (1982) Psychoakustik. Springer, BerlinCrossref


23.
Blauert J, Xiang N (2009) Acoustics for engineers. Springer, BerlinCrossref


24.
Fastl H, Zwicker E (2007) Psychoacoustics: facts and models, 3rd edn. Springer, BerlinCrossref


25.
Hauenstein M (1997) Psychoakustisch motivierte Maße zur instrumentellen Sprachgütebeurteilung. Shaker Verlag, Kiel


26.
Allen J (1994) How do humans process and recognize speech? IEEE Trans Speech Audio Process 2(4):567-577Crossref


27.
Ogden CK, Richards IA (1989) Meaning Of meaning. Mariner Books, New York


28.
Nöth W (2000) Handbuch der Semiotik, 2nd edn. 0.4emJ.B. Metzlersche Verlagsbuchhandlung


29.
Baddeley A (1997) Human memory: theory and practice. Psychology Press, Exeter


30.
Demany L, Semal C The role of memory in auditory perception. In: Auditory perception of sound sources. Springer Science and Business Media, pp 77-113


31.
Cowan N (1984) On short and long auditory stores. Psychol Bull 96(2):341-370Crossref


32.
Volberg L, Kulka M, Sust C, Lazarus H (2006) Speech intelligibility and the subjective assessment of speech quality in near real communication conditions. Acta Acust United Acust 92(3):406-416


33.
Raake A, Egger S (2014) Quality and quality of experience. In: Möller S, Raake A (eds) Quality of experience. Springer International Publishing, pp 11-33


34.
Kreiman J, Gerratt BR, Kempster GB, Erman A, Berke GS (1993) Perceptual evaluation of voice quality—review, tutorial, and a framework for future research. J Speech Lang Hear Res 36:21-40


35.
ITU-T Recommandation P.800 (1996) Methods for subjective determination of transmission quality. International Telecommunication Union, Geneva


36.

                Qualinet (2013) Qualinet white paper on definitions of quality of experience. In: Le Callet P, Möller S, Perkins A eds (Version 1.2) European network on quality of experience in multimedia systems and services (COST Action IC 1003), Lausanne, Switzerland.
                http://​www.​qualinet.​eu/​images/​stories/​QoE_​whitepaper_​v1.​2.​pdf



37.
Geerts D, Moor KD, Ketyko I, Jacobs A, den Bergh JV, Joseph W, Martens L, Marez LD (2010) Linking an integrated framework with appropriate methods for measuring QoE. In: 2010 Second international workshop on quality of multimedia experience (QoMEX). Institute of Electrical and Electronics Engineers (IEEE)


38.
ITU-T Recommandation E.800 (2008) Definitions of terms related to quality of service. International Telecommunication Union, Geneva


39.
ITU-T Recommandation E.802 (2007) Framework and methodologies for the determination and application of QoS parameters. International Telecommunication Union, Geneva


40.
Carroll JD (1972) Individual preferences and multidimensional scaling. In: Shepard RN, Romney AK, Nerlove S (eds) Multidimensional scaling: theory and applications in the behavioral sciences, vol. 1, pp 105-155


41.
Oxford Dictionary of English (2010) Oxford University Press (OUP), Oxford


42.
ITU-T Temporary Document TD 650rev1 (GEN/12) (2011) Requirement specifications for P.TCA (Technical Cause Analysis). International Telecommunication Union, Geneva; Rapporteur Q.16/12 (L. Malfait), 2011


43.
Möller S, Köster F, Skowronek J, Schiffner F (2013) Analyzing technical causes and perceptual dimensions for diagnosing the quality of transmitted speech. In: Proceedings of the 4th international workshop on perceptual quality of systems (PQS 2013), pp 30-35


44.
Köster F, Schiffner F, Guse D, Ahrens J, Skowronek J, Möller S (2015) Towards a MATLAB toolbox for imposing speech signal impairments following the P.TCA schema. Audio Engineering Society Convention 139, New York, pp 1-8


45.
Möller S, Heute U (2012) Dimension-based diagnostic prediction of speech quality. In: Proceedings of speech communication 10, VDE, ITG Symposium, pp 1-4


46.
Blauert J, Jekosch U (2003) Concepts of sound quality: some basic considerations. In: INTERNOISE 2003, Jeju, Korea, pp 72-79


47.
Blauert J (1996) Spatial hearing. The Psychophysics of Human Sound Localization. The MIT Press, Cambridge. Revised Edition


48.
Osgood CE (1952) The nature and measurement of meaning. Psychol Bull 49(3):197-237Crossref


49.
Letowski T (1989) Sound quality assessment: concepts and criteria. J Audio Eng Soc 37:1062


50.
Quackenbush S, Barnwell T, Clements M (1988) Objective measures of speech quality. Ser. Ellis Horwood Series in Artificial Intelligence. Prentice Hall PTR, Upper Saddle River


51.
Osgood C (1957) The measurement of meaning. University of Illinois Press, Urbana


52.
Voiers W (1977) Diagnostic acceptability measure for speech communication systems. In: Proceedings of the IEEE ICASSP, Hartford, USA


53.
Borg I, Groenen P (2005) Modern multidimensional scaling—theory and applications, 2nd edn. Springer Series in Statistics, New York


54.
Möller S (2010) Quality engineering. Springer, BerlinCrossref


55.
Poulton EC (1979) Models for biases in judging sensory magnitude. Psychol Bull 86(4):777Crossref


56.
Zielinski S, Rumsey F, Bech S (2008) On some biases encountered in modern audio quality listening tests-a review. J Audio Eng Soc 56(6):427-451


57.
Köster F, Guse D, Wältermann M, Möller S (2015) Comparison between the discrete ACR scale and an extended continuous scale for the quality assessment of transmitted speech. In: Fortschritte der Akustik, DAGA 2015: Plenarvortr. u. Fachbeitr. d. 41. Dtsch. Jahrestg. f. Akust., DEGA


58.
ITU-T Handbook on Telephonometry (1992). International Telecommunication Union, Geneva


59.
Guski R, Blauert J (2009) Psychoacoustics without psychology. In: Proceedings of the NAG/DAGA 2009 international conference on acoustics, vol. 3, pp 1550-1551


60.
Reiter U, Brunnström K, Moor KD, Larabi M-C, Pereira M-C, Pinheiro A, You J, Zgank A (2014) Factors influencing quality of experience. In: Möller S, Raake A (eds) Quality of experience. Springer International Publishing, pp 55-72


61.
Wolf S, Dvorak C, Kubichek R, South C, Schaphorst R, Voran S (1991) Future work relating objective and subjective telecommunications system performance. In: Proceedings of the global telecommunications conference (GLOBECOM'91), pp 2129-2134


62.
Möller S, Chan W-Y, Côté N, Falk TH, Raake A, Wältermann M (2011) Speech quality estimation: models and trends. IEEE Sig Process Mag 28(6):18-28Crossref


63.
Takahashi A, Yoshino H, Kitawaki N (2004) Perceptual QoS assessment technologies for VoIP. IEEE Commun Mag 42(7):28-34Crossref


64.
ITU-T Recommandation P.564 (2007) Conformance testing for voice over IP transmission quality assessment models. International Telecommunication Union, Geneva


65.
Hammer F (2006) Quality aspects of packet-based interactive speech communication, PhD thesis, Graz University of Technology


66.
ITU-T Recommandation P.59 (1993) Artificial conversational speech. International Telecommunication Union, Geneva


67.
Guéguin M, Bouquin-Jeannès RL, Gautier-Turbin V, Faucon G, Barriac V (2008) On the evaluation of the conversational speech quality in telecommunications. EURASIP J Adv Sig Proc 2008


68.
ITU-T Recommandation P.48 (1988) Specification for an intermediate reference system. International Telecommunication Union, Geneva


69.
ITU-T Recommandation P.830 (1996) Subjective performance assessment of telephone-band and wideband digital codecs. International Telecommunication Union, Geneva


70.
Appel R, Beerends J (2002) On the quality of hearing one's own voice. J Audio Eng Soc 50(4):237-248


71.
Ohm J, Lüke H (2010) Signalübertragung: Grundlagen der digitalen und analogen Nachrichtenübertragungssysteme. Ser. Springer-Lehrbuch. Springer, Berlin


72.
Deville Y, Fleurenceau L, Rech O, Audio G (2000) Telephone having automatic gain control means. US Patent 6,094,481


73.
ITU-T Recommandation G.729 Annex B (1996) A silence compression scheme for G.729 optimized for terminals conforming to Recommendation V.70. International Telecommunication Union, Geneva


74.
Ramirez J, Gorriz JM, Segura JC (2007) Voice activity detection. Fundamentals and speech recognition system robustness. InTech


75.
ITU-T Recommandation O.41 (1994) Psophometer for use on telephone-type circuits. International Telecommunication Union, Geneva


76.
ITU-T Recommandation P.810 (1996) Modulated noise reference unit (MNRU). International Telecommunication Union, Geneva


77.
Benesty J, Chen J, Huang Y, Cohen I (2009) Noise reduction in speech processing. Ser. Springer Topics in Signal Processing. Springer, Berlin


78.
Davis G (2002) Noise reduction in speech applications. Ser. Electrical Engineering & Applied Signal Processing Series. CRC Press, Boca Raton


79.
ITU-T Recommandation P.835 (2003) Subjective test methodology for evaluating speech communication systems that include noise supression algorithm. International Telecommunication Union, Geneva


80.
Vary P, Martin R (2006) Digital speech transmission: enhancement, coding and error concealment. Wiley, Chichester


81.
ITU-T Recommandation G.711 (1988) Pulse code modulation (PCM) of voice frequencies. International Telecommunication Union, Geneva


82.
ITU-T Recommandation G.726 (1990) 40, 32, 24, 16 kbit/s adaptive differential pulse code modulation (ADPCM). International Telecommunication Union, Geneva


83.
Tremain ET (1982) The government standard linear predictive coding algorithm: LPC10


84.
Welch VC, Tremain TE, Campbell JP (1989) A comparison of US Government standard voice coders. In: Military communications conference, 1989, MILCOM '89, conference record on bridging the gap. interoperability, survivability, security, vol 1. IEEE, pp 269-273


85.
ITU-T Recommandation P.729.1 (2006) G.729-based embedded variable bit-rate coder: an 8-32 kbit/s scalable wideband coder bitstream interoperable with G.729. International Telecommunication Union, Geneva


86.
Ahson S, Ilyas M (2008) VoIP handbook: applications, technologies, reliability, and security. CRC Press, Boca Raton


87.
ITU-T Recommandation G.191 (2010) Software tools for speech and audio coding standardization. International Telecommunication Union, Geneva


88.
Perkins C (2003) RTP: audio and video for the internet, 1st edn. Addison-Wesley Professional, Boston


89.
Ogunfunmi T, Togneri R, Narasimha M (eds) Speech and audio processing for coding, enhancement and recognition. Springer Science and Business Media


90.
Gabrielsson A, Sjögren H (1979) Perceived sound quality of sound-reproducing systems. J Acoust Soc Am 65(4):1019-1033Crossref


91.
Bernex E, Barriac V (2002) Architecture of non-intrusive perceived voice quality assessment. In: Proceedings of the international conference on measurement of speech and audio quality in networks (MESAQIN), CZ-Prague


92.
Etame T, Faucon G, Gros L, Le Bouquin Jeannes R, Quinquis C (2008) Characterization of the multidimensional perceptive space for current speech and sound codecs. In: Proceedings of the 124rd AES convention, no 7410, NE-Amsterdam


93.
McDermott BJ (1969) Multidimensional analyses of circuit quality judgements. J Acoust Soc Am 3(45):774-781Crossref


94.
Hall JL (2001) Application of multidimensional scaling to subjective evaluation of coded speech. J Acoust Soc Am 110(4):2167MathSciNetCrossref


95.
Mattila VV (2002) Ideal point modelling of speech quality in mobile communications based on multidimensional scaling (MDS). In: Proceedings of the 112th AES convention, no 5546. Audio Engineering Society, Munich


96.
Mattila VV (2002) Descriptive analysis and ideal point modelling of speech quality in mobile communication. In: Proceedings of the 113th AES convention, no 5704. Audio Engineering Society, Los Angeles


97.
Sen D (2001) Determining the dimensions of speech quality from PCA and MDS analysis of the diagnostic acceptability measure. MESAQUIN, CZ-Prague


98.
Sen D (2004) Predicting foreground SH, SL and BNH DAM scores for multidimensional objective measure of speech quality. In: IEEE international conference on acoustics, speech, and signal processing. Institute of Electrical and Electronics Engineers (IEEE)


99.
Wältermann M, Raake A, Möller S (2010) Quality dimensions of narrowband and wideband speech transmission. Acta Acust United Acust:1090-1103


100.
Côté N, Gautier-Turbin V, Möller S (2007) Influence of loudness level on the overall quality of transmitted speech. In: Proceedings of the 123rd AES convention, no 7175, USA-New York, NY


101.
ITU-T Recommandation P.10/G.100 (2006) Vocabulary for performance and quality of service. International Telecommunication Union, Geneva


102.
ITU-T Recommendation P.806 (2014) A subjective quality test methodology using multiple rating scales. International Telecommunication Union, Geneva


103.
ITU-T Contribution SG12-C228 (2011) P.MULTI subjective testing methodology number of relevant perceptual quality scales and additional validation of the test methodology. International Telecommunication Union, Geneva


104.
ITU-T Recommendation P.862 (2001) Perceptual evaluation of speech quality (PESQ): an objective method for end-to-end speech quality assessment of narrowband telephone networks and speech codecs. International Telecommunication Union, Geneva


105.
ITU-T Recommendation P.862.2 (2007) Wideband extension to recommendation P.862 for the assessment of wideband telephone networks and speech codecs. International Telecommunication Union, Geneva


106.
ITU-T Recommendation P.863 (2011) Perceptual objective listening quality assessment. International Telecommunication Union, Geneva


107.
Beerends JG, Stemerdink JA (1994) A perceptual speech-quality measure based on a psychoacoustic sound representation. J Audio Eng Soc 42(3):115-123


108.
Heute U, Möller S, Raake A, Scholz K, Wältermann M (2005) Integral and diagnostic speech-quality measurement: state of the art, problems, and new approaches. In; Proceedings of HO-Budapest, forum acusticum, pp 1695-1700


109.
Scholz K (2008) Instrumentelle Qualitätsbeurteilung von Telefonbandsprache beruhend auf Qualitätsattributen. Shaker Verlag, Kiel


110.
Huo L (2015) Attribute-based speech quality assessment—narrowband and wideband. Shaker Verlag, Kiel


111.
Sen D, Lu W (2012) Objective evaluation of speech signal quality by the prediction of multiple foreground diagnostic acceptability measure attributes. J Acoust Soc Am 131(5):4087Crossref


112.
ITU-T Temporary Document TD 438rev1 (GEN/12) (2014) Requirement specifications for P.AMD (perceptual approaches for multi-dimensional analysis). International Telecommunication Union, Geneva. Rapporteur Q.9/12 (J. Berger)


113.
ITU-T Recommendation P.563 (2004) Single-ended method for objective speech quality assessment in narrow-band telephony applications. International Telecommunication Union, Geneva


114.
Kim DS, Tarraf A (2004) Perceptual model for non-intrusive speech quality assessment. In: Proceedings of the IEEE ICASSP, Montreal, Canada


115.
ITU-T Temporary Document TD (GEN/14) (2014) Technical requirement specification P.SPELQ. International Telecommunication Union, Geneva. Rapporteur Q.9/12 (J. Berger)


116.
ITU-T Contribution SG12-C387 (2016) Proposal for a new work item on diagnostic single-ended quality indicators. International Telecommunication Union, Geneva


117.
Köster F, Mittag G, Polzehl T, Möller S (2016) Non-intrusive estimation of noisiness as a perceptual quality dimension of transmitted speech. In: Proceedings of the 5th international workshop on perceptual quality of systems (PQS 2016), pp 74 - 78


118.
Mittag G, Köster F, Möller S (2016) Non-intrusive estimation of the perceptual dimension coloration. In: Fortschritte der Akustik, DAGA 2016: Plenarvortr. u. Fachbeitr. d. 42. Dtsch. Jahrestg. f. Akust., DEGA


119.
Köster F, Cercos-Llombart V, Mittag G, Möller S (2016) Non-intrusive estimation model for the speech-quality dimension loudness. In: Informationstechnische gesellschaft im VDE (ITG) conference on speech communication, 2016. ITG, pp 175-179


120.
Cavanaugh JR, Hatch RW, Sullivan JL (1976) Models for the subjective effects of loss, noise, and talker echo on telephone connections. Bell Syst Tech J 55(9):1319-1371Crossref


121.
Osaka N, Kakehi K (1986) Objective model for evaluating telephone transmission performance. Rev Electr Commun Lab 34(4):437-444


122.
Johannesson N (1997) The ETSI computation model: a tool for transmission planning of telephone networks. IEEE Commun Mag 35(1):70-79Crossref


123.
Zollinger SA, Brumm H (2011) The lombard effect. Curr Biol 21(16):R614-R615Crossref


124.

                Lombard E (1911) Le signe de l'
                
                l
                
                vation de la voix. Annales des Maladies de L'Oreille et du Larynx 37:101-119
              


125.
Lane H, Tranel B (1971) The lombard sign and the role of hearing in speech. J Speech Lang Hear Res 14(4):677Crossref


126.
Proakis J (2007) Digital signal processing: principles, algorithms, and applications, 4/E. Pearson Education, New York


127.
Vlaj D, Kacic Z (2011) The influence of lombard effect on speech recognition. In: Speech Technologies. InTech


128.
ITU-T Recommendation P.831 (1998) Subjective performance evaluation of network echo cancellers. International Telecommunication Union, Geneva


129.
ITU-T Recommandation G.107 (2011) The E-model: a computational model for use in transmission planning. International Telecommunication Union, Geneva


130.
Egger S, Reichl P, Schoenenberg K (2014) Quality of experience and interactivity. In: Möller S, Raake A (eds) Quality of experience. Springer International Publishing, pp 149-161


131.
Möller S, Engelbrecht K-P, Kühnel C, Naumann A, Wechsung I, Weiss B (2010) Evaluation of multimodal interfaces for ambient intelligence. In: Human-centric interfaces for ambient intelligence. Elsevier BV, pp 347-370


132.
Möller S, Engelbrecht K-P, Kühnel C, Wechsung I, Weiss B (2009) A taxonomy of quality of service and quality of experience of multimodal human-machine interaction. In: International workshop on quality of multimedia experience, QoMEx 2009. IEEE, pp 7-12


133.
ITU-T Recommandation G.114 (2003) One-way transmission time. International Telecommunication Union, Geneva


134.
ITU-T Recommendation P.805 (2007) Subjective evaluation of conversational quality. International Telecommunication Union, Geneva


135.
ITU-T Contribution SG12-C35 (1997) Development of scenarios for short a conversation test. International Telecommunication Union, Geneva


136.
Kitawaki N, Itoh K (1991) Pure delay effects on speech quality in telecommunications. IEEE J Sel Areas Commun 9(4):586-593Crossref


137.
ITU-T Contribution SG12-C55 (2003) A subjective/objective test protocol for determining the conversational quality of a voice link. International Telecommunication Union, Geneva


138.
ITU-T Temporal Document TD 27 (WP 2/12) (2005) Proposed scope for P.CQO. International Telecommunication Union, Geneva


139.
ITU-T Temporary Document TD 965 Rev.1 (GEN/12) (2016) Revised status report of question 7/12). International Telecommunication Union, Geneva. Rapporteur Q.7/12 (P. Usai)


140.
ETSI ETR 250 (1996) Speech communication quality from mouth to ear for 3,1 kHz handset telephony across networks. European Telecommunications Standards Institute, Sophia Antipolis


141.
ITU-T Recommandation G.107.1 (2011) Wideband E-model. International Telecommunication Union, Geneva


142.
ITU-T Recommandation G.113 (2007) Transmission impairments due to speech processing. International Telecommunication Union, Geneva


143.
Hammer F, Reichl P, Raake A (2005) The well-tempered conversation: interactivity, delay and perceptual VoIP quality. In: Proceedings of the IEEE international conference on communications (ICC), Seoul, Korea


144.
Köster F, Möller S (2014) Analyzing perceptual dimensions of conversational speech quality. In: Proceedings of 15th Annual Conference of the International Speech Communication Association (Interspeech 2014). ISCA Interspeech 2014 Proceedings, Singapore, pp 2041-2045


145.
Kruskal J, Wish M (1978) Multidimensional scaling, quantitative applications in the social sciences. SAGE Publications, Newbury


146.
Choe B (2001) Nonmetric multidimensional scaling of complex sounds: dimensions of preference ratings and perceived similarity of vehicle noises. Shaker, Kiel


147.
Kruskal J (1964) Nonmetric multidimensional scaling: a numerical method. Psychometrika 29(2):115-129MathSciNetCrossrefMATH


148.
Takane Y, Young FW, De Leeuw J (1977) Nonmetric individual differences multidimensional scaling: an alternating least squares method with optimal scaling features. Psychometrika 42:7-67CrossrefMATH


149.
Kaiser HF (1958) The varimax criterion for analytic rotation in factor analysis. Psychometrika 23(3):187-200CrossrefMATH


150.
MATLAB/Simulink (2014) Version 8.3.0.532 (R2014a). The MathWorks Inc., Natick


151.
Bortz J (2005) Statistik. Springer, Berlin


152.
Hinterleitner F, Norrenbrock C, Möller S, Heute U (2012) What makes this voice sound so bad? A multidimensional analysis of state-of-the-art text-to-speech systems. In: Proceedings of the 2012 IEEE workshop on spoken language technology (SLT), Miami, USA, pp 240-245


153.

                Puckette M (2015) Puredata.
                http://​puredata.​info/​
                . Accessed 26 Aug 2015
              


154.

                The Telephone.
                https://​github.​com/​TheTelephone
                . Accessed 19 Sep 2016
              


155.
Helder GK (1966) Customer evaluation of telephone circuits with delay. Bell Syst Tech J 45(7):1157-1191Crossref


156.
ITU-T Contribution SG12-C388 (2016) Proposal for a draft new recommendation for a subjective test methodology to analyse transmitted speech in a telephone conversation as a baseline for P.CQO. International Telecommunication Union, Geneva


157.
Köster F, Möller S (2016) Introducing a new test-method for diagnostic speech quality assessment in a conversational situation. In: Fortschritte der Akustik—DAGA 2016: Plenarvortr. u. Fachbeitr. d. 42. Dtsch. Jahrestg. f. Akust. DEGA, Berlin


158.
ITU-T Contribution SG12-C304 (2016) Introducing a new subjective test methodology to analyse conversational quality. International Telecommunication Union, Geneva


159.
Köster F, Möller S (2015) Perceptual speech quality dimensions in a conversational situation. In: Proceedings of the 16th Annual Conference of the International Speech Communication Association (Interspeech 2015). ISCA Interspeech 2015 Proceedings, Dresden, Germany, pp 2544-2548


160.
Berger J, Llagostera A (2015) Multidimensional evaluation and predicting overall speech quality. In: Proceedings of 16th Annual Conference of the International Speech Communication Association (Interspeech 2015). ISCA Interspeech 2015 Prceedings, Dresden, Germany, pp 2549-2552


161.
Belmudez B, Lewcio B, Möller S (2013) Call quality prediction for audiovisual time-varying impairments using simulated conversational structures. Acta Acust United Acust 99(5):792-805Crossref


162.
Field A (2013) Discovering statistics using IBM SPSS statistics, 4th edn. SAGE Publications Ltd., Newbury


163.
Miles J, Shevlin M (2001) Applying regression and correlation: a guide for students and researchers. SAGE Publications Ltd., 2001


164.

                F. Köster and S. Möller, "Analyzing the Relation Between Overall Quality and the Quality of Individual Phases in a Telephone Conversation," in
                Proc. 17th Ann. Conf. of the Int. Speech Comm. Assoc. (Interspeech 2016)
                . San Francisco, USA: ISCA Interspeech 2016 Proceedings, 2016, pp. 2493-2497
              


165.
Glasberg BR, Moore BCJ (2002) A Model of Loudness Applicable to Time-Varying Sounds. Journal of the Audio Engineering Society 50(5):331-342














T-Labs Series in Telecommunication Services

Series Editors

Sebastian Möller

Quality and Usability Lab, Technical University of Berlin, Berlin, Germany

Axel Küpper

Deutsche Telekom Laboratories, Technical Univ of Berlin, Berlin, Germany

Alexander Raake

Innov Labs, Assessment of IP-based Apps, Technical Univ of Berlin, Telekom, Berlin, Germany





          More information about this series at
          http://​www.​springer.​com/​series/​10013






Friedemann Köster



Multidimensional Analysis of Conversational Telephone Speech













Friedemann Köster

Quality and Usability Lab, Technical University of Berlin, Berlin, Germany





ISSN 2192-2810
e-ISSN 2192-2829

T-Labs Series in Telecommunication Services


					ISBN 978-981-10-5223-1
e-ISBN 978-981-10-5224-8


https://doi.org/10.1007/978-981-10-5224-8

Library of Congress Control Number: 2017946624
© Springer Nature Singapore Pte Ltd. 2018
Zugl.: Berlin, Technische Universität, Diss., 2017
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Printed on acid-free paper

This Springer imprint is published by Springer Nature
The registered company is Springer Nature Singapore Pte Ltd.
The registered company address is: 152 Beach Road, #21-01/04 Gateway East, Singapore 189721, Singapore



Acknowledgements

The present book is the result of the work I have performed in the context of my doctoral dissertation at the Quality and Usability Lab, Technische Universität Berlin. It would not have been possible without the help of numerous people who have given their support. As the people who deserve acknowledgments are numerous to list, I mention all of them who receive my special thanks, all others who are not mentioned shall be aware of my appreciation.

                I would like to thank the following:
                First of all, I would like to thank my supervisor, Prof. Dr.-Ing. Sebastian Möller, for his support, his advise, his scientific assistance, his motivation, and last but not least, for enabling this thesis.Prof. Dr.-Ing. Ulrich Heute for introducing me into the topic of speech quality and for co-supervising the thesis.Prof. Dr.-Ing. Jens Ahrens for being a very helpful colleague and taking the role of an "uncle" during my Ph.D. time as well as for also co-supervising the thesis.Dr.-Ing. Christoph Norrenbrock for introducing me into scientific work.The Deutsche Forschungsgemeinschaft (DFG) for their financial support.Irene Hube-Achter and Yasmin Hillebrenner for their support in all administrative steps.Dr.-Ing. Sebastian Arndt for reviewing the manuscript and for being a helpful and supporting colleague.Dr. Dennis Guse also for reviewing the manuscript, for his support, and for his open ear for all "problems".All former and current colleagues at the Quality and Usability Lab, including Dr.-Ing. Benjamin Bähr, Dr. Benjamin Weiss, Falk Schiffner, Dr.-Ing. Tilo Westermann, Dr.-Ing. Justus Bayer, Dr.-Ing. Tim Polzehl, Dr.-Ing. Florian Hinterleitner, Patrick Ehrenbrink, Babak Naderi, Tobias Hirsch, Laura Fernandez Gallardo, Ph.D., Steffen Zander, and many more...My students, Gabriel Mittag, Maxim Szepansky, and Maxim Spur, for their help and for "keeping my back free".The colleagues from the ITU SG 12, including Ludovic Malfait, Dr.-Ing. Jens Berger, and Vincent Barriac.All my friends who supported me in all sorts of ways, especially Hauke Günther, Florian von Oertzen, and Johann Harmstorf, as well as all former study buddies.Everybody who supported me during my defense.My family, in particular my sister, Karoline, my mother, Dr. Ulrike Köster, and my grandmother, Hannelore Nausch, as well as all the Bucherts.A very special thank you to my life-coach and greatest supporter, my beloved and missed father, Dr. med. Eckhard Köster.My daughter, Marlene, for giving me a deadline.And finally, I have to thank the most important person, my wife, Kristina!

Thank you very much, everyone!
Berlin
May 2017


Friedemann Köster



Acronyms



A/D

Analog/Digital



ACR

Absolute Category Rating



ANIQUE

Auditory Non-Intrusive QUality Estimation



ANOVA

ANalysis Of VAriance



AP

Antonym-Pairs



CCR

Comparison Category Rating



CI

Confidence Interval



CMOS

Comparison Mean Opinion Score



CO

Overall Conversation



Col

Coloration



CQO

Conversation Quality Objective



CQS

Conversation Quality Subjective



CT

Conversation Test



DAM

Diagnostic Acceptability Measure



DCR

Degradation Category Rating



DIAL

Diagnostic Instrumental Assessment of Listening quality



Dim

Dimension



Dis

Discontinuity



DMOS

Degradation Mean Opinion Score



DNC

Discontinuity Noisiness Coloration



Dos

Degradation of one's own voice



EC

Echo Cancellation



ER

Echo Reduction



ERB

Equivalent Rectangular Bandwidth



ETSI

European Telecommunication Standards Institute



FB

Fullband



GC

Gain Control



GSM

Global System for Mobile Communications



ICT

Information and Communication Technology



IN

Interaction Phase



Ios

Impact of one's own voice on speaking



IRS

Intermediate Reference System



iSCT

Interactive Short Conversation Task



ISDN

Integrated Service Digital Network



ITU

International Telecommunication Union



LI

Listening Phase



LOT

Listening-Only Tests



Lou

Loudness



LP

Linear Prediction



LPC

Linear Predictive Coding



LQO

Listening Quality Objective



LQS

Listening Quality Subjective



LTE

Long-Term Evolution



LTL

Long-Term Loudness



LTM

Long-Term Memory



MDS

Multi-Dimensional Scaling



MNRU

Modulated Noise Reference Unit



MOS

Mean Opinion Score



MULTI

MULTIple rating scales



NB

Narrowband



Noi

Noisiness



NOS

Noise on Speech



NR

Noise Reduction



OPINE

Overall Performance Index model for Network Evaluation



P.AMD

Perceptual Approaches for Multi-Dimensional analysis



P.CQO

Conversational Quality Objective



P.CQS

Conversational Quality Subjective



P.SAMD

Single-ended Perceptual Approaches for Multi-Dimensional analysis



P.TCA

Technical Causes Analysis



PC

Principal Component



PCA

Principal Component Analysis



PCM

Pulse Code Modulation



PD

Pure Data



PESQ

Perceptual Evaluation of Speech Quality



PESQM

Perceptual Echo and Sidetone Quality Measure



PLC

Packet-Loss Concealment



PM

Preference Mapping



POLQA

Perceptual Objective Listening Quality Assessment



PS

Pairwise Similarity



PSQM

Perceptual Speech Quality Measure



PSTN

Public Switched Telephone Network



QoE

Quality of Experience



QoS

Quality of Service



RMSE

Root Mean Square Error



RNVT

Random Number Verification Task



RTP

Real-time Transport Protocol



SAR

Speaker Alternation Rate



SCT

Short Conversation Test



SD

Semantic Differential



SNR

Signal-to-Noise Ratio



SOT

Speaking-Only Tests



SP

Speaking Phase



SQO

Speaking Quality Objective



SQS

Speaking Quality Subjective



STM

Short-Term Memory



STMR

SideTone Masking Rating



S-WB

Super-Wideband



TELR

Talker Echo Loudness Rating



TOSQA

Telecommunication Objective Speech Quality Assessment



UDP

User Datagram Protocol



UMTS

Universal Mobile Telecommunications System



VAD

Voice Activity Detection



VIF

Variance Inflation Factor



VoIP

Voice over Internet Protocol



WB

Wideband



ZI

Zero Insertion







Contents





1 Introduction

1





2 Fundamentals

5




2.​1 Research Scenario

5





2.​2 Human Speech

7




2.​2.​1 Production

7





2.​2.​2 Transmission

9





2.​2.​3 Perception

12






2.​3 Quality of Transmitted Speech

14




2.​3.​1 Definition of Perceived Quality

14





2.​3.​2 Quality Features and Quality Elements

18





2.​3.​3 Perceptual Quality Space and the Concept of Diagnosing Speech Quality

19





2.​3.​4 Assessment Methods

23






2.​4 Conclusion

31






3 Speech Quality in a Telephone Conversation

33




3.​1 Phases of a Conversation

33





3.​2 Quality Elements

35




3.​2.​1 User Terminal

36





3.​2.​2 Sidetone

37





3.​2.​3 Analog to Digital Converter

37





3.​2.​4 Gain Control

37





3.​2.​5 Voice Activity Detection

38





3.​2.​6 Noise

38





3.​2.​7 Echo

39





3.​2.​8 Speech Codec

39





3.​2.​9 Packet-Loss

40





3.​2.​10 Delay

41






3.​3 The Listening Phase

41




3.​3.​1 Perceptual Quality Space

42





3.​3.​2 Subjective Methods

45





3.​3.​3 Instrumental Methods

48






3.​4 The Speaking Phase

50




3.​4.​1 Perceptual Quality Space

51





3.​4.​2 Subjective Methods

52





3.​4.​3 Instrumental Methods

53






3.​5 The Interaction Phase

54




3.​5.​1 Perceptual Quality Space

56





3.​5.​2 Subjective Methods

58





3.​5.​3 Instrumental Methods

61





3.​5.​4 Conversational Parameters

64






3.​6 Conclusion and Research Topics Covered in This Book

64






4 Perceptual Quality Space in a Telephone Conversation

67




4.​1 Introduction

67





4.​2 Experimental Paradigms to Analyze the Perceptual Quality Space

67




4.​2.​1 Multidimensional​ Scaling

68





4.​2.​2 Semantic Differential

69






4.​3 Uncovering the Perceptual Quality Space in the Speaking Phase

70




4.​3.​1 Technical Setup

70





4.​3.​2 Test Design

71





4.​3.​3 SD Experiment

71





4.​3.​4 Results

72





4.​3.​5 MDS Experiment

74





4.​3.​6 Results

75





4.​3.​7 Discussion

77






4.​4 Uncovering the Perceptual Quality Space in the Interaction Phase

78




4.​4.​1 Technical Setup

78





4.​4.​2 Test Design

78





4.​4.​3 SD Experiment

79





4.​4.​4 Results

80





4.​4.​5 MDS Experiment

81





4.​4.​6 Results

81





4.​4.​7 Discussion

82






4.​5 Conclusion

83






5 Direct Scaling of Perceptual Dimensions in a Conversational Situation

85




5.​1 Introduction and Scope

85





5.​2 Rating Scales

87





5.​3 Test Procedure

88




5.​3.​1 General

88





5.​3.​2 Dimension Rating Scheme

90





5.​3.​3 Reference Conditions

91





5.​3.​4 Test Duration

92






5.​4 Setup

94




5.​4.​1 Test Rooms and Test Subjects

94





5.​4.​2 Introduction and Training

94






5.​5 Conclusion

96






6 Conversational Validation Experiments

97




6.​1 Introduction

97





6.​2 Validation of the Perceptual Quality Space

98




6.​2.​1 Test Design

98





6.​2.​2 Results

100





6.​2.​3 Discussion

104






6.​3 Validation of the Direct Scaling Test Method

105




6.​3.​1 Test Design

105





6.​3.​2 Results

106





6.​3.​3 Discussion and Conclusion

120






6.​4 Comparison of the Two Validation Experiments

121





6.​5 Conclusion

123






7 Resulting Quality Profile in a Telephone Conversation

125




7.​1 Introduction

125





7.​2 Relation Between the Dimension Scores and the Overall Conversational Quality

127





7.​3 Relation Between the Dimension Scores and the Quality of Individual Phases

130





7.​4 Relation Between the Overall Conversational Quality and the Quality of Individual Phases

134





7.​5 Conclusion

137






8 Instrumental Diagnostic Conversational Quality Modeling

139




8.​1 Introduction

139





8.​2 General Approach

140





8.​3 Modeling Perceptual Dimension Scores of the Listening Phase

141





8.​4 Modeling Perceptual Dimension Scores of the Speaking Phase

147





8.​5 Modeling Perceptual Dimension Scores of the Interaction Phase

153





8.​6 Modeling the Overall Conversational Quality

156





8.​7 Conclusion

158






9 Conclusions and Future Work

161



Appendix A: Short Conversation Test (SCT)
167


Appendix B: Random Number Verification Task (RNVT)
169


Appendix C: Test Instructions
171


References
177















