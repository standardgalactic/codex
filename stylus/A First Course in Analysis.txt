





















  A First Course in Analysis
This rigorous textbook is intended for a year-long analysis or advanced calculus
course for advanced undergraduate or beginning graduate students. Starting with
detailed, slow-paced proofs that allow students to acquire facility in reading and
writing proofs, it clearly and concisely explains the basics of differentiation and
integration of functions of one and several variables, and covers the theorems of
Green, Gauss, and Stokes. Minimal prerequisites are assumed, and relevant linear
algebra topics are reviewed right before they are needed, making the material
accessible to students from diverse backgrounds. Abstract topics are preceded by
concrete examples to facilitate understanding - e.g. before introducing differential
forms, the text examines low-dimensional examples. The meaning and importance
of results are thoroughly discussed, and numerous exercises of varying difficulty give
students ample opportunity to test and improve their knowledge of this difficult yet
vital subject.
John B. Conway is Professor Emeritus of Mathematics at George Washington
University. He is the author of eleven books, including Mathematical Connections: A
Capstone Course, A Course in Functional Analysis, and the two-volume Functions
of One Complex Variable.















Cambridge Mathematical Textbooks

Cambridge Mathematical Textbooks
is a program of undergraduate and beginning graduate level textbooks for core
courses, new courses, and interdisciplinary courses in pure and applied mathematics.
These texts provide motivation with plenty of exercises of varying difficulty,
interesting examples, modern applications, and unique approaches to the material.
Advisory Board
John B. Conway, George Washington University
Gregory F. Lawler, University of Chicago
John M. Lee, University of Washington
John Meier, Lafayette College
Lawrence C. Washington, University of Maryland, College Park
 A complete list of books in the series can be found at
www.cambridge.org/mathematics Recent titles include the following:
 


Chance,
 Strategy,
 and
 Choice:
 An
 Introduction
 to
 the
 Mathematics
 of
 Games
 and
 Elections,
 S.
 B.
 Smith
 

Set
 Theory:
 A
 First
 Course,
 D.
 W.
 Cunningham
 

Chaotic
 Dynamics:
 Fractals,
 Tilings,
 and
 Substitutions,
 G.
 R.
 Goodson
 

Introduction
 to
 Experimental
 Mathematics,
 S.
 Eilers
 &
 R.
 Johansen
 

A
 Second
 Course
 in
 Linear
 Algebra,
 S.
 R.
 Garcia
 &
 R.
 A.
 Horn
 

Exploring
 Mathematics:
 An
 Engaging
 Introduction
 to
 Proof ,
 J.
 Meier
 &
 D.
 Smith
 

A
 First
 Course
 in
 Analysis,
 J.
 B.
 Conway
 













"This is an excellent text for a first course in analysis in one and several variables
for students who know some linear algebra. The book starts with the real
numbers, does differentiation and integration first in one variable, then in several,
and finally covers differential forms and Stokes' theorem. The style is friendly and
conversational, and hews to the principal of going from the specific to the
general, making it a pleasure to read."
- John McCarthy, Washington University in St.
Louis
"Conway's previous texts are all considered classics. "A First Course in
Analysis" is destined to be another. It is written in the same friendly, yet
rigorous, style that his readers know and love. Instructors seeking the breadth
and depth of Rudin, but in a less austere and more accessible form, have found
their book."
- Stephan Ramon Garcia, Pomona
College
"This is a beautiful yet practical introduction to rigorous analysis at the senior
undergraduate level, written by a master expositor. Conway understands how
students learn, from the particular to the general, and this informs every aspect
of his text. Highly recommended."
- Douglas Lind, University of
Washington
"A First Course in Analysis charts a lively path through a perennially tough
subject. Conway writes as if he's coaching his reader, leavening the technicalities
with advice on how to think about them, and with anecdotes about the
subject's heroes. His enjoyment of the material shines through on page after
page."
- Bruce Solomon, Indiana University,
Bloomington
"This year-long undergraduate book carefully covers real analysis "from
sets to Stokes" and is done in a friendly style by an experienced teacher
and masterful expositor. There are plenty of examples, exercises, and
historical vignettes that both give the student the opportunity to gain
technical mastery of the material and to whet their appetites for further
study."
- William T. Ross, University of
Richmond
"A First Course in Analysis is a beautifully written and very accessible
treatment of a subject that every math major is required to learn. It will join
Conway's other textbooks as a classic in Advanced Calculus. Those who teach
 
 and learn analysis through Conway's book will appreciate his cheerful and
 easy-to-understand style."
 
- Wing Suet Li, Georgia Institute of
 Technology
 
 
 













 
A First Course in Analysis
John B. Conway
The George Washington University, Washington, DC, USA















 
 
University
Printing
House,
Cambridge
CB2
8BS,
United
Kingdom
One
Liberty
Plaza,
20th
Floor,
New
York,
NY
10006,
USA
477
Williamstown
Road,
Port
Melbourne,
VIC
3207,
Australia
4843/24,
2nd
Floor,
Ansari
Road,
Daryaganj,
Delhi
-
110002,
India
79
Anson
Road,
#06-04/06,
Singapore
079906
 
 

Cambridge
University
Press
is
part
of
the
University
of
Cambridge.

It
furthers
the
University's
mission
by
disseminating
knowledge
in
the
pursuit
of
education,
learning
and
research
at
the
highest
international
levels
of
excellence.

www.cambridge.org
Information
on
this
title:
www.cambridge.org/9781107173149
DOI:
10.1017/9781316779811

Â©
 John
 B.
 Conway
 2018
 
This
 publication
 is
 in
 copyright.
 Subject
 to
 statutory
 exception
 and
 to
 the
 provisions
 of
 relevant
 collective
 licensing
 agreements,
 no
 reproduction
 of
 any
 part
 may
 take
 place
 without
 the
 written
 permission
 of
 Cambridge
 University
 Press.
 
First
 published
 2018
 
Printed
in
the
United
States
of
America
by
Sheridan
Books,
Inc.

A
catalog
record
for
this
publication
is
available
from
the
British
Library.
ISBN
978-1-107-17314-9
Hardback

Cambridge
University
Press
has
no
responsibility
for
the
persistence
or
accuracy
of
URLs
for
external
or
third-party
internet
websites
 
 referred
 to
 in
 this
 publication,
 and
 does
 not
 guarantee
 that
 any
 content
 on
 such
 websites
 is,
 or
 will
 remain,
 accurate
 or
 appropriate.
 

















 For
AnnAs
always
 
 













Contents

Preface
1 The Real Numbers
1.1 Sets and Functions
1.2 The Real Numbers
1.3 Convergence
1.4 Series
1.5 Countable and Uncountable Sets
1.6 Open Sets and Closed Sets
1.7 Continuous Functions
1.8 Trigonometric Functions
2 Differentiation
2.1 Limits
2.2 The Derivative
2.3 The Sign of the Derivative
2.4 Critical Points
2.5 Some Applications
3 Integration
3.1 The Riemann Integral
3.2 The Fundamental Theorem of Calculus
3.3 The Logarithm and Exponential Functions
3.4 Improper Integrals
3.5 Sets of Measure Zero and Integrability
3.6 The Riemann-Stieltjes Integral
4 Sequences of Functions
4.1 Uniform Convergence
4.2 Power Series
5 Metric and Euclidean Spaces
5.1 Definitions and Examples
5.2 Sequences and Completeness
5.3 Open and Closed Sets
5.4 Continuity
5.5 Compactness
5.6 Connectedness
5.7 The Space of Continuous Functions
6 Differentiation in Higher Dimensions
6.1 Vector-valued Functions
6.2 Differentiable Functions, Part 1
6.3 Orthogonality
6.4 Linear Transformations
6.5 Differentiable Functions, Part 2
6.6 Critical Points
6.7 Tangent Planes
6.8 Inverse Function Theorem
6.9 Implicit Function Theorem
6.10 Lagrange Multipliers
7 Integration in Higher Dimensions
7.1 Integration of Vector-valued Functions
7.2 The Riemann Integral
7.3 Iterated Integration
7.4 Change of Variables
7.5 Differentiation under the Integral Sign
8 Curves and Surfaces
8.1 Curves
8.2 Green's Theorem
8.3 Surfaces
8.4 Integration on Surfaces
8.5 The Theorems of Gauss and Stokes
9 Differential Forms
9.1 Introduction
9.2 Change of Variables for Forms
9.3 Simplexes and Chains
9.4 Oriented Boundaries
9.5 Stokes's Theorem
9.6 Closed and Exact Forms
9.7 Denouement
Bibliography
Index of Terms
Index of Symbols














Preface
This book is intended for the year-long course on analysis taught to
undergraduates near the end of their education and graduate students at
the beginning of theirs. It is recommended for students in the physical
sciences, economics, and statistics. Sometimes this course is titled Advanced
Calculus and sometimes just Analysis. The subject matter comprises the
basics of differentiation and integration of functions of one and several
variables, topped off with some form of the theorems of Green, Gauss, and
Stokes.
How is the material presented in this book? A guiding principle I have
followed for a long time when I teach or when I write a textbook, as
opposed to a monograph, is to go from the particular to the general.
This practice came about from a combination of what I observed in the
classroom and the historical way mathematics developed. The present book
contains many instances of this approach, but a dramatic illustration is
what happens in the last two chapters on surfaces and the Green, Gauss,
and Stokes Theorems. I begin (Chapter 8) with an exposition of what
happens in  and  including proofs of these just mentioned theorems
in this setting. Unlike the rest of this book, however, there are places
here where I relax the rigor. This is especially so when I discuss the
orientation of surfaces in . In the following chapter (Chapter 9) I
introduce differential forms on , constantly illustrating everything with
reference to what was seen in the lower dimensional spaces. Here rigor is
enforced. After we establish the Generalized Stokes Theorem, we go back and
prove the particular cases of the three big theorems in  and  as a
consequence. I think this is a better approach than going directly to a treatment
of differential forms and surfaces in . My experience is that most
students at this level are not ready for such a direct route without some
preparation.
Another philosophy of mine in writing is not to introduce a concept until it's
needed; I want the reader to quickly see the concept in action. For example I
wanted to give a rather detailed diagnosis of the nature of a critical point for a
function from  into . For me this entails introducing symmetric matrices
and the Spectral Theorem. This could have been done in a special chapter on
linear algebra. Instead I waited until we were ready to discuss critical
points. In the first course in Linear Algebra the usual practice, due to time
constraints, is never to talk about the Spectral Theorem. I therefore prove it in
.
Speaking of linear algebra, that's a major difficulty for anyone teaching a version
of this course. It was certainly a problem when I was writing this book. Linear algebra
is a stated prerequisite, but I know most of the students whom I've taught over
the years have forgotten some of the linear algebra they learned. Nevertheless when
we teach a course on multivariable analysis we cannot reteach linear algebra. The
path I take is to recall some of the high points, usually without proofs. On the other
hand I need and use more on determinants than I think students know or have even
seen. As a consequence I define determinants (6.4.18) and derive their properties,
though the proofs tend more toward the sketchy than elsewhere in this book.
Another of my beliefs about teaching and writing a text is that just because I
know some topic that extends the basic material doesn't mean I should teach it
in a class or include it in the text. Besides, I want to keep the book lean. I also
want to have confidence that anyone using this book could make it to the
multivariable versions of the Fundamental Theorem of Calculus. I suspect
many instructors will regret the absence of some topic they like. If this
is your case, I'm sorry; but I think you'll find other interesting things
here.
Universities with graduate programs frequently have graduate students enrolled
in this course. When I teach a mixed class I focus on the undergraduates; this is
what I did while writing this book. This has several consequences. I assume a
minimum background: three semesters of calculus and a semester of linear
algebra. I have to also assume that the students have some level of comfort
reading and writing proofs. I certainly am aware that someone with my
stated minimum background may not be comfortable with proofs. As a
partial bridge, the proofs that are in the first half of the book are more
detailed.
Finally, three additional statements about this book. When I write a text I
always imagine myself presenting the material in front of a classroom. Some have
commented on my "chatty" style and this is the source. Sections marked with an
asterisk (*) are optional and are not needed for the rest of the book. You might
also observe that to some extent computational exercises are sparse (but not
absent). It seems to me that students have done a lot of such things in the
three semesters of calculus that is assumed of the readers of this text. If
they survived that, I didn't see a reason to put more of the same here.
Synopsis of the Chapters
The book begins with a chapter on the real numbers and some other basic
material. It may be that some students could skip part of this, but I suspect it
will be rare that there is a student in a class using this book who could skip the
 
 entire chapter. The starting point is a development of the real numbers assuming
 that you understand the rationals. I give two approaches to this: an abbreviated
 one and a more thorough one. (This thorough one still has some gaps as this
 is not the focus of this book.) The chapter also includes material on
 sequences, open and closed sets in , continuity, as well as countable
 and uncountable sets. The point of this chapter is to give all readers
 a chance to fill in gaps and expose them to proofs. (The proofs here
 are straightforward and presented in more detail than elsewhere in the
 book.)
 
The next three chapters contain the core of the basic material in one
 dimension. Chapter 2 is on differentiation in one variable and concludes with
 l'HÃ´pital's Rule and Taylor's Theorem. Chapter 3 gives the theory of the
 Riemann integral over subsets of . It also contains starred sections on
 Lebesgue's Theorem giving a necessary and sufficient condition for integrability
 and the Riemann-Stieltjes integral. Chapter 4 is entitled "Sequences of
 Functions." It covers the standard material on uniform convergence as well as
 power series.
 
Chapter 5 is entitled "Metric and Euclidean spaces." I am aware
 that many books at this level avoid metric spaces, but I decided not to.
 Less you think this violates my principle of going from the particular to
 the general, don't forget that almost everything here has first appeared
 as a result for  in Chapter 1. When this is combined with the fact
 that the exposition is replete with examples in  that illustrate the
 results, I feel comfortable that my principle is intact. It also seems to
 me that proofs in the abstract spaces are easier. In fact if you state a
 result in Euclidean space and try to fashion a proof of it, you are strongly
 tempted to get involved with coordinates and such while the proof in
 metric spaces is clean and shows what is really going on. The chapter
 ends with a section on spaces of continuous functions. Included here are
 the Stone-Weierstrass Theorem and the Arzela-Ascoli Theorem, two
 results I consider basic but are frequently omitted at this level. (In fact
 the Stone-Weierstrass Theorem is used to prove Fubini's Theorem in
 Chapter 7.)
 
Chapter 6, "Differentiation in Higher Dimensions," covers the standard topics
 in this subject. An introduction and recollection of most of the linear algebra
 needed for the rest of the book is presented and used here. The treatment of
 critical points may differ from most books. Here the observation that the second
 derivative of a C-function from  into  is a hermitian linear
 transformation is central. This permits the application of the Spectral Theorem
 and allows us to carefully analyze the behavior of the function at a critical point,
 even when it's a saddle point.
 
Chapter 7 is titled "Integration in Higher Dimensions" and covers the
 Riemann integral in an abbreviated way. It seems to me that some books spend
 too much time on this integral, time that I think can be better spent on other
things. The treatment of Riemann integration given in Chapter 7 achieves
simplicity and rigor by only integrating continuous functions. Students who
continue their study of mathematics will see the Lebesgue integral, which is
not only more general but a lot easier to understand than an in-depth
treatment of the Riemann integral in . For example, the issue of
integrability is largely dormant in the Lebesgue case but complicated in
the Riemann case. Students who don't continue in mathematics are not
hurt, since when they encounter integration in higher dimensions in their
future life it is almost always an iterated integral and what we do here is
ample.
Chapter 8, "Curves and Surfaces," focuses on these objects in  and .
Chapter 9, "Differential Forms," extends this to . I've already discussed
these chapters and the approach taken.
References and Sources
As I indicate at various places in the body of this book, I have used [7], [11], and
[15] while I was writing this book. I have certainly used the last two as sources of
exercises. Also I've made use of the Internet more heavily than with any of my
previous books. Sometimes I used articles from the Web that, as far as I know,
are not available in print. When I did this I usually corresponded with the author
if (s)he was identifiable. In the Bibliography I list this reference with the site
as I found it during one of my final readings of this book. I also found
a lot of my exercises online. Sometimes these were found on the Web
where no author was designated; in such a case I did not reference the
site.
Biographical notes
As in my last two books I have added a short biographical note for any
mathematician whose work is quoted. There is no scholarship on my part in this,
as all the material is from secondary sources, principally what I could find on the
Web. In particular, I made heavy use of the St Andrews University site
www-history.mcs.st-andrews.ac.uk/history/BiogIndex.html and
some use of Wikipedia.
I emphasize the personal aspects of the mathematicians we encounter along
the way, rather than recite their achievements. This is especially so when I
discover something unusual or endearing in their lives. I figure many students will
see their achievements if they stick with the subject and most, at this stage of
 
 their education, won't know enough mathematics to fully appreciate the
 accomplishments. In addition I think the students will enjoy learning that these
 famous people were human beings.
 
For Students
From a simplistic point of view, this course repeats calculus. That's grossly
 misleading. True, we'll talk about differentiation and integration in one and
 several variables and I am assuming that all students have completed the
 standard three-semester sequence in calculus. On the other hand everything done
 here will be presented with complete mathematical rigor. The emphasis is not on
 computing but on understanding the concepts; part of that understanding is
 proving the results as well as working out examples and exercises. In addition,
 we'll see new material in the second semester when we discuss integration of
 functions defined on surfaces.
 
I've long thought this course is the most difficult in the undergraduate
 curriculum. It's also one of the most important for your future in mathematics,
 whether you go on to graduate school or begin a career just after graduation. So
 work hard at this.
 
My advice to all students is to read the book with paper and a writing implement
 of your choice. Draw pictures, if this is needed. For goodness sake, read the material
 between the proofs; these paragraphs contain a lot that will help your understanding.
 I leave a lot of detail checking to the reader and frequently insert such things as
 (Why?) or (Verify!) in the text. I want you to delve into the details and answer
 these questions. It will check your understanding and give some perspective on the
 proof.
 
I am also convinced there are some details that should not appear in books
 and that professors should not present in the classroom. Good examples of
 such material are detailed calculations and long proofs that contain a
 jungle of subscripts. You just can't absorb such things by watching and
 listening. One place where I leave a lot of details to the reader is the
 definition and properties of the determinant of a square matrix. This
 starts at (6.4.18). You aren't going to understand this course by watching
 someone else do the work. You need to go to your study desk and push on
 ahead. As I have often said, learning mathematics is not a spectator
 sport.
 
I also strongly advise you to at least read all the exercises. With your schedule
 and taking other courses, you might not have the time to try to solve them all,
 but at least read them. They contain additional information.
 
Thanks
First I thank all the students who have sat in my classes over the years. I think
you learned something from me, but I also learned something from you. I've had
conversations during my career with several professional mathematicians on
subjects that appear here. These are too numerous to remember let alone list,
but I thank you all. I specifically want to thank Waclaw Szymanski who showed
me a nice improvement of the proof of the Stone-Weierstrass Theorem.
Undoubtedly my greatest thanks go to Professor Mark Hunacek who read
many of the chapters, gave me several exercises, and provided valuable
feedback.
Thanks for your attention.Live long and prosper













1 The
Real
Numbers
In this chapter we'll develop the properties of the real numbers, the foundation of
this book. But first we start with an introduction to set theory.
1.1.  Sets and Functions
The concept of a set is the basis for all of mathematics. The reader is likely to
have come across many of the notions associated with set theory, and if this
experience has been extensive, please skip to the next section.
A set X is a collection of things called elements or points. We'll treat the idea
of a set and an element of a set as a fundamental notion and not try to give
a more formal definition. The notation  is used to denote the
fact that x is an element that is contained in the set X. You might also
sometimes see ; this means that x and y are both elements of
X. (Note that the statement  does not imply that these two
points are distinct.) When x fails to be an element of the set X, we write
.
A basic concept of set theory is that of a subset. We say that A is a subset of
X if A is a set and every element of A is also an element of X. Using symbols we
can write this relation by saying that if , then . We introduce the
notation  to denote this; this is read as "A is contained in X," or "A is a
subset of X." We could also write , read as "X contains A." Another
notation for  that the reader will encounter in the literature is ,
but we won't use this in this book. Note that if  it is also the case that
 
 . We say that A is a proper subset of X provided  but
 .
 
There are many ways to define sets and subsets, depending on the
 situation. For example, consider the set of natural numbers; that is, the set of
 positive integers denoted by . To define this set we could also write
 . If we want to denote the subset of  consisting of even
 integers, we can write . The odd integers can be expressed by
 , or we could write . We also
 have the set  of all integers, positive and negative as well as zero.
 So
 


Hence . (We are assuming that the reader is familar with the
 natural numbers, , the integers, , the rational numbers, , and with
 their properties. In the next section we'll introduce the real numbers,
 .)
 
If we are given a set X and A and B are both subsets of X, then in a similar
 way as above we say that A is a subset of B if every element of A is also an
 element of B; that is, if , then . In symbols we write this as
  or . We can also say that A is contained in B or B contains  A.
 The two sets A and B are equal if we have both  and .
 
There are two special subsets of any set X: the set X itself and the empty set
 consisting of no elements. The empty set may take a moment to digest, but it
 plays an important role in mathematics. A distinction of  is that it is a subset
 of every subset of X, the only such subset of X. If  and , there is
 also the notation  to indicate that the point x does not belong to A. So
 if , then . There is another special subset - actually a
 collection of them. If , then denotes the set consisting of
 the single element x. This is called a singleton set. So  and
 .
 
We want to define some operations between subsets. So we consider X as the
 universe and examine its various subsets 

1.1.1. Definition. If , the intersection of A and B is the set
 defined by


1.1.2. Example. (a) If , then .
(b) Consider the set  of all rational numbers, positive, negative, and
0. That is


If , then .
(c) If  and , then .
(d) Note that if , then .
If , we say that the sets A and B are disjoint. 

1.1.3. Definition. If , then the union of A and B is the set
 defined by
 
 


It's worth emphasizing that the use of the word "or" in the preceding
 definition is not the exclusive "or". In other words, when we say in the definition
 that  or  we do not exclude the possibility that x belongs to both
 A and B. That is, we do not insist that .
 
1.1.4. Example. (a) If , then .
 
(b) .
 
(c) For any subset A of X, .
(d) If  and , then
.
(e) If  and , then
.

1.1.5. Proposition. The distributive laws hold for union and intersection.
That is:
(a)  if , then ; and
(b)  if , then .
Proof. This proof is the prototype for establishing that two sets are equal:
we take an element of the left-hand side and show it's an element of the
right-hand side; then take an element of the right-hand side and show it's
an element of the left-hand side.
(a) If , then  and . Thus 
and . But this says that either " and " or "
and ." Therefore . Conversely, assume that
. So either  or . In the
first case,  and ; in the second case,  and .
Thus in either case, ; also, depending on the case, either  or
. Therefore .
(b) The proof of this part has a slightly different flavor than the proof of
the first part. If , then  and .
So either  or . If  then we have that .
If , then the fact that  and  implies that
 and ; hence . Therefore . The
proof of the other half of (b) is Exercise 2. â 
We also define the difference of the two sets as


Some mathematicians use the notation  instead of . I prefer
 the notation  because in some situations  is ambiguous.
 For example, if A and B are subsets of , we will use the definition
 . The same applies when A and B are subsets of
 a vector space. So throughout this book the difference of two sets will be denoted
 using the backslash.
 
1.1.6. Example. (a) If X is any set and , then  and
 .
 
(b) If  and , then
 .
 
(c) If  and , then
 .
 
For any subset A of X, the difference  is called the complement of A.
 Elsewhere the reader might encounter the notation  or  to denote the
 complement of A. Note that  (Exercise 4).
 
1.1.7. Proposition (De Morgan's1
 Laws). If X is any set and A and B are subsets of X, then:
 
(a)  ;
 
(b)  .
 
Proof. We prove (a) and leave the proof of (b) as Exercise 5. Again we use
 the standard
 approach to proving that two sets are equal. If , then
 . The only way this can happen is that both of the following
 two statements are true:  and . That is,  and
 ; equivalently, .
 
Now assume that . This says that 
 and ; that is,  and . But combining these two
 statements means , or that . â 
 
We now extend the concepts of intersection and union to multiple sets.
 Indeed, we'll extend these to infinite collections of sets. Namely, assume that
  are subsets of X and define
 




There is a version of De Morgan's Laws for this as well.

1.1.8. Theorem (De Morgan's Laws). If X is a set and  is a
collection of subsets, then:
(a)  ;
(b)  .
The proof of this last theorem is Exercise 6 and proceeds like the proof of
Proposition 1.1.7.
We conclude this section with a discussion of functions. If X and Y  are two
sets, then a function from X into Y  is a rule, denoted by , that
assigns to each x in X a unique point y in Y . Synonyms for function are the
terms map and mapping. The set X is called the domain of f  and the set Y  is
called the range of f . The set  is called the image of
f . Note the distinction between range and image. Now that you have noted
the distinction you should be aware that some mathematicians define
the range of a function to be what we have called the image and vice
versa. When they do this they sometimes use the term codomain for
what we call the range. Confused? Don't worry too much about it except
when you consult other sources; we will consistently use the terms as we
defined them above. Frankly, the distinction will affect very little that is
said.

1.1.9. Example. (a)  defined by  is a function. Its
domain is  and its image is the set of rational numbers in . What
is its range? You could say it's the same as its image or you could say it's
. Perhaps this vagueness is unappealing, but there is no "correct" answer.
What you call its range might depend on your purpose or the context of the
discussion.
(b) If for each x in  we let  when  and 
when , then this is not a function since the value of  is not
 
 uniquely defined. If we were to redefine f  by stating that  when
 , then it is a function.
 
(c) If X and Y  are sets, , and  for every x in X, then
  is a function - called a constant function.  
(d) If X is any set and , define  by
 


This function is called the characteristic function of A. Some call this the
 indicator function. Observe that for all x in X,  and .
 
If  and , then the composition of f  and g is the
 function  defined by
 


for all x in X. So, for example, if  and , then
 . Similarly , so that in this case
 . If again  and , then 
 while . So it is not true that composition is commutative.
 
1.1.10. Definition. A function  is called surjective if for each
 y in Y  there is at least one x in X such that . f  is injective if
 for  in X, the relation  implies that . f  is
bijective if it is both injective and surjective.
In the literature the reader will often see the term "onto" instead of surjective
and one-to-one instead of injective. I have no problem with the term one-to-one; I
often use it and the reader might see it in this book. I have a language problem,
however, with using onto as an adjective when it is a preposition. While I might
use it that way in a casual conversation, when I am being a bit more formal I
won't.
We'll encounter the terms surjective, injective, and bijective frequently as we
progress.

1.1.11. Example. (a) The function  defined by 
is bijective.
(b) The function  defined by  is injective but not
bijective.
(c) The function  defined by  is
surjective but not injective.
Exercises
In these exercises X is a given set and  are subsets of X.

(1)Let , , ,
, . Determine each of the
following sets: (a) ; (b) ; (c) ; (d) ; (e)
.
 
(2) Complete the proof of Proposition 1.1.5(b).
 
(3) Prove that the associative laws apply to unions and intersections:
 and .
 
(4) Give a detailed proof that .
 
(5) Prove part (b) of Proposition 1.1.7.
 
(6) Prove Theorem  1.1.8.
 
(7)If  is a function, prove that the following statements are
 
 equivalent. (a) f  is injective. (b)  for all subsets A
 and B of X. (c)  for all subsets A and B of X.
1.2.  The Real Numbers
I am aware that the reader has been working with the real numbers for the
 entirety of his/her mathematical life. However I suspect that many students
 studying the present material for the first time may be unaware of some of the
 properties of  that are crucial for making calculus work. Indeed one of these
 properties, The Completeness Property, is not shared by  and makes it
 impossible for calculus to survive as a theory only involving rational
 numbers.
 
For the teacher there are two ways to handle this. One is to just state the
 needed properties of  and proceed to develop calculus. Another is to start with
 the properties of  and carefully develop the definition of the real numbers and
 derive the needed properties. This second approach gives a solid understanding of
 the material and gives a grounding in writing proofs in analysis. The
 disadvantage is that going through this material takes time that an instructor
 may not have. The first approach has the advantage of quickly getting to
 the more advanced topics. If I were the instructor, I can easily imagine
 different circumstances under which I would be led to use either of these
 approaches.
 
So which approach will be adopted in this book? In some sense both. We will
 begin with a quick survey of the first approach and then go through
 a more thorough grounding. Why? I assure you that doing it this
 way is not chosen because of intellectual indecision or cowardice. As
 I said before, there are reasons that support taking either route. I'm
 going to leave it to individual instructors and readers to figure out if
 they have the time to do the second or are comfortable only taking
 the first.
 
Quick Approach
In this approach we assume the reader is familiar with the arithmetic properties
 of the set of real numbers, , as well as its usual order relations,  and .
 We also assume the reader knows the distinction between rational numbers and
 irrational numbers. The first important fact about  that the reader may not
 be fully conscious of is the following.

1.2.1. Axiom (Density Property). If a and  are rational numbers and
, then there is an irrational number x with . Similarly, if
 are irrational numbers and , then there is a rational number x
with .

The Density Property will be used frequently as we develop the theory of
differentiation and integration. The other important property we need involves
the ordering on .
If  we say that E is bounded above if there is a number a such that
 for all x in E. Such a number a is called an upper bound of E. Similarly
E is bounded below if there is a number b with  for all x in E; b is called a
lower bound of E. It is easy to see that E is bounded above with an upper bound
a if and only if the set  is bounded below with a lower
bound . For this reason any statement about the upper bound of a set has
its analogue for the lower bound and we will frequently only do the upper
version. A set E is bounded if it is both bounded above and bounded
below.

1.2.2. Definition. If  and E is bounded above, then a least upper
bound or supremum of E is a number  that satisfies: (i)  is an upper
bound for E; (ii)  for any other upper bound a for E. Similarly, if
E is bounded below, then the greatest lower bound or infimum of E is a
number  that satisfies: (i)  is a lower bound for E; (ii)  for any
other lower bound b for E. In symbols we write  and .
(The reader may have seen the notation  and , but
we will use the  and  notation.)

1.2.3. Axiom (Completeness Property). If a non-empty subset E of  has
an upper bound, it has a supremum. If a non-empty subset E of  has a
lower bound, it has an infimum.

We also have uniqueness for the supremum.
 
1.2.4. Proposition. If the subset E of  is bounded above, its supremum
 is unique. That is, if  and  are both the supremum of E, then .
 If E is bounded below, its infimum is unique.
 
Proof. Let  and  be as in the statement of the proposition. Since 
 is an upper bound for E and  is a supremum, the definition of a least
 upper bound implies that . Similarly, since  is also a supremum,
 we have that . Thus .
 
That the infimum is unique when it exists can be proved in a manner
 analogous to the preceding proof or you can use Exercise 2. â 
 
Also see Exercise 3.
 
The density and completeness properties may seem obvious to you, but that is
 probably because you have always thought of  as having them. Nevertheless,
 unless you are in possession of an exact definition of the real numbers, as will be
 carried out shortly, you cannot give a rigorous proof of their existence. Let's also
 remark that the set  does not have the Completeness Property. For example
  does not have a supremum within the set . (See Proposition
 1.2.9 below.) Of course it has a supremum in , namely , but this
 is not a rational number as is established in the proof of Proposition
 1.2.9.
 
More Thorough Approach
Here we will define the real numbers. From the student's point of view
 this may seem unnecessary. After all, you have been working with real
 numbers since high school, solving equations and doing calculus. Most of the
 time calculus is presented in what might be called a "naive" way: the
 presentation glosses over some intrinsic properties of the real numbers that
 make calculus work. Here we want to present the theory in a precise
 mathematical way. To do this we need a precise definition of the real
 numbers.
 
Caveat. I have entitled this subsection with the words "More Thorough" rather than
 just "Thorough." I am not going to present every detail of a thorough approach. To
 prove every detail and totally explore the definition of the real numbers would make
 it impossible to complete our study of functions of a single variable in one semester.
 I will present more than enough of the material to establish the density and
completeness properties. But some topics will not be encountered. In addition the
proofs of many facts will be left as exercises. If the reader is interested in seeing a
complete development of the real numbers, the books [6] and [13] will provide them.
How do we define the set of real numbers? There has to be a starting point. In
some treatments the beginning is a development of the properties of the natural
numbers. In others it is the properties of the rational numbers. We are going to
start somewhere in between these two. We will definitely assume you know the
natural numbers. There are, however, some properties of  that I think you will
readily accept but may not have seen explicitly stated. Here is one that
is a first cousin of the fact that there is no largest integer. No proof is
given.

1.2.5. Lemma. If , then there is a natural number N such that

The definition of  has already been given in (1.1.2). It's an algebraically
defined entity and we are certainly going to assume the reader is knowledgeable
of all its algebraic properties. There are some non-algebraic properties of  that
we need and that some readers may not have been exposed to. These will involve
the order structure of . Here is one that is the version of the preceding lemma
for .

1.2.6. Proposition. If x and  are positive rational numbers, then there
is an n in  with .
Proof. Put  and  with  in . If , then


By the preceding lemma we can choose n such that . For that
value of n, . â 
 
 
In the Quick Approach above we defined the concept of a set of real numbers
 that is bounded above or below. The same concept applies to subsets of ,
 which are, of course, subsets of . But here we want to underline that
 we must choose the upper bound to be a rational number. This is not
 so important until we also discuss the concept of the supremum and
 infimum of subsets of . Here for a bounded subset of  to have a
 supremum it must be rational. There are subsets of  that are bounded
 above but do not have a supremum in . To do this we present two
 lemmas.
 
1.2.7. Lemma. There is no rational number x with .
 
Proof. In fact if there were such a rational number, we could write it
 as , where  and n and m have no common divisor
 other than . If , then we get ; so  is
 even. This implies that n is even; in fact if it weren't, we would have
 that it's odd. That is, we would have that . But then
 , which is odd. This is in
 direct contradiction to the fact that  is even. But if n is even we can
 write , so that . Dividing by 2 we get that 
 is even; as before we get that m is even. That is, we have shown that 2 is
 a common divisor of both n and m, contradicting the fact that they were
 chosen with  as the only common divisor. â 
 
1.2.8. Lemma. If  are positive rational numbers with , then
 .
 
Proof. By the hypothesis we have that . But
 since a and b are positive, . Thus . â 
 
1.2.9. Proposition. The set  is bounded above but
 has no supremum in .
 
Proof. It is immediate that 2 is an upper bound for A so it remains to show
 that A has no supremum in . The proof is by contradiction; so assume
there is an x in  with . We will show that , thus
contradicting Lemma 1.2.7 and finishing the proof. We show that 
by showing that  can be neither larger nor smaller than 2. First assume
that . We will show that there must be a number w in  with
 and . In fact suppose such a w exists. It then follows
that if , then . But if , then ; if ,
then Lemma 1.2.8 shows . This establishes that w is an upper bound
of the set A. Since , we have our desired contradiction.
In , then


Using (1.2.6) we can choose n in  such that . Thus
 and the above inequality shows that  works.
Now assume that . Again let  and examine . We
have that


As we did before, choose n sufficiently large that  satisfies
. This says that . But , contradicting the fact
that x is an upper bound of A. So again we arrive at a contradiction. â 
The last proposition inspires the definition of the real numbers.


1.2.10. Definition. A Dedekind2
 cut, or simply a cut, is a non-empty subset A of  satisfying the following
 three conditions: (a) A is a proper subset of ; (b) if  and ,
 then ; (c) if , there is a b in A with .
 
An example of a cut can be obtained from Proposition 1.2.9 except we have to
 adjoin to the set A in that proposition all the negative numbers. That is, an
 example of a Dedekind cut is
 
 
â(1.2.11)

 This can be shown to be a cut by using the techniques of the preceding proof
 (Exercise 10). Note that if , then the set  is not a
 cut (Why?) while  is. (See (1.2.13).)
 
A useful observation about cuts is the following. If A is a cut and ,
 then  for every a in A. In fact otherwise there is an a in A with .
 Since , it must be that . But then (b) in the definition says
 .
 
In the literature there is another definition of a Dedekind cut as a
 pair of non-empty subsets  of  having certain properties. See
 [8].
 
1.2.12. Definition. The set of real numbers is the collection of Dedekind cuts
 of . The real numbers are denoted by .
Does
 this
 definition
 strike
 you
 as
 strange?
I thought it strange the first time I saw this. But think of the cut given in
(1.2.11). Isn't it natural to call this ? Nevertheless, you have a right to pause
when we define a number to be a set.
We have a rather involved task before us. We want to show that  as defined
above has all the properties we are used to thinking the set of real numbers
has: the ability to add and multiply as well as a notion of order. We'll
also see that it has the Density and Completeness properties, (1.2.1)
and (1.2.3). A caveat is that many details will be left to the reader to
prove.
We start by showing that  in a natural way. But first let's make a
temporary agreement about notation. For elements of  we'll use small
Greek letters, while rational numbers will be denoted by small roman
letters.

1.2.13. Proposition. If , then  is a real
number; that is,  is a cut.
Proof. Clearly  is a proper subset of , and if  and , then
. Finally if , then  and . Thus
 is a cut. â 
What is happening in the last proposition is that we have embedded  into
 by using the map . We identify each rational number a with its image
 in . Unless there is a good reason to make a distinction between a rational
number a and its image  under this map, no distinction will be made. Thus we
write


In particular, . So we use the symbol 0 to denote both the
rational number 0 and the corresponding cut.
We introduce the concept of an order on .


1.2.14. Definition. If , say that  if  and .
 Say that  if
  with the possibility they are equal. We define  and 
 similarly.
 
As usual, if , we say  is positive; if , we say  is negative.
 The proof of the next result is Exercise 11.
 
1.2.15. Proposition. (a)  If  and  such that , then
 .
 
(b)  If , then either  or .
 
(c)  (Trichotomy Law) If , then either , , or .
 
1.2.16. Theorem. If E is a non-empty subset of  that is bounded above,
 then  exists. That is,  has the Completeness Property.
 
Proof. So E is a set of cuts; that is, a set of subsets of . Take a moment
 to absorb this and the notation and reasoning that follow will seem more
 natural. Let  be an upper bound for E and let . The
 crux of the proof is to first show that  is a cut, and so ; then we'll
 show that . To see that  is a cut, observe that it is non-empty
 since . Since  for every  in E,  and so . To
 show that  satisfies the other two parts of the definition of a cut, fix b in
  and let  such that . If  with ; it follows that
  because  is a cut; hence . Finally, since  is a cut there is a
 rational number x in  with ; since , . Therefore  is
 a cut.
 
Now that we have that , we show that . Since 
 for every  in E,  is an upper bound for E. On the other hand, if  is
 any upper bound for E, then  for all  in E. That is,  for all
  in E. Therefore . â 
 
Now that we have the Completeness Property, we can prove half of the
 Density Property. In fact it is a direct consequence of the definition of  that if
  and , then there is a rational number  with .
 Indeed, since , there is a b in  such that . If we let  be the cut
 defined by b, then . The proof of the other half of the Density
 Property must wait until we have established the arithmetic properties of the real
 numbers. We start with the definition of addition in . To justify this we need a
 proposition.

1.2.17. Proposition. If , then


is a cut.
Proof. (a) To show that  is a proper set we first note that it is clear that
it is not empty. Now take positive rational numbers  such that 
for all a in  and  for all b in . (Why do p and q exist?) It follows
that  for all a in  and b in . Thus , and so
.
(b) Let  and suppose . Put , where  and
. So ; hence . But then .
(c) Take  in  and let  such that . So 
and is strictly bigger that . â 

1.2.18. Definition. If , then  is the cut  defined in the
preceding proposition.

1.2.19. Proposition. If , the following hold.
(a)  .
(b)  .
(c)  .
The proof is an exercise.
Now we start the path to the definition of the negative of a real number .
It is convenient to introduce the notation . The
method for defining  may seem a bit opaque at first, so let's take a
minute to motivate it. Examine the cut  introduced in Proposition
1.2.9 to show that  is not rational; suppose we want to find the cut
associated with . This would be . (We have
departed somewhat from the notation and spirit we have been following up
 
 to this point, but this is an intuitive discussion and so we take some
 liberties.) Note that  if and only if . Now for any b in
  there is an r in  such that . Thus  if and only if
 there is an r in  such that . Note that this necessary
 and sufficient condition for membership in  is consistent with the
 rigorous approach we are following for defining ; remember this intuitive
 discussion when we define the negative of a real number in the proposition
 below.
 
1.2.20. Proposition. For every  in  there is a  in  such that
 .
 
Proof. Fix  in  and let
 


The first task is to show that  is a cut. To see that , assume
  and put . Since , . On the other
 hand, if  and ,  and so  for every
 . That is,  and . The remainder of the proof that
  is a cut is left to the reader.
 
Now observe that if , then . In fact if , then
 for every r in  since it is smaller than ; this violates
 the definition of membership in . Hence for any a in , 
 and so . Therefore . To show that , let
  and put ; so . By Lemma 1.2.6 there is an n in
  such that  but . (Details?) So 
 and . Therefore  and we have shown that
 . â 
 
1.2.21. Definition. For  in , we define  to be the cut  in
 Proposition 1.2.20.
The proof of the next proposition is Exercise 12.

1.2.22. Proposition. Let .
(a)  The element  is unique. That is, if , then
.
(b)  .
(c)  If , then .
Defining multiplication is more complicated than defining addition due to
the fact that the product of two negative rational numbers is positive.
Consequently we begin with the definition of the product of two elements of
 and later we will see how to extend this to the definition
of the product of arbitrary real numbers. The proofs of the various properties of
the definition are very similar and will be left as exercises. The proof of the next
proposition is Exercise 13.
1.2.23. Proposition. If , then


is a cut.

1.2.24. Definition. If , then  is the cut defined in the
preceding proposition.
The proof of the next proposition is Exercise 14.

1.2.25. Proposition. If , then the following hold.
(a)  .
(b)  .
(c)  If 1 is the cut , then .
(d)  .
(e)   is a cut and .
 
 
Now we extend the definition of the product to all real numbers.
 
1.2.26. Definition. Let . (a) Define . (b) When
 neither  nor  is 0, define
 


I am going to leave it to the interested reader to formulate and prove a version
 of Proposition 1.2.25 for products of arbitrary real numbers. There are also
 properties relating the order structure and the arithmetic structure of
 , such as  when  and , that will be left to the
 reader.
 
Define the absolute value of , , by
 


1.2.27. Proposition. If , the following hold.
 
(a)  .
 
(b)  .
 
(c)  (Triangle Inequality) .
 
(d)  (Reverse Triangle Inequality) .
Proof. The proof of the first three parts is left to the reader in Exercise 14.
The proof of (d) is easy if we apply the triangle inequality and use a
little trick that will be used frequently in the future, namely adding and
subtracting a quantity. Observe that .
Subtracting we get that . Now reverse the roles of
 and  in this inequality to get . Using the definition
of absolute value we get (d). â 
The triangle inequality will be used frequently as we progress in this book and
we will not cite it by name; it's that fundamental. Also be aware that adding and
subtracting a term and then applying the triangle inequality is a method of proof
you will also see used often in the future.
The reader knows that the definition of an irrational number is an element in
. In the language of cuts, it is a cut that is not of the form given in
Proposition 1.2.13.

1.2.28. Theorem. (a)  If , then there is an irrational number 
with .
(b)  If  and , then there is a rational number x with
.
Proof. The proof of (b) was given just after Theorem 1.2.16, so it remains
to prove (a). To start we show there is an irrational number t with
. Indeed,  works, where  denotes the irrational
number corresponding to the cut . If 
and , then it is easy to see that . Also
, so if it were the case that  is rational, we would
have that t is rational. â 
Before we conclude the section, we introduce the concept of infinity as
related to  as well as the set of extended real numbers . We first
define  as the set , where  are two abstract
points, and we define an order on this set by declaring that for any  in
 we have that . We assume that the reader has some
familiarity with the idea of infinity and understands that  are not real
numbers.
This concludes the present section. The reader interested in going deeper into
these matters can consult [6] and [13]. We now abandon the formalism of this
section and starting in the next section we return to using  as we have all
known it.
 
 
Exercises

 (1) For real numbers a and b write the quantities  and
  without using absolute values.
 
 (2)  If , show that .
 
 (3)  Let E be a subset of  that is bounded above and set
 . Show that .
 
 (4) Give a proof that  is not a rational number.
 
 (5)  Fill in the missing details in the proof of Proposition 1.2.9.
 
 (6) For each of the following sets X find  and  if they
 exist and say if they belong to X. (a) . (b)
 . (c) .
 
 (7) Find the infimum and supremum of the set .
 
 (8) Find the infimum and supremum of the set .
  
 (9) If E and F are bounded subsets of real numbers, show that
 .
 
 (10)  Show that the set  is a cut.
 
 (11)  Prove Proposition 1.2.15.
 
 (12)  Prove Proposition 1.2.22.
 
 (13)  Prove Proposition 1.2.23.
 
 (14)  Prove Proposition 1.2.27.
 
 (15) If A and B are two non-empty subsets of  that are bounded, give a
 necessary and sufficient condition that .
 
(16)If E is a non-empty bounded subset of  and , find formulas
for  and  in terms of  and
.
1.3.  Convergence
We divorce ourselves from the notation convention of the preceding section
where we denoted real numbers as lower case Greek letters. We will often
use the idea of an interval in , of which there are several types. An
open interval I is a subset of the form , where
; it is denoted by . A closed interval is a set of the
form , where . A half-open
interval is a set having one of two forms:  or
, where there are appropriate restrictions on c and
d. (What restrictions?) An interval in  is a set I of any one of these types.

In this section we will examine the convergence of sequences of real numbers.
Recall that a sequence in  is an enumeration of some real numbers: 
It is usually denoted by . 

1.3.1. Definition. A sequence  in converges to a if for any open
interval containing a, I contains all but a finite number of terms of the
sequence. This is denoted by writing  or .



Observe that if , what happens with the first finite number of
elements of a sequence is irrelevant to whether it converges. That is, for any
integer ,  if and only if the sequence . The first
result is that when a sequence converges, the limit is unique.

1.3.2. Proposition. A convergent sequence can only converge to one point.
That is, if  and , then .
Proof. Adopting the notation in the statement of the proposition, assume
 
 that . Thus we may assume that . It follows that
 


Since these two intervals are disjoint, it cannot be that they each contain
 all but finitely many members of the sequence . This contradicts the
 hypothesis that the sequence converges to both a and b. â 
 
Before presenting some examples, let's establish the next result; this
 proposition quantifies the definition of convergence.
 
1.3.3. Proposition. Let  be a sequence in  and let .
 
(a)   if and only if for every  there is an N such that
  for all .
 
(b)   if and only if .
 
Proof. (a) Suppose  and . Since  is an
 open interval that contains A, I contains all but a finite number of the
 terms of the sequence. This means there is an integer N such that 
 when ; that is,  when . Conversely, assume
 the condition holds and  is an open interval containing a. Since
 , there is an  such that . Thus
 there is an integer N such that  when . That is
 .
 
(b) Exercise 1. â 
 
1.3.4. Example. For the sequence  defined by , we have
 that .
 Note that if  and , then  when . We
 could also take  and get that  when . In other
 words, in the preceding proposition that value of N obtained for a given  is
 not unique. If , then we could take . In general, for
any  we could take for N any integer larger than .
It is worth observing that in part (a) of the preceding proposition the
condition  can be replaced by  and the conclusion 
can be replaced by . (Verify!) The value of part (a) above is that it
quantifies the idea of convergence as the preceding example shows. See
Exercise 2.

1.3.5. Example. (a) If  for all n, then .
(b) . In fact if , then by Proposition 1.2.6 there is an N in
 with . It follows that for , .
(c) If  and  is a bounded sequence, then . In fact
let  for all  and let . Choose N such that 
when . If , then .
(d) If , then  is bounded. In fact choose an
integer N such that  for . Since 
is finite, there is a number A with  for . If
, then . Therefore for every ,
.
 
 
1.3.6. Proposition. If  and , the following hold.
 
(a)  .
 
(b)  .
 
(c)  If , then  except for possibly a finite number of integers
 n. If  for all n, then .
 
Proof. The proof of (a) is left to the reader. To prove (b) note that
 

By Example 1.3.5(d) there is a constant C such that  for all n. Choose
 . If , let N be such that  and
  whenever . From the above inequality we have that
 when ,  and so (b) holds.
 
To start the proof of (c), choose  such that  when
 . Thus for , ,
 and it follows that . In particular we have the first part of the
 statement of (c). Now observe that we actually proved that we have a constant
  such that  for all but a finite number of integers n. As we
 observed after Proposition 1.3.3, we can assume that  for all n. Note
 that if we prove that , an application of part (b) shows that (c) is
 valid. But
 


From here the reader can easily supply the details to demonstrate that
. â 
A sequence  is said to be increasing if  for all n; it is strictly
increasing if  for all n. It should be noted that some call a sequence
satisfying  for all n a non-decreasing sequence and reserve the term
"increasing" for what we have called strictly increasing. Similarly we define
 to be decreasing if  for all n, and we can define strictly
decreasing if the  sign is replaced by . Observe that if  is a
decreasing sequence, then  is increasing. So every time we prove a
result for increasing sequences we have an analogous result for decreasing
sequences.

1.3.7. Proposition. If  is an increasing sequence that is bounded
above and , then . Similarly, if  is a decreasing
sequence that is bounded below and , then .
Proof. As we observed before the statement of the proposition, we need
only prove the statement concerning increasing sequences. If , then
by definition of the supremum,  is not an upper bound of . Thus
there is an integer N
such that . But since  is increasing we have that
 whenever . Thus . â 

1.3.8. Definition. If  is a sequence and  is a sequence of positive
integers with  then  is called a subsequence of .
Note that a subsequence is a new sequence, so it makes sense to discuss the
convergence of a subsequence.

1.3.9. Example. (a)  is a subsequence of .
(b)  is not a subsequence of . (Why?)
(c)  is not a subsequence of . (Why?)
The proof of the next proposition is Exercise 8. Also see Exercise 9.

1.3.10. Proposition. If  and  is a subsequence of ,
then .
The next result is extremely important, our crucial result on convergence. As
might be expected, its proof is rather complex.

1.3.11. Theorem (Bolzano3-Weierstrass4
 Theorem). A bounded sequence has a convergent subsequence.
 
Proof. As we mentioned the proof is involved so be careful. Start by letting
  be the bounded sequence and assume that x and y are real numbers
 such that  for all n. The proof is trivial if the sequence has only
 a finite number of distinct elements since in that case there is at least one
 point that is repeated infinitely often; hence we can take a subsequence all
 of whose entries are equal to that point. So assume  has an infinite
 number of distinct points. Divide the interval  into two equal parts
 and look at which points in the sequence  belong to each half. Since
  is an infinite set, one of the intervals has an infinite number
 of these points; call it  and let . Observe that
 the length of , , equals . Put ,
 and let . We have the first element in our desired subsequence,
 , and it satisfies .
 
To find the second element in the desired subsequence, we proceed in a
 similar way. Divide the interval  into two equal parts, and let  be a
 half interval that contains infinitely many of the points . Put
 , and let . We are tempted
 to put . It might happen, however, that , in which
 case  and we would have that . Since we want to
 define the second element  in a subsequence, we need that .
 Thus put . From the construction we have that
 


Also because , we have that


Continue this process. We obtain decreasing intervals 
infinite sets of integers  with  and integers
. We define . We have that these
satisfy:

Now these conditions imply that  is an increasing sequence and it is
bounded above by y. By Proposition 1.3.7 there is a number a such that
. Therefore

 â 
The reader would do well to study the preceding proof. To begin, be conscious
of the fact that we have used the Completeness Property of the real numbers.
(Where?) There are many bounded sequences in  that do not have a
subsequence that converges to another rational number. For example, take a
sequence in  that converges to . Also not only does the proof establish an
important theorem, but it uses techniques that can and will be employed in the
future.
 
 
1.3.12. Definition. A sequence  is called a
 Cauchy5
 sequence if for every  there is an integer N such that 
 when .
 
1.3.13. Theorem. A sequence converges if and only if it is a Cauchy
 sequence.
 
Proof. Half of the proof is straightforward. Assume that  and
 . There is an integer N such that when , .
 Hence when , .
 
Now assume that  is a Cauchy sequence.
 
Claim. If  is a subsequence of  that converges to a, then
 .
 
In fact let  and choose an integer  such that  when
 . Choose  such that  when . Put
 , and suppose . Pick any integer . Since we
 also have that , it follows that . Since , we
 have that . Hence  and we
 have established the claim.
 
From here the proof is an easy consequence of Theorem 1.3.11. In fact there
 is an integer N such that  when . Thus when ,
 , and so  is bounded. Since what
 remains of the sequence is finite,  is a bounded sequence. By the Bolzano-Weierstrass
 Theorem  has a convergent subsequence. Hence the claim proves the
 theorem. â 
 
In light of this theorem, we see the importance of the concept of a Cauchy
 sequence - if we are given a Cauchy sequence, we don't have to produce a limit in
 order to know that the sequence converges. We will see the importance of this as
 we proceed.
 
We conclude this section with two important concepts for sequences. First,
 however, we need to introduce the idea of a sequence converging to . Say
 that a sequence converges to  if for each real number R there is an
 integer N such that  for all . Similarly,  if for each
 real number R there is an integer N such that  for all .
 It is easy to see that  if and only if . Also see
 Exercise 13.
 

If  is a given sequence, let  and consider the
sequence . Note that as n increases, we are taking the supremum over a
smaller collection of terms. Thus  for all n; that is,  is a
decreasing sequence. As such it has a limit, though that limit might be
. (Note that it could be that  for all n if  is not
bounded above; in this case . Though it is impossible that any
, it might still happen that .) Similarly if we set
, then  is an increasing sequence and so it converges
though it may be that the limit is . We formalize this discussion in the
following.

1.3.14. Definition. If  is a sequence of real numbers, the limit superior
or upper limit of  is defined as


The limit inferior or lower limit of  is defined as


We will frequently just say the limsup or liminf  of the sequence .


Notice that because we allow  as the limits, the limsup and
liminf of a sequence always exists as an element of .


1.3.15. Example. (a) If , then  and
 .
 
(b) If  when n is odd and  when n is even, then
  and .
 
(c) If  is the sequence
 


then  and .
 
(d) If  when n is odd and  when n is even, then
  and .
 
The proof of the next proposition is Exercise 14.
 
1.3.16. Proposition. If  is a sequence of real numbers, then the
 following hold.
 
(a)  .
 
(b)   is bounded above if and only if  and it is
 bounded below if and only if .
 
(c)   if and only if .
 
(d)  If  is another sequence and  for all , then
  and .
 
1.3.17. Proposition. If  is any sequence in , then
 


This last result allows us to reduce the proof of an assertion about  to
proving an analogous assertion about . The reader is asked to prove this
as Exercise 15. In fact anyone who is not thoroughly familiar with  and
 should complete this exercise to solidify the concepts in their
brain.

1.3.18. Proposition. If  is a sequence in , ,
and , then there is a subsequence of  that converges to
 and another that converges to .
Proof. We only prove the statement about  as the other
half of the proposition follows by the preceding proposition. In addition we
will assume ; when , we leave the proof to the reader. Let
; so . By the definition of the limit superior,
for each  there is an  with . By the definition
of supremum there is an  such that . Thus
 and so the subsequence  converges to . â 

1.3.19. Corollary. Let  be a sequence in .
(a)  If  such that , then there are infinitely many
values of n such that .
(b)  If  such that , then there is an integer N such
that  for all .
Proof. (a) By the preceding proposition there is a subsequence  such
that . Thus there is an N such that  for all
.
(b) If , then the definition of the  implies there
is an N with . Hence part (b). â 
Exercises

 (1)  Prove Proposition 1.3.3(b).
 
 (2)  For each of the following sequences  find the value of the limit and
 for each stipulated value of , find a value of  such that 
 when . (a) . (b) . (Are the
 values for N you found the smallest possible? This has no bearing on the
 convergence, but it's a bit more challenging to find the smallest possible N.)
 
 (3)  If  and  is a renumbering of the original sequence, does 
 converge to a?
 
 (4) Prove that the sequence  does not converge.
 
 (5) (a) Show that  converges and find its limit. (b) What is ?
 ( c) Show that .
 
 (6) Show the following. (a) . (b) . (c)
 .
 
 (7) Show that the following sequences converge. (a) . (b)
 .
 
 (8)  Prove Proposition 1.3.10.
 
 (9)  If  is a sequence in  with the property that every convergent
 subsequence of  converges to the same point x, show that .
 
 (10)  Prove the converse of Proposition 1.3.7. That is, show that if  is
 an increasing sequence and , then  is bounded above and
 .
 
 (11)  (a) If , show that . (b) If , show that
 .
 
 (12) If , show that
 



(13) Let  be a sequence in . (a) If  and  is a
subsequence, show that . (b) Find an example of a sequence
 then converges to  and a sequence  such that , but
 does not converge to . (c) Give a condition on a sequence 
such that if  and , then . (d) If  is a
sequence and , show that . (e) If , is it true that
?
 
(14) Prove Proposition 1.3.16.
 
(15) Prove Proposition 1.3.17.
 
(16) If  and  are sequences of positive numbers such that
, show that . Are the requirements
that  needed?
 
(17)Show that there are sequences of real numbers  and  such that
.
1.4.  Series
If  is a sequence in , and  we define the m-th partial
sum of  as . The notation
 is called the infinite series or just the series and stands for
the sequence  of partial sums. Sometimes we may want to start
the summing process at a different number than . In particular
we will often examine infinite series of the form  as we do in
Proposition 1.4.4 below.

1.4.1. Definition. If  is a given sequence of numbers in  and ,
we say that the infinite series  converges to s if the sequence of
partial sums , , converges to s. When this happens
we call the series a convergent series and we write . If the
 
 series  fails to converge to any real number s, then we say that
 the series diverges or that it is a divergent series. 

1.4.2. Proposition. If the infinite series  converges, then
 .
 
Proof. Suppose  and let  be the m-th partial sum. So
 . Thus . â 
 
Most of you learned the last result in calculus as well as the fact that the
 condition that  does not imply that the series converges. Here is the
 standard example.
 
1.4.3. Example. Consider the series . This is called the harmonic
 series. The origin of this name has to do with the concept of overtones in music,
 a topic we won't go into. To see that this diverges we rewrite the series grouping
 together the terms as follows:
 

In other words we group the terms together in such a way that each sum within
 parentheses is larger that a half. So the next parenthetical expression would
 contain  terms with the last term being . We therefore see that the partial
 sums grow infinitely large. (This example was important to present at this
 moment in the text, but what we just did was to use Corollary 1.4.8
 below. Nevertheless in this specific instance the application is evidently
 valid.)
 
The next result is an example, but its importance elevates it to a
 proposition.
 
1.4.4. Proposition. When , the series  converges to
 . When  the series  diverges.
 
Proof. We begin with the following.
Claim. If  and , then


In fact this is demonstrated by verifying that .
Now that the claim is established we invoke Exercise 1.3.11(b) to
get that the series converges to  when . Notice that
when ,  so the series diverges by Proposition 1.4.2.
â 
The series in the preceding proposition is called the geometric series.

We can use Theorem 1.3.13 to obtain a necessary and sufficient condition for
an infinite series to converge.

1.4.5. Proposition. An infinite series  converges if and only
if for every  there is an integer N such that when ,
.
Proof. If  denotes the n-th partial sum of the series and , then
. Hence the condition stated in this proposition is
equivalent to the condition that  is a Cauchy sequence. By Theorem
1.3.13 this is equivalent to the condition that  converges. â 
If all the terms of a series are positive, it becomes a bit easier to discuss
convergence. In fact note that if  for all n, then 
defines an increasing sequence. Hence the next result is immediate from
Proposition 1.3.7.


1.4.6. Proposition. If  for all n, then  converges if
 and only if the sequence of partial sums is bounded.
 
Also see Exercise 3.
 
1.4.7. Theorem (Comparison Test). If  and  are two
 infinite series such that there is an integer N with  when 
 and if  converges, then  converges.
 
Proof. First note that the hypothesis implies that  for all n.
 Let  denote the n-th partial sum of the series . If ,
 the fact that  converges implies that we can choose 
 such that when , . Thus when ,
 . That is the
 sequence  is a Cauchy sequence and hence must converge. â 
 
1.4.8. Corollary. If  and  are two infinite series such
 that there is an integer N with  when  and if 
 diverges, then  diverges.
 
Proof. If it were the case that  converges, then the theorem would
 imply that  converges. â 
 
It is worth underlining that unlike in the theorem, in the corollary we are
 assuming that each term of the series  is non-negative.
 
1.4.9. Definition. An infinite series  converges absolutely if the
 series of positive terms  converges.
 
1.4.10. Proposition. If a series converges absolutely, then it converges.
 
Proof. Suppose  is an absolutely convergent series. Let
  and choose an integer N such that when , 
 (Exercise 3). If  is the n-th partial sum of the series , then for
  we have that .
 That is,  is a Cauchy sequence and hence it converges. â 

1.4.11. Example. Consider the alternating harmonic series .
By Example 1.4.3 we know this series is not absolutely convergent. On the
other hand for ,


Now observe that in this sum, if we group successive pairs of terms after
, each of those pairs is positive and they are all subtracted from
. Hence we have that


By Proposition 1.4.5, the alternating harmonic series converges. So the
converse of Proposition 1.4.10 is false: there are convergent series that are
not absolutely convergent.

1.4.12. Theorem (Root Test). Let  be a sequence in  and put


(a)  If , then the series  converges absolutely.
 
(b)  If , then  does not converge to 0 and the series 
 diverges.
 
Proof. (a) Let . By Corollary 1.3.19(b) there is an integer
 N such that  for all . Now the geometric series
  converges since . Thus the comparison test implies
 that  converges.
 
(b) Since , Corollary 1.3.19(a) implies that  for infinitely
 many values of n. Hence it cannot be that  and so 
 diverges. â 
 
1.4.13. Example. When  there is no conclusion. Consider
 the harmonic series , which diverges. We claim that .
 To see this we need two results from later in this book: L'HÃ´pital's Rule
 (2.5.1) and properties of the natural logarithm (Â§3.3). Since the reader
 has encountered both of these in calculus and we are only concerned
 with an example here, we will use these results from the future to
 explore the present example. By L'HÃ´pital's Rule,  as
 . (See Exercise 3.3.14.) Hence , and so
 . On the other hand the alternating harmonic
 series converges and satisfies .
 
We should also underscore an additional disparity between the two parts in
 the Root Test. Part (a) concludes that the series converges absolutely, while (b)
 says that the series diverges, not merely that it fails to converge absolutely. The
 same disparity pertains to the next result. 

1.4.14. Theorem (Ratio Test). Let  be a sequence in  and assume
 that  exists.
 
(a)  If , then the series  converges absolutely.
 
(b)  If , then the series  diverges.
Proof. The proof is similar to that of the Root Test. If , then
there is an N such that
 for all . Thus  whenever .
Therefore for , .
By the Comparison Test with the geometric series , 
converges. The proof of part (b) is similar to the proof of (1.4.12(b)) and is
left to the reader. â 

1.4.15. Example. The series


converges absolutely for every real number x. (Recall that .) In
fact we can apply the Ratio Test to find that


The preceding series is very important and we'll see it again later. In fact the
reader may remember from calculus that this series converges to . We'll
establish this and more when we discuss convergence of functions in Chapter
4.
 
 
Absolutely convergent series have many additional properties. For example it
 can be shown that if  converges absolutely and 
 is a bijection, then  converges. On the other hand, if the
 series  is conditionally convergent, that is, it converges but
 not absolutely, then for any real number x there is a bijection  on
  such that  converges to x. This amazing result is called the
 Riemann6
 series theorem. A proof can be found at
 http://en.wikipedia.org/wiki/Riemann_series_theorem
Exercises

 (1)  If the series  converges, then prove that for any integer 
 the series  converges.
 
 (2)  (a) Show that if  converges to A and  converges to B,
 then  converges to . (b) If  converges to
 A and , show that  converges to .
 
 (3)  Show that a series , where each  , converges if and only
 if for every  there is an integer N such that .
 
 (4)  Prove Theorem 1.4.14(b).
 
 (5) Prove the following. If  and  are two sequences of strictly positive
 numbers such that  for all , then the following
 hold: (a) If  converges, then  converges; (b) if 
 diverges, then  diverges.
 
 (6)  Does
 

converge absolutely?
 
(7)Suppose that the series  converges absolutely. (a) If  is a
bounded sequence of numbers, show that  converges absolutely.
(b) By giving an example, show that if it is only assumed that the series
 converges (not absolutely), then  may diverge.
 
(8)If  converges absolutely, does  converge absolutely?
 
(9)If  converges and , does  converge?
1.5.  Countable and Uncountable Sets
Here we will explore the notions of countable and uncountable sets. The fact that
not all infinite sets are equivalent is one that comes as a surprise to many people.
Indeed historically this was a shock to the world of mathematics when
Cantor7
first revealed it.

1.5.1. Definition. A set X is countable if there exists a subset A of the
natural numbers  and a bijective function . It is called
uncountable if it fails to be countable.


1.5.2. Example. (a) Any finite set is countable. For infinite sets that are
countable, we will say they are countably infinite. Some say that such an
infinite set is denumerable. Below we show the existence of sets that are
uncountable.
(b) The set of all integers, , is countable. In fact, 
describes a bijective function from  onto . For convenience we will
often show a set is countable by describing how to exhaust the set by writing
it as a sequence as we just did. Such an undertaking tells us how to define
a bijective function even though finding a formula for that function may
 
 be unclear. In the present case it is not difficult to write a formula for this
 function. Indeed if we define  by
 


then this is the function that gives the correspondence described above.
 In other situations writing a formula for the function may range from
 challenging to impossible. Understand, however, that proving the existence
 of such a function does not mean we have to write its formula. If we describe
 a process or algorithm for determining which element of the set corresponds
 to each integer and if this process exhausts the set, then we have described
 the required function.
 
(c) Any subset of a countable set is countable. In fact this is immediate
 from the definition of a countable set.
 
The next two propositions are useful in showing that a given set is countable.
 See, for example, Corollary 1.5.5 below.
 
1.5.3. Proposition. (a)  If X is any set such that there is a subset A of
  and a surjective function , then X is countable.
 
(b)  If X is a countable set, Y is another set, and there is a surjection
 , then Y is countable.
 
Proof. To prove (a), let f  and A be as in the statement. For each x in X let
  be the first integer n in A with ; that is, .
 So  is another subset of  and  defined by
  is a bijection. Part (b) is immediate from (a) and the definition
 of a countable set. â 
 
We take a moment to interrupt the discussion of different types of infinite sets
 to return to the discussion of set theory. We specifically want to define the
 cartesian product of two sets, , something many readers may have
 
already seen. This is the set


Similarly if  are a finite number of sets we could define the
cartesian product


1.5.4. Proposition. If X and Y are countable sets, then so is
.
Proof. We only consider the case where the two sets are infinite. To
prove the proposition it is equivalent to show that  is countable.
(Why?) Here we want to define a bijection . Again we
need only show how to arrange the elements  in  in a
sequence. So imagine  as an infinite square array of pairs of
positive integers. On the first row are all the pairs ; on
the second ; etc. We write down the following sequence of
entries.
 
 


If you write the array on paper and draw northeast diagonal lines
 connecting these pairs, you should be able to discern the pattern. (Many
 other patterns are possible.) This describes the bijection. â 
 
1.5.5. Corollary. The set of rational numbers is countable.
 
 
Proof. Writing each rational number as a fraction in reduced terms we
see that there is a bijection between  and a subset of , which is
countable by the proposition. â 
Using induction and the preceding proposition we can obtain the following
corollary.

1.5.6. Corollary. If  are countable sets, then so is
.

1.5.7. Proposition. If  and each of the sets  is
countable, then Xis countable.
Proof. We write . If  is infinite, we can do this
with  for all ; if  is finite, repeat one of the points an
infinite number of times. Thus  defined by  is
surjective. It follows by Proposition 1.5.3(b) that X is countable. â 

1.5.8. Corollary. The set of all finite subsets of  is countable.
Proof. If F denotes the set of all finite subsets of , then note that
, where  is the set of all subsets of . But
 is a finite set. (In fact from combinatorics we know that  has 
elements.) By the preceding proposition, F is countable. â 
Now we turn to some results showing the existence of uncountable
sets.

1.5.9. Proposition. The set of all sequences of zeros and ones is not
countable.
Proof. Let X be the set of all sequences of zeros and ones, and suppose
 it is countable; so we can write . We manufacture an
 element a in X such that  for any . This will furnish a
 contradiction to the assumption that we have an exhaustive list and thus
 prove the proposition. Suppose that for each ,  is a
 sequence of zeros and ones; in other words, . If
  and , let ; if , let . This defines an
  in X. Since ,  for any . This gives our
 desired contradiction. â 
 
1.5.10. Corollary. The collection of all subsets of , , is not countable.
 
Proof. In fact by looking at the characteristic functions of subsets of
 , we see that the set of all sequences of zeros and ones is in bijective
 correspondence with . â 
 
To prove the next proposition we have to consider dyadic expansions of
 numbers in the unit interval. For  we can write
 


where each  or 1. (This series always converges since it is dominated
 by .) The proof that each x in the unit interval can be so
 expanded is not too complicated and proceeds as follows. Consider x and
 divide the interval into its equal halves:  and . If x belongs
 to the first half, let ; if , let . (We note an
 ambiguity here if  and we will address this shortly.) Note that in either
 case we have that . Now consider whichever half interval
 contains x and divide it into two equal halves; let  if x belongs to
 the first half and  if it belongs to the second half. Now we have
 that


Continue this process and we see that the series so defined will converge to x.
(The reader who wants to write out the details can formulate an induction
statement based on what we just did and prove it. See Exercise 2.)
What about the ambiguity? If  for some  and ,
then the choice of  can be either 0 or 1. In fact this is the only way
such an ambiguity arises. In fact using the summation for a geometric
series,


It follows that if  are two sequences of zeros and ones, then the
only way that we can have that  is that either there
exists an integer N such that  for all , or one sequence ends in
all zeros and the other ends in all ones. See Exercise 3.

1.5.11. Proposition. The interval  is not countable.
Proof. In a sense, this proposition is a corollary of Proposition 1.5.9,
but its proof is a bit more involved than you usually associate with a
corollary. Let X be the set of all sequences of zeros and ones that are
not constantly one from some point on. Let Y  be the set of all sequences
of zeros and ones that are constantly one from some point on. Note that
 and  is the set of all sequences of zeros and ones. Now by
 
 considering the characteristic functions of subsets of , there is a bijective
 mapping between  and . Hence  is uncountable by
 Corollary 1.5.10.
 
Let  be the singleton consisting of the identically 1 sequence and for
 each  let  be the set of all sequences  in Y  with 
 whenever . We note that there is a bijection between  and the
 set of all subsets of . Hence  is finite. By Proposition
 1.5.7,  is countable. Again using Proposition 1.5.7 we have
 that the only way for  to be uncountable is for X to be uncountable.
 Therefore  is uncountable. â 
 
Exercises

(1) Show that if A is an infinite subset of , X is a countably infinite set,
and  is a bijection, then there is a bijection . (Hint:
First show that if A is an infinite subset of , then there is a bijection
.)
 
(2) Write out a detailed proof that each x in the unit interval has a dyadic
expansion.
 
(3) If  are two sequences of zeros and ones, show that


if and only if there is an integer n such that  and  for all
.
1.6.  Open Sets and Closed Sets
Here we examine certain special subsets of  that together with their
extensions to higher dimensional space underpin analysis.

1.6.1. Definition. A subset F of  is said to be closed if whenever  is
a sequence of points in F and  we have that . A subset G
is said to be open if  is a closed set.


1.6.2. Example. (a)  and  are simultaneously closed and open.
 
(b) Finite subsets of  are closed.
 
(c) A closed interval is a closed set. (Why?) Similarly intervals of the
 form  and  are closed. A closed interval is not, however, an
 open set.
 
(d) The union of two closed intervals is a closed set. In fact if
  and  is a sequence in F such that , then
 there is a subsequence  contained in either  or . Since
 , we have that  and F must be closed.
 
(e) An open interval  is an open set since its complement is the
 union of two closed intervals. An open interval is not, however, a closed set
 unless it is the interval .
 
1.6.3. Proposition. (a)  If  are closed sets, then  is
 closed.
 
(b)  If  are closed sets, then  is closed.
 
(c)  If  are open sets, then  is open.
 
(d)  If  are open sets, then  is open.
 
Proof. (a) Let  be a sequence in  such that . It
 follows that at least one of the sets  contains infinitely many
 of the points in . That is, there is a set ,  and a
 subsequence  contained in . Since , ,
 so this union is closed.
(c) By De Morgan's Law, , which is closed
by (a).
(b) If  is a sequence in  that converges to x, then for
  is a sequence in . Thus  since  is closed.
Thus , which is therefore closed by definition.
(d) As in the proof of (c),  so that 
must be open by (b). â 
Also see Exercises 4 and 3. Now we give an equivalent formulation of open
sets that will be used more often than the definition.

1.6.4. Proposition. A subset G of  is open if and only if for each x in
G there is an  such that .
Proof. Suppose G is open and . If the stated condition in the
proposition is false, then for every  there is a point  in
 with . Thus . Since  is closed it follows
that , a contradiction. Now assume that G satisfies the stated
condition; we want to show that  is closed. Let  be a sequence
in  that converges to a point x. If it were the case that ,
then . By assumption there is an  with .
But since  there is an n such that  and so , a
contradiction. â 

1.6.5. Example. Let 
with . If , then E is not open. In
fact if , we can choose  such that ,
but the Density Property of  implies there is an irrational number y
in . Hence  is not a subset of E. Similarly,
 is not a closed set.
We need a lemma that characterizes intervals in - whether they
are bounded or not, closed, open, or neither. To be clear an interval is
any set of the form , or , where a and b are any
real numbers and there is the possibility that , or , or
both.

1.6.6. Lemma. If , then I is an interval if and only if whenever
 with  it follows that .
Proof. It is clear that every interval has the stated property, so we need only
 assume that I has the property and show that it is an interval. To do this let
  and ; it may be that  or  or both. If
 , then the definition of supremum and infimum implies there are
 points a and b in I with . By hypothesis, ; in
 particular, . Hence . Therefore it must be that I is one of
 the four possible intervals with endpoints  and . â 
 
1.6.7. Proposition. A subset G of  is open if and only if it is the union
 of a countable number of pairwise disjoint open intervals.
 
Proof. Clearly if G is the union of a sequence of open intervals, then it
 is open by Proposition 1.6.3(d). Now assume that G is an open set. By
 the preceding proposition whenever , there is an  such that
 . Let  denote the collection of all open intervals that
 contain the point x and are contained in G. By what we just said, ;
 put . We'll use the preceding lemma to show
 that  is an interval. Let  and assume that . By definition
 there are intervals  in  such that  and . Since 
 is an open interval containing a as well as x,  and .
 Similarly  and . Let's assume that . It
 follows that , so . Now let's assume that
 ; so  and  and thus .
 The remaining case that  is similar to the first. By the lemma,
  is an interval and it contains x by its definition.
 
We claim that if x and y are distinct points in G it follows that either
  or . In fact if , then Exercise 5 implies
 that  is an open interval. As such it must belong to both  and
 . By definition, .
 
Therefore  is a collection of pairwise disjoint open intervals.
 On the other hand the Density Property of  implies each  contains a
 rational number. Since  is countable,  must be a countable
 collection of open intervals whose union is G. â 
 
For any set E contained in  define its diameter as
 


Note that the set E is bounded if and only if it has finite diameter.

1.6.8. Theorem (Cantor's8
Theorem). Let  be a sequence of non-empty subsets of  satisfying:
(i) each  is closed, and (ii) 
(a)  If one of the sets  is bounded, then .
(b)  If the sequence of sets  also satisfies (iii) , then
 is a single point.
Proof. Let  be as in the statement of the theorem and put
. By (i) and Proposition 1.6.3, F is closed. (a) If  is
bounded, then condition (ii) implies that  is bounded for all .
Without loss of generality we may assume that  is bounded. For each
 pick a point  in ;  is a bounded sequence. By the
Bolzano-Weierstrass Theorem there is a subsequence  and a point
x such that . Fix any positive integer m; by (ii), 
for all . By (i), . Since m was arbitrary,  and so
.
(b) Note that by condition (iii), from some point on the sets  are all
bounded. So by part (a), . On the other hand,  for all n, so
 for all n. Therefore (iii) implies  and so it
can have only one point. â 
In most of the literature you will find that Cantor's Theorem is part (b) alone.
Part (a) is separated because we will need it later in this book. At this point
Exercise 6 is compulsory.

1.6.9. Theorem. If X is a closed and bounded subset of  and  is
a sequence of open sets such that , then there is an integer
N such that .
Proof. Let . So  is closed and bounded and
 
 . If  for all n, then Cantor's Theorem implies
 ; but this contradicts the assumption that
 . Therefore it must be that there is an N such that ,
 proving the theorem. â 
 
For any non-empty subset E of  define the distance from a point x to E
 by
 


1.6.10. Definition. For a non-empty subset E of  define the closure of E
 to be the set .
 

1.6.11. Proposition. Let E be any non-empty subset of .
 
(a)  The closure of E is a closed set.
 
(b)  If F is any subset of  such that , then .
 
(c)  If E is a closed set, then .
 
Proof. Suppose E is not empty and  is a sequence in  that
 converges to x; we want to show that . Since , there is a
  in E with . Thus .
 Hence  (Why?), proving (a). If F is a set that contains E and
 , then
 .
 Hence . The proof of (c) is Exercise 7. â 
 
The next result is a corollary of the proof rather than the statement of the
 preceding proposition.
 
1.6.12. Corollary. If , then


The preceding proposition says that the closure of E is the smallest closed set
that contains E.
Exercises

(1) Prove that a closed interval is a closed set.
 
(2) Prove part (d) of Example 1.6.2.

(3) Show that parts (a) and (c) of Proposition 1.6.3 are false if the finite
collections of sets are replaced by an infinite sequence of sets.
 
(4) If G is an open set and F is a closed set, prove that  is open and
 is closed.
 
(5) Show that if I and J are two interval in  and , then 
is an interval. Note that I and J are not assumed to be open or closed
intervals. (Hint: Lemma 1.6.6 may be useful.)
 
(6) Consider the three restrictions (i), (ii), and (iii) placed on the sets  in
Cantor's Theorem. (a) Find a sequence of sets  that satisfies (i) and
(ii), but . (b) Find a sequence of sets  that satisfies (i)
and (iii), but . (c) Find a sequence of sets  that satisfies
(ii) and (iii), but .
 
(7) Prove part (c) of Proposition 1.6.11.
 
 
 (8)  Prove Corollary 1.6.12.
 
 (9)  If  is a sequence in  and
 

show that E is a closed set.
 
 (10) Find the closure of the set E in Example 1.6.5.
 
 (11)  If , say that x is a limit point of E if for every , there is a
 point e in E with . (Note that we insist that  though
 there is nothing to preclude x being in the set E.) A point x is called an
 isolated point of E if  but x is not a limit point. (a) Show that E is
 a closed set if and only if it contains all its limit points. (b) Show that x is
 a limit point of E if and only if there is a sequence of distinct points in E
 that converges to x.
1.7.  Continuous Functions
In this section we begin to focus on functions defined on subsets of . This
 focus and the related one of functions defined on subsets of higher dimensional
 Euclidean space will remain for the rest of the book. We begin by studying
 properties that many functions have. Here is an important and desirable
 elementary property.
 
1.7.1. Definition. If  and , a function  is
 continuous at a if whenever  and  is a sequence in X that
 converges to x, . It is said to be continuous on X if it is
 continuous at each point of X.
Easy examples of continuous functions are the constant function, 
for all x, and the identity function, defined by  for all x in X. Usually
we will be looking at functions defined on intervals and we may want to restrict
the range to something less than the entirety of . This, however, does not
affect the definition.
Suppose X is any set, not just a subset of , and . (We are
taking X to not necessarily be a subset of  because we will need this in the
future.) Define the following functions from X into .  is
defined by  for all x in X.  is defined by
 for all x in X. If  for all x in X, then
.

The proof of the next proposition follows immediately from Proposition
 1.2.6.
 
1.7.2. Proposition. If  and  are functions
 continuous at a point a in X, then the following hold.
 
(a)   is continuous at a.
 
(b)   is continuous at a.
 
(c)  If  for all x in X, then  is continuous at a.
 
1.7.3. Corollary. (a)  Every polynomial is a continuous function on all of
 .
 (b)  A rational function is continuous at every point where its denominator
 does not vanish.
 
Proof. The identity function and the constant functions are continuous
 from  into itself. Now repeatedly apply the preceding proposition. â 
 
We will see many more examples of continuous functions as we progress.
 In particular, the trig functions introduced in the next section will be
 seen to be continuous. Recall the definition of the composition of two
 functions.
 
1.7.4. Proposition. Let ,  such that ,
 and let . If f is continuous at a and g is continuous at ,
 then  is continuous at a.
 
Proof. If  and , then  by the continuity
 of f . Thus  by the continuity of g. â 
 
Here is an equivalent formulation of continuity.
 
1.7.5. Theorem. If , , and , then f is
 continuous at a if and only if for every  there is a  such that
  whenever  and .
 
Before beginning the proof of the theorem, let's take a moment to understand
 this equivalent formulation of continuity at the point a. (Let me add
 that many books take the statement of this theorem as the definition of
 continuity.) If you want to phrase the condition that is equivalent to continuity
in words (with the equivalent symbolic statement inserted in brackets)
you would say: Tell me how close you want  to come to  [for
every  ] and no matter how close you want to get I can always tell
you how close you must take x to a [there is a  ] so that it always
works.
Proof. Assume f  is continuous at a and let . Suppose no  can
be found such that the condition is satisfied; that is, for any  there is
at least one x with  and . It follows, by taking
, that for every n in  there is a point  in X with 
but . But then we have that  and  does
not converge to , violating the definition of continuity.
Now assume that f  satisfies the stated condition and let  be
a sequence in X that converges to a. If , then we know we can
find  as in the condition. But since , there is an N such that
 when . Thus  when . By
definition,  so we have shown that f  is continuous at a. â 
At this point we will stop discussing functions that are continuous at a
point and focus on functions continuous on a subset of , usually an
interval.

1.7.6. Theorem (Extreme Value Theorem). If  is a bounded closed
interval in  and  is a continuous function, then f is a
bounded function and there are points  and  in  such that
 for every x in .
Proof. Let's prove that the point  exists. To do this put
, with the full realization at this stage in the
argument that it could be that . That is, it could be that f  is not
bounded below on the interval. The fact that this cannot happen will follow
when we show the existence of the point  such that . By
the definition of an infimum there is a sequence  in  such that
. But  is a bounded interval and so  is a bounded
sequence. By the Bolzano-Weierstrass Theorem there is a subsequence
 and a point  such that ; of necessity,  since
 is a closed interval. But then , so .
The proof of the existence of  follows by using the first half of the
proof applied to the function . â 
 
 
The theorem states that the function attains its maximum and minimum
 values, hence its designation as the Extreme Value Theorem. We will refer to this
 theorem as the EVT. If the interval is not closed and bounded the theorem is no
 longer valid; just consider the the identity function on any interval that is either
 not closed or not bounded. 

1.7.7. Theorem (Intermediate Value Theorem). If I is an interval in ,
  is a continuous function, , and  such that
 , then there is a t in I that lies between a and b such that
 .
 
Proof. First note that since I is an interval, . Let
 ; so  since  and  for all x
 in A. Let . By the definition of supremum there is a sequence
  in A that converges to t. Since f  is continuous, ; thus
 . We'll show that . In fact if , there is an 
 such that . By Theorem 1.7.5 there is a  such that
  when . In particular when ,
  and so . Since , this contradiction
 shows that it must be that . â 
 
We will refer to the Intermediate Value Theorem as the IVT.
The preceding proof shows the importance of Theorem 1.7.5. In the future we
 will use this equivalent formulation of continuity without citing the reference
 (1.7.5). Now we state a consequence of the Intermediate Value Theorem together
 with the Extreme Value Theorem.
 
1.7.8. Corollary. The image of a closed and bounded interval under a
 continuous function is a closed and bounded interval.
 
Proof. Given
 a bounded interval  and a continuous function , put
 . Thus . The Extreme
 Value Theorem implies . The preceding theorem implies that
 if , then . Thus . â 
 
1.7.9. Definition. If  are two functions defined on a set X and taking values
 in , define the two functions  and  as
 follows:

For obvious reasons the function  is called the maximum of f and g and
 is called the minimum of f and g. 


If  is the function defined as , let's point out that
 and . The proof of the next lemma is Exercise 7.

1.7.10. Lemma. If  and  is continuous, then  is a
continuous function on X.

1.7.11. Proposition. If  and  are continuous
functions, then  and  are both continuous.
Proof. In light of Exercise 6, we need only show that  is
continuous. Begin by showing that for any two real numbers a and b,
. Hence for the functions f  and g,


The proposition now follows from the preceding lemma and other previous
results. â 
The preceding proposition allows us to construct new continuous functions
from old ones. For your cultural edification, what's going on here is that we have
shown that if we define  to be the collection of all continuous functions
 
 from X into , then, with the operations  and  defined above,
  becomes what is called a lattice. The interested reader can look up the
 definition on the Web. (Actually it must be checked that the axioms defining a
 lattice are all satisfied.)
 
We will close this section by introducing and exploring the following
concept.

1.7.12. Definition. If , then a function  is uniformly
continuous on X if for every  there is a  such that whenever
 and  we have .
Note that by Theorem 1.7.5 every uniformly continuous function is
continuous. The difference is in that theorem when we are given the , the
choice of  is allowed to depend on a point. For a uniformly continuous function
we can obtain the  independent of the point. Keep this in mind as you consider
the following example.

1.7.13. Example. The function  from  into itself is not uniformly
continuous even though it is continuous. In fact .
So if we are given an , no matter how small we make
 if we take , then when  we have
.
If ,  is called a
Lipschitz9
function if there is a positive constant M such that 
for all x and y in E. As we progress in this book, we'll see many examples of
Lipschitz functions, including one below. First, however, we establish one of their
fundamental properties, a property that is easy to prove.

1.7.14. Proposition. A Lipschitz function is uniformly continuous.
Proof. If , let  and the definition of uniform continuity
is
satisfied. â 
Recall the definition of the distance from a point to a set E, ,
given in Â§1.6.

1.7.15. Proposition. If  and , then
 
 


Consequently the function  defined by  is
 a Lipschitz function.
 
Proof. If , then ; so taking the infimum
 over all e in
 E we get .
 Reversing the roles of x and y we have ,
 whence we get the desired inequality. â 
 
Here is the main result on uniformly continuous functions.
 
1.7.16. Theorem. If X is a bounded closed subset of  and 
 is continuous, then f is uniformly continuous.
 
Proof. Assume f  is not uniformly continuous. So there is an  such
 that for any  there are points  in  with 
 but . Letting  we obtain sequences  and
  in X such that  and . Since X
 is bounded there is a subsequence  and a point x in X such that
 . Because , . Since f  is continuous,
  and . This gives a contradiction to the fact
 that  for all integers . â 
 
Before presenting the final result of this important section, we start with a
 discussion. Suppose we are given a closed and bounded interval  and a
 closed subset X of . What is the nature of the set ? Such a set in
 mathematics is called a relatively open subset of . In other words, it wants
 to be open in relation to . In fact Exercise 1.6.4 implies that  is
 open. So the only way that  fails to be an open subset of  is
 if  or  or both. Remember this when we prove the next
 result.
 
Now suppose  and we have a continuous function
 . We want to get an extension of f  to a continuous function
 . That is we want  to be a continuous function on  such
 that  when . There is a simple way to do this.
Let  and  be any real numbers and let  be the function defined
on  whose graph looks as follows: (i) between a and c the graph
of  is the straight line connecting the points  and ;
(ii) between c and d it has the same graph as f ; and (iii) between d and
b the graph is the straight line between  and . (The
interested reader can write down the equations that define . In fact, in the
proof of the theorem below we'll need this.) The choice of  and  was
arbitrary, but if we want  to have an additional property enjoyed by f , a
restriction on the choice of  and  must be made. For example, if
 when  and we choose , then we will
have  for all x in . In particular, if f  is a positive
function, we can make  positive by stipulating that . The next
result generalizes this discussion and the proof uses the method just
described.

1.7.17. Theorem. If X is a closed subset of  and  is a
continuous function with  for all x in X, then there is
a continuous function  that is an extension of f such that
 for all x in .
Proof. Consider . For the moment assume that 
so that  is open (Exercise 1.6.4). By Proposition 1.6.7,
, where the intervals  are pairwise disjoint.
Define  to be  when ; and, when , define it
so that the portion of its graph lying above this interval is the straight line
connecting the points  and  as discussed prior to
the statement of this theorem. It is clear that  is an extension of f  and
 for all x in . It remains to show that it is continuous.
Clearly  is continuous at the points in G. Assume  and that
 is a sequence in  that converges to x; we want to show that
. The sequence  can be partitioned into two
subsequences: one that consists of the points that belong to X and the
other the points that belong to G. In the first case we have that  of that
subsequence converges to  since  is an extension of f . Therefore
the proof will be finished if we assume  is a sequence entirely lying
in G. Thus for every  there is a integer  such that 
contains .
Claim.  and .
By Theorem 1.7.16, f  is uniformly continuous. So if  there is a  such
that  when  and . Since G is a subset of
 
 the bounded interval , G is bounded and so ; hence
  and there is an integer N with  for . (The
 reason for using  rather than  will become clear a little later.) It follows that
  when , establishing the first part of the claim. Now
 when , since  it follows that . Since 
 and , there is an integer K such that  and  when
 . Therefore when , . Therefore
  when , establishing the second part of the claim.
 
From the definition of  we have that
 


Keeping in mind that , we have that
 

by the claim. Therefore  is continuous at x.
 
What happens when one or both of a and b do not belong to X? For example, assume
  and put . Since X is closed, ; by definition . If
 in addition , then , where the intervals 
 are pairwise disjoint. If neither a nor b belong to X, then there is a number d
 such that . If  but , then there is a
 number d such that . In any of these three cases the proof
 proceeds as in the case that both endpoints are in X. The details are left to the
 reader. â 
 
The preceding theorem can be generalized and is called the Tietze Extension
 Theorem, something the reader will see if (s)he continues the study of
 mathematics. A cursory examination of the proof above shows that it uses
properties particular to  and any generalization necessitates a completely
different proof.
Exercises

(1) Using Proposition 1.7.2, perform an induction argument to show that every
polynomial is a continuous function on .
 
(2) If f  is a continuous function defined on  and  for all x in
, show that f  is a constant function.
 
(3)Let  be defined by  when x is irrational and
 when , , and a and b have no common divisor
except 1. Where is f  continuous?
 
(4) Use the IVT to show that if  is a continuous function, then
it has a fixed point. That is, there is a point x with . Equivalently
there is a point x with .
 
(5)If  is a continuous function such that  and
, show there is a number c in  such that .
 
(6) If  are two functions defined on a set X and taking values in , show
that . Similarly .
 
(7) Prove Lemma 1.7.10.
 
(8) Complete the proof of Proposition 1.7.11.
 
(9)Let  be an increasing function and assume that f  has the
intermediate value property. That is, assume that if , then
there is a number  in  such that . Prove that f  is
continuous.
 
(10)If  is continuous and  for every x in , show that f 
is constant.
 
(11)Give an example of a bounded function that is continuous on  but
not uniformly continuous.
 
 
 (12) Let  and show that  is uniformly continuous on
 .
 
 (13) Let  be pairwise disjoint closed and bounded subsets of . If
  and f  is uniformly continuous on  for , show
 that f  is uniformly continuous on X.
 
 (14)  For a function  and for each c in  and , define
  (a) Show that f  is continuous at
 c if and only if  (b) Show that f  is uniformly continuous
 if and only if
 


 (15)  Is the composition of two uniformly continuous functions a uniformly
 continuous function?
 
 (16)  If f  and g are uniformly continuous functions on X, are  and 
 uniformly continuous?
 
 (17)  If  and  is uniformly continuous, show that when
  is a Cauchy sequence in E it follows that  is a Cauchy
 sequence in . Show that the function  on  maps Cauchy
 sequences into Cauchy sequences even though it is not uniformly continuous
 (1.7.13).
 
 (18)  In reference to the preceding exercise, show that if f  is only assumed to
 be continuous it does not follow that  is a Cauchy sequence in 
 when  is a Cauchy sequence in E.
 
 (19) If , show that f  is uniformly continuous if and only if
 whenever  and  are sequences in X such that  an
  we have that .
 
(20) If E is a closed subset of ,  is a continuous function, and
 is a sequence in E, is ? (If the answer
is yes, prove it; if the answer is no, give a counterexample.) (b) If the answer
in (a) was no, can you add a condition on f  that makes the statement true?
1.8.  Trigonometric Functions
We are going to assume that the reader knows the definition of all the trig
functions as well as the various trig identities. What we want to concentrate on
here is showing that they are continuous. We start with the sine function and we
show it is continuous at . (Note: all angles in this book are measured in
radians. They are the natural measurement of angles and are the only
measurement we can use for calculus.)
Consider the circle of radius 1 centered at the origin; this is referred to as
 the unit circle. Let  and draw a line starting at the origin O and
 making an angle having  radians with the positive x-axis. The point B
 where this line meets the unit circle has coordinates .
 Let . (See Figure 1.8.1.) Note that the length of the
 base of the triangle  is , while its height is .
 We get that . On the other hand we know that
 the area of the sector of the unit circle subtended by the arc of length
  is . (This is where we need to have  in radians.) Since 
 is contained in this sector, we get that . On
 the other hand we also know that . So when ,
 . Thus we arrive at the fact that  when
 . So if , we have that . This proves half the
 following.
 



 Figure 1.8.1 

1.8.1. Lemma. The functions  and  are continuous at 0.
Proof. We have the statement involving the sine function. Now for  close
 to 0 we know that . So if , .
 â 
 


1.8.2. Proposition. The functions  and  are continuous
 everywhere.
Proof. If , then we know that .
 From the lemma we see that as , , so that the
 sine function is
 continuous at a. The proof for the cosine function is similar. â 
 
Now using Proposition 1.7.2 we can discover where the other trig functions are
 continuous. For example,  is continuous everywhere
 . That is,  is continuous everywhere except the points
 .
 
The next example is not only revealing but will be important as we
 progress.
 
1.8.3. Example. If , let  be defined by


It follows that no matter how a is chosen, f  is not continuous at 0 but it
is continuous at each point . In fact the continuity away from 
follows by
Proposition 1.7.4. On the other hand if , then ,
but  for all ; if , then , but
 for all . Therefore no matter how we define  it
cannot be that f  is continuous at 0.
Exercises

(1)Prove that  has a convergent subsequence.
 
(2)Where is the function  continuous?
 
(3)Where is the function  continuous?
1Augustus De Morgan was born in 1806 at Madura, India (now Madurai). His father was an officer in
the British Army stationed there. The young Augustus lost his sight in one eye shortly after birth and
the family returned to England when he was seven months old. He entered Trinity College,
Cambridge in 1823. He received his BA but refused to take a theology exam, which was
required for an advanced degree. He returned to London in 1826 to study for the Bar, but
instead he became the first professor of mathematics at the newly established University
College London in spite of the fact that he had never published in the subject, a fact he soon
remedied. On a matter of principle he resigned in 1831. He was once again appointed in 1836,
but resigned again in 1866. In 1838 he introduced the term "mathematical induction." The
process had been in use before, but without clarity; De Morgan managed to give it a rigorous
basis. Through his life he was a prolific author with hundreds of articles and many books. He
introduced the laws of the present proposition and was a great reformer of mathematical logic. In
addition he founded the London Mathematical Society and became its first president. He was
quite dogmatic, as his two resignations might indicate. He never voted and never visited
the House of Commons, the Tower of London, or Westminster Abbey. He died in 1871 in
London.
2Richard Dedekind was born in 1831 in Braunschweig, Germany also referred to as Brunswick.
His father was a professor at the Collegium Carolinum in Brunswick, an institution between a
high school and a university. He received his doctorate in 1852 from the University of GÃ¶ttingen
and was Gauss's last student. In 1854 he began to teach at GÃ¶ttingen and was joined by Riemann
and then Dirichlet, who influenced him greatly. In 1858 he accepted a position in Zurich and it
was during his first year there while teaching calculus that the idea of a cut came to him. In
1862 he accepted a position at the Brunswick Polytechnikum in his hometown. He made many
contributions to number theory and algebra, where he introduced the idea of an ideal in a ring.
He never married and he had no PhD students. He died in 1916 in the same town where he was
born.
3Bernard Bolzano was born in Prague in 1848. His father was from northern Italy and migrated to
Prague where he was an art dealer. Bernard was the fourth of twelve children, but only he and a brother
made it to adulthood. Bernard had delicate health his entire life. In 1796 he entered the Charles
University in Prague, where he studied philosophy, physics, and mathematics. In 1800 he began a course
in theological studies while simultaneously writing a doctoral thesis in geometry; he earned his
doctorate in 1804. Two days after receiving that degree he was ordained as a Catholic priest. He
soon realised he wanted to teach rather than minister to people. Nevertheless he was given a
chair in philosophy and religion at the university, though his views differed from those of the
Habsburgh rulers. Between 1821 and 1825 he was tried for heresy but refused to recant. He
resigned his chair and spent most of his time working on mathematics. It was earlier, in
1817, that Bolzano proved the present theorem, which he used to prove the Intermediate
Value Theorem. (See Theorem 1.7.7 below.) It was proved 50 years later by Weierstrass and
it was recognized as a fundamental result. Bolzano died in 1848 in Prague. It seems a bit
mysterious why Weierstrass shares the credit for this result, given the amount of time that elapsed
before he found it. I suspect it has something to do with the great prestige Weierstrass has in
mathematics.
4Karl Weierstrass was born in 1815 in Ostenfelde, Germany. His early schooling was rocky, though he
exhibited greater than usual mathematical ability. The difficulty was that his father wanted him to
pursue a career in finance, but his passion was for mathematics. At first he reacted to this with a
rebellious approach, neglecting all his studies and focusing on fencing and drinking. Nevertheless
he studied mathematics on his own with extensive readings, even though he was supposed
to follow a course in finance. After having left the university of Bonn without taking any
examinations, he seems to have reached an understanding with his father and attended the
academy at MÃ¼nster with the intention of becoming a high school teacher. Here he came
under the influence of Christoph Gudermann, a mathematician of note, and impressed his
mentor with a paper on elliptic functions. In 1841 Weierstrass passed the exam to become a
teacher, a career he followed for some years. In 1854 he published a paper on Abelian functions
and attracted considerable attention from the research world - sufficient for the University
of KÃ¶nigsberg to give him an honorary doctorate, enabling him to launch his university
career at Braunsberg. He obtained a chair at the University of Berlin in 1856, where he
remained for the rest of his life. He had a profound influence on mathematics, setting new
standards of rigor and fostering the careers of numerous mathematicians including many whose
contributions were profound. He became known as the father of modern analysis. He was plagued by
health problems that periodically surfaced and then ebbed. Starting in the early 1860s he
lectured while seated and while a student assistant wrote on the board. During his last three
years he was confined to a wheelchair and died of pneumonia in Berlin in 1897. He never
married.
5Augustin Louis Cauchy was born in Paris in August 1789, a month after the storming of the
Bastille. He was educated in engineering and his first job was in 1810 working on the port facilities
at Cherbourg in preparation for Napoleon's contemplated invasion of England. In 1812 he returned
to Paris and his energies shifted toward mathematics. His contributions were monumental, with
a plethora of results bearing his name. His collected works fill 27 published volumes. As a human
being he left much to be desired. He was highly religious with a totally dogmatic personality, often
treating others with dismissive rudeness. Two famous examples were his treatment of Abel and
Galois, where he refused to consider their monumental works, which they had submitted to him.
Both suffered an early death. Perhaps better treatment by Cauchy would have given them some
recognition that would have resulted in a longer life and a productive career to the betterment
of mathematics; we'll never know. He had two doctoral students, one of which was Bunyakowsky.
Cauchy died in 1857 in Sceaux near Paris.
6See the definition of Riemann integrable in Â§3.1 below for a biographical note.
7See the biographical note in Theorem 1.6.8.
8Georg Cantor was the child of an international family. His father was born in Denmark and his
mother was Russian; he himself was born in 1845 in St. Petersburg where his father was a successful
merchant and stock broker. He is recognized as the father of set theory, having invented cardinal and
ordinal numbers and proved that the irrational numbers are uncountable. He received his doctorate from
the University of Berlin in 1867 and spent most of his career at the University of Halle. His work was a
watershed event in mathematics, but it was condemned by many prominent contemporary
mathematicians. The work was simply too radical, with counterintuitive results such as  and
 having the same number of points. He began to suffer from depression around 1884.
This progressed and plagued him the rest of his life. He died in a sanatorium in Halle in
1918.
9Rudolf Lipschitz was born in KÃ¶nigsberg, Germany (now Kaliningrad, Russia) in 1832 to well-to-do
parents. (As you read these biographical notes, you might note that most of the mathematicians
discussed here came from professional families. Long ago higher education was not readily available to
the children of those who did physical labor.) He began his studies at the University of KÃ¶nigsberg but
moved to Berlin. With a year off for health reasons he received his doctorate from Berlin in 1853. After
four years teaching in a gymnasium he became a privatdozent at the University of Berlin. In 1862 he
became an extraordinary professor at Breslau. During this time he married a woman who had lived near
him in KÃ¶nigsberg. Then in 1864 he left Breslau for Bonn where he spent the rest of his
distinguished career, making substantial contributions in a variety of fields including number theory,
Fourier series, differential equations, mechanics, and potential theory. He died in Bonn in
1903. 












2 Differentiation
2.1.  Limits
In this section we want to introduce and explore the concept of a limit of a
function. We require the reader to consult Exercise 1.6.11 for the concepts of an
isolated point and a limit point of a set. These will be used in the next
definition.

2.1.1. Definition. If , a is a limit point of , and ,
say that the limit of f  on X at a is the number L provided that for every
 there is a  such that  whenever  and
. In symbols we denote this by


or


If a is an isolated point of X, then we define .
There are a few additional things worth emphasizing. First, it is not necessary
that a belong to the set X if it is a limit point; the restriction that a is a limit
point, however, insures that there are points in X that are arbitrarily close to a.
In particular we do not require that the function f  be defined at a. Second, look
at the part of the definition "." It may well be that there are
other points, not in X, where f  is defined; these do not influence whether
 as  with x in X. Third, look at the part of the definition
that states that  holds when "." Even if
 so that  is defined, we do not insist that .
Now consider the case that a is an isolated point of X. (For example it
might be that  and .) In this case there are
sufficiently small values of  such that there are no points x in  satisfying
. Technically or logically, if we used the first part of this
definition, we would have the sorry state of affairs that no matter what we
choose for L the conclusion  holds whenever  and
. In other words the value of  could be
anything. Of course this is intolerable, so we make a separate definition of the
limit of  for isolated points. Finally note that the case when a is a
limit point or an isolated point can be covered with the statement that
, though the definition of the limit still differs from one case to the
other.
As we progress we won't make an issue of the comments in the last paragraph,
though the reader should keep them in mind. In fact we see that these issues do
not appear in the notation used to denote the limit. There are certain situations,
however, where we want to emphasize how the variable x approaches a. When X
is an interval and a is one of the endpoints of the interval, we introduce special
notation for the limit. (Note that in this case a is not an isolated point of X.) For
example if a is the left-hand endpoint of the interval X we will use the
notation
 
 


This is called the right-hand limit of f  as x approaches a. If  and
  we might also discuss , where we apply the original
 definition to the restriction of f  to the set . Similarly if a is the
 right-hand endpoint of an interval X we use
 


This is called the left-hand limit of f  as x approaches a. Again when
  and  we might also discuss ,
 where we apply the original definition to the restriction of f  to the set
 .
 
Finally note that in the definition above both a and L are numbers.
 Later in this section we will explore the notion of a limit being equal to
  as well as taking a limit as . The reader will note a
 similarity between the proof of this next proposition and that of Theorem
 1.7.5.
 
2.1.2. Proposition. If , a is a limit point of X, and ,
 then  if and only if for every sequence  in 
 that converges to a, .
 
Proof. Suppose  and let  be a sequence in 
 that converges to a. If , let  such that  when
. By the definition of convergence there is an N such that
 when . It follows that  when
, and so . Now assume that  whenever
 is a sequence in  that converges to a, and let . Suppose
no  can be found to satisfy the definition. Thus for every 
there is a point  in X such that  but .
It follows that  is a sequence in  that converges to a, but
 does not converge to L, thus furnishing a contradiction. â 

2.1.3. Corollary. A function  is continuous at a point a in X if
and only if .
The next result follows from the fact that  if and only if
. (Verify!)

2.1.4. Proposition. If  and , then f is
continuous at c if and only if  and  exist and are equal to
.
 
 
The next result is a consequence of Proposition 1.3.6 applied to Proposition
 2.1.2.
 
2.1.5. Proposition. Suppose , , , and
 . If  and , then the
 following hold.
 
(a)  .
 
(b)  .
 
(c)  If  for all x in X and , then
 .
 
We return to Proposition 2.1.4 above to make a closer examination of how a
 function can be discontinuous at a point.
 
2.1.6. Definition. If  and , then f  has a simple
 discontinuity or a jump discontinuity at c provided 
 and  exist but .

2.1.7. Example. (a) If  when  and  when
 , then  has a simple discontinuity at 0.
 
(b) If  is defined by  when  and
 , then the discontinuity of f  at 0 is not simple. See Example 1.8.3.
 
If , a function  is increasing if  whenever
  and . The reader should look once again at the definition of
 an increasing sequence in Â§1.3 where there is a discussion of different
 terminology. The same discussion applies here. When discussing functions
 we will also use terms like strictly increasing, decreasing, and strictly
 decreasing; the definitions should be apparent from their use with sequences.
 The function is monotonic if it is either increasing or decreasing and
 strictly monotonic if the monotonicity is strict. Note that  is
 increasing if and only if  is decreasing. So any result established for an
 increasing function has a companion result that holds for decreasing
 functions.
 
2.1.8. Proposition. If  is a bounded increasing function,
 then  and  exist for every x in . Moreover
 
 


and every discontinuity of f is simple. In addition  and 
exist with


Proof. Fix x in  and put . If  let
 such that . Because f  is increasing we
have that  whenever . Letting
 shows that when  we have  and
so . Thus  exists and equals L. Also note that
since f  is increasing,  is an upper bound for  so that
. The proof of the statement for  is similar and left
to the reader as are the statements for  and .
Finally, the only way that f  can fail to be continuous at x is for the limit
 not to exist. By what we have just shown this means that
 and so there is a jump discontinuity at x. â 
Of course there is an analogue of the preceding proposition for decreasing
functions. See Exercise 3. Note that in light of this proposition when f  is a
bounded monotonic function on  we can extend f  to a function
 by letting . The extended function
remains monotonic, and, moreover, is continuous at the endpoints of
.

2.1.9. Proposition. If  is a monotonic function, then the
number of discontinuities of f is countable.
 
 
Proof. Assume f  is increasing and for the moment assume f  is bounded.
 As remarked just before the statement of this proposition, we can assume
 that  is increasing and continuous at the endpoints. Let
 . Assume that  has an infinite
 number of points; thus there is a sequence  of distinct points in .
 If we think geometrically, each  measures the vertical
 "gap" in the graph of f  at the discontinuity . The sum of all the
 gaps at the points  must be less than the gap . That
 is, . But by the definition of
 , , a contradiction. So  is finite. By
 Proposition 1.5.7,  is countable; by the preceding proposition
 D is the set of discontinuities of f . When f  is not bounded, consider
 the restriction of f  to ; this restriction is bounded. (See
 Exercise 6.) If  denotes the set of discontinuities of f  inside this closed
 interval, then  is countable by the first part of the proof. Since 
 is the set of discontinuities of f  on , again Proposition 1.5.7 implies
 that the set of discontinuities of f  is countable. â 
 
2.1.10. Definition. If , a is a limit point of , and ,
 say that the limit of f  on
 X at a is  provided that for every positive number P there is a 
 such that  whenever  and . In symbols
 we denote this by
 


An alternate phrasing of the same thing is to say  as .
 Say that
 


if for every negative number N there is a  such that 
whenever  and .
We leave it to the reader to formulate the definition of .
Also we are only going to state results for the case that  and leave the
statements for the case that  to the reader. The analogue for
Proposition 2.1.2 seems sufficiently clear that we leave it as Exercise 5. The only
result we pay close attention to here is the analogue of Proposition 2.1.5 as it
contains a few dangerous curves.

2.1.11. Proposition. Suppose
, , , and . If 
and  where , then the following hold.
(a)  .
(b)  .
(c)  If  for all x in X and , then
.
The proof is Exercise 7. If in the preceding proposition we were to
allow K to take on negative values then all hell can break loose. See
Exercise 8.
Recall that a subset X of  is not bounded above if for every positive
number P there is an x in X with .

2.1.12. Definition. If  such that X is not bounded above,
, and , say that the limit of f  on X as x approaches 
is L provided that for every  there is a positive number P such that
 when  and . In symbols we denote this by


An alternate phrasing of the same thing is to say  as .
 
Needless to say there is a definition of the statement  as
 well as the statements , , etc. It doesn't
 seem worthwhile to explicitly state all these.
 
Exercises

 (1)  If  and , show that  if and only
 if .
 
 (2)  Let  and . (a) Show that  if
 and only if for every decreasing sequence  in  that converges to
 a, . (b) Show that  if and only if for every
 increasing sequence  in  that converges to a, .
 
 (3)  State and prove the version of Proposition 2.1.8 for decreasing functions.
 
 (4)  The following result is called the squeezing principle. Suppose  are
 functions on X and . Show that if  for all x
 in X and , then .
 
 (5)  State and prove a version of Proposition 2.1.2 for  as .
 
 (6)  Why in the last half of the proof of Proposition 2.1.9 can we assume that
 ?
 
 (7)  Prove Proposition 2.1.11.
 
 (8)  Find examples of functions f  and g defined on all of  such that the
 following happen. (a)  and , but
 


(b)  and , but


(c) , , but


does not exist.
(d) Is it possible that  and , but



2.2.  The Derivative
2.2.1. Definition. Suppose  is a given open interval, ,
 and  such that . Say that a function
  is differentiable at x if the function defined on
  by
 


has a finite limit as . When this happens we call the value of this limit
 the derivative of f  at x and denote it by
 
â(2.2.2)
Of course another notation for the derivative of f  is


There are equivalent ways to define these notions. Using the same set-up as in
the preceding definition but not making specific the restrictions to make
everything precise, we can say that f  is differentiable at x if and only
if


exists. As we just did, we will henceforth drop specifying the eligible values of
y where this quotient is defined.
The reader can consult other books to see discussions of the right and left
derivatives of f  at x. These are defined just as above except that in (2.2.2) we
take the left-hand and right-hand limits. These have a use, especially when f  is
defined on a closed interval and we want to define the derivative at an endpoint
as we do now.

2.2.3. Definition. If  we say that f  is differentiable at a if


exists. Similarly we can define f  to be differentiable at b. Say that f  is
 differentiable on  or  if it is differentiable at every point of the
 interval.
 
In what follows we often state results about functions differentiable at a point
 of , but we will only prove them for the behavior of the function at a point
 x in the open interval . The proofs in the case where  or  are
 left to the reader.
 
2.2.4. Proposition. If , , and f is differentiable
 at x, then f is continuous at x.
 
Proof. Assume that . (The case that x is an endpoint is similar.) Note
 that
 

 â 
 
Now for the algebraic permanence of derivatives.
 
2.2.5. Proposition. If f and g are differentiable at a point x in ,
 then the following hold.
 
(a)   is differentiable at x and .
 
(b)  fg is differentiable at x and .
 
(c)  When  for all y in ,  is differentiable at x and
 
 


Proof. We assume . The proof of (a) is easy in light of
previous results on limits. To establish (b), put  and note that
.
Dividing by t gives


Now let  and use the fact that g is continuous at x (2.2.4) to
obtain part (b).
The proof of (c) proceeds in a similar way, but here we let . After
some algebra we get

Letting  produces the result. â 
We might point out that (c) needs the proof given because we have to show
that  is differentiable. If we knew that h were differentiable, however,
we could easily find the formula for  by setting , using (b), and
solving for .
 
 
Recall from calculus the geometric significance of . If we plot the graph
 of f  near the point , we see that for any x different from a the quotient
  is the slope of the straight line  going through the
 points  and . If f  has a derivative at c, then as 
 the line  approaches the line tangent to the graph of f . Thus the
 quotient  approaches the slope of the tangent line.
 Hence the equation of the line tangent to the graph at the point 
 is
 


2.2.6. Example. Here we sketch the details of showing that polynomials
 are differentiable. Note that from this and part (c) of the preceding
 proposition we obtain that the rational functions are differentiable
 everywhere the denominator does not vanish. We begin with the easy
 calculation from the definition that for any constant c, .
 Also if we are given the identity function, , we quickly get from
 the definition that . Now if  and , we have
 that . Hence if ,
 forming  and letting  we
 see that
 


Now let's derive the formulas for differentiating the trig functions. To start we
 need a lemma.

2.2.7. Lemma. (a)  .
(b)  .
Proof. (a) Since , we need only consider the
limit as . To do this return to the proof of Lemma 1.8.1
and the triangle  in Figure 1.8.1. We showed there that
. Now extend the line OB until it intersects the
line perpendicular to the x-axis at the point A and denote the point of
intersection by C. Consider the right triangle  and note that since
the length of the segment OA is , we have that .
Hence . Comparing the areas of , the sector
of the unit circle subtended by the arc AB, and the area on  we get
that  or


Therefore


Now we know that  is continuous so if we let  we get the
desired conclusion. (See Exercise 2.1.4.)
(b) Note that
 
 

By part (a) this must converge to 0 as . â 
 
2.2.8. Proposition.  and .
 
Proof. Using the formula for the sine of the sum of two numbers we
 get
 

By the preceding lemma this converges to  as . The proof that
  is similar and left as Exercise 5. â 
 
Deriving the formulas for the derivatives of the remaining trig functions can
 now proceed by using the preceding proposition with Proposition 2.2.5. For
 example, since , we can use (2.2.5(c)) to determine that the
 tangent function is differentiable whenever  and obtain that for such x
 we have that .
 
The next result is an equivalent formulation of differentiability that is often
 useful in executing proofs. Its proof is easy.
 
2.2.9. Proposition. A function  is differentiable at a point x
 in X if and only if there there is a function  and a number D
 such that  and  for all
 y in X. When f is differentiable at x, we have .
Proof. We only prove half of this result. The proof of the other half is
left as Exercise 7. Assume f  is differentiable at X, put , and
let  when  and . The
condition is easily seen to be
satisfied. â 
We'll see the usefulness of the preceding result in this next proof.

2.2.10. Theorem (Chain Rule). Let  be differentiable at a
point x in , , and let  be a function
that is differentiable at . If  is defined by ,
then h is differentiable at x and


Proof. Use the preceding proposition to write 
and , where , F and G
are functions defined on the appropriate sets, , and
. Therefore

where
 


We must show that  as . Let's consider what happens to
 each of the summands in the definition of  as . We know that since
 f  is differentiable at x, it is also continuous there. Hence  and so
 . Thus the first summand converges to 0. The second summand
 converges to 0 since . The third summand converges to 0 by combining
 the two things we have just established:  and . By
 Proposition 2.2.9 this proves the Chain Rule. â 
 
2.2.11. Example. Before studying this example, the reader should look at
 Example 1.8.3. Define  by
 


We will show that f  is a continuous function on  that is differentiable
 when , but it is not differentiable at . The fact that f  is
 continuous when  is clear, and continuity when  follows by
 observing that . The differentiability of f  when  follows
 from the Chain Rule and a judicious use of Proposition 2.2.5(b). The fact
 that f  is not differentiable at  is seen by observing that for ,


and using Example 1.8.3.
Exercises

(1) State and prove a version of Proposition 2.2.4 when  is
differentiable at a.
 
(2) Show that if  and there are constants M and  such
that  for all  in , then f  is a constant.
 
(3)Let  and suppose that  and  are
continuous functions with  and such that f  is differentiable on
, g is differentiable on . If we define  by


give a necessary and sufficient condition that h is differentiable at .
 
(4)For each positive integer n, find the points x in  where 
is differentiable and compute its derivative.
 
 
 (5)  Show that .
 
 (6)  For which values of x is  differentiable and derive the formula for its
 derivative.
 
 (7)  Prove the other half of Proposition 2.2.9.
 
 (8)  Use Proposition 2.2.5(b) and induction to show that 
 (Example 2.2.6).
 
 (9)  Find  when .
 
 (10) Are there any values of n in  such that  is differentiable at
 ?
 
 (11) For each of the following functions determine where it is differentiable
 and find a formula for its derivative. (a) . (b) . (c)
 .
 
 (12) Let . The function f  is an even function if  for all
 x; f  is an odd function if  for all x. (a) Give two examples
 of an even function and two examples of an odd function. (b) If f  is a
 differentiable even function, show that  is an odd function. (c) If f  is a
 differentiable odd function, what can you say about ? 
2.3.  The Sign of the Derivative
2.3.1. Definition. If  and , we say that f  has a
 local maximum at x if there is a  with  with
  when . Similarly we define what it means for f  to
 have a local minimum at x.
 
We note that f  has a local maximum at x if and only if  has a local
minimum at x. Also a constant function has both a local maximum and
minimum everywhere, while  has neither a local maximum nor a local
minimum anywhere. Now for a result that should be beloved and familiar to all
calculus students.

2.3.2. Theorem. If f is a differentiable function on  and f has a local
maximum or minimum at a point x, then .
Proof. Assume that f  has a local maximum at x. (If f  has
a local minimum at x, we apply the argument that follows to
.) Thus there is a  such that 
and  when . In particular when ,
. This implies that . Taking
the limit as  shows that . Now assume that .
Again , but now . Taking the
limit as  shows that . Therefore we have proved the
theorem. â 
Be aware that an examination of the proof shows that in the statement of the
theorem it is required that the interval  is open. That is, if f  is
differentiable on  and has a maximum at b it does not follow that
. A consideration of  on  makes the point.

2.3.3. Example. The function  defined by  satisfies
, but 0 is neither a local maximum nor a local minimum for f .
Hence the converse of the preceding theorem is not true.

2.3.4. Theorem (Mean Value Theorem). If  is continuous
and f is differentiable at each point of , then there is a point x in
 with


Proof. Define  by . A
 little algebra reveals that to prove the theorem it suffices to show there
 is a point x in  with . Some more algebra reveals that
 . If h is constant,  for every t in  and we have
 the result. Suppose there is some point t in  with . Since
 h is continuous on , the EVT implies there is a point x where h attains
 its maximum. Of necessity, . It must be that this maximum for h
 is a local maximum; so  by Proposition 2.3.2. On the other hand
 if it is the case that there is a point t in  with , then by
 similar reasoning h attains its minimum value at a point x in . For
 this point x we have that . â 
 
We'll refer to the preceding theorem as the MVT.

2.3.5. Corollary. If f and g are continuous functions on  and they are
 differentiable on , then there is a point x in  with
 



Proof. Apply the MVT to the function
. â 
This last corollary is sometimes called the Generalized Mean Value Theorem.
That it is more general than (2.3.6) can be see by letting  in the
corollary.

2.3.6. Corollary. If  is a differentiable function and
 for all x in , then f is a constant function.
Proof. If  and , the MVT implies there is
a point c between x and y with , a
contradiction. â 
The student is, undoubtedly, very familiar with the fact that the derivative
measures the rate of change of the function. Indeed the very definition of the
derivative shows this. The next result formalizes such a discussion.

2.3.7. Proposition. If f is a differentiable function on , the
following hold.
(a)  f is an increasing function if and only if  for all x.
(b)  If  for all x, then f is strictly increasing.
(c)  f is a decreasing function if and only if  for all x.
(d)  If  for all x, then f is strictly decreasing.
Proof. The proofs of (c) and (d) follow from their counterparts in (a) and
(b) by considering .
(a) Assume f 
is increasing. If , let  be such that .
If , then , and so .
Taking the limit shows that . Conversely assume that 
for all x in . If , then the MVT implies there is an x
in  such that , and we have that f  is
increasing.
 
 
(b) Assume  for all x, and let . Just as
 we did in the proof of (a), there is a point x in  such that
 , and we have that f  is strictly increasing.
 â 
 
Note that the function  shows that the converse of part (b) is not
 true. See Exercise 2.
 
The next result is a cousin of the preceding one but is unrelated to derivatives.
 It is presented here for the reader's cultural edification and its use in the further
 study of differentiable functions.
 
2.3.8. Proposition. If I is an interval and f is a continuous injective
 function defined on I, then  is an interval and f is strictly monotonic.
 
Proof. The fact that  is an interval is part of the IVT (1.7.7).
 
Observe that since f  is injective, it suffices to show that it is monotonic.
 Assume that f  is not monotonic; so (Exercise 4) there are points 
 with  such that either  and  or
  and . As usual we need only consider the first of
 these since if the second occurs we can consider .
 
Let's compare  and : either  or . If
 it is the case that , then we have that ;
 that is  is in the interval . By the IVT there is a point
  in  with , contradicting the fact that f  is injective.
 If it is the case that , then we have that ;
 that is,  is in the interval . Again an application of the
 IVT yields a contradiction. These contradictions lead to the conclusion that
 f  must be monotonic. â 
 
To set the stage for the next topic, we return to the abstract setting of
 functions defined between sets that are not necessarily contained in . If X
 and Y  are sets and  is a bijective function, we can define
 its inverse  as follows. If , then the fact that f  is
 surjective implies there is an x in X such that . Because f  is
 also injective, the point x is the only such point in X. Therefore we can
 define  and we have a function . We note
 that  for all y in Y , and  for all x in
 X.
 
Now to return to subsets of . If I is an interval in  and  is a
 continuous function that is also injective, then Proposition 2.3.8 above implies
 that  is also an interval and f  is monotonic. Thus  is also
monotonic.

2.3.9. Proposition. If I is an interval,  is an injective
continuous function, and , then  is a continuous
function.
Proof. f  is strictly monotonic by the preceding proposition. We only
consider the case where it is increasing. Suppose  and let
. First let's assume that a is not an endpoint of I; the case
where it is an endpoint will be treated later. There are points b and c in I
such that ; put . Since f  is strictly increasing,
. To show that  is continuous at  we need to show that
if  is a sequence in  that converges to , then .
But if , then . By the Bolzano-Weierstrass
Theorem there is a subsequence  and a point  in  such
that . Since f  is continuous, . But since
 is a subsequence of the convergent sequence , it must be that
; thus . We have shown that every convergent subsequence
of  converges to a. By Exercise 1.3.9, .
Now for the case that a is an endpoint of I; assume it is the left-hand
endpoint. Since f  is increasing,  must be the left-hand endpoint of J.
Choose a point c in I with . It follows that  and .
The proof of this part follows the lines of the argument used to prove the
case where a was not an endpoint and is left to the reader as Exercise 7. â 

2.3.10. Proposition. If  is a differentiable function
that is bijective, then the function  is differentiable and


for every  in .
 
 
Proof. Fix  in . By Proposition 2.2.9 we want to find a function
  defined on a small interval about  such that  as 
 and such that
 


Put . By the differentiability of f  at x we have the existence
 of a function  defined in a small interval about x such that 
 as  and
 


If  is given and , then
 

where


Now by the preceding proposition we know that  is a continuous
function. Thus as , ; hence . It
follows that  as required. â 
We know several functions that are differentiable bijections and so we can
apply the preceding result. For example,  is a
differentiable bijection, and we can use (2.3.10) to find the derivative of its
inverse, . See Exercise 9. 
Exercises

(1) Give the details of the proof of Corollary 2.3.5.
 
(2) Try to prove the converse of Proposition 2.3.7(b) by assuming f  is strictly
increasing and starting the argument used to prove the first part of (a) of
 
 that proposition. Where does it break down?
 
 (3) Let  be a continuously differentiable function such that
  and there is a constant C with  for all x. (a) Use
 the Mean Value Theorem to show that  for all .
 (b) Prove that . (c) Show that there is a 
 such that . (d) Prove that there is only one point 
 satisfying .
 
 (4)  If I is an interval and  is injective, show that f  is increasing if and
 only if when  with  we have that .
 
 (5) Let n be an integer with . If , show that there
 are at most three numbers x with .
 
 (6)  Show that if I and J are intervals and  is a continuous bijection,
 then  is strictly monotonic. (See Proposition 2.3.8.)
 
 (7)  Fill in the details of the proof of Proposition 2.3.9.
 
 (8)  Why can't you prove Proposition 2.3.10 by applying the Chain Rule to the
 fact that  for all  in ?
 
 (9)  Find an appropriate domain on which the trig functions , and 
 are bijective and use Proposition 2.3.10 to calculate the derivatives of their
 inverses.
2.4.  Critical Points
2.4.1. Definition. If f  is a differentiable function on , a critical point
is a point x in  with .
 
Why
 is
 it
 called
 a
 critical
 point?
Because interesting things happen there. Of course if the derivative is zero on an
entire interval, then it is constant there; from one point of view there is not much
critical happening there, from another there's a lot that's going on. Suppose it is
zero at an isolated point; then three possible things might happen. The
derivative could change from being positive to negative; change from
being negative to being positive; or it could have the same sign on both
sides of the place where it is zero. An example of this last phenomenon
is the function . In the first two cases something truly interesting
happens. In fact recall Theorem 2.3.2 where it is shown that when a
function has a local maximum or minimum it has a critical point. We
saw that  shows the converse of this is false, but below we present
the partial converse of (2.3.2), something the reader has encountered in
calculus.

2.4.2. Theorem. Suppose  is a differentiable function and
 is a critical point of f.
(a)  If there is a  such that , 
when , and  when , then f has
a local maximum at .
(g)  If there is a  such that , 
when , and  when , then f has
a local minimum at .
Proof. The proof is intuitively clear, but we must translate that intuition
into precise mathematics. We only prove (a). If , then the
MVT
implies there is a y with  and .
But the assumption on  when  implies that
. If , the MVT implies there is a z
with  and . Since  by
hypothesis and  we have that . Thus f  has
a local maximum at . â 
 
 
There is a small drawback to the preceding theorem. Namely we assume that
 the  exists. There is, however, a simple extra condition on f  that helps in
 this process. To set the stage, realize that if f  is a differentiable function on
 the open interval , then the derivative defines another function,
 .
 
2.4.3. Definition. Say that f  is a continuously differentiable function on
  if it is a differentiable function and  is a continuous
 function. The collection of all continuously differentiable functions on
  is denoted by . Functions in  are also
 called smooth functions. Now  can also be differentiable, in which case
 we say that f  is a twice differentiable function. The second derivative
is denoted by . If  is continuous, we say that f  is a
 twice continuously differentiable function; denote the collection of all twice
 continuously differentiable functions on  by .
 This continues with the definition of higher derivatives denoted by
  If  defines a continuous function, we say that f 
 is n-times continuously differentiable and we denote the space of all such
 functions on  by . If we can form all the derivatives 
 for , we say that f  is infinitely differentiable and denote the space of
 all such functions as . In some places in the literature the term
 "smooth function" is reserved for functions in , where we have
 used the term for functions in .
 
See Exercise 1.
 
2.4.4. Example. (a) Recall Example 2.2.11 and define  by
 


Clearly  is differentiable at . In fact,
  when . Also note that


as , so that  is differentiable at  and .
However, using Example 2.2.11 we have that  is not continuously
differentiable on all of  though it is on any open interval not containing
0. Since  is not continuous at 0,  is not twice differentiable.
(b) Define  by


It follows that  but it is not twice differentiable at .
The reader is asked to show this in Exercise 4 as well as explore additional
functions.
 
 
We now present the second derivative test for a critical point.
 
2.4.5. Theorem. Suppose  and f has a critical point at .
 
(a)  If , then f has a local maximum at .
 
(b)  If , then f has a local minimum at .
 
(c)  If , then the nature of the critical point at  cannot be
 determined.
 
Proof. (a)
 Since , there is a  such that 
 and  for . Since , this means that we
 can apply Theorem 2.4.2(a) and conclude that f  has a local maximum at
 . The proof of (b) is similar.
 
(c) Note that when , , and f  has nether a local
 maximum nor a local minimum at 0. If , , and f  has
 a local minimum at ; if , , and f  has a local
 maximum at . â 
 
The next curious result says that if the function is differentiable, then it has
 the intermediate value property even if we do not assume that the derivative is a
 continuous function.
 
2.4.6. Theorem (Darboux's1 Theorem). If
  is differentiable,
 , and y is a point between  and , then there is
 an x in  with .
Proof. Without loss of generality we can assume that ; for
 convenience assume that . If we define  by
 , then  and . Since g is
 continuous there is a point x in  with .
 Now , and so there is a point
  with  for . Hence . Similarly there
 is a  with . This shows that the point x is in . By
 Theorem 2.3.2, . â 
 
We conclude this section with a discussion of using what we have done to find
 the global maximum and minimum of a differentiable function . By
 the EVT we know these exist. To find them we can find the critical points
of f  in the interval, compute the value  for each critical point
, then compute the values  and . Comparing all these
values will then reveal the extreme values as well as their location. See the
exercises.
 
 
Exercises

 (1)  Show that  is an algebra; that is, it is a vector space over  that
 also has the property that the product of any two elements is again in the
 vector space and all the usual distributive laws hold.
 
 (2) If f  and g are functions on  such that each has derivatives there of
 order k for , show that fg has a derivative of order n and
 

where 
 (3) For each of the following functions f , decide whether  is a local
 maximum or local minimum of f  or neither. (a) .
 (b) . (c) .
 
 (4)  Define  by
 

(a) Show that , but  is not twice differentiable at .
(b) Show that , but is not three-times differentiable at .
(c) Show that , but it is not -times differentiable
at . (Warning: This is a complicated computation.)
 
(5)Let f  be a  function on  and suppose there is a point  in
 with . Show that there is a continuous
function g on  with  for all x in .
 
(6)Let
. Find the critical points of f  and diagnose their
nature.
 
(7)Let . Find the critical points of f  and diagnose their
nature.
 
(8) Find the global maximum and minimum values of the function
 on the interval  and find the point x where they
occur.
 
(9) Find the global maximum and minimum values of the function
 on the interval  and find the point x where
they occur.
2.5.  Some Applications
In this section we will use what we have learned about derivatives to establish
two results, L'HÃ´pital's Rule and Taylor's Theorem. 

2.5.1. Theorem (L'HÃ´pital's2
 Rule). Assume  and f and g are differentiable
 functions on  such that  for all x. If
  and there is an L in  such that
 


then
 


Proof.
 We begin by showing that . Let  and choose
  such that  when . Corollary
 2.3.5 implies that when , there is a z with  and
 . Hence when ,
 we have that


Now  and  as . So holding x
fixed in  and letting  in the above inequality,
we get that  when . Since  was
arbitrary, this shows that . The proof that
 is similar and left to the reader. â 
There are variations on L'HÃ´pital's Rule, which are also called by
the same name. Usually these involve having  involved. Here is
one.

2.5.2. Theorem (L'HÃ´pital's Rule). Assume  and f and g are
differentiable functions on  such that  for all x. If
 and there is an L in  such that


then


Proof. The proof begins as in the proof of the preceding theorem. Let  and
 choose  such that  when .
 Corollary 2.3.5 implies that when , there is a z with
  and . Hence when
 , we have that
 
 
â(2.5.3)

 Fix x with . Since  as , there is a  with
  such that when  we have both 
 and ; note that for such a y, . So
 if we multiply the inequalities (2.5.3) by this quotient we obtain the
 following two inequalities, separated for convenience and valid for all y with
 
 
â(2.5.4)

and
 
â(2.5.5)

Doing some algebra (2.5.4) becomes


or


Remember that x is fixed. Since  as , we can find a 
 with  so that when  we have that
 


can be made as small as we want. Thus we can find such a  so that for
 


Now for (2.5.5). Doing similar algebra we arrive at the inequality
 


We again use the hypothesis to find a  with  such that when
 we have that


Combining our inequalities we get that when , .
This establishes that . In similar fashion we get that
. â 
You should also see [11] where there are several variations on the
theme of L'HÃ´pital's Rule as well as a number of exercises. As we progress
we'll use these results, referred to by the name but possibly with small
variations.

2.5.6. Theorem (Taylor's3
Theorem).  If , , f is n-times differentiable at the
point c in , and  is the polynomial


then there is a function  such that  as 
 and
 


Moreover for every x in  there is a point d between x and c such
 that
 


Proof. Let be the polynomial defined in the statement of the
 theorem. If we set
 


then . Let's show that . This is
accomplished by repeated use of L'HÃ´pital's Rule. Note that applying the rule
once won't suffice when . In fact this becomes clear once we calculate that
 for . So L'HÃ´pital's rule repeated yields

Now fix x in ; we want to show there is a point d between x
and c such that . To do this introduce the function
, where


From the definition of the polynomial  we can compute that
; so we want to produce a point d
between x and c with . We will do this by applying the MVT to the
successive derivatives of .
To begin we use the fact that for ,  and we
conclude that . Now from the definition of M
we get that . Thus the MVT applied to g shows there is a
 
 point  between x and c with . But ; so applying
 the MVT to  shows there is a point  between  and c with
 . Now apply the MVT to  and so on. Eventually we show the
 existence of a point  between  and c such that .
 Therefore if we let , then it lies between x and c and .
 â 
 
Again I can recommend [11] for more on Taylor's Theorem.
 
Exercises

 (1)  In Theorem 2.5.1 assume  and prove that the theorem remains
 valid. Can you do the same for Theorem 2.5.2?
 
 (2)  Can you state and prove a version of L'HÃ´pital's Rule covering limits as
 ?
 
 (3)  Assume  are differentiable functions such that 
 for all x in . If  and there
 is an L in  such that , then
 .
 
 (4) For each of the following specified functions find the stated limit if it
 exists, where existing includes the possibility that the limit is .
 (a) . (b) .
 
 (5) Let f  be an infinitely differentiable function on an open interval  and
 suppose . If  and  for  and
 , show that there is an infinitely differentiable function
  such that  and .
1Jean Gaston Darboux was born in 1842 in Nimes in the Languedoc region of France. His early
education was in Nimes and the nearby city of Montpellier. After this, in 1861, he entered
the Ãcole Polytechnique and then the Ãcole Normale SupÃ©rieure. While still a student he
published his first paper on orthogonal surfaces, a subject that became his main research
focus. These results were part of his doctoral dissertation, which he was awarded in 1866.
He had several academic positions until he was appointed as supplÃ©ant to Liouville at the
Sarbonne in 1873. He continued in this position for five years. In 1878 he became supplÃ©ant
to Chasles in the chair of higher geometry at the Sorbonne. Two years later Chasles died
and Darboux was appointed as his successor. He held this chair for the rest of his life with
a term as dean of the Faculty of Science from 1889 to 1903. He made many contributions
to geometry and there is also the Darboux Integral. He was also an excellent teacher and
administrator. Among his doctoral students are Ãmile Borel, Elie Cartan, Ãdouard Goursat, and Ãmile
Picard.
2Guillaume FranÃ§ois Antoine Marquis de L'HÃ´pital was born in Paris in 1661. An earlier
version of his family name is l'Hospital and you will sometimes see this used today when his
result is presented. His family was prominent in France for centuries, and his father was
a general in the King's army. L'HÃ´pital's mathematical story is complicated; it is cloaked
in obscurity, and, for present day eyes, strangeness. This is partly due to the fact that he
lived so long ago, a fact that means that many documents are forever lost and also that
social behavior was so different from what it is today. From an early age L'HÃ´pital displayed
mathematical ability, but he would have probably never been known to calculus students except
for his meeting Johann Bernoulli, who at the age of 24 in 1691 had just arrived in Paris.
Bernoulli was an expert in the differential calculus of Leibniz. (Realize that Newton was just 18
years older than L'HÃ´pital and had published his Principia Mathematica in 1683; also at the
same time Leibniz was developing calculus in Paris.) L'HÃ´pital and Bernoulli became friends
but later had a falling out due to a priority dispute. In 1694 L'HÃ´pital wrote a letter to
Bernoulli promising him money in return for his working on problems of L'HÃ´pital's choice.
Needless to say he added the proviso that Bernoulli not publish this work independently. There
is no copy of Bernoulli's reply, but apparently he accepted the proposal and later letters
record the exchange of ideas. (The practices of mathematicians as well as the rest of society
have changed since then. Others have written on this agreement with more authority than I
can muster for this footnote.) In 1696 L'HÃ´pital published the first textbook on differential
calculus; it contains L'HÃ´pital's Rule. This book was extremely influential with new editions
published until 1781. L'HÃ´pital was a married man and had four children. He died in Paris in
1704.
3Brook Taylor was born in 1685 in Edmonton, England to a financially comfortable family. He was
schooled at home until he entered Cambridge. His first paper of note was published in 1714 and was on
mechanics using Newton's calculus. In 1721 he married, but his wife died in 1723 during childbirth; the
baby also died. He married again in 1725, but his second wife also died in childbirth, though the baby
survived. Besides the present theorem Taylor discovered integration by parts and invented the field of
finite differences. He made contributions to a variety of sciences as well as the mathematical study of
perspective in art. Unfortunately he became distracted as he was virulently involved in the debate
over whether the credit for inventing calculus belonged to Newton or Leibniz. This involved
nationalism to a degree that is surprising to a modern mathematician. He died in 1731 in
London. 












3 Integration
This chapter gives a mathematical foundation of the theory of integration the
reader began in calculus. Unlike when the student took calculus, there will
not be as much emphasis on computing integrals. Before the chapter
concludes we'll see some topics never covered in calculus as well as establish a
foundation for future embellishments and extensions. Integration is a vast,
powerful, and useful subject. The development given in calculus, as well as
the material on this subject contained in this book, only introduces the
subject.
3.1.  The Riemann Integral
Throughout this section we work with a closed and bounded interval,
. A partition of  is a finite, ordered subset of the form
. (This is the usual notation for a partition
where both the points and the ordering are listed.) Say that a partition Q is a
refinement of a partition P if . Hence Q adds additional points to P, and
each subinterval of  determined by two consecutive elements of P is the
union of one or more of the intervals determined by the elements of Q.
For example  is a partition of . Both
 and  are
refinements of P as is P itself. An observation that will be used often as we
proceed is that if P and Q are two partitions of , the partition  is a
refinement of both P and Q.
If  is any bounded function and ,
 
then for  define

and let


The term  is called the upper sum of f  for the partition P;  is
called the lower sum. If you remember the way the integral was introduced in (many)
 
 calculus courses, for a positive function f ,  is the sum of the areas of
 rectangles placed below the graph of the function f  while  is the total of
 the areas of the rectangles placed above the graph of f .
 
3.1.1. Example. (a) Assume  is a constant function:
  for all x in . For any partition P and with the
 notation as above,  for each j. Thus for any partition P,
 .
 
(b) Now define  by
 


By the Density Property (1.2.1), for
 any partition  and , 
 and . This implies that  and .
 
Of course we'll see many other examples, but not until we develop a little
 more of the theory. Before we start we might call attention to Exercise 1, which
 can often be used to derive a result for the lower sum from a result for the upper
 sum.
 
3.1.2. Proposition. If f is a bounded function on  with
  for all x in  and P and Q are partitions of ,
 then the following hold.
 
(a)  .
 
(b)  If Q is a refinement of P, then
 


(c)  If Q is a refinement of P, then


Proof. (b) Let  and, as usual, define
 for . Let's consider the case
that Q is obtained by adding one point to P; in fact assume that
. (The case where  is between
two other points is similar and only involves more complicated notation.) Let
. Note that
. Thus 
and so . The fact that this inequality holds when Q is
obtained by adding any number of points is an argument using induction;
the details are left to the reader. The proof that  is
analogous and left to the reader as Exercise 2.
(c) This is immediate from (b) and is stated only for convenience.
(a) For the moment
consider just one partition P. Using the usual definitions of  and 
for , we have that . From here we easily get
that . Now assume we have two
partitions, P and Q. Note that  is a refinement of both P and Q.
 
 Applying
 (b) twice we get that
 .
 â 
 
3.1.3. Definition. Using the preceding proposition we have that
 

When these two expressions are equal, we have a desirable event and we
 set
 

In this situation we say that f  is
 Riemann1 integrable
 or simply integrable. The set of all Riemann integrable functions on  is
 denoted by .
 
A brief word about notation. Ordinarily we will use the notation  rather
 than  as seen in calculus. The use of the notation involving dx will be
 limited to those occasions where there might be some confusion as to the variable
 of integration. This will be our practice partly because the x is redundant, but
 mainly to emphasize that we are integrating a function. The notation for a
 function is f , while  is the value of the function at the point x in its
 domain.
 
Note that the function f  appearing in Example 3.1.1(b) is not integrable,
 while the constant functions are. The next result gives a necessary and
 sufficient condition for integrability that is more convenient than the
 definition and that will usually be employed when we prove results about
 integrability.

3.1.4. Proposition. If f is a bounded function on , then f is
Riemann integrable if and only if for every  there is a partition P
of  such that . Moreover  is the unique
number such that for every refinement Q of P we have



Proof. Define

We always have that . Suppose that for every  we can find a partition
P with . But . Since  was
arbitrary we have that . Conversely, assume f  is Riemann integrable
and let . Choose partitions  such that  and
. If we put , then Proposition 3.1.2 implies
that . If Q is a refinement of P, then Proposition 3.1.2(c)
implies that . Since  was arbitrary
we have that there can be only one number between  and  for
every such refinement. By definition, this unique number must be .
â 
The uniqueness part of the last proposition is there mainly for emphasis, since
when a function is integrable there can be no other number between all the lower
and upper sums. There is, however, some small benefit in using only partitions
Q that are refinements of P as seen in the proof of Proposition 3.1.6
 
 below.
 
3.1.5. Corollary. If f is a bounded function on , then f is Riemann
 integrable if and only if there is a sequence of partitions  of  such
 that each  is a refinement of  and  as
 . When this happens we have that
 


Proof. If such a sequence of partitions exists, then it is immediate
 from the proposition that . Now assume that f  is
 integrable. By the proposition for each  there is a partition
  with . If , then 
 is a refinement of  and so Proposition 3.1.2(c) implies that
 . The evaluation of the integral as the limit of
 the upper and lower sums follows from the definition of the integral. â 
 
3.1.6. Proposition. If  is a bounded function and
  is a partition such that f is Riemann
 integrable on  for , then f is Riemann integrable on
  and
 


Proof. Let  and let  be a partition of  such that
. If , then P is a partition of
 and


Thus .
To finish the proof let Q be any refinement of P and set .
It follows that  and each  is a refinement of . We have that
 for . Thus

By the uniqueness part of Proposition 3.1.4 it follows that


 â 
Now we see a useful sufficient condition for integrability.
 
3.1.7. Theorem. If  is a bounded function that is continuous
 at all but a finite number of points, then f is Riemann integrable.
 
Proof. Suppose  for all x in . We begin with a
 special case.
 
3.1.8. Claim. If f  is continuous at every point, then f  is Riemann integrable.
 
Let . Recall that Theorem 1.7.16 says that  is uniformly
 continuous. Hence there is a  such that  implies that
 . Let  such that
  for . Since  when , it
 follows that . (Why?) Therefore
 


and so  by the Proposition 3.1.4.
 
3.1.9. Claim. If f  has a single point of discontinuity in , then
 .
 
We will assume the point of discontinuity is at the left-hand endpoint, a. (The
 proof of the case where the discontinuity is at b is practically identical. The proof
 of the case when the discontinuity occurs at an interior point is Exercise 3.) Let
 and choose the point  with . Since f  is continuous on
 there is a partition of this interval, , with
. If ,
then

By (3.1.4) .
Now assume that f  is continuous on  except for the points
. Pick points  in  such
that  and each subinterval  contains  but
 when . Hence Claim 3.1.9 implies  for
. By Proposition 3.1.6, f  is Riemann integrable on .
â 
With the last theorem we have a large supply of integrable functions. In Â§3.5
below a necessary and sufficient condition for Riemann integrability is presented,
but the preceding theorem covers the cases we will see in the rest of this
book. Now it is time to develop some of the properties of an integrable
function.

3.1.10. Proposition. If , then the following hold.
(a)  If  for all x in , then


(b)  If  for all x in , then
 
 


Proof. (a) From the definition of the upper sum we have that for any
 partition P, . The result follows from Corollary 3.1.5.
 
(b) Since  for all x in , part (b) follows from
 part (a). â 
 
3.1.11. Proposition.  is a vector space over . Moreover if
  and , then
 


Proof. If , then note that 
 and . Thus for
 any partition P of  we have that
 

It follows from Proposition 3.1.4 that if , then . Now
use Corollary 3.1.5 to find a sequence of partitions  such that each 
is a refinement of  and simultaneously ,
, and . (Supply the details needed.)
From Corollary 3.1.5 (see Exercise 8(a)) we have that

The rest of the proof is Exercise 8(b). â 
Finally we introduce what might be considered as a definition or a convention.
If  and , then
 
â(3.1.12)

Let's also add the agreement that
 
 


In some ways this is unnecessary and follows from the definition of the
 integral. On the other hand we have, at least implicitly, defined everything to do
 with the integral under the assumption that .
 
Exercises

 (1)  If f  is a bounded function on  and P is any partition of , show
 that .
 
 (2)  Prove that  when Q is a refinement of P. (Proposition
 3.1.2(b).)
 
 (3)  Prove (3.1.9) when the discontinuity occurs at an interior point of .
 (Hint: Use Proposition 3.1.6.)
 
 (4) If  is a monotonic function, show that f  is integrable.
 
 (5) If  and  is such that  is
 finite, show that  and .
 
 (6)  Let  be an increasing sequence in  such that 
 and . If f  is a bounded function on  that is integrable on
  for all , is f  integrable on ?
 
 (7) Show that if  is a continuous function,  for all x,
 and , then  for all x in .
 
 (8)  (a) Supply the missing details in the proof of Proposition 3.1.11 needed to
 show that . (b) Show that when  and
,  and .
 
 
 (9)  (a) Show that if , then . (b) Use the identity
  and part (a) to show that if , then
 .
 
 (10)  Using (3.1.12) show that if  and f  is integrable on some interval
 including these three numbers, then .
3.2.  The Fundamental Theorem of Calculus
There are several versions of what people call the Fundamental Theorem of
 Calculus. Here is the most general.

3.2.1. Theorem (Fundamental Theorem of Calculus). If f is a bounded
 Riemann integrable function on  and  is defined by
 


then F is a continuous function. If f is continuous at a point c in ,
 then F is differentiable at c and .
 
Proof. If  for all x in , then for ,
 

So not only is f  continuous, it is a Lipschitz function.
Now assume f  is continuous at c, which we assume is an interior point of the
interval. If  there is a  such that  when
. Thus when ,

By definition  exists and equals . When c is one of the endpoints
of the interval the proof is similar and left to the reader (Exercise 1).
â 
Because of its frequent use in the rest of the book, we refer to this result as
well as its corollary below as the FTC. The function  is called the
 
 indefinite integral of f . It is also sometimes referred to as the anti-derivative of f ,
 though that is a moniker that comes from the following consequence of the preceding
 theorem.
 
3.2.2. Corollary. If  is a continuous function and F is
 its indefinite integral, then F is a continuously differentiable function
 on  and . Equivalently, if  is a continuously
 differentiable function and , then .
 
Proof. The first statement in the corollary is immediate from the
 theorem. For the second we note that if G is the indefinite integral
 of , then , so  is the constant function. Thus
 . â 
 
We can use the FTC to calculate several integrals.
 
3.2.3. Example. (a) If , then . In
 fact,  (2.2.6), so this is immediate from the FTC.
 
(b)  and .
 
(c) To find , note that , where
  and . So the Chain Rule and the FTC imply
 that .
 
We now apply the FTC to obtain other important results. 

3.2.4. Theorem (Mean Value Theorem). If  is a continuous
 function, then there is a point c in  such that
 


Proof. Define  as the indefinite integral of f . By the
MVT for derivatives (Theorem 2.3.4) there is a point c in  with
. By the Fundamental Theorem this
finishes the proof. â 


3.2.5. Theorem (Change of Variable Theorem). Suppose 
is a continuously differentiable function and I is an interval such that
. If  is a continuous function, then


Proof. Define  as the indefinite integral of f :


By the FTC, . Hence the Chain Rule implies
. Again applying the FTC we have
that

 â 
 
The preceding result will be referred to as the COV Theorem, which, of
 course, is used in integration by substitution. 

3.2.6. Example. Consider the integral . If
 
 for , then  maps  onto
  (Why?). So the COV Theorem implies
 .
 This example emphasizes the importance of correctly placing the limits of
 integration  and  and using (3.1.12).
 

3.2.7. Theorem (Integration by Parts). If f and g are two continuously
 differentiable functions on , then
 


Proof. This is one of the easiest
 proofs of a result labeled as a theorem. Just apply the FTC to obtain that
. â 
In calculus this is presented as one of the many techniques of integration. It is
much more than that and is a basic tool of analysis.
Exercises

(1) Prove the Fundamental Theorem of Calculus when the point c is an
endpoint of .
 
(2) Find  where .
 
(3) Evaluate the following. (a) . (b) .
 
(4)If f  is a continuously differentiable function on  such that  and
 for all x in , show that  on .
 
(5)Compute the following integrals. (a) . (b) . (c)
.
 
(6)For any continuous function , show that



(7) If f  is infinitely differentiable on  and , show that
 
 

(Hint: Use integration by parts.)
3.3.  The Logarithm and Exponential Functions
In this section we introduce the logarithm of a positive number, study the
 properties of the associated function, and explore its inverse, the exponential
 function. The logarithm we study is often called the natural logarithm so as to
 distinguish it from the logarithm to base , which will be introduced
 later.
 
3.3.1. Definition. If , define
 


This is called the logarithm of x and the function  is
 also called the logarithm function or sometimes the log function.
 
We note that many people use the notation  instead of , which
 they reserve for the logarithm to base . This seems more understandable
 when these notions are used in an algebra course. The only use I know for the
 logarithm to base 10 is in performing calculations, a virtue that seems outdated
since the advent of computers. The natural logarithm is truly natural, as its
definition shows, while the others are somewhat artificial. Hence we use  as
the natural logarithm.

3.3.2. Theorem. The logarithm function has the following properties.
(a)  The logarithm function is differentiable and .
(b)  ,  when , and  when
.
(c)  If , then  and .
(d)  The logarithm function is a strictly increasing function that is a
bijection between the interval  and the entire real line .
Proof. (a) This follows immediately from the FTC.
(b) It's clear that  and when  the integral
defining  integrates a strictly positive function. When ,
 (3.1.12).
(c) Fix a in  and consider the
function . An easy computation (using the
Chain Rule) shows that  for . Hence f  is a constant
function; so for all x, . Therefore , yielding the
first formula. Using this we have that ;
so we have that . Now evaluate  to obtain the
second formula in (c).
(d) By (a),  so it is strictly increasing and hence injective
(2.3.8). Using (c) we have ; since ,
we have that  as . Therefore if , choose n
sufficiently large that . Now consider the log function on the
interval . We have that . Therefore the IVT
implies that there is an x in this interval with . Similarly if ,
there is a point x in the interval  with . Thus the logarithm
is bijective. â 
Since the log function is a bijection from  onto all of , it has an
inverse function from  onto . 

3.3.3. Definition. The inverse of the logarithm function is called the
exponential function and is denoted by .

3.3.4. Theorem. The exponential function has the following properties.
(a)  The exponential function is continuously differentiable and
 
 .
 
(b)  ,  when , and  when
 .
 
(c)  If ,  and .
 
(d)  The exponential function is a strictly increasing function that maps
  bijectively onto .
 
(e)  We have that
 


Proof. As a glance at Theorem 3.3.2 reveals, the parts (a) through (d) in
 this theorem parallel the corresponding ones of that result and are direct
 consequences of the fact that the exponential function is the inverse of the
 log function. The details are left to the reader in Exercise 1. Establishing
 (e) proceeds as follows. Since the exponential is strictly increasing and maps
 onto , we must have that . Similarly we obtain
 the other half of (e). â 
 

3.3.5. Definition. If  and  define
 


First note that this definition makes sense since .
From here we can get the usual laws of exponents by using the previous two
theorems. The details are left to the reader in Exercise 4.

3.3.6. Proposition. If  and , the following hold.
(a)  .
(b)  .
(c)  .
(d)  .
The number x where  is denoted by e. We want to emphasize the following:


So we frequently will write the exponential function as  as does the rest of the mathematical world.
The next definition is possible because both the logarithm and exponential functions are bijective. 

3.3.7. Definition. If , we define  to mean that .
The proof of the next result is left to the reader (Exercise 5).

3.3.8. Proposition. If , the following hold.
(a)  .
(b)  .
(c)  For any a in , .
We return to an examination of the properties of the exponential
function.

3.3.9. Proposition. For any real number a,
 
 


Proof. Observe that proving this result is equivalent to showing that
 


(Why?) Now if , then . Thus
 

 â 
 
The next result says that exponential decay is more rapid that polynomial
 decay.
 
3.3.10. Proposition. For any ,


Proof. Note that the second of these equalities follows from the first by
substituting  for x. The proof of the first equality consists of applying
L'HÃ´pital's Rule n times.


by Theorem 3.3.4(e). â 
In the statement of the preceding proposition we made expicit in the second
equality a variation on the theme of the first. There are many other variations
that will be used and we will just refer to this proposition. In particular we'll see
an additional variation in the following example.

3.3.11. Example. If


then f  is infinitely differentiable and  for all .
 To see this put  so that when , .
 By the Chain Rule we have that . Also
 . So (3.3.10) implies that f  is differentiable
 at 0 and .
 
Claim. For every  there is a polynomial  such that when ,
 .
 
This is proved by induction. Just before the statement of the claim we saw
 that the claim holds when . Assume it holds for n and let's prove it for
 . In fact when 

where , a polynomial. This establishes the above
 claim.
 
Claim. For each , .
 
Again we have already shown this for . Now assume that we have that
 . The first claim shows that ,
 and by Proposition 3.3.10 this converges to 0 as .
 
We have seen that . It turns out that, except for multiplying it by
 a constant, the exponential function is the only function that has the property
 that it equals its derivative. The proof is easy.
 
3.3.12. Proposition. If  is a differentiable function such
 that  for all x in , then there is a constant c such that
  on .
Proof. In fact for any x in 


Hence  must be the constant function. â 
 
 
Exercises

 (1)  Give the details of the proof of parts (a) through (d) in Theorem 3.3.4.
 (Hint: use Proposition 2.3.10 to establish (a).)
 
 (2) Let  be defined by . (a) Show that
 . (b) Show that f  is uniformly continuous.
 
 (3) Let  be a continuous
 function that satisfies  for all  in . Show
 that if f  is differentiable at  with , then f  is differentiable
 everywhere and  for all x.
 
 (4)  Prove Proposition 3.3.6.
 
 (5)  Prove Proposition 3.3.8.
 
 (6)  What is ?
 
 (7)  Which is bigger,  or ? (Of course you can answer this with a
 calculator or computer, but try to answer it by an examination of the
 function .)
 
 (8) For each of the following functions f  determine whether 
 is a local maximum, local minimum, or neither. (a) .
 (b) . (c) . (d) . (e)
 .
 
 (9) Evaluate the following. (a) . (b) .
 
 (10) Find the derivative of  when  and .
 
 (11) Let  be the vector space of all functions from  into itself and show
 that any finite collection of functions in  is linearly
 independent.
 
 (12)  If  is defined by


show that f  is infinitely differentiable. Compare this with Example 2.4.4
and ponder this comparison while regarding Proposition 3.3.10.
 
(13)If  is a sequence of positive real numbers such that , show
that .
 
(14) Show that . (Hint: Apply L'HÃ´pital's Rule as expressed
in Exercise 2.5.3 to .)
3.4.  Improper Integrals
When we defined the Riemann integral at the start of this chapter, we did so
only for bounded functions on a closed and bounded interval. We are frequently
confronted with situations where we want to integrate unbounded functions over
intervals that are not bounded, or not closed, or neither. Here we will deal with
such situations, relying on what we know from the previous sections. The
material in this section is influenced by the treatment of this subject in
 
 [15].
 
3.4.1. Definition. Suppose  and . We
 say f  is locally integrable on  if whenever  we have that
 f  is integrable on . Say that f  is integrable or improperly integrable on
  if it is locally integrable on  and
 


exists and is finite. When f  is integrable on  we denote this iterated
 limit as .
 
Let's emphasize that the interval  could be the whole line and that the
 function f  need not be bounded. Because of the fact that f  is assumed to be
 locally integrable, however, it is required that f  is bounded on every closed and
 bounded interval contained in . We'll see many examples below, but the
 first thing we should do is establish that the order of the two limits in the
 definition above does not matter.
 
3.4.2. Proposition. If f is integrable over , then
 


Proof. Pick some arbitrary point x in  and observe that

 â 
Often we will encounter the situation where the difficulty in defining the
integral of f  on  only occurs at one of the endpoints. Consider the
following.

3.4.3. Proposition. If  and  is a
function that is integrable on , then


The proof is Exercise 1.
We record here several facts about integrable functions whose statements and
proofs are similar to the corresponding facts about integrable functions on closed
and bounded intervals. The proofs are left to the reader's discretion.

3.4.4. Proposition. If  and , the
following hold.
 
 
(a)  If  and f is integrable both on  and , then f is
 integrable on  and 
(b)  If f and g are integrable functions on  and , then
  is integrable and .
 
The next result could easily be called the Comparison Test for improper
 integrals.
 
3.4.5. Proposition. If f and g are functions defined on  such that
  for all x in  and g is integrable on , then f is
 integrable on  and
 


Proof. Let , temporarily fix c, and
 define ; it follows that  whenever
 . Moreover because the functions f  and g are positive, F and
 G are increasing. Hence their limits exist as , and we have that
 . To complete the proof
 a similar argument can be used when we let . â 
 
In analogy with infinite series we say that  is absolutely
 integrable when  is integrable.
 
3.4.6. Proposition. If  is absolutely integrable, then f is
 integrable and


Proof. Note that  for all x in  and use the
preceding proposition. â 

3.4.7. Example. (a) The integral  converges if and only if .
First note that when  we have that  as ,
so the
integral diverges. We assume that . Let  and consider
. Let . When , this converges
to ; when , this diverges to . Note that since  is positive
on , it is absolutely integrable if and only if .
(b) . Since we intend to
use the substitution  over an interval involving both positive
and negative numbers, it is expeditious to split the integral as
. Now making the substitution in the
second of these integrals gives


Treating the first integral similarly we get

Therefore  is integrable on  and .
 
(c) . Now , which
 has no limit as . Hence the sine function is not integrable on
 .
 
(d) Note that  for every c since . Hence
 . However  is not integrable on  as an argument
 similar to that used in (c) shows. This provides a cautionary note that as we did
 in (b) we must use the definition of an improper integral and cannot take
 shortcuts without justification.
 
(e)  converges. In fact  on , so that the
 statement follows by Proposition 3.4.6.
 
(f)  is integrable. In fact let . Since the function is
 continuous here it is integrable over any bounded interval in . Using
 integration by parts we get
 


By the preceding example,  is integrable. It is not, however,
 absolutely integrable. See Exercise 6.
 

3.4.8. Theorem (Integral Test). If  is a non-negative
function that is decreasing, then the series  converges if and
only if the function f is integrable on .
Proof. Because f  is non-negative and decreasing, 
when
 and so . Thus if the series
converges, then , and so f  is integrable. If the
function is integrable, then . â 
 
 
3.4.9. Example. The series  converges if and only if . In
 fact this follows by using the Integral Test and Example 3.4.7(a). Recall that
 when  this series is called the harmonic series and diverges (1.4.3).
 For other values of p it is called the harmonic p-series. 
Exercises

 (1)  Prove Proposition 3.4.3.
 
 (2)  For which values of p do the following integrals converge?
 


 (3)  Show that  converges. (Hint: First show that 
 on .)
 
 (4)  Justify the statements made in Example 3.4.7(d).
 
 (5)  Use integration by parts to show that  for every integer
 .
 (Note that this necessitates combining integration by parts with improper
 integrals.)
 
 (6)  Show that  is not integrable over . (Hint: Note that


and evaluate.)
 
(7)Show that  exists and determine its value.
 
(8)Is  integrable over ?
 
(9)Show that the product of two improperly integrable functions is not always
improperly integrable.
 
(10)Let  be locally integrable positive functions and assume
 exists and satisfies . Show that if the
improper integral of g exists on , then the improper integral of f  exists
on .
 
(11)(a) If f  is integrable over  and  exists, show that this
limit must be 0. (b) If f  is integrable over , show by example that
 may not exist.
3.5.  Sets of Measure Zero and Integrability
In this section we will give a necessary and sufficient condition for a bounded
function on a closed and bounded interval to be Riemann integrable. This
condition is phrased using a concept that has widespread use in a more general
setting.
3.5.1. Definition. A subset E of  has
measure zero if for every  there is a sequence of intervals 
such that  and
 
 


The quantity  is the length of the interval , so the definition
 of a set E of measure zero is that E can be covered by a sequence of intervals the
 sum of whose lengths is as small as desired. Note that the inequality  can be
 replaced by . It's clear that  has measure zero, and here are some more
 examples.
 
3.5.2. Example. (a) Any
 finite set has measure zero. In fact if , then the intervals
  work.
 
(b) Any sequence has measure zero. If  is given, then the sequence
 of intervals  will work.
 
(c) Sets of measure zero can be very large in a certain sense. For example
 , the set of rational numbers, has measure zero. In fact by Corollary 1.5.5,
  is countable so it is possible to arrange  as a sequence and it follows
 from (b) that  has measure zero.
 
From these examples it becomes clear we will use some of the material from
 Â§1.5, so the reader has to be familiar with countable sets.
 
3.5.3. Proposition. If  is a sequence of sets of measure zero, then
  has measure zero.
 
Proof. If  and , let  be a sequence of open
 intervals covering  and satisfying . It follows
 that  is countable and can be written as a sequence.
 Moreover . â 
 
To prove the main result of this section we need to introduce an additional concept.
 If  and , define . It
 will be useful as we progress to observe that if , then . If
 , define the oscillation of f  at x to be


(The interested reader can compare this with Exercise 1.7.14.) Note that
when x is not an endpoint we can write


So  measures how much the values of f  vary as points get closer to x
(and hence its name). It is not difficult to see that if  is
defined by letting  when  and , then
.
Keep in mind that we have two types of oscillation for a function: one for
intervals and one for points. The pertinence of the oscillation for integrability can
be seen in the following.
3.5.4. Proposition. If  is a partition
of  and , then


Proof. If , then it is easy to verify that ,
 where  and . From here
 the proposition follows. â 
 
The next result gives some basic properties of the oscillation. Particularly
 notice the last part.
 
3.5.5. Proposition. If , the following hold.
 
(a)  For any ,  is open unless it contains one
 of the endpoints of . If it contains an endpoint it contains a half-open
 interval that includes that endpoint.
 
(b)  For any ,  is closed.
 
(c)  The function f is continuous at x if and only if .
 
Proof. The proof of (a) when the set contains an endpoint is similar to
 that of the statement when it contains no endpoints and is left to the reader
 (Exercise 1). So assume that  and fix x in G. By
 definition there is a  such that
 .
 Now for any y in  let  such that
 ; we see that . Therefore
 ; that is , and so G is open. Part (b) follows
 since .
 
To prove (c) assume f  is continuous at x and . Thus there is a
  such that  when . This says that
 .
 Since  was arbitrary, . Conversely, assume  and
 let . By definition this implies there is a  such that
 . That is  when . â 
 
Given the basic criterion for integrability (3.1.4) as well as the relationship
 between oscillation and the continuity of f  at a point we just established, the
 statement of the next theorem might be less surprising. 

3.5.6. Theorem (Lebesgue's2
Theorem). A bounded function  is integrable if and only if
its set of discontinuities has measure zero.
Proof. Suppose  is a function with  for all x in
 and let D denote its set of discontinuities. By Proposition 3.5.5(c),
; for each  let . Assume
f  is Riemann integrable; we must show that D has measure zero. The
reader can check that , so by Proposition 3.5.3 we will
be successful if we show that each set  has measure zero. Fix 
and let . From Proposition 3.5.4 we have the existence of a partition
 such that


If , then for each j in J we have that
. (Verify!) Hence


But  contains  except possibly for some subset of the
 endpoints of these intervals, which has at most  points. Since each of
 these points can be included in an interval of length less than 
 and  was arbitrary, we have that  has measure zero.
 
Now assume that D has measure zero. Let ; so  has measure
 zero. (As we see what we need, we will take t to be a multiple of
 an arbitrary .) Note that  is closed and bounded by Proposition
 3.5.5(b). Because of this and the fact that  has measure zero we
 can find a finite number of open intervals  such
 that  and . By replacing any two
 of the closed intervals  that intersect with their
 union, we can assume that these closed intervals are pairwise disjoint. Put
 . Note that X is closed and bounded. Moreover,
 since  is the complement in  of the union of a finite number of open
 intervals, X itself is the union of a finite number of pairwise disjoint closed
 intervals.
 
Observe that  for each x in X. Therefore for each x in X there is a
 closed interval  with x in  and such that . Since X is
 compact there are a finite number of closed intervals whose union contains X and
 
such that each satisfies this inequality. By intersecting these intervals with X
and using the fact that X is itself the union of a finite number of closed
intervals, we obtain closed intervals  having the following
properties:

(When we say the intervals "do not overlap" in (iii), we mean they can only
intersect at their endpoints. How do we get (iii)?) Put  for
.
Because of our construction we have that the closed intervals  are a
collection of non-overlapping intervals whose union is all of . Therefore
their endpoints form a partition ; thus
. In additon we have that

If we are given , we can choose  such that  and
so we have that f  is Riemann integrable by Proposition 3.1.4. â 
Exercise

 (1)  Prove Proposition 3.5.5(a) under the assumption that the set contains one
 of the endpoints.
3.6.  The Riemann-Stieltjes Integral
For a fixed closed, bounded interval  we want to define an extension of
 the Riemann integral. This extended integral will also assign a number to each
 continuous function on the interval.
 
3.6.1. Definition. A function  is of bounded variation if there is
 a constant M such that for every partition 
 of J,
 


The quantity
 


is called the total variation of  over J.
We'll see many examples of functions of bounded variation. The first below is
specific and the other two contain collections of such functions.

3.6.2. Example. (a) The "mother of all" functions of bounded variation is
.
(b) Suppose  is a smooth function and M is a constant
with  for all t in . If , then
for each j the Mean Value Theorem for derivatives says there is a point
 in  such that . Hence
, so that  is
of bounded variation.
(c) Any increasing or decreasing function is of bounded variation.
Also see the Exercises.
For any interval  let  denote the set of all functions of bounded
variation defined on . The proof of the next proposition is left to the
reader.

3.6.3. Proposition.  is a vector space over , where the
algebraic operations on these functions are defined pointwise.
In light of the preceding proposition any linear combination of increasing
functions is a function of bounded variation. The surprising thing is that the
converse holds.

3.6.4. Proposition. If  is a function of bounded variation,
then we can write , where  are increasing functions.
Proof. Let
 and . It is
clear that , so what we have to do is show that these functions
are increasing. Let , , and let  such that
. Now it is easy to verify that
 
 


(Note that we are not allowed to randomly make a choice of sign each time
  appears; it must be consistent.) Since  is a partition of
 , we get that
 

Since  is arbitrary, we have that 
 and so the functions  are increasing. â 
 
Now that we have discussed functions of bounded variation, gotten many
 examples, and discovered a structure of such functions (3.6.4), we might pose a
 question.
 
 Why the interest? 
The important thing for us is that we can define integrals or averaging
 processes for continuous functions by using a function of bounded variation.
 These integrals have geometric interpretations as well as applications to the
 study of various problems in analysis. Let's define the integrals, where the reader
 will notice a close similarity with the definition of the Riemann integral. Indeed if
  is the increasing function , then what we do below will result in the
 Riemann integral over J even though we will bypass the upper and lower sums
 for a partition. (This is because here we will only integrate continuous functions.
 )
 
If  is a function in ,  is some function, and P is a
partition, define


where the points  are chosen in the subinterval . Yes, the
notation does not reflect the dependency of this sum on the choice of the
points , but I am afraid we'll just have to live with that; indicating
such a dependency is more awkward than any gained benefit. When the
function  is the special one, , let . That is,


Define the mesh of the partition P to be the number
, and for any positive number  let 
denote the collection of all partitions P with . From the proof of
Theorem 3.1.7 in the continuous case, it is seen that when  is a
continuous function, then there is a unique number  such that for every
 there is a  with  whenever .
In fact, a look at that proof shows this follows from the fact that f  is
uniformly continuous. (Verify!) We now start the process of showing that a
similar existence result holds if we replace the Riemann sum 
by the sum  for an arbitrary function of bounded variation
.
 
 
Here is another bit of notation that will simplify matters. For  and a
 function , the modulus of continuity of f  for any  is the
 number . (Compare this with the
 definition of the oscillation of a function defined in the preceding section and
 Exercise 1.7.14.) This will be infinite for some functions, but the main place we
 will use it is when X is a closed and bounded interval and f  is continuous. In
 that case f  is uniformly continuous so that we have that for any  there is a
  such that .
 
Just as in the definition of the Riemann integral, we want to define the
 integral of a function with respect to a function of bounded variation . Here is
 the crucial lemma to get us to that goal.
 
3.6.5. Lemma. If  is a function of bounded variation on J and
  is a continuous function, then for any  there is a 
 such that  whenever .
 
Proof. We start by observing that when  are two partitions and
 Q is a refinement of P, then . (Imitate the proof
 of the appropriate part of Proposition 3.1.2.) In light of the preceding
 observation and using the same reasoning as in the proof of (3.1.2) it suffices
 to prove that there is a  such that when  and , then
 .
 
Use the uniform continuity of f  to find a  such that .
 Assume that  and that they belong to . To simplify matters we will
 assume that Q adds only one point to P and that this point lies between
  and . That is, we assume 
 and . Now for ,
 let , , .
 Note that
 

We therefore obtain

An inspection of the preceding argument shows that if Q had added more than a
single point to P, then the same reasoning would prevail and yielded the same
result. â 
It is important to emphasize that the value of the inequality obtained in the
preceding lemma is independent of the choices of transitory points  in
 that are used to define . This amply justifies not
incorporating them in the notation used to denote such a sum.

3.6.6. Theorem. If  is a function of bounded variation on J and
 is a continuous function, then there is a unique number I with
the property that for every  there is a  such that when ,


The number I is called the Riemann3-
Stieltjes4
integral of f with respect to , is denoted by


and satisfies
 


Proof. According to the preceding lemma, for every integer  there
 is a  such that if , . We can
 choose the  so that they are decreasing. Let  be the closure of
 the set of numbers . If  for all x in J,
 then for any partition P, . So each set  is
 bounded and hence compact. Since the numbers  are decreasing, for all
   and so . Finally by the choice of the ,
 . Therefore by Cantor's Theorem (Theorem 5.5.3 in
 the next section)  for a single number I. It is now routine
 to verify that I has the stated properties; its uniqueness is guaranteed by
 its construction. â 
 
A standard example comes, of course, when  for all t in J and this is
 the Riemann integral. The proofs of the next two results are left to the reader as
 a way of fixing the ideas in his/her head. These results should not come as a
 surprise.
 
3.6.7. Proposition. Let  and  be functions of bounded variation on
 J,  continuous functions, and .
 
(a)  .
(b)  If  for all x in J and  is increasing, then .
(c)  .

3.6.8. Proposition. If  is a function of bounded variation on J, f is a
continuous function on J, and , then
.
Here is an important result that enables us to compute some Riemann-Stieltjes
integrals from what we know about the Riemann integral.

3.6.9. Theorem. If  is a function on J that has a continuous derivative
at every point of J, then


for any continuous function f.
Proof. We already know from Example 3.6.2 that such a function is of
bounded variation, so everything makes sense. Fix a continuous function f 
on J, let , and choose  such that simultaneously


whenever . Momentarily fix  in .
 For each subinterval  defined by P, the MVT for derivatives implies
 there is a  in this subinterval with .
 Therefore
 

Since  was arbitrary, we have the desired equality. â 
 
We now introduce some special increasing functions whose role in the general
 theory has significance in spite of their simplicity.
 
3.6.10. Example. Fix s in J. When , define
 


and
 


Each of these functions is increasing. Let  and choose
 such that  whenever  and
also such that  when . Assume .
(A separate argument is required when  and this is left to
the reader. See Exercise 6.) Choose a P in  that contains s
and let  be the point in P that immediately follows s. Using
 as the point in  at which to evaluate f, a moment's
reflection reveals that . Thus
.
Since  was arbitrary we have that


for every continuous function f  on J. Similarly,  for all
such f .
Using the preceding example we can calculate the integrals with respect to
many functions that only differ from a continuously differentiable one by having
jump discontinuities. Consider the following.

3.6.11. Example. Define  by  for  and
 for . What is  for f  in ? Note that
, where  is defined in the preceding example. So using
Proposition 3.6.7(c) and Theorem 3.6.9 we get

We want to spend a little time studying functions of bounded variation. We
 begin with the following.
 
3.6.12. Proposition. If  is a function of bounded variation,
 then  has at most a countable number of discontinuities.
 
Proof. By Proposition 3.6.4 it suffices to show that the conclusion holds for
 increasing functions. Hence the result now follows from Proposition 2.1.9. â 
 
A function  is called left-continuous at c if the left limit  exists and
 is equal to . The definition of right-continuous is analogous. If 
 theh the left limit of  at a doesn't really make sense, but we will define
 . Similarly, . So every function  on J is
 left-continuous at a and right-continuous at b by default. Note that if ,
 the function  (3.6.10) is left-continuous at s; however,  is not
 left-continuous at b.
3.6.13. Corollary. If  is increasing and we define 
 by , then  is an increasing function that is left-continuous
 everywhere, has the same discontinuities as  on , and agrees with
  except possibly at its discontinuities.
 
Proof. It is clear that  is increasing and left-continuous at each point of
 J. If c is a point of discontinuity of , then . If
 , then since there are points of continuity for  that approach c from
 the right, we have that  and  is discontinuous at
 c. If , then , so that  is continuous at b
 irrespective of whether  is continuous at b. (See the function  defined
 in Example 3.6.10.) â 
Note that the integral of a continuous function with respect to a constant
function is 0; hence  for all continuous functions f . There
are other ways that we can produce two functions of bounded variation that yield
the same integral. (Compare the function defined in Exercise 3 with the
functions in Example 3.6.10.) We want to examine when  for
two fixed functions of bounded variation and for every continuous function f  on
J.
For a function of bounded variation  on J and , define
 
â(3.6.14)

where  is defined in Example 3.6.10. Call  the normalization of . The
first thing to observe is that  except at the points where
 is discontinuous. Also if  is increasing, so is its normalization. Furthermore,
if , then . Therefore  is also a function
of bounded variation. Finally note that if  is continuous at b, then
.

3.6.15. Proposition. If  is a function of bounded variation on J
and  is its normalization, then  for every continuous
function f on J.
Proof. We split this into two cases.
Case 1.  is continuous at b.
Let D be the set of points in J where  is discontinuous - a
countable set. Here ; fix  and f  in . Let
 such that  and 
whenever . Since D is a countable set in , we can choose
 in  such that  for .
We have by definition
 
 


and
 


For ,  and so
 . Since , we also have ;
 thus  for .
 That is, . Therefore . Since 
 was arbitrary, this proves Case 1.
 
Case 2.  is discontinuous at b.
 
Here . Consider the function
 . It follows that  is continuous at
 b since . By Case 1, .
 Moreover since  for all t in J, including ,
 it follows that . Now
 .
 After canceling we get that . â 
 
The converse of the above result holds. To be precise, if  and  are two
 functions of bounded variation on the interval J, then  for
 every continuous function f  on J if and only if . The proof of this
 requires more advanced techniques and can be found in [3], Proposition
 4.5.3.
 
Exercises
We continue to assume that  unless the interval is otherwise
specified.

(1)Show that a function of bounded variation is a bounded function.
 
(2)Show that the function  is not of bounded variation.
 
(3) Define  on the unit interval  by  and 
when . Observe that  is neither left nor right-continuous
at . Show that  is of bounded variation and find increasing
functions  such that . Compute  for an
arbitrary continuous function f  on the unit interval. Are you
surprised?
 
(4) If  is an increasing function on J such that  for every
continuous function f  on J, show that  is constant. Contrast this with
Exercise 3. (Hint: First show that you can assume that , then
show that  must be continuous at each point of J. Use Example 3.6.10.
Now show that  is identically 0.)
 
(5) Give the details of the proof of Proposition 3.6.7

(6) If  is defined as in Example 3.6.10, show that  for every
continuous function f  on J.
 
(7) Suppose a left-continuous increasing function  has a
discontinuity at  and . Let  be the increasing
function defined as in Example 3.6.10:  for  and
 for . (Once again if  is the right-hand endpoint of J,
a separate argument is required.) (a) Show that  is an increasing
function that is continuous at . (b) Show that any left-continuous
increasing function  on J can be written as , where both
 and  are increasing,  is continuous, and  has the property that if
 is continuous on the open subinterval , then  is constant there.
 
 
 (8)  If  is an increasing function with the property of  in Exercise 7,
 calculate  for any continuous function f  on J.
 
 (9)  If A is any countable subset of J, show that there is an increasing function
  on J such that A is precisely the set of discontinuities of . (So, in
 particular, there is an increasing function on J with discontinuities at all
 the rational numbers in J.)
 
 (10)  Let  denote the set of all rational numbers in the interval J and
 define  by  where the sum is taken over all n such
 that . (a) Show that  is a strictly increasing function that is
 left-continuous and satisfies  and . (b) Show that  is
 continuous at each irrational number and discontinuous at all the rational
 numbers in J.
 
 (11)  If  is an increasing function, discuss the possibility of defining 
 when f  has a discontinuity.
 
 (12)  Suppose  is an increasing function. Is it possible to define
  for a continuous function ?
1Georg Friedrich Bernhard Riemann was born in 1826 in Breselenz, Germany. His early schooling was
closely supervised by his father. When he entered the university at GÃ¶ttingen in 1846, at his father's
urging he began to study theology. Later, with his father's blessing, he switched to the Faculty of
Philosophy so he could study mathematics. In 1847 he transferred to Berlin where he came under the
influence of Dirichlet, which influence was permanent. He returned to GÃ¶ttingen in 1849 where he
completed his doctorate in 1851, working under the direction of Gauss. He took up a lecturer position
there and in 1862 he married a friend of his sister. In the autumn of that same year he contracted
tuberculosis. This began a period of ill health and he went between GÃ¶ttingen and Italy, where he sought
to recapture his health. He died in 1866 in Selasca, Italy on the shores of beautiful Lake
Maggiore. Riemann is one of the giants of analysis and geometry. He made a series of significant
discoveries and initiated theories. Besides this integral there are many other things named
after him, including the Riemann zeta function, Riemann surfaces, the Riemann Mapping
Theorem.
2Henri LÃ©on Lebesgue was born in 1875 in Beauvais, which is in the Picardie region of France just
north of Paris. He began his education in Beauvais and entered the Ãcole Normale SupÃ©rieure in Paris in
1894, where he was awarded the teaching diploma in mathematics in 1897. He remained there for two
years, reading mathematics in the library. In 1899 he went to Nancy as a professor at a lycÃ©e where he
remained for another two years. In 1901 he formulated the theory of measure in a ground
breaking paper that defined what we now know as the Lebesgue integral. This formed the
basis of his doctoral dissertation and earns him the title of the father of measure theory. The
present theorem is important for us, but does not top the list of his most important results. In
1902 he joined the faculty at the University of Rennes in Brittany. He married in 1903 and
he and his wife had two children. Unfortunately, the union ended in divorce in 1916. He
published two fundamental monographs, LeÃ§ons sur l'intÃ©gration et la recherche des fonctions
primitives in 1904 and LeÃ§ons sur les sÃ©ries trigonomÃ©triques in 1906. These books were unjustly
criticized at the time by the classicists. Nevertheless he joined the faculty at the University of
Poitiers and finally overcame his critics before joining the faculty at the Sorbonne in 1910. In
1921 he became Professor of Mathematics at the CollÃ¨ge de France and held this position
until he died in 1941. Lebesgue received many honors throughout his life and made serious
contributions in many areas, but he will forever be associated with measure theory and its impact on
analysis.
3See Definition 3.1.3 for a biographical note.
4Thomas Jan Stieltjes was born in 1856 in Zwolle, The Netherlands. He attended the university
at Delft, spending most of his time in the library reading mathematics rather than attending
lectures. This had the effect of causing him to fail his exams three years in a row and he left the
university without a degree. (This phenomenon of talented people having trouble passing exams
is not unique and examples exist in the author's personal experience.) The absence of a degree
plagued the progress of his career, in spite of the recognition of his mathematical talent by some
of the prominent mathematicians of the day. In 1885 he was awarded membership in the Royal
Academy of Sciences in Amsterdam. He received his doctorate of science in 1886 for a thesis on
asymptotic series. In the same year he secured a position at the University of Toulouse in France.
He did fundamental work on continued fractions and is often called the father of that subject.
He extended Riemann's integral to the present setting. He died in 1894 in Toulouse, where he is
buried. 












4 Sequences
of
Functions
In this chapter we present some basic results in analysis that are used throughout
the theory and its applications. We also start a process of increased sophistication
that eventually migrates to thinking of functions as points in a larger space. As the
reader progresses, (s)he will notice a similarity between various aspects of our discussion of sequences of functions
and sequences of real numbers. This similarity is no coincidence as the next chapter in this book will reveal.
4.1.  Uniform Convergence
In this section we discuss a notion of convergence for sequences and series of
functions.

4.1.1. Definition. If  is a sequence of functions from a subset X of
 into , say that converges uniformly to a function f  if for every
 there is an N such that  for all x in X and all
. In symbols this is written as  on X. 
In other words,  if for every  it is possible to find an N such
that  when , where the same N works for all x at the
same time. We are interested in examining the properties of functions that are
preserved under taking uniform limits. That is, if  on X and
each  has some property, does f  have this same property? We'll see
several examples of this shortly. There is, of course, another notion of
convergence of a sequence of functions on a subset X of . Namely, we could
investigate what happens when  for every x in X. This is
called pointwise convergence. This has some value but not as much as
uniform convergence, as we'll see below in Example 4.1.7 as well as in some
of the exercises. Observe that when , pointwise convergence
follows.

4.1.2. Example. (a) Suppose  and  is defined by
. Since  for all x in  and , we have
that  converges uniformly on  to the constantly zero function.
See Exercise 1.
(b) If  and  is defined by , then
 on X. In fact if  is any sequence of functions on any
subset X in  such that there is a constant M with  for all
x in X, and  is a sequence of real numbers converging to 0, then
 on X.
(c) If  and , then for each x in
, where f  is the function defined by  when
 and . In this case  does not converge uniformly
to f . This can be shown directly (Exercise 3), but an easier way is to use
what is contained in Example 4.1.7 below.
The next result is often useful in showing that a sequence of functions
converges uniformly.

4.1.3. Proposition. If , and  are three sequences of
functions on X such that  for all x in X and there
is a function  such that  and  on X, then
 on X.
Proof. Let
 and choose N such that  and 
for all x in X and all . It follows that for each x in X and all ,
. Hence 
for all x in X and . By definition, . â 
The preceding proposition is often called the Squeeze Principle or Sandwich
Principle. It is actually what is happening in Example 4.1.2, parts (a) and (b).
Here is another use of the Sandwich Principle.

4.1.4. Example. Define  by . Note
 
 that  on . So if we let  and
 , we have that for all ,  on
 . By the preceding proposition,  uniformly on .
 
4.1.5. Proposition. Let . If  is a sequence of bounded
 functions on X that converges uniformly to a function , then
 f is a bounded function and the sequence of functions  is uniformly
 bounded; that is, there is a constant M such that  for all x in
 X and all .
 
Proof. Let N be such that  for all x in X and
 all . If  is a number such that  for all
 x, then for each x in X, .
 Hence f  is a bounded function. Note that if  and ,
 then . If  and
  for all x in X, put . It follows
 that  for all x in X and all . â 
 
Also see Exercise 6.
 
4.1.6. Theorem. Let . If  is a sequence of bounded continuous
 functions on X and  on X, then  is a continuous
 function.
 
Proof. Fix an arbitrary point a in X; we want to show that f  is
 continuous at a. If , then by uniform convergence we can choose
 an integer n such that  for all x in X. Since 
 is continuous there is a  such that  when
  and . Thus for any x in X with ,
 .
 By definition, f  is continuous at a. â 

4.1.7. Example. If the functions  are as in Example 4.1.2(c), the fact
 that the limit function f  is not continuous shows, in light of the preceding
 result, that  does not converge uniformly on  to f .
 
4.1.8. Theorem. Let . If  is a sequence of bounded uniformly
continuous functions on X and  on X, then  is a
uniformly continuous function.
Proof. This proof is similar to the proof of the preceding result but with a
critical difference. If , then by the uniform convergence we can choose
an integer n such that  for all x in X. Since  is
uniformly continuous, there is a  such that 
whenever . Thus for  we have that
.
By definition, f  is uniformly continuous on X. â 

4.1.9. Theorem. If  is a sequence of bounded integrable functions on
the interval  and , then f is integrable and


Proof. By Proposition 4.1.5 there is a constant M such that  for all x
in  and all . If , then by the uniform convergence we can find an
integer N such that  for all x in  and all .
Temporarily fix an . Since  is integrable there is a partition
 with . Let
 and . Since
 for all x, it follows that 
for . (Verify!) Thus . Similarly
. Therefore

and so f  is integrable. By Proposition 3.1.4, . Similarly
 . Hence
 

Since n was an arbitrarily fixed integer greater than N, this implies .
 â 
 
It is a bit unfortunate that uniform convergence has no respect for
 differentiability as it did for integrability in the preceding theorem. See
 Example 4.1.11 below. Here is the best we can do.
 
4.1.10. Proposition. If  is a sequence of continuously differentiable
 functions on ,  on , and there is a function
  such that  on , then f is continuously
 differentiable and .
 
Proof. This
 is a consequence of the FTC. Note that ; also note
 that Theorem 4.1.6 implies that g is a continuous function on . By
 the preceding theorem,  for every x in . By hypothesis,
 this implies that . Again using the FTC,
 we have that f  is differentiable and . â 
 
4.1.11. Example. (a) For each  define  by
 . It is easy to see that  on . However
, so that  does not converge uniformly even though
the limit function of the original sequence is continuously differentiable.
(b) Examine the sequence of functions  on  in
Example 4.1.4. This shows that when a sequence  of continuously
differentiable functions converges uniformly, it does not follow that the limit
function is differentiable.
Exercises

(1) Let  and suppose there is a real number  with 
for all x in X and each . Show that if , then .
 
(2) Find a sequence of bounded functions  on  and a function
 such that  for all x in , but where f  is
not a bounded function.
 
(3) Using only the definition of uniform convergence, show that the sequence
 in Example 4.1.2(c) does not converge uniformly to f .
 
(4)Let  be a continuous function with . Show that
 uniformly on .
 
(5) Say that  is a uniformly Cauchy sequence on a subset X of  if
each  is bounded and for every  there is an integer N such that
 for all x in X and all . (a) Show that if
 is a uniformly Cauchy sequence, then there is a constant M such that
 for all x in X and all . (b) Show that if  is a
uniformly Cauchy sequence on X, then there is a function  such
that  on X.
 
(6) If ,  on X, and f  is a bounded function, show that
there is a constant M and an integer N such that  for all x in
X and all .
 
(7) For each  let  be a continuous function
with  and assume that ; also assume that
 is a continuous function. If for each ,  on
, show that .
4.2.  Power Series
We start with a definition that is a bit more general than the topic of this
 section.
 
4.2.1. Definition. If  and for each  there is a function
 , then say that the series of functions  converges
 uniformly on X if the sequence of partial sums  converges
 uniformly on X.
 
The reader can go through the last section and state and prove a collection of
 results about series of functions. For example if each function  is
 continuous on X and  converges uniformly on X, then f 
 is a continuous function on X. We will use such results as we proceed
 without reference. Instead we will present one result that implies uniform
 convergence and then proceed with the development of power series.
 

4.2.2. Theorem (Weierstrass1
 M-Test). Let  and for each  suppose  and
 there is a constant  with  for all x in X. If 
 converges, then  converges uniformly on X.
 
Proof. Put  and let . By Proposition 1.4.5 we
 can choose N such that  whenever .
 If  and , then for every x in X,
  for .
 This says that the sequence  is a Cauchy sequence in .
 Thus  exists and defines a function . Now
 . So if x is any point in
 X and , we have that .
 If we hold m fixed but larger than N and let , this shows that
  for all x in X and all . That is,  on
 X. â 
 
Now we come to the focus of this section.
 
4.2.3. Definition. If , a power series about the point c is an infinite
series of the form


where  is some sequence of real numbers.
We note two things about a power series. First, the infinite sum begins with
. This is no big deal and, indeed, some power series will begin the sum
with . Just be conscious of this. Second is the "center" of the power series,
c. If we translate the center to another number, we don't change any of the
convergence properties of the power series except for those that involve the
center. Thus the basic properties of a power series depend more on the
coefficients  than the center. In fact many proofs about an arbitrary power
series will be proved under the assumption that , and many examples will
have . An example of a power series about 0 is the geometric series (1.4.4),
in which case each . Another is the series  (1.4.15),
where . The first result we prove about power series is the
fundamental fact that will form the basis for all that follows on this
topic.

4.2.4. Theorem. For a given power series  define the
extended real number R, , by


(a)  If , the series converges absolutely.
 
(b)  If , the series diverges.
 
(c)  If , the series converges uniformly on .
 
(d)  R is the unique number having properties (a) and (b).
 
Proof. Without loss of generality we may assume that .
 
(a) and (b). Note that .
 Thus both (a) and (b) follow by the Root Test (1.4.12).
 
(c) If , then . By (b), 
 converges, so the Weierstrass M-Test implies  converges
 uniformly for x in .
 
(d) This is routine and left to the reader. In fact it is more of an
 observation than a result. â 
 
The number R obtained in the last theorem is called the radius of convergence
of the power series.
 
4.2.5. Example. (a) The radius of convergence of the geometric series is
  since each coefficient .
 
(b) The power series  has radius of convergence .
 To see this it is better not to use the formula for R. Instead we invoke
 Example 1.4.15 where it is shown as a consequence of the Ratio Test that
 the series converges for all x in . By part (d) of the theorem, .
 
(c) Here is an example that says you have to be a little careful when
 using the Ratio Test to determine the radius of convergence. Consider the
 series
 


Because there are "gaps" in the powers of x we cannot apply the Ratio
Test directly. If however we let , we get the series .
Now we can use the Ratio Test and we get that


So the original power series converges when  and so the radius
of convergence is . See Exercise 1.

4.2.6. Theorem. Assume the power series  has positive
radius of convergence . If  is defined by
, then the following hold.
(a)  The function f is infinitely differentiable, and for  and

 
â(4.2.7)
(b)  The radius of convergence of the power series (4.2.7) is also R.
 
(c)  For every 


Proof. Begin by observing that part (c) is an immediate consequence of (a). To
 prove (a) and (b) we again assume that  and start by establishing the
 following.
 
Claim. .
 
Put  equal to the the reciprocal of the  in the claim so that 
 is the radius of convergence of the power series .
 Notice that . Hence when  we have
 that . By the uniqueness of the
 radius of convergence this shows that . On the other hand, if
 , then . Hence
 , establishing the claim.
 
If (a) and (b) are established for , then, by applying them to the power
 series , we will obtain (a) and (b) for . By repeating this we
 arrive at the validity of (a) and (b) for an arbitrary . So to prove (a) and
 (b) we can restrict our attention to the case where . We start this by
 showing that . Now L'HÃ´pital's rule shows that
 . Hence . By
 Exercise 1.3.16 and the claim, ,
 giving (b).
 
To get (a) when  define the functions , and  on the interval
  by


(The definition of g is valid by part (b).) Fix a number y with ;
we want to show that  exists and . Choose r with
 and let  be arbitrary except that .
(Later in this proof we will impose an additional restriction on .) Let
. For any integer  (this integer will be specified later) we can
write

Let . We want to show that if we take  sufficiently small and n
sufficiently large, we can make each of the summands on the right side of the
preceding inequality less than . This will prove that f  is differentiable and
. The most cumbersome of these three terms to handle is the last,
so let's tackle it first. For any choice of n

But
 
 


so that
 


Now since , (b) implies that  converges. Thus there is an
 integer  such that for all  and for any x in the interval ,
 


Now  is just the sequence of partial sums of the series . So there
 is an integer  such that when , .
 
Let . (So we have now fixed n.) Because  is a
 polynomial and differentiable, there is a  such that


when . (Be aware that the choice of  depends on the fixed value
of n.)
With these choices we have that


when . This completes the proof of (a) and of the theorem.
â 
4.2.8. Example. (a) Theorem 4.2.6 says that when a function is defined
by a power series it is infinitely differentiable. The converse of this is
not true. In fact in Example 3.3.11 we saw that the function defined by
 when  and  is infinitely differentiable on
 with  for all . By (4.2.6(c)) we have that this function
cannot be written as a power series centered at .
(b) The function  can be written as a power series. In fact


This can be seen as follows. In Example 4.2.5(b) we saw that this power
 series has radius of convergence . If  denotes this power series,
 then Theorem 4.2.6 implies
 


By Proposition 3.3.12 there is a constant c such that . Since
 , this constant c must be 1.
 
When we know that a function can be represented as a power series, this gives
 us additional power. In fact Theorem 4.2.6 can be phrased as saying that the
 derivative of a power series is obtained by differentiating the individual terms of
 the power series. (This is often referred to as differentiating term-by-term.)
 Also since the convergence of the power series is uniform on any closed
 interval contained in , Theorem 4.1.9 says we can find the
 integral of this function over this interval by integrating the terms of the
 series. Since simply being infinitely differentiable does not guarantee the
 representation as a power series, we seek a criterion to show that such a function
 can be so represented. The primary tool for this is Taylor's Theorem
 (2.5.6).
 
4.2.9. Theorem. Let  and suppose . If there is a
 constant M such that  for all x in  and all ,
 then for any c in 


and this power series has radius of convergence R with
.
Proof. Let , and for each  let


By Taylor's Theorem (2.5.6) for each x in  there is a point
d between c and x such that


By the hypothesis this implies
 
 


Now an application of the
 Ratio Test reveals that  converges (Verify!) and so the n-th
 term . Therefore  whenever ,
 and so f  has the power series expansion with radius of convergence at
 least r. â 
 
The preceding theorem won't cover all cases, but it will cover many that are of
 interest. Let's look at a few.
 
4.2.10. Example. (a) The function  has the power series expansion
 


The even
 derivatives of the sine function are , so that  for all
 . The odd derivatives are , so that  for all
 . Thus we can apply the preceding theorem with . The exact
 coefficients that appear in the above power series are determined by finding
 the correct formula for . The reader can fill in the details.
 
(b) The function  has the power series expansion
 


See Exercise 6.
(c) The natural logarithm has the power series expansion


and the radius of convergence is 1. Note that here we are finding the power
series expansion centered at . A small induction argument shows that
when  and 


So  cannot be bounded as required in Theorem 4.2.9. We have to do
something different. Here we have that for 

Now the geometric series under the integral sign converges uniformly on
 , so Theorem 4.1.9 implies
 


Since this convergence holds when , we have that . Since
  is not defined at , it must be that .
 
Exercises

 (1)  Show that if we have a power series  with radius of convergence
 R and if  exists, then the value of this limit is R.
 
 (2)  Find the
 radius of convergence of the following: (a) ; (b) ; and
 (c) .
 
 
(3)Find the radius of convergence of the following: (a) ;
(b) , where a is some positive constant; and (c)
.
 
(4)Show that the radius of convergence of the power series


is 1 and discuss convergence of the series when .
 
(5)Find the radius of convergence of the power series



 (6)  (a) For Example 4.2.10(a), find the precise formula for . (b) Fill
 in the details needed to verify Example 4.2.10(b).
 
 (7)  Fill in the details to obtain Example 4.2.10(c).
 
 (8)  If  and , show that f  can be represented as a
 power series in an interval about c if and only if there is an  with
  such that  when .
1See the footnote to Theorem 1.3.11 for a biographical note. 












5 Metric
and
Euclidean
Spaces
In this chapter we begin the study of p-dimensional Euclidean space, ,
but in this beginning we will carry it a step further. We want to discuss
differentiation and integration on , but first we need to extend the notions of
sequential convergence, the properties of sets, and the concept of continuity
to the higher dimensional spaces. The effort to explore these concepts
in , however, is not greater than what is required to explore these
notions in what are called metric spaces. In many respects the abstract
spaces are easier to cope with than . Moreover some of what we have
already done is properly couched in metric spaces. Indeed, the material of
Â§4.1 can be set there with little additional effort. Nevertheless during
this venture into abstraction the main set of examples will be Euclidean
space.
We start with the concept of distance between points. This must be general
enough to encompass a variety of circumstances, but it should conform to the
intuitive notion we all have of what is meant by distance. Since this is done at
the start of the first section, it would be profitable before proceeding for the
reader to reflect on what properties (s)he thinks should be included in an
abstract concept of distance; then you can compare your thoughts with the
definition that starts the following section.
The treatment of metric spaces here is based on Chapter 1 of [4].
 
5.1.  Definitions and Examples
5.1.1. Definition. A metric space is a pair of objects, , where X is a
set and d is a function  called a metric, that satisfies
the following for all  in X:
(a)  ;
(b)   if and only if ; and
(c)  (Triangle Inequality) .
Condition (a) is sometimes called the symmetric property and says that the
distance from x to y is the same as the distance from y to x. The second
property says the obvious: the distance from a point to itself is 0 and the
only point at a distance zero from x is x itself. The third, the triangle
property, says that the shortest distance between two points is the direct
one - not a distance involving a third point. In  this is phrased by
saying that the shortest distance between two points is a straight line. In
the abstract setting we have no concept of straight lines. Though you
might have thought of other properties for an idea of distance, these
three are usually part of what most people intuitively associate with
the concept. In fact, I think the properties above are the minimal ones.
There are several particular situations where additional axioms for a
distance are assumed; those are more specialized theories, and what we are
now going to explore is the basic one. Here are some examples of metric
spaces.

5.1.2. Example. (a) Let , the set of real numbers, and define
. See Exercise 1.
(b) Let , the plane, and
define . The reader knows
from the Pythagorean Theorem that this is the straight-line distance and
(s)he can use geometry to verify that this standard notion of the distance
between two points satisfies the axioms in the preceding definition.
(c) We define p-dimensional Euclidean space, , to be


For  and  in , define 


This is a metric on ; however to prove this satisfies the triangle
 inequality requires some effort that we'll do below (5.1.6).
 
(d) Let  and for  in  define
 


This is also a metric on  but it is easier to verify this than the previous
 example (Exercise 2).
 
(e) Again let  and now define
 


Once again  is a metric space (Exercise 3). It is worth observing
that in each of the last three examples, when , all these metrics are
the standard absolute value on .
(f) Let X be any set and define


It is a simple exercise to verify that  is a metric space. This is
called the discrete metric on X. You won't encounter this much except in
the study of metric spaces, as it is a nice example to test the concepts.
(g) An important class of examples arise as follows. Suppose  is
a given metric space. If Y  is a non-empty subset of X, then  is a
metric space and is referred to as a subspace. As a specific instance of this
we can take  and . We saw this often in  and will see
this often in  when we consider subsets of Euclidean space and examine
them as metric spaces.
The next result will be quite useful in our discussion of metric spaces. It is a
direct consequence of the triangle inequality and is often called the Reverse
Triangle Inequality. 

5.1.3. Proposition. If  is a metric space and , then


Proof. The triangle inequality implies that .
 Now reverse the roles of x and z in this inequality and we
 get that , from which we also have that
 . That is,  from
 which the proposition follows. â 
 
Now let's show that the function d given in Example 5.1.2(c) is a
 metric. To do this we need a famous inequality. To facilitate the proof,
 introduce the helpful notation that for vectors  and
  in , . Actually this is more
 than just "helpful" notation as it denotes the inner or "dot" product in
 the vector space . This connection will not be explored here, where
 we will only regard this as notation. Of course some of you may have
 explored the inner product in linear algebra. It is useful to observe the
 following properties for all vectors  in  and all real numbers
 t.
 
 
â(5.1.4)


5.1.5. Theorem (Cauchy1-Schwarz2
Inequality).  For  and  in  we have



Proof. First note that using the inner product notation introduced above,
the sought after inequality becomes


Using (5.1.4) we have that

where . Thus  is a quadratic polynomial in
 the variable t. Since  for all t, the graph of  stays above
 the x-axis except that it might be tangent at a single point; that is,
  has at most one real root. From the quadratic formula we get that
 . Therefore
 


proving the inequality. â 
 
5.1.6. Corollary. If  is defined as in
 Example 5.1.2(b), then d is a metric.
 
Proof. We begin by noting that . Using the
 Cauchy-Schwarz Inequality, (5.1.4), and the vector space properties of  we
 get that
 

Taking square roots shows that the triangle inequality holds. The remainder
 of the proof that d defines a metric is straightforward. (Verify!) â 
 
Notice. Whenever we are discussing  we assume that the metric
 under consideration is that defined in Example 5.1.2(c).
We close with the following, whose proof is Exercise 5.

5.1.7. Proposition. If  and  are two metric spaces and we
define the function  by


then  is a metric on .
 
 
Exercises

 (1)  Verify the statement in Example 5.1.2(a).
 
 (2)  Verify the statement in Example 5.1.2(d).
 
 (3)  Verify the statement in Example 5.1.2(e).
 
 (4)  In the Cauchy-Schwarz Inequality, show that equality holds if and only if
 the vectors x and y are linearly dependent.
 
 (5)  Prove Proposition 5.1.7.
5.2.  Sequences and Completeness
For the remainder of this chapter  is a given metric space.
 
Now that we have a generalization of the concept of distance, we can
 introduce convergent sequences. As in Chapter 1, a sequence is just a way of
 enumerating some points in the space X: ; this is denoted by .
 Precisely, this is a function from the natural numbers  into X: . As
 when we discussed sequences of real numbers, we'll sometimes change the domain
 of this function to  so that we get a sequence ; or maybe it
 might be changed to get . There is no real difference; we
 have a specific beginning and a countably infinite following. This means
 that the set of all integers, , is not permitted as an indexing set for
 sequences.
 
Unlike when we considered sequences in  we have no concept of an interval
 so we cannot use the definition of convergence we used in . Instead we
 use the generalization of the equivalent formulation from Proposition
 1.3.3.
 
5.2.1. Definition. A sequence  in converges to x if for every
  there is an integer N such that  when . The
 notation for this is  or .

5.2.2. Example. (a) A sequence in  converges in the sense of Â§1.3 if and
only if it converges in  considered as a metric space. (This is the content
of (1.3.3).)
(b) If  and  are in , then 
if and only if  in  for . In fact if , then we
need only note that for ,  to conclude that
. Now assume that  for . Let  and for
 choose  such that  when . If we
put  and , then


Hence  for  and we have that  in .
(c) If  is the discrete metric space, then a sequence  in
X converges to x if and only if there is an integer N such that 
whenever . In words, a sequence in X converges if and only if it is
eventually constant.
As in , if  is a sequence in  and  is a
sequence of positive integers with , then  is
called a subsequence of . As we saw in Proposition 1.3.10, if
a sequence in  converges to x, every subsequence converges
to x. Unlike  it makes no sense to talk of monotonic sequences in an abstract
metric space. So the results proved in Â§1.3 about monotonic sequences have no
analogy here. A concept from our study of  that had little significance there,
however, will have great significance now, though its true prominence will not
arise until Â§5.3.

5.2.3. Definition. A sequence  in  is called a Cauchy sequence
if for every  there is an integer N such that  when
. The discrete metric space  is said to be complete if every
Cauchy sequence converges.


5.2.4. Example. (a) As in , every convergent sequence in  is a
 Cauchy sequence in (Exercise 2).
 
(b)  is a complete metric space (1.3.13) as is  (Exercise 3).
 
(c) If we furnish  with the metric it has as a subspace of , then it is
 not a complete metric space. In fact just take a sequence  in  that
 converges to  in . It is a Cauchy sequence in  but does not
 converge to a point in .
 
(d) The discrete metric space is complete. Indeed a sequence in the
 discrete metric space is a Cauchy sequence if and only if it is eventually
 constant.
 
5.2.5. Proposition. If  is a Cauchy sequence and some subsequence
 of  converges to x, then .
 
Proof. Suppose  and let . Choose an integer  such that
 
 for , and choose an integer  such that  when
 . Put  and let . Fix any .
 Since we have that  and both n and  are larger than , we
 get that . â 
 
Exercises

 (1) Suppose  is a sequence in X that converges to x and  is
 a finite collection of points in X. Define a new sequence  in X by
 letting  for  and  when . Show
 that .
 
 (2)  Verify the statement in Example 5.2.4(a).
 
 (3)  Show that  is complete. (Hint: Use the method in Example 5.2.2(b) to
 show that a sequence in  is a Cauchy sequence if and only if each of the
 sequences of its coordinates is a Cauchy sequence in .)
 
 (4)  Show that a sequence  in  (see Proposition 5.1.7)
 converges to  if and only if the same thing happens when we consider
the sequence as belonging to .

(5) Let  be the cartesian product of the two metric spaces  and
 as in Proposition 5.1.7. (a) Show that a sequence  in
X is a Cauchy sequence in X if and only if  is a Cauchy sequence in
 and  is a Cauchy sequence in . (b) Show that X is complete
if and only if both  and  are complete.
5.3.  Open and Closed Sets
As we did for  in Â§1.6, we define open and closed sets in a metric space. In an
abstract metric space these sets will play an even bigger role than they did in
.

5.3.1. Definition. A subset F of  is said to be closed if whenever
 is a sequence of points in F and  we have that . A
subset G is said to be open if  is a closed set.
Again we note that as in the case that , the entire space X and the
empty set are simultaneously open and closed; also any finite subset of  is
closed. Also see Exercise 1. The first two parts of the next proposition are
restatements in the case of  of the first two parts of Proposition 1.6.3. The
exact same proof used to demonstrate (1.6.3) can be used word for word to prove
these. The other two parts of the next proposition are analogous to the last two
parts of Proposition 1.6.3 with one big difference. Unlike when we discuss
open and closed subsets of  we need to talk about arbitrary unions
and intersections of sets, not just their countable versions. Here are the
definitions.
Suppose I is an arbitrary non-empty set, sometimes called in this
circumstance an index set, and assume that for each i in I there is a subset 
of X. We define the union and intersection of the collection 
by

These operations satisfy the customary rules enjoyed by their finite versions. In
 particular, there is a version of De Morgan's Laws that is valid (Exercise 2).
 

5.3.2. Proposition. Let  be a metric space.
 
(a)  If  are closed sets in , then  is closed.
 
(b)  If  are open sets in , then  is open.
 
(c)  If  is a collection of closed sets, then  is closed.
 
(d)  If  is a collection of open sets, then  is open.
 
Proof. As we said the proofs of (a) and (b) are verbatim copies of the proofs
 of the similar statements for . The proofs of (c) and (d) are similar to
 the proofs for the analogous statements for sequences of sets in  given in
 Proposition 1.6.3. The details are left to the reader. â 
 
When  and , introduce the notation
 

The set  is called the open ball of radius r about x, or centered at x;
  is called the closed ball of radius r about x. If , then 
 is the open interval  and  is the closed interval
 . If , then  is the so-called "open" ball or disk
 centered at x of radius r that does not include the bounding circle; and
  is the corresponding "closed" disk that does include the bounding circle.
 The use of the words open and closed here will be justified momentarily.
 Meanwhile notice the trivial but useful observation that when ,
 .
 
The next result is a restatement of Proposition 1.6.4 for an arbitrary metric
space. Small modifications of the proof of (1.6.4) will furnish a proof of the
present result.

5.3.3. Proposition. A subset G of  is open if and only if for each
x in G there is an  such that .
The preceding proposition quantifies what it means for a set to be open and as
such is most useful as we will see.

5.3.4. Example. (a) For any ,  is closed. In fact let  be
a sequence in  that converges to a.
Thus . Since , we
have that .
(b) For any ,
 is open. In fact let .
If  is a sequence in F that converges to a, then the reverse triangle
inequality implies . Since 
we have that
.
 It is important when discussing open and closed sets 
 to be conscious of the universe. 
When  is a metric space and , we have that  is also
a metric space (Example 5.1.2(f)). To say that we have an open set
A in  does not mean that A is open in X. Note that in such a
circumstance when  and , then the open ball about y of radius r is
. This may not be an open set in
X. For example if  and , then  is open as a subset of Y 
but not as a subset of X; another example: . When we want
to emphasize the open and closed sets in the subspace metric ,
we'll use the terms open relative to Y  or relatively open in Y  and closed
relative to Y  or relatively closed in Y . The proof of the next proposition is
Exercise 3.

5.3.5. Proposition. Let  be a metric space and let Y be a subset
of X.
(a)  A subset G of Y is relatively open in Y if and only if there is an open
subset U in X with .
(b)  A subset F of Y is relatively closed in Y if and only if there is a
closed subset D in X such that .
Now to introduce certain concepts that had little significance when we
 
 studied  but will have importance for  as well as any other metric
 space.
 
5.3.6. Definition. Let A be a subset of X. The interior of A, denoted by
 , is the set defined by
 


The closure of A, denoted by , is the set defined by
 


The boundary of A, denoted by , is the set defined by
 


Let's note that there is always an open set contained in any set A -
 namely the empty set, . It may be, however, that  is the only open set
 contained in A, in which case . Similarly X is a closed set
containing any set A; but it may be the only such set, in which case
. (We'll have more to say about this latter case below.) It
follows from what we have established that  is open (though possibly
empty) and  is closed (though possible equal to X). We also have that
 and . Before looking at more interesting
examples, it is profitable to first prove some properties of the closure and
interior of a set. We start with a characterization of these sets using open
balls.

5.3.7. Proposition. Let .
(a)   if and only if there is an  such that .
(b)   if and only if for every , .
(c)   if and only if for every  we have that 
and .
Proof. (a) If , then since  is open we have that
; hence . Now assume that . So there is
an open set G such that . But since G is open, there is a radius
 with  and we have established the converse.
(b) Suppose . If , then  is open and 
is closed. It cannot be that  since, by definition, this
implies , contradicting the fact that . Thus
. Now assume that ; that is, , an
open set. By Proposition 5.3.3 there is a radius  such that
. So for this radius, .
(c) This is immediate from (b). â 
The preceding proposition is very useful as it provides a concrete,
one-point-at-a-time method to determine the closure and the interior of a set.
We'll see this in the following example.
5.3.8. Example. (a) Sometimes things can become weird with interiors and
closures. Consider the metric space  and the subset  of all rational
numbers. If , then  and this interval must
contain a rational number. By the preceding proposition, . We also
have that . To see this again use the preceding proposition and
the fact that between any two real numbers there is an irrational number.
This means that when , no open ball  can be contained in
 so that . Using the same reasoning we see that 
and . (Verify!) It follows that .
 
 
(b) Here is a cautionary tale. Since  is closed, we have that
 . It may be, however, that . In
 fact suppose that . So X consists
 of the origin in the plane together with the unit circle centered at the
 origin. Give X the metric it inherits as a subset of . In this case
 . It is also true that when X
 is the discrete metric space, then  whereas
 .
 
(c) We haven't said much about the boundary of a set, but note that for
 any x in  and 
 we have that . Is this true in
 every metric space? (Exercise 5).
 
The next proposition contains some useful information about closures and
 interiors of sets. Its proof is left as Exercise 6.
 
5.3.9. Proposition. Let A be a subset of X.
 
(a)  A is closed if and only if .
 
(b)  A is open if and only if .
 
(c)  , , and .
 
(d)  If  are subsets of X, then .
 
Part (d) of the preceding proposition does not hold for the interior.
 For example if , , , and , then
  while . Also see Exercises 7
 and 8.
 
5.3.10. Definition. A subset E of a metric space  is dense if
 . A metric space  is separable if it has a countable dense
 subset.
 
We made a reference to this concept just after defining the closure of a set. So
 a set E is dense if and only if X is the only closed subset of X that contains
 E.
 
5.3.11. Example. (a) Every metric space is dense in itself.
 
(b) The rational numbers form a dense subset of  as do the irrational
 numbers. This is a rephrasing of Example 5.3.8(a). We note that this implies
 that  is separable since  is countable (1.5.5).
 
(c)
 The set of all points in  with rational coordinates is dense in . This
 follows from the preceding example and it also says that  is separable by
 Corollary 1.5.6.
(d) If X is any set and d is the discrete metric on X (5.1.2(e)), then
the only dense subset of X is X itself. In fact if E is a dense subset of
 and , then it must be that ; but from the
definition of the discrete metric it follows that . Hence the
discrete metric space is separable if and only if it is countable.
In part (d) of the preceding example we used the next result, and we record it
here for future reference. Also it is a consequence of Proposition 5.3.7(b).

5.3.12. Proposition. A set E is dense in  if and only if for every
x in X and every , .

5.3.13. Definition. If , a point x in X is called a limit point of A if
for every  there is a point a in  with .
See Exercise 1.6.11, where this concept was defined in .
The emphasis here is that no matter how small we take  we can find such a
point a different from x that belongs to . It is not required that x
belongs to  for it to be a limit point (more on this later). If x is not a limit
point of A and, in addition, belongs to A, then it is called an isolated point of
A.

5.3.14. Example. (a) Let  and . Every point in
 is a limit point of A but 2 is not. In fact, 2 is an example of an isolated
point of A, the only isolated point of A.
(b) If  and , then every point of X is a limit point of A
and A has no isolated points.
(c) If  and , then 0 is a limit point of A while
the points  are all isolated points.

5.3.15. Proposition. Let A be a subset of the metric space X.
(a)  A point x is a limit point of A if and only if there is a sequence of
distinct points in A that converges to x.
(b)  A is a closed set if and only if it contains all its limit points.
(c)  .
Proof. In Exercise 1.6.11 the reader was asked to prove parts (a) and (b)
when .
(a) Suppose  is a sequence of distinct points in A such that
. If , then there is an N such that  for .
 
 Since the points in  are distinct, there is at least one different from
 x. Thus x is a limit point. Now assume that x is a limit point. Let
  such that . Let ; so there
 is a point  with . Note that .
 
Claim. There
 is a sequence of positive numbers  and a sequence of distinct points
  in A such that: (i) ; (ii)  for all ; and (iii)
 .
 
We already have . Assume that  have been chosen. Since the
 numbers  are all positive we can choose 
 and also smaller than any of these numbers. Let  with
 . This proves the claim and finishes the proof of (a).
 
(b) and (c). Clearly (b) will follow once we prove (c). Let B denote the
 set on the right-hand side of the equation in (c). By the definition of a
 closed set and part (a) we have that . On the other hand, if
 , (5.3.7) implies that for every  there is a point  in A
 with . Either  has an infinite number of distinct
 terms or a finite number. In the first case there is a subsequence 
 of distinct terms; by (a), x is a limit point. Thus . In the case
 that  has only a finite number of points, there is a subsequence
  that is constant; thus  for all  and so .
 â 
 
5.3.16. Definition. If  and , the distance from x to A is
 


Clearly when , . But it is possible for the distance
 from a point to a set to be 0 when the point is not in the set as we now
 see.
 
5.3.17. Proposition. If , then .
Proof. If , then there is a sequence  in A such that ;
so  and it follows that . Conversely
if , then there is a sequence  in A such that
. Thus  and so . â 
Also see Exercise 14. Now we extend Cantor's Theorem (1.6.8) to the setting
of a complete metric space. First we need to extend the definition of the diameter
of set from that given in Â§1.6 to the setting of a metric space; a little thought will
show this is the natural extension. If , define the diameter of E to
be


5.3.18. Theorem (Cantor's Theorem). A metric space  is complete
if and only if whenever  is a sequence of non-empty subsets satisfying:
(i) each  is closed; (ii) ; and (iii) , then
 is a single point.
Proof. Assume  is complete and  is as in the statement of
the theorem. For each n let . If , let N be such that
 for . So if , (ii) implies  and
so . Thus  is a Cauchy sequence. Since
 is complete, there is an x in X such that . But each 
is closed, so . If there is another point y in , then
 for each . By (iii), .
Now assume that  satisfies the stated conditions and  is
a Cauchy sequence. Put . Clearly (i) and (ii) are
satisfied. If , let N be such that  for . But for
, . Thus  satisfies
the three conditions so that  for some point x. But for
 
 any , . Therefore  and  is
 complete. â 
 
Notice that we did not state this extension as we did Theorem 1.6.8. What
 happens in the preceding version of Cantor's Theorem if we do not assume
 ? See Exercise 16.
 
The proof of the next proposition is Exercise 17.
 
5.3.19. Proposition. If  is a complete metric space and ,
 then  is complete if and only if Y is closed in X.
 
We close this section by dwelling a bit on the concept of the diameter of a
 set.
 
5.3.20. Definition. Say that a subset A of  is bounded if
 .
 
5.3.21. Proposition.
 
(a)  A subset A of  is bounded if and only if for any x in X there is
 an  such that .
 
(b)  The union of a finite number of bounded sets is bounded.
 
(c)  A Cauchy sequence in  is a bounded set.
 
Proof. (a) If , then , so that A is bounded.
 Conversely assume that A is bounded with  as its finite diameter.
 Fix a point x in X and some point  in A. For any point a in A,
 . If we let ,
 then .
 
(b) If  is bounded for  and ,
 let  such that . If we set , then
 .
 
(c) If  is a Cauchy sequence, there is an  such that
  for . If , this says that
  so that B is bounded. On the other hand, 
 is bounded since finite sets are bounded. By part (b),  is
 bounded. â 
 
The concept of boundedness in an arbitrary metric space is not as useful as
 it was in  and does not have the same consequences. We will see,
 however, that the benefits of boundedness we had in  carry over to
 .
Exercises

(1) Show that the following
sets F are closed. (a) . (b)
. (c) .
 
(2) Prove the following version of De Morgan's Laws for any collection of subsets
, where each :


 (3)  Prove Proposition 5.3.5. (Hint: If G is a relatively open subset of Y ,
 for each y in G let  such that . Now consider
 .)
 
 (4)  If Y  is a subset of X, consider the metric space  and suppose .
 (a) Show that H is a relatively open subset of Z if and only if there is a
 relatively open subset  of Y  such that . (b) Show that
 D is a relatively closed subset of Z if and only if there is a relatively
 closed subset  of Y  such that . (Hint: Use Proposition
 5.3.5.)
 
 (5)  Is it true that  in an arbitrary
 metric space?
 
 (6)  Prove Proposition 5.3.9.
 
 (7)  Show that if  are subsets of X, then .
 
 (8)  Show that (5.3.9(d)) does not hold for infinite unions and the preceding exercise
 does not hold for infinite intersections.
 
 (9) If  and , show that x is either an isolated point of E or a limit
 point.
 
 (10)  If A is a subset of X that is simultaneously open and closed, show that
 .
 
 (11)  See Corollary 1.5.6 for the definition of . Define 
 by
 

(a) Show that  is a metric on . (b) Show that a set G is open
 in  if and only if for every  in G there are open
sets  in  and  in  such that , , and
.
 
(12) Let  denote the set of all bounded sequences of real numbers; that is, 
consists of all sequences  such that  for all  and
. If , define .
(a) Show that d defines a metric on . (b) If  denotes the sequence with a
1 in the n-th place and zeros elsewhere, show that 
when . (c) Is the set  closed?
 
(13) Show that the metric space  defined in Exercise 12 is complete.
 
(14) If , show that . Can you give an
analogous characterization of ?
 
(15) (a) If , show that  if and only if x is either a limit point of A or
an isolated point of A. (b) Show that if a set has no limit points, it is
closed. (c) Give an example of an infinite subset of  that has no limit
points.
 
(16) If  is a complete metric space, show that if  is a sequence of
bounded closed subsets of X satisfying (i) and (ii) in Cantor's Theorem, then
.
 
(17) Prove Proposition 5.3.19.
5.4.  Continuity
Here we will extend the concept of a continuous function seen in Chapter 1 to a
mapping between two metric spaces and investigate the properties of such
functions.
5.4.1. Definition. If  and  are two metric spaces, a function
 is continuous at a point a in X if whenever  is a sequence
in X that converges to a,  in Z. f  is said to be a continuous
function if it is continuous at each point of X
Note that if , then this is the same as the definition of continuity
found in Â§1.7. The most common situation we will encounter in the remainder of
 
 this book is where X is a subset of  and . To establish results in
 such situations, however, requires no more effort than to prove them in the
 setting described in the definition. The next few results should have a familiar
 ring from Â§1.7.
 
5.4.2. Proposition. If  and  are metric spaces and
 , then f is continuous at a if and only if for every  there
 is a  such that when  it follows that .
 
Proof. Suppose
 f  is continuous at a and, to the contrary, there is an  such that for
 every  there is at least one x with  and .
 In particular taking  we have that for every  there is an 
 with  and . But this says that 
 and  does not converge to , contradicting the assumption of
 continuity.
 
Now assume that for every  there is a  as stated in the
 proposition. If  in X, and , let  such that when
  it follows that . Let N be an integer such that
  when . So  when . Since
  was arbitrary, this says that  and f  is continuous at a. â 
 
Let's mention that the previous result is often taken as the definition of a
 continuous function. It is this equivalent formulation of continuity that
 generalizes to more abstract structures than a metric space.
 
We won't spend any time investigating functions continuous at a single
 point, but we will have much to say about functions continuous on the
 entire metric space, especially when that metric space is some subset of
 .
 
5.4.3. Theorem. If  and  are metric spaces and ,
 then the following statements are equivalent.
 
(a)  f is a continuous function on X.
 
(b)  If U is an open subset of Z, then  is an open subset of X.
 
(c)  If D is a closed subset of Z, then  is a closed subset of X.
 
Proof. (b) is equivalent to (c). Note that


From these equalities the equivalence of the two statements is
straightforward.
(a) implies (b). Let  so that . Since U is
open there is an  such that . Since f  is continuous
there is a  such that  implies . In other
words, . Since a was an arbitrary point in
, this says that  is open.
(b) implies (a). If  and , then  is open; so by
(b) we have that  is an open set in X that contains a. Thus
there is a  such that . That is, 
implies  and so f  is continuous at a. â 
See Exercise 5. The next result extends Proposition 1.7.4 to the present
setting. The same proof given there applies here as the reader will see when (s)he
does a step-by-step process of translation.

5.4.4. Proposition. The composition of two continuous functions is also
continuous.
The proof of the next proposition is elementary.

5.4.5. Proposition. If  is a metric space,  are
continuous, and , then:
(a)   defined by  is
continuous;
(b)   defined as  is continuous; and
(c)  the function from X into  defined by  is
continuous.
Now to generate some examples of continuous functions. Of course Â§1.7
furnishes several examples of continuous functions from the real line into
itself. We also have the trigonometric functions, the exponential, and
logarithm.


5.4.6. Example. (a) The function from  defined by
  (vector addition) is continuous.
 
(b) The function from  defined by  (scalar
 multiplication) is continuous.
 
(c) If  is a continuous function for , then
  defined by  is a continuous function.
 (Exercise 7(b)).
 
(d) If  is a continuous function for , then
  defined by  is a continuous function.
 (Exercise 7(c)).
 
(e) If  is any metric space, , and we define  by
 , then f  is continuous. In fact the reverse triangle inequality
 (5.1.3) says that , from which continuity follows by
 either the definition or Proposition 5.4.2.
 
(f) If  is the discrete metric space, then the only continuous
 functions from  into  are the constant functions. On the other
 hand, for any metric space  every function  is
 continuous.
 
(g) Consider , , and integers .
 The function  defined by  is
 continuous. (Exercise 7(e)).
 
Recall the definition of the distance from a point to a set A, 
 (5.3.16).
 
5.4.7. Proposition. If  is a metric space and , then
 


for all  in X.
 
Proof.
 If , ; so taking the infimum over all a in
A we get .
Reversing the roles of x and y we have ,
whence we get the inequality. â 

5.4.8. Corollary. If A is a non-empty subset of X, then  defined
by  is a continuous function.
In the next proof we'll use the preceding results to construct continuous
functions with specified behavior.

5.4.9. Theorem (Urysohn's3
Lemma). If A and B are two disjoint closed subsets of X, then there is a
continuous function  having the following properties:
(a)   for all x in X;
(b)   for all x in A; and
(c)   for all x in B.
Proof. Define  by


which is well-defined since the denominator never vanishes (Why?). It is
easy to check that f  has the desired properties. â 
Don't be fooled by the simple proof; the result is powerful. We did
a lot of work before this theorem to be able to concoct such a simple
proof.

5.4.10. Corollary. If F is a closed subset of X and G is an open set
containing F, then there is a continuous function  such that
 for all x in X,  when , and  when
.
 
 
Proof. In Urysohn's Lemma, take A to be the complement of G and
 . â 
 
Now we extend the concept of a uniformly continuous function to the metric
 space setting. The definition is just a transliteration of the definition in the case
 of .

5.4.11. Definition. A function  between two metric
 spaces is uniformly continuous if for every  there is a  such that
  when .
 
5.4.12. Example. (a) We also extend the concept of a Lipschitz function.
 A function  is a Lipschitz function if there is a constant
  such that  for all  in X. A ready
 collection of examples occurs by letting I be an interval in  and letting
  be a continuously differentiable function with 
 for all x in I. Thus .
 As we saw in Proposition 1.7.14, every Lipschitz function is uniformly
 continuous and the same is true for functions on a metric space.
 
(b) We note that when , the function  is a
 Lipschitz function by Proposition 5.4.7. Thus the distance function gives rise
 to a plentiful source of uniformly continuous functions on any metric space.
 
Exercises

 (1)  Let  and  be metric spaces, , , and let
 a be a limit point of A. Say that  if for every  there
 is a  such that  when . Fix the set
 A and its limit point a. (a) If , show that f  is continuous at a if
 . (b) Show that  if and only if for
 every sequence  in A that converges to a we have that .
 
 (2)  If  is a metric space,  is continuous at a with
 , and  is a function satisfying  for
some constant M and all x in X (but not necessarily continuous), then fg
is continuous at a.
 
(3) If  is continuous, A is a dense subset of X, and 
such that  for every a in A, show that  for every x in
X.
 
(4) If  is both continuous and surjective and A is a dense
subset of X, show that  is a dense subset of Z.
 
(5) Prove the equivalence of (b) and (c) in Theorem 5.4.3 by using only the
sequential definition of continuity.
 
(6) In Theorem 5.4.3, give an independent proof that shows that conditions (a)
and (c) are equivalent. (Here, "independent" means that the proof should
not use the equivalence of (a) and (b) or of (b) and (c).)
 
(7) (a) Prove the statements made in parts (a) and (b) of Example 5.4.6.
(b) Prove (5.4.6(c)). (Hint: Write the function as the composition of
continuous functions.) (c) Prove (5.4.6(d)). (d) Prove the statement made
in Example 5.4.6(f). (e) Prove (5.4.6(g)).
 
(8)If  is defined by


where is f  continuous?
(9) If f  and g are continuous functions from  into  prove
that  and  are
continuous. (See Proposition 1.7.11.)
 
(10) Is the composition of two uniformly continuous functions a uniformly
 
 continuous function?
 
 (11)  Note that Proposition 5.4.5 says that if  is a metric space and we
 define the collection of all continuous functions  by , then
  is a vector space over . Show that  is a finite dimensional
 vector space if and only if X is a finite set. (Hint: use Urysohn's Lemma.)
 
 (12)  Let  be a metric space and let  denote the set of all uniformly
 continuous functions from X into . (a) If , show that
 . In words,  is a vector space over . (b) If , show
 by an example that it does not necessarily follow that . If, however,
 the functions are also bounded, then . (A function 
 is bounded if  is a bounded subset of Z.) (c) Can you give some
 conditions under which the quotient of two functions in  is uniformly
 continuous?
 
 (13)  Is the function  defined in Example 5.4.6(g) uniformly continuous?
 
 (14)  If  are metric spaces and , say that f  is separately
 continuous at  if the following hold: (i) the function from Y  into Z
 defined by  is continuous at b; (ii) the function from X into Z
 defined by  is continuous at a. (a) Show that if f  is continuous
 at , then it is separately continuous at . (b) Show that the
 function  defined by
 

is separately continuous at  but not continuous there.
5.5.  Compactness
To a large extent this section is concerned with extending the Bolzano-Weierstrass
Theorem to the setting of metric spaces. But the concept of compactness involves
much more. In fact as we progress we will develop other ideas that are useful in
the study of  and beyond.
If  is a collection of subsets of X and , then  is a cover of E if
. A subcover of E is a subset  of  that is also a cover
of E. Finally we say that  is an open cover of E if  is a cover and every set
in the collection  is open.

5.5.1. Definition. A subset K of the metric space  is said to be
compact if every open cover of K has a finite subcover.
We mention that the term "open cover" in this definition can be replaced by
"cover by subsets of K that are relatively open." See Exercise 2.
It is easy to find examples of sets that are not compact. Specifically, the open
interval  is not compact. In fact if we put , then
 is an open cover of the interval that has no finite subcover.
Similarly  is not compact since  is an open cover of  that
has no finite subcover. We can easily see that every finite subset of X is compact,
but finding non-trivial examples of compact sets requires us to first prove some
results.

5.5.2. Proposition. Let  be a metric space.
(a)  If K is a compact subset of X, then K is closed and bounded.
(b)  If K is compact and F is a closed set contained in K, then F is compact.
(c)  The continuous image of a compact subset is a compact subset. That is,
if  is continuous and K is a compact subset of X, then
 is a compact subset of Z.
Proof. (a) If , then for each z in K let  such
that . Now  is an open cover
of K. Since K is compact, there are points  in K such
that . Let . Note that
; in fact, if there is a y in , then
there is a k such that ,
which contradicts the choice of the numbers  and . Therefore
. Since x was arbitrary, this says that  is open and
so K is closed. Also for any point  in X,  is an open
cover of K; hence there is a finite subcover. But the sets in this cover are
increasing, so there is an integer n such that  and so K is
bounded.
 
 
(b) Let  be an open cover of F and observe that since F is closed,
  is an open cover of K. The existence of a finite subcover of K
 implies there is a finite sub-collection of  that covers F.
 
(c) Let  be a continuous function and assume K is a
 compact subset of X; we want to show that  is a compact subset of Z.
 Let  be an open cover of  in . Since f  is continuous it follows
 that  is an open cover of K (5.4.3(b)). Therefore
 there are sets  in  such that . It follows
 that . â 
 
We can use the preceding proposition to prove the EVT for continuous
 functions on a compact metric space. 

5.5.3. Corollary. If  is a compact metric space and 
 is a continuous function, then there are points a and b in X such that
  for all x in X.
 
Proof. We have from Proposition 5.5.2 that  is a closed and bounded
 subset of . Put . Since
  is closed, ; this proves the corollary. â 
 
Before extending the Bolzano-Weierstrass Theorem, we need two more
 definitions. 
5.5.4. Definition. Say that a subset K of the metric space  is totally
 bounded if for any radius  there are points  in K such
 that . A collection  of subsets of K has the finite
 intersection property or FIP if whenever , .
 
The following is the main result on compactness in metric spaces.
 
5.5.5. Theorem. The following statements are equivalent for a closed subset
 K of a metric space .
 
(a)  K is compact.
 
(b)  If  is a collection of closed subsets of K having the FIP, then
 
 


(c)  Every sequence in K has a convergent subsequence.
(d)  Every infinite subset of K has a limit point.
(e)   is a complete metric space that is totally bounded.
Proof. (a) implies (b). Let  be a collection of closed subsets of K having
the FIP. Suppose . If , then it
follows that  is an open cover of X and therefore of K. By (a), there are
 in  such that . But since
each  is a subset of K this implies , contradicting the fact
that  has the FIP.
(b) implies (a). Let  be an open cover of K and put
. Since  covers K, . Thus
 cannot have the FIP and there must be a finite number of
sets  in  with . But this implies that
 is a finite cover of K. Hence K is compact.
(d) implies (c). Assume  is a sequence of distinct points in K. By
(d),  has a limit point; since K is closed, that limit point must be in
K. We are tempted here to invoke (5.3.15(a)), but we have to manufacture
an actual subsequence of the original sequence. That is, we must find 
such that  and  This takes a little bit of care and
effort, which we leave to the interested reader.
(c) implies (d). If S is an infinite subset, then S has a sequence of distinct
points ; by (c) there is a subsequence  that converges to some
point x. It follows that x is a limit point of S. (Details?)
(a) implies (d). Assume that (d) is false. So there is an infinite subset
S of K with no limit point; it follows that there is an infinite sequence
 in S with no limit point. Thus for each , 
contains all its limit points and is therefore closed. Also .
But each finite subcollection of  has non-empty intersection,
contradicting (b), which is equivalent to (a).
(a) implies (e). First let  be a Cauchy sequence in K. Since (a)
implies (d), which is equivalent to (c), there is an x in K and a subsequence
 such that . But this implies  by Proposition 5.2.5.
Hence  is complete. To show that K is totally bounded, just note
that  is an open cover of K for any .
 
 
(e) implies (c). Fix an infinite sequence  in K and let 
 be a decreasing sequence of positive numbers such that . By
 (e) there is a covering of K by a finite number of balls of radius .
 Thus there is a ball  that contains an infinite number of points
 from ; let . Now consider the sequence
  and balls of radius . As we just did, there is a point
  in K such that  is an infinite set.
 Using induction we can show that for each  we get a point 
 in K and an infinite set of positive integers  such that 
 and . If , then 
 and . Since K is complete, Cantor's Theorem implies that
  for some point x in X. Now, using a small induction
 argument, pick integers  in  such that . It follows that
  is a subsequence of the original sequence and .
 
(e) implies (a). We first prove the following.
 
5.5.6. Claim. If K satisfies (c) and  be an open cover of K, then there
 is an  such that for each x in K there is a G in  such that
 .
 
Let  be an open cover of K and suppose the claim is false; so for every
  there is an  in K such that  is not contained in any set G
 in . By (c) there is an x in K and a subsequence  such that .
 Since  is a cover, there is a G in  such that ; choose a positive 
 such that . Let  such that . If
 , then , so that
 . Thus , contradicting the restriction imposed
 on . This establishes the claim.
 
From here it is easy to complete the proof. We know that (e) implies (c), so
 for an open cover  of K let  be the number guaranteed by Claim 5.5.6.
 Now let  such that  and for  let
  such that .  is the sought after finite
 subcover.
 
(c) implies (e). If  is a Cauchy sequence in K, then (c) implies it has a
 convergent subsequence; by Proposition 5.2.5 the original sequence converges.
 Thus  is complete. Now fix an . Let ; if ,
 we are done. If not, then there is a point  in . Once
 again, if , we are done; otherwise pick an  in
 . Continue. If this process does not stop after a
 finite number of steps, we produce an infinite sequence  in K with
  whenever . But this implies that this sequence can have
 no convergent subsequence, contradicting (c). â 
 
As an application we tweak Cantor's Theorem (5.3.18) and address a question
that arose in connection with it.

5.5.7. Corollary. If  is compact and  is a sequence
of non-empty closed subsets of X such that , then
.
The proof of this corollary is clear since a decreasing sequence of closed
non-empty sets has the FIP.
Compactness is one of the most important properties in mathematics. Many
good things follow from it as we shall see in this book and the reader will
continue to see as (s)he continues his/her career. The point is that compact sets
are "almost" finite in a very precise sense, and this approximation of finiteness
often suffices to allow us to carry out an argument for a compact set that
we can easily make for a finite set. We already saw this in Corollary
5.5.3.
We might observe that the Bolzano-Weierstrass Theorem together with
Theorem 5.5.5 show that every closed and bounded interval in  is a compact
set. By Proposition 5.5.2 the converse is also true. The next result extends this to
.

5.5.8. Theorem (Heine4-Borel5
Theorem). A subset of  is compact if and only if it is closed and
bounded.
Proof. If K is compact, then K is closed and bounded by Proposition 5.5.2.
Now assume that K is closed and bounded. It follows that there are bounded
intervals  in  such that .
Suppose  is a sequence in K with . Thus  is
a sequence in , so the Bolzano-Weierstrass Theorem implies it has a
convergent subsequence. The notation in this proof could become grotesque
if we do the standard things, so we depart from the standard. Denote
the convergent subsequence by , where  is an infinite
subset of  with its natural ordering. We have that the limit exists, so put
. Now consider the sequence  in .
It has a convergent subsequence  with .
Continue and we get  and  for
. It follows that  is a subsequence of the original
sequence and it converges to ; it must be that  since
K is closed. By Theorem 5.5.5, K is compact. â 

5.5.9. Example. For the metric space , if , the set
 
  is closed and bounded but not
 compact.
 
The next theorem extends Theorem 1.7.16. In fact the proof of that result will
 also extend to the present setting. The details are left to the reader in
 Exercise 9.
 
5.5.10. Theorem. If  is a compact metric space and 
 is a continuous function, then f is uniformly continuous.
 
5.5.11. Proposition. A compact metric space is separable and complete.
 
Proof. The completeness of  is explicit in Theorem 5.5.5(e). To
 prove that  is separable again Theorem 5.5.5(e) implies that
 for each natural number n we can find a finite set  such that
 . Put ; we will show that this
 countable set F is dense in X. In fact if  is an arbitrary point in X and
 , choose n such that . Thus there is a point x in 
 with , proving that . â 
 
In light of the preceding proposition any closed and bounded subset of  is
 separable.
 
5.5.12. Theorem. Let  and  be compact metric spaces and
 assume D is a dense subset of X. If  is uniformly continuous,
 then there is a uniformly continuous function  that extends f;
 that is, the function F satisfies  for all x in D.
 
Proof. If , let  be a sequence in D that converges to
 x. We claim that  is a Cauchy sequence in Z. In fact, if
 , let  such that  when  and
 . Now there is an integer N with  for .
 Hence  when . Thus  is a Cauchy
 sequence in Z. By Proposition 5.5.11,  is complete, so there is a
  in Z such that . If  is another sequence in D that
 converges to x, then the same argument shows there is a  in Z such that
 . But we have that , so the uniform continuity
 of f  implies  (Why?). Thus . This means we
 can define a function  by letting  for any
sequence  in D that converges to x. Clearly F is an extension of f .
Now to show that this function F is uniformly continuous. Let
. Choose  such that  when  and
. Fix points x and y in X with  and let
 and  be sequences in D that converge to x and y. Choose N
such that  and  when . So for all
 we have that . Hence
 when . it follows that .
Therefore F is uniformly continuous. â 
The above proposition fails if f  is not uniformly continuous. See Example 5.6.13
in the next section.
5.5.13. Theorem (Dini's6
Theorem). If  is compact,  is an increasing sequence of
continuous functions on X, and f is a continuous function on X such that
 for all x in X, then  on X.


Proof. Let  and for
each  let . We note that because
both f  and  are continuous,  is a closed subset of X. Also because
the sequence of functions is increasing, . We want to show
that there is an integer N such that . In fact if this is done, then
for all  we have that  for all x in .
That is,  for all x in X and all , establishing that
 on X. But if there is an x in , then  for every
. This says that  for all n, contradicting the fact
that . â 
Exercises

(1) Show that the union of a finite number of compact sets is compact.
 
 
 (2)  If K is a subset of , show that K is compact if and only if every
 cover of K by relatively open subsets of K has a finite subcover.
 
 (3)  Show that the closure of a totally bounded set is totally bounded.
 
 (4)  Show that a totally bounded set is bounded. Is the converse true?
 
 (5)  If  is a sequence of totally bounded sets such that ,
 show that  is totally bounded.
 
 (6)  If  is a complete metric space and , show that E is totally
 bounded if and only if  is compact.
 
 (7)  (a) If G is an open set and K is a compact set with , show that
 there is a  such that . (b) Find an example
 of an open set G in a metric space X and a closed, non-compact subset F
 of G such that there is no  with .
 
 (8)  If K is a compact set in  and G is an open set such that ,
 show that there is an open set  such that  is compact and
 .
 
 (9)  Give the details of the proof of Theorem 5.5.10.
 
 (10)  For two subsets A and B of X, define the distance from
 A to B by . (a) Show that
 . (b) If A and B are two disjoint
 closed subsets of X such that B is compact, then . (c) Give
 an example of two disjoint closed subsets A and B of the plane  such
 that . (d) Is this exercise related to Exercise 7?
 
 (11)  Consider the metric space  (see Exercise 5.3.12) and show that
 

is not totally bounded and, therefore, not compact.
 
(12) Say that a metric space is -compact if it can be written as the union of a
countable number of compact sets. (a) Give three examples of -compact
metric spaces that are not compact. (b) Show that a -compact metric
space is separable.
5.6.  Connectedness
Consider the following two examples of subsets of . The first is the set
 and the second is . In X there are two
distinct "parts,"  and . In the second we have written Y  as the
union of two disjoint sets, but these two sets are not really separate "parts." (The
term "parts" will be made technically precise soon, though we won't use that
term.) In a sense writing Y  as the union of those two sets is just accidental. We
could just as well have written  or  or
even . What's the true difference between the two sets X and
Y ?
Note that in the metric space  of the last paragraph, the set  is
simultaneously both an open and a closed subset of X. For example,
. The set X is an example of
what we now define as a set that is not connected, or, more succinctly, a
disconnected set.

5.6.1. Definition. A metric space  is connected if there are no subsets
of X that are simultaneously open and closed other than X and . If
, we say that E is connected if  is connected. If E is not
connected we will say that it is disconnected or a non-connected set.
An equivalent formulation of connectedness is to say that  is connected
provided that when  where  and both A and B are open
(or closed), then either  or . This is the sense of our use of the
term "parts" in the introduction of this section; for the set X there, 
and  are two disjoint, non-trivial sets that are both open and closed in
X. Let's collect some of these equivalent formulations of connectedness. The
 
 proof is left to the reader (Exercise 1); we will often use this result without
 referencing it.
 
5.6.2. Proposition. If  is a metric space, the following statements
 are equivalent.
 
(a)  X is connected.
 
(b)  If  where  and both A and B or open (or
 closed), then either  or .
 
(c)  If , , and A is both open and closed, then .
 
The next result can be considered an example, but it is much more than
 that.
 
5.6.3. Proposition. A subset of  is connected if and only if it is an
 interval.
 
Proof. Assume that  and let's show that X is connected. (The
 proof that other types of intervals are connected is Exercise 2.) Assume
 that , where both A and B are open and .
 One of these sets contains the point a; suppose . Note that A is
 also closed. We want to show that . Since A is open there is an
  such that . Put . We claim
 that . In fact if  then the definition of the
 supremum implies there is an  such that , , and
 ; thus . Now A is also closed and ,
 so it must also be that . If , then the fact that A is
 open implies that there is a  such that .
 But this means that ,
 contradicting the definition of r. Therefore  and we have that
 . (So .)
 
Recall that by Lemma 1.6.6 a subset I of  is an interval if and
 only if whenever  with  it follows that . Assume
 that X is a non-empty connected subset of  and  with ;
 suppose . If , let .
 Clearly A and B are open subsets relative to X; since  we also
 have that , and they are also closed
 relative to X. Since  and , neither is empty, contradicting the
 assumption that X is connected. Hence . That is,  and by
 Lemma 1.6.6 X is an interval. â 
 

5.6.4. Theorem. The continuous image of a connected set is connected.
Proof. Let  be a continuous function and E a connected
subset of X; we want to show that  is a connected subset of Z. By
replacing X with E, we may assume  is connected; by replacing Z
with , we may assume that f  is surjective. We must now show that
Z is connected. If D is a subset of Z that is both open and closed, then the
continuity of f  implies  is both open and closed in X. Since X is
connected,  is either  or X. But since f  is surjective, this implies
D is either  or Z. Thus Z is connected. â 
 
 
The preceding theorem together with Proposition 5.6.3 allows us to deduce
 the IVT (1.7.7) in this setting.
 
5.6.5. Corollary (Intermediate Value Theorem).  If  is
 continuous, X is connected,  with , then for any number
 c in the interval  there is a point x in X with .
 
Proof. We know that  is a connected subset of  so that it must
 be an interval (5.6.3). Since , it must be that . â 
 
5.6.6. Example. (a) If , then the straight line segment
  is connected. In fact 
 is a continuous function from the unit interval into . Since the unit
 interval is connected, so is its image under this continuous mapping.
 
(b) In  the balls  are connected. In fact let A be a non-empty
 subset of  that is both relatively open and closed and fix a point y
 in A. If , then the line segment  and  is
 connected by part (a). But it follows that  is a non-empty subset
 of this line segment that is both relatively open and relatively closed. Thus
 ; in particular the arbitrary point z from  belongs to A
 so that .
 
(c) Any circle in  is connected. In
 fact if , then 
 defined by  is a continuous function and
 . By Theorem 5.6.4, X is connected.
 
(d) If  is the discrete metric space, then X is not connected if X
 has more than one point. In fact each singleton set  is a non-empty set
 that is both open and closed.
 
5.6.7. Proposition. Let  be a metric space.
 
(a)  If  is a collection of connected subsets of X such that
  for all  in I, then  is connected.
 
(b)  If  is a sequence of connected subsets of X such that
  for each n, then  is connected.
 
Proof. (a) Let A be a non-empty subset of E that is relatively open and
 closed. If , then  is a relatively closed and open subset of ;
 if , then the fact that  is connected implies . Now
since A is non-empty, there is at least one i such that . But then
for every j in I, the hypothesis implies there is a point in  that belongs
to A; thus . Therefore  and E must be connected.
(b) Let A be a non-empty relatively open and closed subset of E. Since
, there is some integer N with . But  is both
relatively open and closed in , so  by the connectedness of
. By hypothesis, , so  and it follows
that . Continuing we get that  for . Since
, similar arguments show that . Continuing
we get that  for all . That is,  and so E is
connected. â 
5.6.8. Corollary. The union of two intersecting connected subsets of a
metric space is connected.
See Exercise 8.

5.6.9. Definition. If  is a metric space, a component of X is a
maximal connected subset of X.
The word "maximal" in the definition means that there is no connected set
that properly contains it. So if C is a component of X and D is a connected
subset of X with , then .
A component is the correct interpretation of the word "part" used in the
introduction of this section. The set X in that introduction has two components.
Notice that a connected metric space has only one component. In the discrete
metric space each singleton set is a component.

5.6.10. Proposition. For any metric space, every connected set is
contained in a component, distinct components are disjoint, and the union
of all the components is the entire space.
Proof. Fix a connected subset D of X and let  denote the collection
of all connected subsets of X that contain D. According to Proposition
5.6.7(a),  is connected. Clearly C is a component and
contains D. By taking  in what was just established, we have that
every point of X is contained in a component so that the union of all the
components is X. Finally note that if C and D are two components and
, then  is connected by Corollary 5.6.8; so it has to be
that  by the maximality of C and D. That is, distinct
 
 components are disjoint sets. â 
 
A consequence of the preceding proposition is that the components form a
 partition of X - they divide the space X into a collection of pairwise
 disjoint connected sets. The next result says that the components are all
 closed, the proof of which emphasizes once again that, when discussing
 relatively open and closed sets, you must be aware of what the universe
 is.
 
5.6.11. Proposition. If C is a connected subset of the metric space X and
 , then Y is connected.
 
Proof. Let A be a non-empty subset of Y  that is both relatively open and
 closed, and fix a point  in A. By Proposition 5.3.5 there is an open subset
 G of X such that . Since  and , there must
 be a point x in ; that is,  is a non-empty relatively
 open subset of C. Since A is relatively closed in Y , Proposition 5.3.5 and an
 analogous argument implies that  is also relatively closed in C. Since
 C is connected, . That is,  so that A is
 both closed in Y  and dense in Y ; hence , and it must be that Y  is
 connected. â 
 
5.6.12. Corollary. The closure of a connected set is connected and each
component is closed.
In light of the preceding proposition and Example 5.6.6(b), if  and
, then E is connected. Here is an example that will
illustrate additional properties as we proceed. In fact this example is used so
often it has a name, the topologist's sine curve. 

5.6.13. Example. 
is connected. In fact,  defined by  is a
continuous function, so  is connected. Since ,
X is connected by Proposition 5.6.11. The space X consists of the graph
of the function  for  together with the origin. Note
that instead of the origin we could have added to the graph any subset of
 and the resulting set would still be connected.
We now focus on . Recall Proposition 1.6.7 where it is proved that every
open subset of  is the union of a countable number of pairwise disjoint open
intervals. We can interpret this as saying that the components of an open subset
G of  are open intervals, which are not closed subsets of . They are,
however, relatively closed in G. We want to extend Proposition 1.6.7 to ; of
course the extension is not literal. We start with an idea in  that is
useful.

5.6.14. Definition. If , , and , say that there is
an -chain from x to y in E when there are a finite number of points
 in E such that: (i) for , ; (ii) for
, ; (iii)  and .
The proof of the next lemma is Exercise 11.

5.6.15. Lemma. If  and , then for any pair of points x and
y in  and all sufficiently small  there is an -chain in 
from x to y.

5.6.16. Proposition. Consider the metric space .
(a)  If G is an open subset of , then every component of G is open and
there are countably many components.
(b)  An open subset G of  is connected if and only if for any  in
G there is an  such that there is an -chain in G from x to y.
 
 
Proof. (a) If H is a component of G and , choose  such
 that . Since  is also connected (5.6.6), Corollary 5.6.8
 implies  is connected. Since this is also a subset of G it follows
 that , so  and H is open. Because  is
 separable, there is a countable dense subset D. Now since each component
 is open, each component contains an element of D and different components
 contain different points. If there are uncountably many components this
 would show there is an uncountable subset of D (Why?), which is
 nonsense.
 
(b) Assume that the open set G satisfies the stated condition and let's
 prove that G is connected. Fix x and let H be the component of G that
 contains x; we want to show that . We know that H is open by part
 (a). If  there is an  such that there is an -chain 
 in G from x to y. Since  for ,
 Proposition 5.6.7(b) says  is connected. Condition (i) of
 the definition of an -chain implies , and so . In particular,
 . Since y was arbitrary,  and G is connected.
 
Now assume that G is connected. Fix a point x in G and let
 


The strategy of the proof will be to show that D is both relatively open
 and closed in G; since it is not empty (), it will then follow that
  and so G will have been shown to satisfy the condition. If ,
 let  and let  be an -chain from x to y. It follows from the
 definition of an -chain that . Thus D is open. Now suppose
  - this is the relative closure of D in G. (Why?) Choose
  such that ; so . Since , there
 is a point y in . Let  be an -chain from
 x to y. By Exercise 10 there is an -chain from x to y in G whenever
 . Applying this with , we may assume .
 Using Lemma 5.6.15 we see that this implies there is an -chain in G from
 x to z. Thus  and so D is relatively closed in G. â 
We note that (i) of the definition of an -chain was used to establish that the
condition in part (b) was sufficient for connectedness. Without this, the result is
false as we see in the following example.

5.6.17. Example. Let .
Clearly X is not connected; in fact it has two components. It is also easy
to see that if  with  and  with , then
for all sufficiently small  there are points  in X such that for
, , and  and .
Unlike open subsets of , components in an arbitrary metric space are not
necessarily open. (Exercise 13.)
Exercises

(1) Prove Proposition 5.6.2.
 
(2) Prove that open and half-open intervals are connected, completing the proof
of half of Proposition 5.6.3.
 
(3) If  is connected and  is a continuous function such that
 for all x in X, show that f  must be constant.
 
(4)Show that X is connected if and only if whenever  are two points in X,
there is a connected subset E of X such that .

(5) If A is a subset of X, define the characteristic function of A as the function
 such that  when  and  when
. Show that A is simultaneously open and closed if and only if 
is continuous.
 
(6) Look at the preceding exercise for the definition of the characteristic
function on a set X. (a) If A and B are subsets of X, which function is
? (b) Which function is ? (c) What is the characteristic
function of the empty set? (d) Is  the characteristic function of some
set?
 
(7) Can you think of any way to generalize Proposition 5.6.7(a) and obtain a
 
 theorem whose conclusion is that  is connected?
 
 (8)  Give an example of two connected sets whose intersection is not connected.
 
 (9) Let  and let
 

(a) Show that if E is compact, then  is compact. (b) Give
 an example of a set E such that  is compact, but E is not.
 (c) Show that if E is connected, then  is connected. (d) Give
 an example of a set E such that  is connected, but E is
 not.
 
 (10)  If E is a subset of , , and  such that there is an -chain
 from x to y, show that for any  with  there is an -chain
 from x to y.
 
 (11)  Prove Lemma 5.6.15.
 
 (12)  A polygon  is the union of straight line segments in
  of the form
 

(a) Show that a polygon is a connected subset of . (b) Show that an
 open subset G of  is connected if and only if for any two points x and y
 in G there is a polygon  contained in G.
 
(13) Give an example of a metric space  such that the components are
not all open.
5.7.  The Space of Continuous Functions
In this section we extend the definition of uniform convergence encountered in
Â§4.1 to sequences of continuous functions defined on a metric space. After
extending the definition and proving some basic propositions, we will shift the
point of view by considering the set of all bounded continuous functions as
a metric space. We continue to assume that  is a fixed metric
space.

5.7.1. Definition. If  is a sequence of functions from  into ,
say that converges uniformly to a function f  if for every  there
is an N such that  for all x in X and all . In
symbols this is written as  on X.

I suspect that many readers could have guessed this was the definition of
uniform convergence. We could have extended the definition further by having
the sequence  consist of functions from  into a second metric
space . We will not explore this here, however. The next result
extends Proposition 4.1.3 to the present context. The same proof will work
here.

5.7.2. Proposition. If , and  are three sequences of
functions from X into  such that  for all x in X
and there is a function  such that  and  on
X, then  on X.
The next proposition extends Proposition 4.1.5 and the same proof will
work.

5.7.3. Proposition. If  is a sequence of bounded functions from
X into  that converges uniformly to a function , then f is a
bounded function and the sequence of functions  is uniformly bounded;
that is, there is a constant M such that  for all x in X and all
.
 
 
The next result extends Theorem 4.1.6. The same proof works provided we
 make a small modification, which is carried out below.
 
5.7.4. Theorem. If  is a sequence of bounded continuous functions
 from X into  and  on X, then  is a continuous
 function.
 
Proof. Fix a point a in X; we want to show that f  is continuous
 at a. If , then by the uniform convergence we can choose
 an integer n such that  for all x in X. Since
  is continuous there is a  such that 
 when . Thus for any x in X with ,
 .
 By definition, f  is continuous at a. â 
 
The next result extends Theorem 4.1.8 to uniformly continuous functions
 defined on a metric space. A slight modification of that proof will work here. The
 details are left to the reader.
 
5.7.5. Theorem. Let . If  is a sequence of bounded uniformly
 continuous functions on X and  on X, then  is a
 uniformly continuous function.
 
Now we change the context of the discussion.
 
5.7.6. Definition. We denote the set of all continuous functions from X
 into  by .  denotes the subset of all those functions f  in
  that are bounded. That is,  consists of all those continuous
 functions f  from X into  such that
 


Here we call upon the student to have a somewhat different point of view and
to begin to think of continuous functions as points in the space . We'll see
this repeatedly as we progress.
An algebra is a vector space  over  in which there is a multiplication and
all the usual distributive and associative laws hold: for all  in  and t in


In other words an algebra is both a vector space and a ring such that the
distributive laws hold. If there is a multiplicative identity, it is denoted by 1.
Note that when the algebra  has an identity, it contains a replica of the
constants:  for every t in .

5.7.7. Proposition. For any metric space  the following hold.
(a)   and  are algebras.
(b)  If we set  for f and g in , then d defines
a metric. Whenever we discuss  as a metric space we refer to this
metric.
(c)  A sequence  in  converges to f in the metric space
 if and only if .
(d)   is a complete metric space.
Proof. Part (a) was already proved in Proposition 5.4.5. (Also see
Exercise 5.4.11.) Part (b) is left as Exercise 1.
(c) If  and , let n be an integer such that
 for all . It follows that 
for ; so  in . For the converse assume that when
, . It follows that for
 we have that  for every x in X; so .
(d) If  is a Cauchy sequence in , let  and choose N such
that  when . Thus for each x in X,  is a
Cauchy sequence in ; hence it has a limit. Put  so
that  defines a function. Let , and choose N such that
 
  when . For  and x an arbitrary point in
 X we have that
 
 
â(5.7.8)

 Now hold  fixed. Since the above inequality holds for any x in X it also
 holds for any y in X and so
 

But  is continuous so there is a  such that  when
 . Putting all this together gives that  when ;
 that is, f  is a continuous function. By (5.7.8) , so 
 (Proposition 5.7.3). â 
 
What we have done so far in our study of  and  can be thought
 of as fundamental orientation and housekeeping. Now we begin the process of
 establishing one of the important results about  when X is compact. We
 begin with a lemma about .
 
5.7.9. Lemma. There is a sequence of polynomials  such that
  in .
 
Proof. We define the sequence of polynomials inductively by letting 
 and . It is an easy job to show that all these
polynomials are positive on  (Exercise 4).
Claim. For all  and all x in , .
In fact this is clear for , so assume it is true for n. Since
 when , we have that .
Hence

establishing the claim.
In light of this claim  so that . Thus for each
x in  we have that  is an increasing sequence in  that is
bounded above by ; hence there is a t in  such that .
Therefore


implying that . Thus the sequence  is increasing and converges
pointwise to the continuous function  on . By Dini's Theorem
(5.5.13), the convergence is uniform. â 
 
There
 is
 a
 part
 of
 
 me
 that
 doesn't
 like
 the
 preceding
 proof.
It works, so what's not to like and why am I raising the issue? The rub is that
 it's not clear how the sequence  is thought up and maybe this disturbs
 some readers as well. The source of the polynomials is connected to Taylor's
 Theorem (2.5.6) and Newton's method from calculus. An explication of this
 would be a distraction. So let's just say we obtain one approximation ,
 add on half the amount by which  fails to equal x, then we keep our
 fingers crossed. Lo and behold, it works.
 
Recall the definition of the maximum and minimum of two functions (1.7.9),
  and . (That definition was given for functions defined on subsets of
  but the same definition extends.)
 
5.7.10. Lemma. If  is a closed subalgebra of  that contains the
 identity and , then .
 
Proof. In light of Exercise 3, it suffices to show that  whenever
 . To do this fix f  in ; we may assume that f  is not the function 0.
 Put  and observe that  and takes its values in .
 Let  be the sequence of polynomials from the preceding lemma such
 that  on . Since  is an algebra that contains the constant
 functions,  for each . It follows that
 in , . (Why?) Because  is a
 closed subalgebra of  we have that . â 
 
A collection of functions  in  is said to separate the points of X if
 whenever  and , there is a function f  in  with .
 Both  and  separate the points of X. (You can show this
 by using Urysohn's Lemma, but it can be done directly.) If X is any
 subset of , the collection of all polynomials separates the points of X.
 

5.7.11. Theorem (Stone7-Weierstrass8
 Theorem). If X is compact and  is a closed subalgebra of  that
 separates the points of X and contains the constant functions, then
.
Proof. Fix an arbitrary f  in  and let's show that . We start with
a simple claim.
Claim. If x and y are distinct points in X, there is a function  in
 such that  and .
The proof is easy. Since  separates points there is a function g in  with
. Set


The reader can verify that this function has the desired properties.
There are many functions in  that take on the values  and  at x
and y. (Name one more.) For every such pair , however, we fix one such
function . Now fix x in X and let . For each y in X put
. Note that the continuity of f  and
 implies that  is open. Using the properties of  we have
that . Hence  is an open cover of X. By
compactness there are points  such that .
Put


Lemma 5.7.10 implies that . Since  for every y in X,
 we have that ; because the sets  cover X, we
 have that  for every z in X.
 
For each x in X let . Once again we
 note that  and so  is an open cover of X; let
  be a finite subcover, and put
 


Once again Lemma 5.7.10 implies . It follows (Verify!) that for every z
 in X, . That is, . since  was arbitrary
 and  is closed, . â 
 
The proof of the next two corollaries is required in Exercise 5.
 
5.7.12. Corollary (Weierstrass Theorem). For any closed and bounded
 interval , the polynomials are dense in .
 
The preceding corollary is the reason that Weierstrass's name is attached to
 (5.7.11).
 
5.7.13. Corollary. If X is a closed and bounded subset of , the set of
 polynomials in the p-variables  is dense in .
 
The reader should examine Exercises 6 and 7.
 
Now we obtain another important result about  when X is compact:
 the characterization of the compact subsets of . We start with a
 definition.
 
5.7.14. Definition. If  is a subset of , then  is said to be
 equicontinuous if for every  and every point , there is a
 neighborhood U of  such that  for all x in U and
 every f  in .
Note that if we were considering a single f , the fact that for each  and 
there is such a neighborhood U is just the fact that f  is continuous at . So
every finite set in  is equicontinuous. The salient point in the definition is
that one open neighborhood U of  works for every function in the family .
That is, the family of functions  is sufficiently constrained that there is
a uniformity in the way that they are continuous â hence the prefix
"equi".

5.7.15. Theorem (ArzelÃ 9-Ascoli10
Theorem). If X is compact, then a subset  of  is totally bounded
if and only if  is bounded and equicontinuous.
Proof. Assume that  is totally bounded. Automatically  is bounded
(Exercise 5.5.4). To establish equicontinuity let . So there are
 in  such that . If
, let U be a neighborhood of  such that for ,
 when . Thus if  and we choose 
with , then
.
Hence  is equicontinuous.
Now assume that  is equicontinuous and bounded. Without loss of
generality we can assume that  for every f  in . Fix ; by
equicontinuity we have that for each x in X there is an open neighborhood
 of x such that  whenever  and .
It follows that  is an open cover of X; by the compactness
of X we can extract a finite subcover . Now choose
 in  such that . Note
that the collection of all ordered n-tuples of elements from the set
 is finite. We don't want to consider all such n-tuples,
however, but only the set B of those ordered n-tuples 
with  such that there is a  in  with
. Since for each f  in  we have that 
we see that . For each b in B fix one such function  in ; so
 is a finite subset of . The fact that  is totally bounded
holds once we establish the following.
Claim. .
If ,  and so there is a  in
B with  for . Thus 
for . For each x in X choose  with x in . Hence
. Since x
 
 was arbitrary, the claim is established. â 
 
5.7.16. Corollary. If X is compact and , then  is compact if
 and only if  is closed, bounded, and equicontinuous.
 
 
Exercises

(1) Prove Proposition 5.7.7(b).
 
(2) (a) Extend the definition of a uniformly Cauchy sequence given in
Exercise 4.1.5 to the context of continuous functions from X into . (b)
Show that a sequence  in  is a Cauchy sequence if and only
if it is a uniformly Cauchy sequence.
 
(3) Show that if , then  and
. (Hint: first prove it for numbers.)
 
(4) Show that each of the polynomials  in the proof of Lemma 5.7.9 satisfies
 for all x in . (Hint: Use induction.)
 
(5) Prove Corollaries 5.7.12 and 5.7.13.
 
(6) Let X be compact and assume  is a closed subalgebra of . Assume
 contains the constants and there are two points  and  such that
if  then there is a function f  in  with .
(a) Show that , with equality if and
only if  for every f  in .
(b) Show that  is the closure of the
set of all polynomials in  and . (Such polynomials are called
trigonometric polynomials.) 
(7) In the Stone-Weierstrass Theorem consider each possible pair of the
conditions: (a)  is an algebra; (b)  separates points; and (c)
 contains the constant functions. For each possible pair of these three
conditions, find an example of a compact space X and a closed algebra
 such that  satisfies those two conditions but .
 
(8) If  such that  for all , show that
.
 
(9) If  is a compact metric space and , show that  is
equicontinuous if and only if for every  there is a  such that
when ,  for every f  in 

 
 (10)  If  is a family of functions in  that is equicontinuous at each
 point of X, does it follow that  is a bounded set? What happens if you
 also assume that X is compact?
1See the footnote in Definition 1.3.12 for a biographical note.
2Hermann Amandus Schwarz was a German mathematician born in 1843 in Hermsdorf, Silesia, which
at present is part of Poland. He began his studies at Berlin in Chemistry, but switched to mathematics
and received his doctorate in 1864 under the direction of Weierstrass. He held positions at Halle, Zurich,
GÃ¶ttingen, and Berlin. His work centered on various geometry problems that were deeply
connected to analysis. This included work on surfaces and conformal mappings in analytic
function theory, any student of which will see his name in prominence. He died in Berlin in
1921.
3Pavel Samuilovich Urysohn was born in 1898 in Odessa, Ukraine. He was awarded his habilitation in
June 1921 from the University of Moscow, where he remained as an instructor. He began his work in
analysis but switched to topology where he made several important contributions, especially in
developing a theory of dimension. His work attracted the attention of the mathematicians of the day, and
in 1924 he set out on a tour of the major universities in Germany, Holland, and France, meeting with
Hausdorff, Hilbert, and others. That same year, while swimming off the coast of Brittany, France, he
drowned. He is buried in Batz-sur-Mer in Brittany. In just three years he left his mark on
mathematics.
4Heinrich Eduard Heine was born in 1821 in Berlin, the eighth of nine children. He received his
doctorate in 1842 from Berlin; in 1844 he received the habilitation at Bonn where he was appointed a
privatdozent. In 1856 he was made professor at the University of Halle, where he remained for the rest of
his career. In 1850 he married Sophie Wolff from Berlin, and, over the years, they had five
children. He worked on partial differential equations and then on special functions - Legendre
polynomials, Lam functions, and Bessel functions. He made significant contributions to spherical
harmonics and introduced the concept of uniform continuity. It was in 1872 that he gave a
proof of the present theorem. It requires some scholarship to discover the differences in the
contribution to this result between him and Borel, who published it in 1895. He died in 1881 in
Halle.
5Emile Borel was born in Saint Affrique in the south of France in 1871. He published his first two
papers in 1890, two years before receiving his doctorate in Paris and joining the faculty
at Lille. He returned to Paris in 1897. In 1909 a special chair in the Theory of Functions
was created for him at the Sorbonne. During World War I he was very supportive of his
country and was put in charge of a central department of research. He also spent time at the
front and in 1918 he was awarded the Croix de Guerre. In 1928 he set up the Institute Henri
PoincarÃ©. He was one of the founders of the modern theory of functions along with Baire
and Lebesgue and he also worked on divergent series, complex variables, probability, and
game theory. He continued to be very active in the French government, serving in the French
Chamber of Deputies (1924-36) and as Minister of the Navy (1925-40). He died in 1956 in
Paris.
6Ulisse Dini was born in 1845 in Pisa. He attended Scuola Normale Superiore in Pisa, a teaching
preparatory college. In 1865 he won a scholarship for study abroad, which he used to go to Paris for a
year. During this time he was very active in research, eventually publishing seven papers based on the
work he had done. He returned to Pisa and an academic position at the university. Dini's life span was a
period of myriad political developments in Italy as the country worked its way toward unification. This is
not a period for the casual historian. In 1859 there was a war with Austria and in 1861 the Kingdom
of Italy was formed, though it did not include Venice and Rome. (Can you imagine Italy
without Venice and Rome?) It was not until 1866 that Venice became part of the kingdom
and Rome had to wait until 1870. The turmoil affected Dini as he progressed in both his
academic as well as a political career. In 1871 he took over Betti's chair of analysis, and that
same year he was elected to the Pisa City Council. In 1877 he was appointed to a second
chair in mathematics, and in 1880 he was elected as a representative of Pisa to the national
assembly. In 1883 he was appointed rector of the university, holding the position for two
years. In 1892 he was elected a senator in the Italian Parliament; and in 1908 he became
director of the Scuola Normale Superiore, a position he held for the rest of his life. This was
a period of development in mathematical analysis when the turmoil seemed to be trying
to parody the events in Italy; mathematicians sought rigorous proofs of results that had
only casually been established, and they sought the boundaries of validity for these results.
Dini seemed to flourish in this undertaking. In addition to the present result, there is one in
Fourier series that bears his name. He also wrote several influential texts. He died in 1918 in
Pisa.
7Marshall H Stone was born in 1902 in New York. His father was Harlan Stone who, after time as the
dean of the Columbia Law School, became a member of the US Supreme Court, including a term as its
chief justice. Marshall Stone entered Harvard in 1919 intending to study law. He soon diverted
to mathematics and received his doctorate in 1926 under the direction of David Birkhoff.
Though he had brief appointments at Columbia and Yale, most of his early career was spent
at Harvard. His initial work continued the direction it took under Birkhoff, but in 1929 he
started working on hermitian operators. His American Mathematical Society book, Linear
Transformations in Hilbert space and Their Applications to Analysis, became a classic. Indeed, a
reading of that book today shows how the arguments and clarity might easily lead to the
conclusion that it is a contemporary monograph. During World War II he worked for the
Navy and the War Department and in 1946 he left Harvard to become the chairman of the
mathematics department at the University of Chicago. He himself said that this decision was
arrived at because of "my conviction that the time was also ripe for a fundamental revision of
graduate and undergraduate mathematical education." Indeed he transformed the department at
Chicago. The number of theorems that bear his name is truly impressive. Besides the present
theorem there is the Stone-Äech compactification, the Stone-von Neumann Theorem, the
Stone Representation Theorem in Boolean algebra, and Stone's Theorem on one-parameter
semigroups. He stepped down as chair at Chicago in 1952 and retired in 1968, but then
went to the University of Massachusetts where he taught in various capacities until 1980.
He loved to travel and on a trip to India in 1989 he died in Madras. He had 14 doctoral
students.
8See Theorem 1.3.11 for a biographical note.
9Cesare ArzelÃ  was born in 1847 in La Spezia, Italy. He received his doctorate from the
university in Pisa under the direction of Enrico Betti. He held positions at Florence and
Palermo before he became a professor in Bologna in 1880. His most famous work is this
result, where he established the condition as sufficient for compactness. He died in 1912 in La
Spezia.
10Giulio Ascoli was born in Trieste in 1843. He received his degree from Pisa and became a professor
at Milan in 1872. He had a distinguished career and this theorem is his most notable result. He died in
1896 in Milan. 












6 Differentiation
in
Higher
Dimensions
Here we want to extend the theory of differentiation to situations involving
several variables. First we'll assume only the range of the function has more than
one variable, then only the domain, and finally where both domain and range
have more than a single dimension. After doing the necessary work to define the
concept of a differentiable function in each of these three cases, we'll see some
applications.
6.1.  Vector-valued Functions
This section starts the chapter by discussing functions  defined on a subset of
 and taking values in  with ; in other words, vector-valued
functions of a single variable. Defining differentiability in this situation
presents few difficulties and the resulting theory does not differ very
much from the case where  that was presented in Chapter 2. The
first task is to define  when  for some subset
X of . This is not a major problem since  is a metric space. To
keep the discussion similar to that in Chapter 2, however, we start by
finding a substitute for the absolute value of a real number. For any x in
 let
 


The quantity  is called the norm of x. Recall that , where
this latter symbol is the inner product in . See (5.1.4). So when ,
 is precisely the distance from x to y as defined in (5.1.2(c)) and makes
 into a metric space. We note from Corollary 5.1.6 that the norm satisfies the
triangle inequality: .
Now when , a function  is a function from one
metric space into another, so the definition of limits and continuity is
inherited from that more general setting. (Also see Exercise 2.) Specifically
 means that for every  there is a  such
that


and . See Exercise 5.4.1.
(The author asks the reader's indulgence for a certain ambiguity in the
notation here. We will use letters like  etc. both for numbers in  and
vectors in . This is to maintain some consistency with the past and future
and hopefully will not cause confusion. Some people employ the convention of
using boldface letters for the vectors, but that strikes me as cumbersome and not
justified. It is also the case that in more advanced courses no such use of boldface
is made. My policy, however, will call for a bit of extra attention and awareness
of the context when reading this material. Maybe that's an extra benefit of such
ambiguity.)
 
 
With the concept of limit there is almost no problem defining the derivative of
 such a function.
 
6.1.1. Definition. A function  is differentiable at x if
 


exists. The
 value of this limit is denoted by  and is called the derivative of 
 at x. Note that when the derivative exists, .  is said to be
 differentiable on  if it is differentiable at each point. Observe that if
  we can define  and  as we did in (2.2.2).
 
Also see Exercise 3.
 
Notice that when  is differentiable, then , so we
 can speak of  being continuously differentiable or twice differentiable or having
 any number of derivatives. We refer to a function that is continuously
 differentiable as a smooth function.  

6.1.2. Definition. A curve in  is a continuous function .
 Say that the curve  is smooth if  is continuously differentiable.
 The trace of the curve is its image in  and is denoted by
 .
It would not surprise me if some readers are a bit uncomfortable when we
 define a curve as a function. Most think of a curve as a set of points, what we call
 the trace of the curve. For example, we might say the top arc of the circle in
  centered at the origin and having radius r is a curve. This language is not,
 however, sufficiently precise to do mathematics. Defining it as a function allows
 us to better introduce and use the analysis we are developing to study
 curves. For example, we eventually want to examine the direction of
 the curve. This is easy to do when we define the curve as the function
  as  has the natural direction it inherits from the interval
 ; we simply look at the direction of  as t goes from a to b.
 As another example, in (7.1.2) we define the length of a smooth curve,
something that is awkward to formulate if a curve is defined as a set of
points.
When the curve  is smooth, its derivative is a tangent
vector to the curve. We'll examine this in a more general context in Â§6.7
 
 below.
 
We state a version of Proposition 2.2.9 for the present situation.
 
6.1.3. Proposition. A function  is differentiable at a
 point x in  if and only if there there is a function 
 and a vector G in  such that  and
 


for all y in . When  is differentiable at x, we have .
 
As in the case of a scalar-valued function, the proof is straightforward; see the
 proof of Proposition 2.2.9.
 
Most of the results for the derivatives of scalar-valued functions obtained in
 Â§2.2 carry over to this situation. In particular the derivative of the sum of
 two vector-valued functions is the sum of the derivatives. The straight
 product of two functions with values in  makes no sense, though we
 can employ the inner product of two such functions. Recall the inner
 product notation on  introduced when we proved the Cauchy-Schwarz
 Inequality:
 


The essential properties of the inner product were listed in (5.1.4).
 
6.1.4. Proposition. If  and  are two functions from  into
 that are differentiable at x, then the function  defined by
 is differentiable at x and


Proof. The proof proceeds much like the proof of Proposition 2.2.5(b) except
that we use the properties of the inner product to get

Now we let  and appeal to Exercise 1 to get the result. â 
In Exercises 2 and 3 we show that discussing the differentiability of
a function  can be reduced to discussing the functions
, where  is the standard basis. In fact what we have
done is demonstrate that there is little distinction between the theory of
differentiation of functions with values in  and those with values in
.
 
There
 is,
 however,
 a
 result
 for
 derivatives
 
 of
 functions
 from
  into
 that
 is
 dramatically
 lacking
 when
 we
 consider
 vector-valued
 functions:the
 Mean
 Value
 Theorem
 (2.3.4).
 
See Exercise 4.
 
Exercises

 (1)  If , , and , show
 .
 
 (2)  For  and , let  be defined
 by , where  are the standard basis vectors.
 (a) Show that if , then  if and only if
  for . (b) Show that  is continuous on
  if and only if each  is continuous on .
 
 (3)  Use the notation established in the preceding exercise. (a) Show that  is
 differentiable on  if and only if each  is differentiable on .
 (b) If  is differentiable on , show that .
 
 (4)  Show that the function  defined by  does not
 satisfy  for any point c in .
6.2.  Differentiable Functions, Part 1
Now we confront the differentiability of functions from an open subset of 
into . In this situation the difficulties in defining differentiability are
significant. We start by examining the partial derivatives of such functions,
something everyone has brushed up against in calculus. Here we renew that
acquaintance and perhaps broaden and deepen the encounter.
For a variety of reasons, including ease of notation, we will continue to denote
the elements of  as vectors x rather than a p-tuple of real numbers
 unless there is a reason for such specificity. As usual the
standard basis of the vector space  will be denoted by . In other
words .
In this section, G will always denote an open subset of .

6.2.1. Definition. If , , and , say that the j-th
partial derivative  of f  exists at x provided


exists. When this limit exists, it is denoted by


There is a possible confusion in the term "j-th partial derivative." For
 example, the term "second partial derivative" could mean  as defined above
 or the same phrase might mean  or . The context
 should indicate which we mean and the notation is certainly different.
 
What is happening here is that for x fixed in G we are considering the
 scalar-valued function  defined on a small interval about 0 and we
 are differentiating this with respect to t. This is why we insist that f  be defined
 on an open set G so that for  there is an  such that
  is defined for t in  and we can discuss its derivative. We
 are assuming the reader remembers from calculus how to carry out the partial
 differentiation: just treat all the variables  as constants and
 differentiate the remainder as though it were a function of the variable 
 alone.
 
If the j-th partial derivative of  exists throughout G, then this
 gives us another function . We can discuss the continuity of
  as well as the existence of its partial derivatives. When  has a
 partial derivative with respect to  for some i we write that derivative
 as
 


Note the order of the indices i and j in  as this is important. The
 question immediately arises whether . This is not always the
 case.
 
6.2.2. Example. Define  by


(In the calculations that follow, the reader is asked in Exercise 2 to
supply the details.) It follows that . Hence


On the other hand  and so .
The key is whether those second partial derivatives are continuous. The
next proof uses the MVT for derivatives of functions of one variable
(2.3.4).

6.2.3. Proposition. If , , and both  and
 exist and are continuous at x in G, then .
Proof. Fix i and j and fix  when . By considering the function
, we see that if we prove the proposition when
, we prove the proposition for any value of p. So without loss of
generality assume .
 
 
Fix a point  in G; we want to show that .
 Fix  such that , and let  be any
 positive number with . ( will be further specified later.)
 Put . Consider a point  in the disk 
 with  and . Apply the MVT for derivatives to the
 
function of one variable  to obtain a point 
between x and a such that


Now apply the MVT to the function  (Is the hypothesis
of the MVT satisfied?) to obtain a point  between y and b such that


Combining these equations we see that for any  in the disk  there is a point  in  with
 
â(6.2.4)

Interchanging the roles of the first and second variable in the preceding argument
we see that when  with  and , there is a point
 in  with  between x and a and  between y and b such that
 
â(6.2.5)

 But a quick inspection of the left-hand sides of (6.2.4) and (6.2.5) shows they are equal. Hence
 . But since  we have that
 


Now we use the hypothesis that both  and  are continuous. If  there is
 a  such that  and  when
 . Combining this with the last equation we see that 
 for every positive , so the conclusion of the proposition follows. â 
 
There
 is
 something
 disagreeable
 about
 all
 this.
 
If we want to use partial derivatives to study the behavior of a function, we
 cannot do it one variable at a time. Exercise 5.4.14 shows that there are
 functions defined on  that are continuous in each variable separately, but not
 continuous. In fact that example illustrates an additional anomaly. In Exercise 3
 below the reader is asked to show that that function has partial derivatives at the
 origin with  even though it is not continuous at the
origin. We must have a concept of the differentiability of a function 
that simultaneously incorporates the influence of all the variables on f . We will
now see such a concept of differentiability for a real-valued function defined
on an open subset of  that implies the existence of all the partial
derivatives and also has the psychologically satisfying property that it implies
continuity.
To do this recall Proposition 2.2.9 where it is shown that  is
differentiable at x if and only if there there is a a number D and a function
 such that  for all y in X
and . (When this is the case, .) We also
saw a similar result for functions  in Proposition 6.1.3.
We modify these results for functions f  defined on an open subset of
. The first thing to observe is that should we write such an equation
when f  is defined on a subset of , the left-hand side of this equation,
, is a number while on the right-hand side the vector  in 
appears. Therefore we have to a find suitable way to interpret D and the
function F.
We start with ; finding a substitute for D will come shortly. If we
return to the case of a scalar-valued function we see that we could change the
F-term to  without changing the definition of differentiability. So in
our present case we can use  instead of , where F
remains a scalar-valued function . But now we need an appropriate
definition of the limiting process as  in . We need look no further
than what we did in the preceding chapter since such a function F maps
one metric space to another. Namely, if  and , say
that  if for every  there is a  such that
 whenever .
It is more involved to find a replacement for the number D that appears in the
equation  in Proposition 2.2.9. Unlike
with the term , we cannot replace  with  in the
one-variable situation without changing the definition of differentiability. (Why?)
So the replacement for D cannot be a number. What to do? Don't forget that in
the case of a function f  defined on an open interval it was the case that
. This argues, perhaps, that the correct replacement for D should be
some form of a vector though it must be able to interact with  and
produce a number. It is possible to once again resort to the inner product. But
for a variety of reasons the solution is that D will be replaced by a linear
functional  from linear algebra. We review here some of the
pertinent facts about linear functionals and present some additional things
needed for our discussion of differentiability. We start by recalling the
definition.

6.2.6. Definition. A linear functional on  is a function  that
 
 satisfies  for all  in  and all  in
 . Denote the collection of all linear functionals on  by .
 
We recall that  is also a vector space where for two linear functionals
  and , . Since the unit vectors
  form a basis for , the numbers  determine
 any linear functional L. That is, if  and ,
 then . (Also see Exercise 4.) We rephrase this a bit
 differently.
 
6.2.7. Proposition. If  and we define  by
 


then . Moreover,  is a basis for .
 
Proof. We leave it to the reader to show that each  is a
 linear functional. To show that  is linearly independent,
 first observe that for ,  when  and
 . Thus if  in , we have that for each
 k, . So the linear functionals  are
 linearly independent. If  and , then for 


Since  is a basis for , this shows that .
â 
Now we relate linear functionals to the inner product.

6.2.8. Proposition. If , then there is a unique vector a in
 such that . In fact .
Proof. If L is given, set  and put  in . It
follows that


The proof of uniqueness is Exercise 5. â 
We need the next result for making estimates. The key here is to set things up
so we can apply the Cauchy-Schwarz Inequality. Recall that using the inner
product the Cauchy-Schwartz Inequality becomes


for  in .
 
6.2.9. Proposition. If we define
 


then for every x in  we have that . Moreover there
 is a vector x in  with  and . Therefore
 


Proof. From the preceding proposition , where a is
 the vector whose j-th coordinate is . Thus the quantity
 , and so . Also
 setting  gives that  and . The fact that
  is now straightforward. â 
The quantity  is called the norm of the linear functional L. We are now
in a position to define a differentiable function following the discussion that
precedes the definition of a linear functional.
6.2.10. Definition. If G is an open subset of , , and 
say that f  is differentiable at x if there is a linear functional 
and a function  such that


for all y in G and . We define the derivative of f  at x
to be the linear functional


If f  is differentiable at every point of G then f  is said to be differentiable
on G.
Again you might want to show that this coincides with the definition of a
function  being differentiable at a point x by examining
Proposition 2.2.9. For such a function what is the linear functional ?
The introduction of the notation  may seem capricious, but I'll ask
the reader to be patient. There are times that Df  is more convenient
than . This is especially true when we later consider functions from
 into . This notation Df  is in wide use and rather standard. In
 
 fact it seems to me more convenient. The reader might want to look at
 Exercise 6.
 
In the atmosphere of the preceding definition, since  is a linear
 functional it makes sense to write  for any y in . Indeed
 .
 
6.2.11. Proposition. If  and  are differentiable
 at x then for any scalars  and , the function  is differentiable
 at x and .
 
Proof. Exercise 7 â 
 
6.2.12. Theorem. If G is an open subset of , , and 
 is differentiable at x, then the following hold.
 
(a)  f is continuous at x.
 
(b)  For , the j-th partial derivative of f at x exists.
 
(c)  If we define the vector
 


then for every y in  we have
 


(d)  The linear functional L in the definition of differentiability is unique.
 
 
As in calculus we call  the gradient of f  at x.
 
Proof. The theorem contains a lot of information, but part-by-part the
 proof is not difficult. We use the notation of Definition 6.2.10.
 
(a) We have that , so the
 continuity is immediate.
 
(b) From Definition 6.2.10 we have that for  and 

since  remains bounded by 1. Thus (x) exists and equals .
 
(c) This is immediate from Proposition 6.2.8.
 
(d) This follows from part (c) since the partial derivatives are unique.
 â 
 
Here is a convenient sufficient condition for differentiability. If you are
 presented with a function, you can often use it to establish this.
 
6.2.13. Theorem. If  is such that each partial derivative of f
 exists and is continuous, then f is differentiable.
 
Proof. Fix a point x in G. We have to find a linear functional L such that
 


That is we must find L with the property that for every  there is
a  such that when ,


Finding the linear functional L is easy since we know from the preceding
theorem that if the derivative exists, it must be given by the gradient:
, which the hypothesis implies exists. Since each  is
continuous and there are only a finite number of these derivatives, for every
 there is a  such that


when  and .
Assume  with  and write .
Define vectors  in  by  and  for
. Note that .
(Verify!) Now the hypothesis says we can apply the MVT to the function defined
on  by . This yields a  in  such that

Because ,
 we have that . Therefore using the
 Cauchy-Schwarz Inequality we have
 

 â 
 
Because we have so many different situations where functions are defined with
 values in  or domain in  we will have many Chain Rules. Here is the
 first.
 
6.2.14. Theorem (Chain Rule). Let  with range contained
 in G and suppose . If ,  is differentiable at ,
 , and f is differentiable at , then  is
 differentiable at  and
 
 


Proof. We use the notation of Definition 6.2.10.
Also let , where  such
that  as .
If  with  and we put , then


Now


Thus as , this remains bounded while . Hence

 â 
 
6.2.15. Theorem (Mean Value Theorem). If ,
 is differentiable, and , then there is a point x
on the line segment  such that


Proof. Define the function  by .
Using the just established Chain Rule with  we
have that .
Now apply the MVT
to g. â 

6.2.16. Definition. If G is an open subset of , , , and
, then f  is said to have a directional derivative at x in the direction
d provided the function  is differentiable at . When
the directional derivative exists we denote it by


If you consult the literature you may sometimes find a small variation on the
 definition of the directional derivative where the vector d is constrained to be a
 unit vector. This difference is conceptually minor though certain formulas will be
 different. Note that if the vector , then the function f  has a directional
 derivative at x in the direction  precisely when the corresponding partial
 derivative of f  at x exists, and in this case . Also observe that
 if in the definition of the directional derivative we choose  such that
  for  and define  by , then we
 can apply the version of the Chain Rule proved above. With this observation the
 proof of the next proposition is an immediate consequence of Theorem
 6.2.14

6.2.17. Proposition. If  and  is differentiable at x,
 then  exists for any direction d and
 


6.2.18. Proposition. If G is a connected open subset of , 
 is differentiable at every point of G, and  for all x in G, then f is
 a constant function.
 
Proof. If  and we consider  instead of f , we may assume
 there is a point a in G with . Set ; so we
 want to show that . We do this by showing that X is non-empty
 and both open and relatively closed in G, so that the equality will follow
 from the connectedness of G.
 
We know that  since it contains a; since f  is continuous on G, it
 follows that X is relatively closed in G. We want to show that X is also open.
 Fix c in X and pick  such that . If , let d be
 the vector  and define . By Theorem 6.2.14 for all
 t where , . By Theorem 2.3.2,
  is constant. Hence . Since b
 was an arbitrary point in  we have that  and so X is
open. â 
We extend some definitions given in Â§2.4.

6.2.19. Definition. If  and  is differentiable at a, then f 
has a critical point at a provided ; equivalently, if .
We say that f  has a local maximum at a if there is a  such that
 when .
Similarly we say that f  has a local minimum at a if there is a  such
that  when . If f  has either a local maximum or
local minimum at a, then we say f  has a local extremum there. If there is a
vector x in  such that the function  defined on 
has a local maximum at  and there is a vector y in  such that the
function  defined on  has a local minimum at ,
then f  is said to have a saddle point at a.

6.2.20. Theorem. If  and  is differentiable on G and has
a local extremum at a, then .
Proof. Let  and consider the function . Since f  has
a local extremum at a, this function has a local extremum at .
By Theorem 2.3.2, the derivative of this function at  must vanish.
According to Proposition 6.2.17 this means that . Since d
was an arbitrary vector in , this proves the theorem. â 
We can extend Theorem 2.4.2 to the present case.

6.2.21. Theorem. Let G be an open subset of , , and let
 be a differentiable function on all of G.
(a)  If for each vector d in  there is  such that 
and  for , then f has a local maximum at a.
(b)  If for each vector d in  there is  such that 
and  for , then f has a local minimum at a.
Proof. The idea is to look at the behavior of f  near a in each direction d and
apply Theorem 2.4.2. That is, for each vector d in  consider the function
 and apply Theorem 2.4.2 to this function. Exercise 9 asks
the reader to supply the details. â 
 
 
We'll say more about critical points in Â§6.6.
 
6.2.22. Proposition. Let G be an open subset of , let ,
 and let  be a differentiable function on all of G. If d is any
 unit vector in , then . Equality is achieved when
 .
 
Proof. According to Proposition 6.2.17 . Therefore
 by the Cauchy-Schwarz Inequality, . The statement on
 equality is immediate. â 
 
In light of the preceding proposition we conclude that for any a the vector
  points in the direction in which the scalar-valued function f  is changing
 the fastest.
Exercises

(1)Define  by


Find  and  for every point  in . (Be careful
when .)
 
(2) Supply the missing details in Example 6.2.2.
 
(3) Show that the function f  defined in Exercise 5.4.14 has partial derivatives
at the origin with  even though it fails to be
continuous at .
 
(4) Show that if  and  for , then
 for all x in .
 
(5) (a) Show that if  and  for every y in , then .
(b) Prove the uniqueness statement in Proposition 6.2.8.
 
(6) Let  and let . Suppose we say that the function f  has
Property D at x if


exists. (a) Show that if f  is differentiable at x, it has property D at x.
 (b) Does Property D at x imply that f  is differentiable at x? (Prove or give
 a conterexample.)
 
 (7)  Prove Proposition 6.2.11.
 
 (8)  (a) Let 
 and find  when . (b) Let  be defined
 by  and  and calculate .
 
 (9)  Supply the required details for the proof of Theorem 6.2.21.
6.3.  Orthogonality
This section and the next are a linear algebra interlude, one that is required to go
 further in our study of differentiability in . Specifically, when we study the
 differentiability of functions from open subsets of  into , we need to
 explore linear transformations and the inner product more extensively than we
 have.
 
6.3.1. Definition. If  we say that x and y are orthogonal if
 ; in symbols we write . Say that the vectors in a non-empty
 subset  of  are pairwise orthogonal  if  whenever x and y are
 distinct points in . Say that the set  is orthonormal if  is pairwise
 orthogonal and also  for all x in . An orthonormal basis for
  is a basis for  that is also an orthonormal set.
 
If , write  when  for all y in . Let  denote
 the set of all vectors that are orthogonal to the set . Two non-empty
 subsets  and  of  are said to be orthogonal if every vector in  is
 orthogonal to every vector in ; in symbols, .
 
First note that  if and only if . Now observe that if  is a
 pairwise orthogonal set of non-zero vectors, then the vectors in  are linearly
 independent. In fact, if  are distinct vectors in  and if
  are scalars such that , then for a fixed k,
,


So each  is zero. Since  has dimension p,  cannot have more than p
vectors. Examples of pairwise orthogonal sets abound. To start, any non-empty subset
of the standard basis for  is an orthonormal set, and the standard basis is an
example of an orthonormal basis. There are other orthonormal bases as we will see in
Corollary 6.3.4 below.
The reader may recall some of this from linear algebra. Assume the
vectors x and y are linearly independent and consider the two-dimensional
subspace of  spanned by them. These vectors are orthogonal if the
straight lines they define form a right angle. Note that for any  we
have


This is called the polar identity. From here we get the following. 

6.3.2. Proposition (Pythagorean1
Theorem). If  are pairwise orthogonal vectors in , then
 
 


Proof. If , then this easily follows from the polar identity. The proof
 can now be completed using induction (Exercise 1). â 
 
We observed earlier that a set of pairwise orthogonal vectors is linearly
 independent. A similar argument shows that if  and , then
 , the linear span of S (Exercise 3). 

6.3.3. Theorem (Gram2-Schmidt3
 Process). If  are linearly independent, then there are
 orthonormal vectors  such that for ,  is in the
 linear span of . Consequently,
 


for .
 
Proof. Observe that the last statement of the theorem follows from
 the first. In fact since the first part of the proposition implies
 , to show equality we need only show that
 these two subspaces have the same dimension. But since  are
 orthonormal and  are linearly independent, both subspaces
 have dimension j.
The proof of the first part is by induction on m. When  just take
. Now assume the proposition is true for some  and
that  are linearly independent. By the induction hypothesis
there are orthonormal vectors  such that for ,  is
in the linear span of
. Consider . If , then
.
Also note that  since . If we
set , then  is an orthonormal set. It is left to
the reader to check that . â 
We will eventually want to manufacture an orthonormal basis for
 different from the standard basis. The next corollary allows us to do
this.

6.3.4. Corollary. If  is a set of orthonormal vectors in , then there
is an orthonormal basis  for  that contains .
Proof. From linear algebra we know there is a basis  for  that
contains  since  is a linearly independent set. By The Gram-Schmidt
Process we can replace  by orthonormal vectors  with
the same span. Hence  is an orthonormal basis. But if the
Gram-Schmidt process is examined, we see that the orthonormal vectors
 will not be altered by the process. Hence . â 
The proof of the next result is Exercise 4.

6.3.5. Proposition. If  is an orthonormal basis for  and
, then


The next result is crucial in our study of orthogonality.
 
6.3.6. Theorem. If  is a vector subspace of  and , then
 there is a unique vector  in  such that
 


In addition .
 
Proof. Let  be an orthonormal basis for  and set
 


We want to show that  has the desired properties. It is easily checked that
  for . Since  is a basis for ,
 this shows that . Now let y be an arbitrary vector in .
 Since  and , the Pythagorean Theorem implies
 that
 

This shows that . Since , we must have
equality.
Before showing the uniqueness of  we first prove the following, which is
another way in which  is unique.
Claim.  is the only vector in  such that .
 
 
Suppose  is another vector in  such that . Since
 , it follows that  for . Thus
  is both in  and orthogonal to . In particular it is orthogonal to itself and thus
 .
 
Now assume  such that . If , then
  so using the polar identity we get that
 

Thus  for all y in . If , then by substituting
  for y if necessary we may assume that . Letting  and
 replacing y by ty, the inequality becomes , valid
 for all . Divide both sides by t and letting  shows that
 . That is, . By the claim, this implies that
 . â 
 
If , and  are as in the preceding theorem, then  is called the
 orthogonal projection of x onto . We will return to this concept after we
 begin the study of linear transformations in the next section. See Definition
 6.4.13.
 
6.3.7. Definition. When  and  are two linear subspaces of  and
 , write
 


This is actually the linear space  and the symbol  is used for
 emphasis of the fact that every vector in  is orthogonal to every vector
 in . In fact we will sometimes want to write  when .
 
Exercises

(1) Perform the induction argument needed to complete the proof of the
Pythagorean Theorem.
 
(2) Prove the Parallelogram Law:  for
all x and y in . Why is this called the parallelogram law?
 
(3) Prove that if  and x is a vector that is orthogonal to , then
.
 
(4) Prove Proposition 6.3.5. (Hint: Show that  for
.)
 
(5) In  let , and . Show that
 is a set of linearly independent vectors and carry out the
Gram-Schmidt process to manufacture the corresponding orthonormal
basis.
 
(6) In  let 
and describe the vector space .
6.4.  Linear Transformations
We want to define the derivative of a function  when G is an open
 subset of . When  we saw that the natural object to define as 
 was a linear functional. When , we'll see that the derivative is a linear
 transformation . In this section we will discuss some of the essential
 features of linear transformations. We continue to assume that every reader
 knows the basics of vector spaces and has been exposed to linear transformations.
 For some what is presented here may be familiar. If that's the case just be
 patient or you can skip to the next section, though I suspect most readers will
 encounter some material here for the first time. In particular I think
 Theorem 6.4.29 below will be a first-time experience for most readers of this
 book.
 
Only linear transformations between  and  are discussed here, rather
 than the usual linear transformations between arbitrary vector spaces. Recall
 that a linear transformation is a function  such that whenever
  and  we have that . (A
 notational point should be made here: we will often use the notation Ax rather
 than . This practice is widespread and not limited to the author.)
 The set of all linear transformations from  into  is denoted by
 . This itself is a vector space where for  in  and
  in  we define . We note that
 . An important special case occurs when . In this case we
 let
 


Also recall that the kernel and range of A are defined as
 

So A is injective if and only if ; and A is surjective if and only if
. 
The first step is to represent the linear transformation as a  matrix. To
facilitate this and keep things straight, we'll continue to denote the standard
basis in  by ; however, we will denote the standard basis in  by
. So when  and ,


This leads to the matrix representation of A
 
â(6.4.1)

We assume the reader remembers matrix multiplication and that if
 , then
 


which is a  column vector; equivalently, a vector in .
 
When , define (see Exercise 2) the norm of A to be the
 quantity
 


We might point out that when  and the linear transformation A
 becomes the linear functional L, we defined the norm of L in Proposition 6.2.9. It
 is left to the reader to prove the following in Exercise 3.
 
6.4.2. Proposition. If  and , then the following
 hold.
 
(a)  .
 
(b)   defines a metric on .
 
(c)  For every x in  we have that .
 
(d)  If , then  and .

6.4.3. Corollary. With the metric d on  defined in the
proposition, addition and scalar multiplication are continuous functions.
Proof. See Exercise 4. â 

6.4.4. Proposition. (a)  With the definition of distance given in the
preceding proposition,  is a complete metric space.
(b)  If  is a sequence in  and , then the
infinite series  converges in .
Proof. (a) If  is a Cauchy sequence in  and ,
then ; it follows that
 is a Cauchy sequence in . Hence there is a vector y in
 such that ; define  by .
It is left to the reader to show that A is a linear transformation. It
remains to show that . If  with , then
.
If  then we can choose N such that  when
. Thus  when .
Now choose  such that  when .
(Note that M depends on x.) This implies that  when
 and the value of N is independent of x. Since x was arbitrary with
, we have that  when . That is, 
in .
(b) The proof of this part is like that of the Weierstrass M-Test (4.2.2).
Put  and note that  for each x in . Put
 in . We have that for ,


Thus  is a Cauchy sequence in . By (a) there is a linear
 transformation A in  such that . â 
 
When  we have an additional property.
 
6.4.5. Proposition. If  is a sequence of invertible linear
 transformations in , A is an invertible linear transformation in
 , and , then .
 
Proof. We begin with the following.
 
Claim. If  and , then B is invertible and
 


To prove the claim first observe that since there is an r with ,
 we have that  and so the series 
 converges. By part (b) of the preceding proposition this implies that
  converges in . Put .
 Now
 

But , so we have that . Similarly  and so
the claim is established. (Using linear algebra we could have said that 
means B is left invertible, but a linear transformation on  that is left
invertible is invertible.)
Claim. If  is a sequence in  and , then there is an
integer N such that  is invertible for all  and .
We choose  such that  when . By the preceding claim
 is invertible for all such n. If  (we'll further specify  in a moment),
choose  such that  when . Again the first claim
implies that .
Hence


Now if  we can choose  with  and we have that
 when , establishing the claim.
Now to finish the proof. Using the notation in the statement of the
proposition, we have that . By the last claim
 
 


Therefore  by Exercise 4. â 
 
The preceding proposition can be rephrased as follows: If  is the set of all
 invertible linear transformations from  into itself, then the map  is
 a continuous function from  into itself.
 
Writing  and using the notation established in (6.4.1) we
 have
 

Hence by the Cauchy-Schwarz Inequality
 

This implies the following.
 
6.4.6. Proposition. If  and A has the matrix , then
 
 


See Exercise 6.
Let  and fix a vector z in . Observe that the map
 is a linear functional on . By Proposition 6.2.8 there is a
unique vector  in  such that  for every x in . Since
this vector  is unique, we have defined a function from  into :
. Note that the definition of this map depends on the linear
transformation A and so we denote it by ; that is  for every
z in . From what we have just done we have that for all x in  and all z in
,
 
â(6.4.7)

The function  is called the adjoint of A. The reader is asked to recall from
his/her encounter with linear algebra the definition of the transpose of a matrix.
The transpose of a  matrix  is denoted by  and is the 
matrix that has as its ji-entry the number . This is needed in the next
proposition.

6.4.8. Proposition. If , then the function 
is a linear transformation. The matrix of the adjoint  is the transpose
of the matrix for A.
Proof. The proof that  is Exercise 7. Observe that the
 matrix of  is size . If its matrix is given by  with
 , then . But using (6.4.7) we have
 that . Therefore the matrix  is
 precisely . â 
 
We also have the following. The proof is left to the reader in Exercise 8(a);
 doing this exercise will help further cement the properties of the adjoint in your
 mind.
 
6.4.9. Proposition. If  and , then
 .
 
We now focus on linear transformations . So when ,
 its matrix is a square one of size . Recall from linear algebra that in this
 case the three statements A is invertible, A is injective, and A is surjective are
 equivalent.
 
When  we have that . When  we can
 form the product AB. In this case we have the following (Exercise 8(b)).
 
6.4.10. Proposition. If , then .
 
6.4.11. Definition. A linear transformation in  is self-adjoint or
 hermitian4
 if .
 
A linear transformation A is hermitian if and only if its matrix is equal to its
 transpose. That is,  if and only if . (Why?) Thus
  is hermitian if and only if  for all i and j. In other words, A
 is hermitian if and only if its matrix is symmetric. In the literature many will
 use the term "symmetric" for these linear transformations rather than
 "hermitian." This discrepancy with our usage of hermitian arises because you
 can also carry out this study of linear transformations and adjoints on
 vector spaces over the complex numbers and some prefer to reserve the
 term hermitian for this case. The point is when you use the complex
 numbers the matrix of a self-adjoint linear transformation is not quite
 symmetric. If you are curious and/or interested, please investigate the
 literature.
 
6.4.12. Example. Denote by  the matrix that has the
 entries  along its main diagonal and zeros everywhere else. Call
 such a matrix a diagonal matrix. A linear transformation whose matrix is
diagonal is hermitian.
Warning. Soon we will prove an important result about hermitian linear
transformations (6.4.29). To do this we need to extend the definition of the adjoint,
and therefore of hermitian linear transformations, to linear transformations defined
on a subspace of  rather than the entirety of Euclidean space. In reality this is
a technical matter and not a substantial problem since, as some of you may recall
from your course on linear algebra, all finite dimensional vector spaces over  are
isomorphic to some Euclidean space. The details of all this are not presented here
as this extension is only used in one place in the proof of Theorem 6.4.29. The
interested reader can carry out the details as a project; this would involve taking each
result and definition involving the adjoint and making the appropriate modifications
so that it holds for linear transformations defined on a linear subspce  of .
We now use the main result obtained in the last section (Theorem 6.3.6) to
define an important hermitian linear transformation.

6.4.13. Definition. If  is a linear subspace of  and , then
the unique vector  in  such that  is called the
orthogonal projection  of x onto .
Note that if , then ; if , then . The
converses of these two statements are also true.

6.4.14. Proposition. If  is a linear subspace of  and, for each x
in , Px is the orthogonal projection of x onto , then the following
hold.
(a)   is a hermitian linear transformation.
(b)   for all x in .
(c)  P is an idempotent; that is, .
(d)   and .
(e)  If  is any orthonormal basis for , then


Proof. Note that (e) has already been proven when we proved Theorem
 6.3.6 and is only included for emphasis. But (e) easily implies that P is linear.
 Also for any  in 

Hence , completing the proof of (a).
 
Since , we have by the Pythagorean Theorem that
 , proving (b).
 
The meaning of (c) is that  for all x in . If x is any
 vector in , then . But as we observed,  for all y in , so
 .
 
Using (e) it is clear that  and . Since
  whenever , it must be that . Also since
 , the only way that x can be in  is for x to be
 orthogonal to each , . Since the  form a basis for , it
 follows that  whenever . â 
 
6.4.15. Definition. An orthogonal projection is an idempotent
  such that  for every x in .
 
In a certain sense the preceding definition is redundant. There is a sense,
 however, in which it is required. Definition 6.4.13 depends on first being given a
 subspace  of ; Definition 6.4.15 defines what it means for a linear
 transformation to be an orthogonal projection without first being given such a
 subspace. On the other hand, if P is as in Definition 6.4.15 and ,
then P is the orthogonal projection of  onto  as in Definition
6.4.13.
We need to recall and establish the definition and properties of the
determinant for a square matrix. The reader is assumed to be somewhat familiar
with this, but my experience is that this material is not fully known to most
students who take this course; consequently there follows a presentation of
determinants, including the definition. This must be preceded, however, by a
discussion of permutations. Most of the results on permutations will be stated
without proof. The reader can consult any source on permutations for the
missing details, but I have used [2].
For  we want to consider an ordered set having p elements, where the
word "ordered" is key. An example, of course, is the set of the first p integers,
. A permutation is a reordering of the set. An example when  is
given by ; the meaning of this notation is that this permutation
 
 maps . Another permutation when  is
 ; this permutation maps  and .
 Another is  where the absence of 4 and 5 means they are left fixed; if
 you prefer, . In particular  denotes the identity
 permutation that leaves every number fixed. If you prefer, a permutation is a
 bijection of the set, but where the resulting order is important. We let 
 denote the set of all permutations of the integers . If you know the
 concept of a group,  is a group under composition: if , then 
 is the element of  defined by  for .
 In fact it is one of the first examples of a group when you study this
 subject; it is called the symmetric group on p elements. See Exercise 9.
 
A permutation that switches two of the elements and leaves all the others
 fixed is called a transposition. For example the permutation  is a
 transposition that interchanges 4 and 5 and leaves the other integers fixed. A fact
 that seems intuitively clear after thinking about it but requires proof (see [2],
 p. 94) is that every  in  is the product of a finite number of transpositions.
 As one example . The way to write  as a
 product of transpositions, however, is not unique.
 
6.4.16. Proposition. Any permutation  in  can be written as a
 product of transpositions. If there are two products of transpositions that
 are both equal to , one containing m factors and the other containing n
 factors, then m and n are either simultaneously even or simultaneously odd.
 
A proof of the existence of the factorization could be concocted by using the
 example factorization of  above. For a complete proof of the result
 see [2], p. 94.
 
This enables us to define the sign of a permutation or its parity. If ,
 define  to be  if  is the product of an even number of
 transpositions and  otherwise. In light of the preceding
 proposition, this is well-defined.
 
6.4.17. Proposition. If , then .
 
Proof. Let  be arbitrary in  and let  be a transposition.
 Thus the factorization of  as a product of transpositions
 has one more transposition than a factorization of  and so
 . If we repeatedly apply this to an
 arbitrary , we get the result. â 
 
We now use this material on permutations to define the determinant of a
square  matrix. Let  with  matrix ; for
convenience let .

6.4.18. Definition. If  is a  matrix, define the determinant
of A as


It is helpful to have another expression for the sign of a permutation. To state
 it we need to introduce the sign of a real number a as:  if ;
  if ; . (A word about notation. The usual
 notation for the sign of a real number a is . I've chosen the different
 notation  to avoid any confusion with the sign of a permutation.)
 

6.4.19. Lemma. For any  in ,
 


Hence for any  matrix ,
 

where  and the sum is taken over all the
 distinct p-tuples  with .
 
Proof. The proof of the formula for  can be fashioned from the
 material in [2], page 98 in the section labeled "Second Proof". The proof of
 the additional formula for  is immediate from the formula once we
 realize that , where  is the permutation
 defined as . â 
 
There are other ways to define the determinant, and if you have defined it
 differently you should show that the two definitions are the same. You might also
 try Exercise 10. It will be helpful to regard the determinant as a function of the
 columns of A. So if , we define , where
 A is the matrix with column vectors .

6.4.20. Theorem. If  with columns , the following
hold.
(a)  .
(b)  If  and B is the matrix with columns , then
.
(c)  If two columns in A are equal, then .
(d)  For , if the columns  are held fixed, then the
function  is a linear functional of  into .
(e)  For any B in , .
(f)  A is invertible if and only if , in which case
.
Proof. (a) If , we have that  and 
when . It follows that the only permutation  such that
 is , in which case this product is 1.
Since the sign of  is 1, this proves the result.
(b) Here we will use Lemma 6.4.19 that gives the second formula
for . We also start by assuming that  is a transposition.
Notice from the definition of  that if two of these
integers are interchanged, then  changes sign. For example
. Since interchanging two columns has
precisely the effect of interchanging two of these integers, this proves (b)
when  is a transposition. The general form of (b) follows by induction
since every permutation is the product of transpositions
(c) If two columns in A are equal, interchanging those columns does not
effect A. So (c) is a corollary of (b).
(d) Again use the formula for  in (6.4.19). Consider each of the
summands  in Definition 6.4.2. Since the sum
in this formula is over all the  distinct p-tuples and all but the r-th
column are held fixed, what is left is a linear function of that column.
(e) The proof of this part is more involved than the preceding parts. Fix
B and define  by . If  are the
columns of A, then the columns of BA are . Thus


Note that  also enjoys properties (b), (c), and (d). (Verify!) Hence
 considering only the first column of A, property (d) implies that
 


Repeating this argument for all the succeeding columns we get that
 
 
â(6.4.21)

 where the sum is over all p-tuples of integers  between 1
 and p. Using properties (b) and (c) for , we get that for any p-tuple
 , , where the number
  equals 0 or . (For the moment do not worry about the
 relation between the numbers  and , where this
 last number was used in the definition of the determinant. As we will
 see, it all comes out in the end.) Using the fact that ,
 using the preceding equalities, and substituting them into (6.4.21) shows
 that


Observe that when , the preceding equation becomes
, and we see that the preceding
displayed equation becomes what we want to prove.
(f) If A is invertible, then by (e) we have that ,
so  and . Conversely assume that A is not
invertible. This implies there is at least one column of A that is a linear
combination of the others. (Why?) For notational convenience assume the
dependent column is the first. Hence there are real numbers  such that
. Observe that

Repeating this argument for successive columns we get that


 â 
The following corollary follows by invoking Exercise 12.

6.4.22. Corollary. If , the following hold.
 
 
(a)  If B is the matrix obtained by applying the permutation  in  to
 the rows of A, then .
 
(b)  If two rows in A are equal, then .
 
(c)  For , if the rows  are held fixed and  is the
 matrix with rows , then the function  is a linear
 functional from 
 into .
 
Also see Exercises 10, 12, and 13.
 
We will use the above material on permutations and determinants now as well
 as in Â§9.2 and elsewhere in Chapter 9.
 
(Note that here, as well as in many other places in the literature, for a scalar
 ,  is used for the linear transformation . In other words,
 when we write  we are talking about both the scalar  and the linear
 transformation .)
 
6.4.23. Proposition. If , then the mapping of  into itself
 defined by  is a polynomial in  of degree p.
 
Proof. Let  be the columns of A. Repeatedly using part (d) of the
 preceding theorem as well as part (a), we have
 

for some choice of constants . This completes the proof since the
 coefficient of  is not zero. â 
 
The polynomial  is called the characteristic polynomial of A. Recall that if , an eigenvalue of A is a scalar  such
 that there is a non-zero vector x called an eigenvector with . The
 eigenvector x is said to correspond to . So the eigenvectors are precisely the
 vectors that belong to . The subspace  is called the
 eigenspace of A corresponding to . Thus  is an eigenvalue for A if and only
 if ; equivalently, if and only if  is not invertible;
 equivalently, if and only if . So the eigenvalues of A are precisely
the zeros of the characteristic polynomial. The multiplicity of the eigenvalue 
is the dimension of its eigenspace. (Be aware that some books give a different
definition of multiplicity.) The reader will often encounter in this section and
beyond a phrase like the following: let  be the eigenvalues of A
repeated as often as their multiplicity. This means that if  is an eigenvalue of
A of multiplicity m, then  appears in the sequence  precisely m
times. Also realize that since  is a polynomial of degree p and
eigenvalues happen only when this polynomial has a zero, A can have
at most p eigenvalues counting multiplicity. It is possible that a linear
transformation has significantly fewer eigenvalues as the next example
shows.

6.4.24. Example. (a) Let  and let


So , which has no zeros. Thus A has no eigenvalues.
(b) If  then each  is an eigenvalue. The
multiplicity of  is the number of times it occurs in the finite sequence
.

6.4.25. Definition. The set of all eigenvalues of A, not counting multiplicity,
is called the spectrum of A and is denoted by .
From Example 6.4.24(a) we see that it is possible for  to be empty. If A
is  times the identity,  is the singleton . When A is hermitian,
 as we will see shortly.

6.4.26. Proposition. If A is a hermitian linear transformation, then
 
 


Proof. Let M denote the supremum in the statement. Since
 , we have .
 
If , using the fact that  we have the following two
 equations. (Here when  appears more than once in an equation it is always a
  in that equation or always a .)
 

Since , when we subtract one of these equations from the other and do
 some simplifying, we get . Now
  for all z in . When , the parallelogram
 law (Exercise 6.3.2) shows that this last equation yields
 

Since , substituting  for x in the above inequality if
 necessary gives  whenever . If we take the
 supremum over all y with , we get ; now take the supremum
 over all x with  and the proof is complete. â 
 
6.4.27. Corollary. If A is hermitian and  for all x, then
 .
 
The preceding proposition and corollary are decidedly false if the operator A
is not hermitian. For example consider the linear transformation defined in
Example 6.4.24(a). It is easy to check that in that example  for
every x.

6.4.28. Proposition. If A is hermitian, then either  or  is
an eigenvalue for A.
Proof. According to Proposition 6.4.26, .
But  is a continuous function from  (Exercise 15)
and  is a compact set by the Heine-Borel Theorem.
Therefore the supremum is attained and there is a vector  with
 such that . Let . We will show
that  is an eigenvalue with eigenvector , completing the proof. Indeed,
.
Therefore . â 
Now for a very important result in mathematics. Before tackling the proof, the
reader should solve Exercise 18.

6.4.29. Theorem (The Spectral Theorem). Assume A is a hermitian linear
transformation on . If  are the distinct eigenvalues of A and, for
,  is the orthogonal projection of  onto , then
 for  and
 
â(6.4.30)
Proof. We can assume that . According to Proposition 6.4.28, A has
 an eigenvalue . Put  and let  be the orthogonal
 projection of  onto . By Exercise 18 we can consider the restriction
 , a linear transformation of  into itself. It is left to the
 reader to verify that  is hermitian. (Here is where we encounter the
 small wrinkle mentioned in the Warning given earlier in this section. We
 have only discussed hermitian linear transformations on , and  is a
 subspace of .) Therefore  has an eigenvalue  by (6.4.28); clearly
  is also an eigenvalue for A. It is transparent that every eigenvector
 for  is also an eigenvector for A. Thus we note that  must be
 different from  since all the eigenvectors for A corresponding to  were
 disposed of in . Put  and let  be the orthogonal
 projection of  onto . Note that . (Why?) So if 
 and ,
 


That is, . Since  and  and
  were arbitrarily chosen, it must be that .
 
Let  and continue the above process. Since
  is finite dimensional, this process must stop after a finite number of
 steps and we obtain distinct eigenvalues  of A with  the
 orthogonal projection of  onto , . Just as we
 showed that , we can show any pair of distinct eigenspaces are
 orthogonal. (Do it!) Now  or we could
 continue the process still further. Therefore if ,  and
 so
 


â 
When A is hermitian the expression in (6.4.30) is called the spectral
decomposition of A.

6.4.31. Example. Let  and
let A be the linear transformation on  defined by the diagonal matrix
with these entries  on the main diagonal. So if  is the
standard basis for ,  for . To find the spectral
decomposition of A, let  be the distinct eigenvalues of A. So each
 is at least one of the numbers , but it may appear several times in
the list . If for , , let  be
the linear span of . If  is the orthogonal projection of 
onto , then the spectral decomposition of A is .
There are other ways in which The Spectral Theorem is sometimes
stated. Here is one, which partially furnishes a converse of the preceding
example.

6.4.32. Corollary. If A is a hermitian linear transformation on , then
there is an orthonormal basis for  consisting of eigenvectors for A.
Proof. Using the notation from The
Spectral Theorem, let . For  pick an
orthonormal basis  for . The union of these m bases, , is
an orthonormal basis for  and each vector in this basis is an eigenvector
for A. â 
Exercises

 (1)  Let  and let  be some basis for . Show
 that if  for , then . In other words, a linear
 transformation in  is determined by its values on a basis.
 

(2) In defining the norm of a linear transformation why does the supremum
exist?
 
(3) Prove Proposition 6.4.2.
 
(4) (a) Prove Corollary 6.4.3. That is, show that the following functions are
continuous: (i) the map from  defined
by ; and (ii) the map from 
defined by . (b) Show that when , the map from
 defined by  is continuous.
 
(5) If , show that A is a continuous function.
 
(6) Find an example of a linear transformation in  such that the
inequality in Proposition 6.4.6 is strict.
 
(7) Prove that the function  in Proposition 6.4.8 is a linear transformation.
 
(8) (a) Prove Proposition 6.4.9. (b) Prove Proposition 6.4.10.
 
(9) If  is the set of all permutations of  and , show that
with the definition of multiplication  as composition the following hold.
(a) . (b) This multiplication is associative. (c) There is a  in
 such that  is the identity permutation. (This shows that
 is a group under composition.)
 
(10) (a) Use Definition 6.4.18 to show that when A is either a  or a
 matrix, the definition gives the expected answer for . (b) Use
Definition 6.4.18 to show that  equals its expansion by minors using
the first column of A. (c) If your definition of a determinant is not that given
in (6.4.18), prove that formula from your definition.
 
(11) In Theorem 6.4.20(d) find the unique vector u in  such that the linear
functional  equals ,
 
(12) Let A be a  matrix. (a) Show that . (b) If two
columns of A are linearly dependent, show that . (c) If two rows
of A are linearly dependent, show that . (d) Show that any
statement about the columns of A relative to  can also be made about
the rows of A relative to  since the rows of A are the columns of 
as stated in Corollary 6.4.22.
 
 
 (13)  When we compute the matrix  for a linear transformation A in
 , recall that we are using the usual basis . Recall from
 linear algebra that for any basis  of  we can form another matrix of
 A, which we denote by . Show that the determinant of this new matrix
 is the same as  as defined in (6.4.18).
 
 (14)  If  is a polynomial and A is a linear transformation on  such that
 , show that  for every  in . What does this say
 about the relationship between  and the characteristic polynomial of
 A?
 
 (15)  Prove that for any A in ,  is a continuous function
 from .
 
 (16)  Show that if E is an idempotent on , then .
 
 (17)  Let  be a linear subspace of , give  its subspace topology, and
 show that the orthogonal projection  is an open mapping; that
 is,  is an open subset of  whenever G is open in .
 
 (18)  Let A be a hermitian linear transformation on  and let  be
 an eigenvalue of A. (a) Show that  and
 . (b) If P is the orthogonal projection of
  onto , show that .
6.5.  Differentiable Functions, Part 2
6.5.1. Definition. If G is an open subset of , , and ,
 then f  is differentiable at x when there is a linear transformation
  and a function  such that  and
 for all y in G


We define the derivative of f  at x to be the linear transformation
. If f  is differentiable at every point of G then f  is said
to be differentiable on G.
Once again in this section G is always an open subset of .

6.5.2. Proposition. Suppose  and . If there are
 in  and functions  from G into  such that

and 
whenever , then . In other words the derivative of f at x,
if it exists, is unique.
Proof. Just following Theorem 6.2.12 we pointed out that that theorem
implies the uniqueness of the derivative of a function from G into . The
idea here is to reduce the proof of this proposition to the scalar case.
For any vector d in  let  be defined as


for all y in G. (The notation is a bit awkward, but we'll just have to live
with it. The alternatives all seem awkward.) We note that for ,


By Definition 6.2.10  has a derivative at x and that derivative is the
 linear functional on  defined by . Since the derivative
 of  is unique,  for all w in . Since d was
 arbitrary in , we have that . â 
 
6.5.3. Example. (a) If  and  is defined by
  for all x in , then f  is differentiable everywhere and
  for all x in . In fact this f  satisfies the definition with
  for all y in .
 
(b) If  is differentiable, then . It
 therefore makes sense to ask whether Df  is differentiable. As we progress
 we'll revisit this idea of the second derivative of a real-valued differentiable
 function of several variables.
 
The proof of the next result is left to the reader as Exercise 1.
 
6.5.4. Proposition. A function  is differentiable at x if and
 only if there is a linear transformation A in  such that
 


We set some notation that will be frequently used. Suppose 
 and  is the standard basis for . Recalling the notation
 introduced in the proof of Proposition 6.5.2, for  define 
 by
 
 
â(6.5.5)

We note that if  for , then  in . Hence the
functions  completely determine f . If f  is differentiable at x, then each
 is differentiable at x, with its derivative a linear functional from
 into  such that for each z in ,
 
â(6.5.6)

(Verify!)

6.5.7. Theorem. If G is an open subset of , , and 
is differentiable at x, then the following hold.
(a)  f is continuous at x.
(b)  For  and  the j-th partial derivative of  exists
at x.
(c)  The matrix representing the linear transformation  is
 
â(6.5.8)
Proof. The proof of part (a) follows as the analogous part of Theorem 6.2.12
 did. The reader is required to show the details in Exercise 2. For (b) we leave
 it to the reader to show that for ,  is differentiable at
 x by using Definition 6.2.10 and the fact that f  is differentiable. Thus the
 partial derivative of  with respect to  exists by (6.2.12(b)). For (c)
 we observe that the ij-entry of the matrix representation of  is, by
 Theorem 6.2.12,
 


 â 
The next result is the extension of Theorem 6.2.13 to the present situation. It
 can be proved by using that theorem. The details are left to the reader in
 Exercise 6.
 
6.5.9. Theorem. If  such that for  and 
 the j-th partial derivative of  exists and is continuous, then f is
 differentiable.

6.5.10. Proposition. If G is a connected set and  is
differentiable with  for all x in G, then f is constant.
 
 
Proof. For , examine the function  defined in (6.5.5).
 As in (6.5.6) we have that the linear functional  on  is given
 by  by hypothesis. By Proposition 6.2.18,
 each  is constant. Thus  is constant in . â 
 
6.5.11. Definition. If  is differentiable, then f  is continuously
 differentiable provided  is continuous.
 
The metric on  is the one defined in Proposition 6.4.2, so in the
 above definition the function Df  is a mapping between two metric spaces. It is in
 this sense that the continuity of Df  is defined. Also from Theorem 6.5.7(c), if f  is
 continuously differentiable, then all the partial derivatives  are also
 continuous. (Why?)
 
The next result is undoubtedly expected. The proof is left to the reader in
 Exercise 7.
 
6.5.12. Proposition. If  and  are differentiable,
 then  is differentiable and . If
 , then  is differentiable and .

6.5.13. Theorem (Chain Rule). If  is differentiable, H is an
 open subset of  that contains , and  is differentiable,
 then  is differentiable and
 


or, equivalently,
 
 


for all x in G.
Proof. The proof parallels the proof of Theorem 2.2.10. Fix x in G, let
 in H, and set  and . From the
definition of differentiability we know that

where , , and . We
want to show that

where .
Now

where  is the vector in  defined by
 

Note that
 

So if we set  we have that 
 and
 


proving the theorem. â 
 
As we said, when  is differentiable, . We
 have discussed the continuity of the derivative, but can we take a second
 derivative?
 
Therein
 lies
 the
 road
 to
 complication.
We can make sense of this second derivative, but the effort doesn't seem
worthwhile. For example we could identify  with  by identifying
each linear transformation in  with its  matrix and then
considering . In this setup . This is
beyond the scope of this course.
Exercises

(1) Prove Proposition 6.5.4.
 
(2) (a) Prove Theorem 6.5.7(a). (b) Fill in the missing details of the proof of
Theorem 6.5.7(b).
 
(3)If  is given by ,
compute Df .
 
(4)If  is given by , compute Df .
 
(5)If  is given by , compute Df .
 
(6) Prove Theorem 6.5.9.
 
(7) Prove Proposition 6.5.12.

(8)Let  and  be defined by 
and  and compute  in two different ways:
first by using the Chain Rule and then by computing  and
performing the calculation of the derivative.
6.6.  Critical Points
Here is a theorem found in many Calculus books.


6.6.1. Theorem. Suppose  and 
 is twice continuously differentiable. If , , ,
 and , then f has a relative minimum at a.
 
When
 I
 first
 saw
 this
 as
 a
 student,
 I
 was
 befuddled
First there was the sense of disappointment. The test for a relative minimum
 of a function of one variable was so plain and simple, while this test was even
 difficult to remember. Second, the generalization of this to functions defined on
 G when G is an open subset of  and  seems formidable if not
 impossible. If we are to succeed we need a different approach. In this
 section we'll see this and, I think, see what is really going on in the above
 theorem.
 
We continue to assume that G is always an open subset of . In Â§6.2 we
 defined a differentiable function  to have a critical point at  if
 . (Recall that the derivative of such a function, , is a linear
 functional on  while  is the vector in  that implements this linear
 functional via the inner product:  for all w in .) In
 this section we want to use what we have developed about linear transformations
 to analyze the behavior of f  at such a point. What we do here is analogous to
 what we did for a differentiable function of one variable in Theorem
 2.4.5.
 
Let's underline that we are only discussing functions that are real-valued. We
 could just as easily define a differentiable function  to have a critical
 point at  when . However the diagnosis of the behavior of f  near
 a critical point for such a function is not as complete and satisfying as what we
 can do for a real-valued function.
 
Making no distinction between  and the vector  in  for the
 moment, we have that . Thus . What we will
 show is that when , then f  has a local minimum at 
 when . What does this condition  mean? This is
 discussed below, but we start by examining Theorem 6.5.7(c) and applying this
 to .

6.6.2. Proposition. If G is an open subset of  and 
is a twice differentiable function, then the matrix representing the linear
transformation
 is


Observe that by Proposition 6.2.3, if we assume the second partial derivatives
of  are continuous, the matrix above that represents  is
hermitian because all its mixed partial derivatives are equal. This leads us to
introduce the following.

6.6.3. Definition. A hermitian linear transformation is positive (or
non-negative) if all its eigenvalues are positive numbers; it is negative or
(non-positive) if the eigenvalues are all negative numbers. (We will always
use the terms "positive" and "negative"; other terms are sometimes seen
in the literature.) The hermitian linear transformation is positive definite
if it is positive and invertible. A negative definite linear transformation is
defined similarly.
Note that in light of the Spectral Theorem (6.4.29) a hermitian linear
transformation is positive definite if all its eigenvalues are strictly positive.

6.6.4. Theorem. Let  be an open subset of  and let  be a
twice continuously differentiable function. If  such that 
and A is the hermitian matrix
 
 


the following hold.
 
(a)  If A is positive definite, then a is a local minimum for f.
 
(b)  If A is negative definite, then a is a local maximum for f.
 
(c)  If A is invertible and has some eigenvalues that are positive as well as
 some that are negative, then a is a saddle point.
 
(d)  If A is not invertible, the nature of this critical point is undetermined.
 
What happens when ? In this case  and  are real
 numbers. So the statement that A is positive definite is just the condition that
 . Therefore when , (a) and (b) are just the conditions we saw
 in Theorem 2.4.5. Also in this case (c) is meaningless. When  the
 statement in (d) that A is not invertible is the statement that ; so
 again this is what we have seen before for critical points of functions of a single
 variable.
 
The proof of the general theorem requires a few lemmas.
 
6.6.5. Lemma. If A is a hermitian linear transformation on  that is
 positive definite, then there is a constant  such that 
 for all x in .
 
Proof. Adopt the notation of The Spectral Theorem 6.4.29, and let
  be the spectral decomposition of A. Because A is positive
 definite,  for . Let . For any x in
 ,  with  in . Hence  for  and
 so
 

 â 

6.6.6. Lemma. With the hypothesis of Theorem 6.6.4, there is a real number
 and a function  such that:
(a)  ; and
(b)  for ,


Proof. Choose  such that . Define 
by  and for ,
 
 


Clearly (b)
 holds and we must show that (a) holds as well. Fix a  with ;
 in a moment we will specify  further. Let  and define
  by ; we apply Taylor's Theorem (2.5.6)
 to the function . By the Chain Rule (6.2.14) we have that
 ; so . To calculate , apply the
 Chain Rule (6.5.13) to the composition of  and the function
 . This shows that
 


But . Putting these values of the derivative into Taylor's
 Theorem and using the fact that  we get that there is a value of
 t in  such that
 


Letting  gives that

So . Because the second derivatives of f  are continuous, if
 we can specify that  is such that  whenever
. But y is on the line segment  so that it is indeed the
case that . Thus  when . This proves part (a).
â 
Proof of Theorem 6.6.4. (a) Using the preceding two lemmas we have that
there is an  such that for 

Since  as  and , we can find a  such that 
for . Thus  for , showing that a is a local
minimum for f .
The proof of (b) follows from (a) by consideration of . To prove (c) let
 be two eigenvalues of A with  and . Let x and y be
eigenvectors for  and , respectively, and assume that . For
,

Again  as , so for all sufficiently small t, .
 Similarly, for all sufficiently small s, . Hence f  has a saddle
 point at a.
 
To establish (d) one need only consider various examples. See Exercise 1.
 â 
 
The reader should note that the proof of (c) yields additional information.
 Using the notation in that proof we have that along the direction determined by
 the vector x - that is, along the line  - the function has a local minimum
 at a or when . On the other hand if we go along the direction determined
 by the vector y the function has a local maximum at a. It is precisely by
 concentrating on these two directions that we see the saddle nature of the
 behavior of the function at this critical point.
Now let's reconcile Theorem 6.6.1 with what we have done.
6.6.7. Lemma. If  and A is the hermitian matrix


then A is positive definite if and only if  and .
Proof. Assume A is positive definite. Then . Also since
 is the product of the eigenvalues of A, it must be positive. Now assume
that  and  are positive. If , then

 â 
We can now see that when , Theorem 6.6.1 is a direct consequence of
Theorem 6.6.4 once the criterion for positive definiteness from the preceding
lemma is applied to the matrix
 
 


Actually Lemma 6.6.7 can be generalized. For any square real matrix
 


define the principal minors of A to be the square matrices
 



 where .

6.6.8. Theorem. A hermitian matrix is positive definite if and only if
 is positive for each of its principal minors.
For a proof see [5], page 328.
 
 
Exercises

 (1)  Let  and show that f  has a local minimum at  but
  is not invertible. Give an example of a function g on  that
 has a local maximum at  but  is not invertible.
 
 (2)  Find all local extrema of the function  and
 decide whether each is a local minimum, maximum, or saddle point. If the
 function has a saddle point at , find the eigenvectors corresponding
 to the two eigenvalues of .
 
 (3)  Find all local extrema of the function  and decide
 whether each is a local minimum, maximum, or saddle point.
 
 (4)  Let  and define f  on  by
 . Find all the critical points of f  in 
 and give the nature of each whenever you can.
 
 (5)  Find the critical points of 
 on  and, whenever you can, decide whether each is a local minimum,
 maximum, or saddle point.
 
 (6) Find the critical points of  and, whenever you
 can,
 decide whether each is a local minimum, maximum, or saddle point.
 
 (7)  Using the notation of Theorem 6.6.4, assume that A is positive definite
 so that f  has a local minimum at a. In which direction is the function f 
 increasing the fastest? Prove your assertion.
6.7.  Tangent Planes
As we have mentioned and the student no doubt recalls, when  is
 differentiable at c in ,  is the slope of the straight line tangent to the
 graph of f  at the point . Thus the equation of the line tangent to the graph
 is . When G is an open subset of , , and 
 is differentiable, what is the geometric significance of  or ? First
note that the graph of f  in this case is the surface .
(We are taking the idea of a surface as an intuitive concept and are not precisely
defining it. This will be properly defined in Chapter 9 below.) It makes no sense
to talk about the tangent line to the surface since there are many such lines.
Therefore we must increase the level, or dimension, of the discussion. For inspiration we return to the case where  and show that  has an additional
property.

6.7.1. Proposition. If  is differentiable and ,
then the vector  in  is orthogonal to the line tangent to the
graph of f at the point .
 
 
Proof. We know that the typical point in the tangent line to the graph at
 the point  is . Thus in 


 â 
The preceding result rephrases something else the student may recall from
 calculus. Namely that when ,  is the slope of the line
 perpendicular to the graph of f  at the point . The statement in the
 preceding proposition has an advantage over this last fact since it does not need
 to exclude the possibility that .
 
So we might hope that for f  defined on an open subset of  the
 vector  plays a similar role. In fact we'll show that it is
 perpendicular to all lines tangent to the surface at . But rather
 than discuss all the tangent lines we will incorporate this into another
 concept.
 
6.7.2. Definition. A subset H of  is called an affine hyperplane if
 there is a vector v in H such that  is a linear
 subspace of  having dimension p. If H itself is a linear subspace of
  having dimension p, then H is said to be a hyperplane.
For emphasis, a hyperplane has dimension one less than the dimension of
 the containing space. Let's quickly state the following, whose proof is
 Exercise 1.
 
6.7.3. Proposition. If H is an affine hyperplane, then for all vectors v
 and w in H, . Consequently,  is a linear subspace
 of  having dimension p for every vector v in H.
 
6.7.4. Example. (a) Any straight line in  is an affine hyperplane.
 
(b) The affine hyperplanes in  are the translates of planes.
(c) If  and not all of them are 0, then
 is an affine hyperplane. In fact if ,
.
(See Exercise 2.) So if , then
 and thus has dimension p.
(d) If H is any affine hyperplane and , then  is an
affine hyperplane. In particular this works when H is a linear subspace of
 of dimension p.
(e) If  is any non-zero vector in  and , then
 is an affine hyperplane.
Here is an easy way to manufacture an affine hyperplane. Let  be
a non-zero linear functional. For any real number c, 
is an affine hyperplane. In fact if , then . It is easy to
check that  is a vector subspace of . Since  there is
a vector u in  with . So if  and ,
; that is,  so that the dimension of  must
be p. Note that this is exactly how we got Example 6.7.4(c). In fact if
 
 ,  is the affine hyperplane in that example. This leads to
 the following.
 
6.7.5. Proposition. If , the following statements are
 equivalent.
 
(a)  H is an affine hyperplane in .
 
(b)  There is a non-zero linear functional L on  and a real number c
 such that .
 
(c)  There is a non-zero vector a in  and a real number c such that
 .
 
Proof. The equivalence of (b) and (c) is a consequence of the fact that
 every linear functional L on  has the form  for some
 a in (6.2.8). The fact that (b) implies (a) is in the discussion
 that preceded the proposition. It remains to prove that (a) implies
 (b). If H is an affine hyperplane, fix a vector v in H and consider
 . By definition  is a linear subspace of dimension p.
 Therefore if , we have that . It follows
 that for any x in  there is a unique vector m in  and a unique
 scalar  such that  (Exercise 3). By the uniqueness of
 these objects it follows that  defines a linear functional on
  and . (Verify!) If we put ,
 then . â 
 
What about the uniqueness of the vector a in part (c) of the preceding
 proposition? Here is the answer.
 
6.7.6. Proposition. If H is an affine hyperplane, , and
  such
 that , then there
 is a t in  such that .
 
Proof. Let  and consider . So both  and  are
 orthogonal to . Since , it must be that there is a scalar t
 with . â 
 
So the vector that is orthogonal to an affine hyperplane is not unique, but it's
 close to unique. The frequent practice is to take a unit vector  that's orthogonal
 to H.
Let's establish some notation. As before assume that G is an open
subset of ,  is a differentiable function, and .
Put ; we say that S is the surface in
 associated with f . Note that when  is a differentiable
curve,  defines a curve  and this curve
lies in the surface S. We leave it to the reader (Exercise 4) to prove that  is
differentiable and
 
â(6.7.7)

As usual the vector  is tangent to the curve defined by .
 
 
6.7.8. Proposition. Using the notation above, put . We have
 that
 


Proof. Using (6.7.7) and the fact that , we have that
 


Hence
 

 â 
 
6.7.9. Lemma. With  as above, if  and 
 is a smooth curve with , then there is a smooth curve
  with  and  for all t in
.
Proof. Consider the projection map of  onto  and let 
be its restriction to S; so we know  to be continuous and given by
. Note that  is a map of G onto S and  is its
inverse. In fact, if S has its relative topology, this map is a homeomorphism.
(Verify!) Define  by . Save for verifying that
 is smooth, it is immediate that  has all the desired properties. To show
smoothness it suffices to show that  as in (6.7.7). This is
left to the reader (Exercise 5). â 
Reflect on Proposition 6.7.8. Note that the vector  depends only
on the function f  and the point c in G. In light of the preceding lemma, this
proposition says that this vector is orthogonal to every curve lying in S that
passes through the point . Thus we make the following definition and
say that  is orthogonal to the surface defined by f  at the point
.

6.7.10. Definition. If G be an open subset of ,  is a
differentiable function, and , call


the tangent affine hyperplane to the graph of f  at the point .
Exercises

 (1)  Prove Proposition 6.7.3.
 
 (2)  Verify the statements made in Example 6.7.4(c). Give a basis for 
 when
 .
 
 (3)  Prove that if  is a subspace of  of dimension p and ,
 then for any x in  there is a unique vector m in  and a unique
 scalar  such that .
 
 (4)  Prove (6.7.7).
 
 (5)  In the proof of Lemma 6.7.9 show that  is smooth.
 
 (6) Let  be defined by  and find the tangent
 affine hyperplane to the graph of f  when .
 
 (7) Let  and find the tangent affine hyperplane to the
 graph of f  when .
 
 (8) Let  and find the tangent affine hyperplane
 to the graph of f  at the point .
 
 (9) Let  and
 define  by . For any point c in G find
 the tangent affine hyperplane to the graph of f  at the point .
6.8.  Inverse Function Theorem
We begin this section with a result from metric spaces. While the only use of this
 result in this book is the proof of the title result of this section, it has many uses
 elsewhere in mathematics. There are proofs of the Inverse Function Theorem that
 do not use this fixed point theorem, but its use lends a simplicity to the
 argument.
 


6.8.1. Theorem (Banach5
Fixed Point Theorem). Let  be a complete metric space. If
 is a function such that there is a constant c with 
and


for all  in X, then there is a unique point  in X with .
The point  in the theorem is called a fixed point of .
Proof. Take any point  and put  for all . Note that for
, . Using mathematical
induction we obtain that . 
Claim.  is a Cauchy sequence.
In fact when ,

Provided we take N sufficiently large this can be made arbitrarily small for
.
 
 
Since  is complete there is a point  such that . Note that
 since , we have that ;
 thus  is a fixed point of . If  is another fixed point
 of , then . Since
  this is impossible unless . Thus  is
 unique. â 
 
There are other proofs of this theorem than the one presented. Finding other
 proofs is good, but the proof above is Banach's original one and it has always
 struck me as the "natural" proof. It certainly seems intuitive. Banach's original
 proof also has the advantage in that it tells you how to find the fixed
 point.
 
It is rather easy to manufacture examples illustrating this result. For example,
 if  is defined as the identity function,  for all x, then
  has every point as a fixed point even though it satisfies the inequality but
 with . If instead we let , there are two fixed points. Also see
 Exercise 1.
 
Recall Proposition 2.3.10 where we saw that when  is a
 differentiable function that is bijective, then the function  is
 differentiable and
 


for every  in . Here we wish to extend this result to differentiable
 functions f  from an open subset of  into . Let's underline the fact that
 this concerns a function from a subset of Euclidean space into the space of the
 same dimension. Hence the derivative belongs to  and we can speak of its
 inverse.
 
6.8.2. Theorem (Inverse Function Theorem). Let G be an open subset of
  and assume  is a continuously differentiable function. If
  with  and  is an invertible linear transformation,
 then there is an open neighborhood U of a such that  is open
 in  and f is a bijection of U onto . If  is the inverse of
 , then g is continuously differentiable and for every  in 


Before starting the proof, let's be sure you understand that we already have
this result when . In fact the hypothesis in the case that 
is that . Thus there is a small open interval 
where f  is strictly monotonic. Hence by the result referred to before
the statement of the theorem, f  is bijective and its inverse function is
differentiable.
Proof. Let A denote the invertible linear transformation  and
let . Since  is continuous there is an
 such that  when . Put 
and . We want to show that f  is injective on U and that  is
open; then we'll tackle showing that the inverse of f  on  is continuously
differentiable. Doing these things is not particularly deep, but it is involved.
For any  in  define  by


Note that a point x is a fixed point of  if and only if . So
showing that f  is injective on U amounts to showing that  has a unique
fixed point on U. (By the way, we will not use Banach's Fixed Point
Theorem here. We will use it later when we show that  is open.) Since
, we know there is at least one fixed point x in U. Now
. Hence when ,
. Using Exercise 2 we have
that
 
 
 
â(6.8.3)

 So if both  and  are fixed points of  in U, it must be that .
 Thus  is injective and therefore bijective.
 
Now to show that  is open. This is done as follows. Fix  in , and let
  be the unique point in U with . Choose  such that
 .
 
Claim.  and so  is open.
 
Fix  in  and define the function  as above. Thus
 . If , then (6.8.3)
 implies
 

In other words,  maps  into itself. Because  is compact and
 thus complete, we can apply Banach's Fixed Point Theorem. Therefore 
 has a unique fixed point x and this means , establishing the
 claim.
 
Let  be the inverse of f  on U and let's show that it is continuously
 differentiable. Note that the argument above shows that  is an open
 map. That is, if V  is an open subset of U, the same reasoning will show that
  is open. Equivalently,  is a homeomorphism so that
  is continuous. This implies we need only show that g is
differentiable. Indeed once this is done we can apply the Chain Rule (6.5.13) to
 for x in U and obtain that  on U. Thus
on  we have that  and, by Proposition 6.4.5, g is
continuously differentiable.
To show that g is differentiable we'll use the definition. Fix  in
 and let  with  sufficiently small that . Let
 and . Put  and
. If  exists, the Chain Rule tells us that it should be that
. By definition to show that g is differentiable we want to show the
following:
 
â(6.8.4)

In what follows it is helpful to note that . With this
.
Hence

Since , the right-hand side of this inequality converges to 0 as
, but this happens exactly when . (Why?) This
establishes (6.8.4), showing that g is differentiable. â 

6.8.5. Corollary. If G is an open subset of  and  is
continuously differentiable such that  is invertible for every x in G,
 
 then whenever U is an open subset of G,  is an open subset of .
 
The proof of this corollary is left to the reader in Exercise 3. We
 note that this corollary says that the function f  is an open mapping.
 For this reason it is sometimes called the Open Mapping Theorem. We
 aren't going to use this name as it is more frequently used for another
 result.
 
When  is differentiable, the  matrix that represents the
 linear transformation  in  is given in (6.5.8). To determine if this
 linear transformation is invertible, we could take its determinant. This is denoted
 by
 


and is called the Jacobian6
 of f . We will sometimes refer to this as the Jacobian determinant. We do this
 to make a distinction with the  matrix (6.5.8) which is denoted
 as
 


and is also sometimes referred to as the Jacobian or Jacobian matrix. Another
definition of the Jacobian matrix is applied to differentiable maps 
where it is the  rectangular matrix . Here the notation
is


At this stage the reader might be concerned about the possible confusion, but
in practice the context will make it clear what is being discussed.

6.8.6. Example. (a) Define  by .
Computing the Jacobian yields


Thus  is invertible for any  in the plane so that f  is an
open mapping on . (See Exercise 4.) Since , f  does
not have an inverse on the entire plane.
(b) Many examples are available in  to show the existence of local
inverses but where the function does not have a global inverse. See
Exercise 5.
(c) Here is another example in one variable that illustrates that we must
have the continuity of the derivative. Define  by
 
 


The function f  is differentiable everywhere on the real line with
 . However f  fails to be injective in any neighborhood of 0. The
 reader is asked to supply the details in Exercise 6.
 
Exercises

(1) (a) Is there a continuous function  with no fixed points?
(b) Find an example showing that the condition on  in Theorem 6.8.1
is not necessary for there to be a unique fixed point. (c) Find an example
of an incomplete metric space  and a continuous function  of
 into itself such that  for some constant c
with  and all  in X but where  does not have a fixed point.
 
(2) If , , , and  is a continuously
differentiable function with  for all x in , show
that  whenever . (Hint: Use
Proposition 3.1.10(b).)
 
(3) Give the details of the proof of Corollary 6.8.5.
 
(4) In Example 6.8.6(a) note that  and find the inverse of f 
defined in a neighborhood of .
 
(5) Give an example of a continuously differentiable function f  on  such that
 for every x but such that f  does not have a global inverse.
 
(6) Give the details in Example 6.8.6(c).
 
(7) Define  by . Determine all
the points  where there is a function g defined in a neighborhood
of  with  for all  in this neighborhood.
Justify your answer.
 
(8) Define  by .
(a) Compute the Jacobian matrix (not determinant) of f . (b) Does
the Inverse Function Theorem imply there is a function g defined
in a neighborhood of  such that 
in this neighborhood? (c) Does the Inverse Function Theorem imply
there a function g defined in a neighborhood of  such that
 in this neighborhood?
 
(9) Define  by
 
 

(a) Compute the Jacobian matrix (not determinant) of f . (b)
 Does the Inverse Function Theorem imply there a function g defined
 in a neighborhood of  such that  in this
 neighborhood?
 
 (10)  Recall the Chain Rule (6.5.13) when : if G and H are open
 subsets of ,  is differentiable, , and 
 is differentiable, then  is differentiable and
 

Express the Jacobian determinant  in terms of  and .
 
 (11) Define  by  and show that there is a ball
 B of positive radius and centered at  and a continuous function
  such that  and  for all
  in B. Justify your answer.
 
 (12) Define  by . (a) Does the Inverse
 Function Theorem apply to f  at the point ? If it does not, state why.
 If it does, state what it implies. (b) Does the Inverse Function Theorem
 apply to f  at the point ? If it does not, state why. If it does, state
 what it implies.
6.9.  Implicit Function Theorem
I can remember when I was a student and first encountered the Implicit Function
Theorem. It perplexed me. There is a certain aspect of the theorem that is
mathematically pleasing, but I think at least part of the reason for my confusion
was that the proof is complicated and I couldn't understand why we were doing
all this work. What was the use of this difficult theorem? Let's see if you have
less consternation and irritation than I did on my first encounter. I hope
so.
As far as the purpose of the result is concerned, you can Google "implicit
function theorem economics" and discover a great interest in this theorem by
economists. There are also the uses of this theorem in analysis and especially
geometry, some of which you will see later in this book; but I am afraid that to
see most of this you must wait until a future course. That's true of much of what
you study at this point in your development just as it was for me at the
corresponding stage. We are exploring basic properties of functions and
these underly most of what mathematics is about. This fundamental
understanding has permanent value, but a lot of that value only becomes clear
later.
The difficulty in understanding the result cannot be removed by a magic
wand, but there are some helpful guide posts. You can regard the Implicit
Function Theorem as an extension of the following. If we are given the equation
, this expresses an interdependence of the real variables x and y.
Can I solve for one in terms of the other? Equivalently, can I express one, say y,
as a function of x? The answer is clearly no as the graph of this relation in
the plane is a circle and that's not the graph of a function of x. On the
other hand we can write  and this works for some values of
x.
Let's recast the above problem by writing . If we set
 we say that this equation "defines" y implicitly in terms of x (and
vice versa, x in terms of y). The word "defines" here is set in quotation marks
because for the values of x the corresponding value of y is not unique. So it is
impossible to solve for y in terms of x in a global way, if by solving we mean
expressing y as a function of x. But as we mentioned  works
sometimes; that is, it works locally near some values of x. The key here is to
consider the partial derivative . When this partial
derivative is zero, we cannot get a local solution. Indeed, the partial
derivative being zero corresponds to the points  on the graph of
 and an examination of the graph near these points shows that it
cannot be the graph of a function . As long as we avoid places
where this partial derivative is 0 we can indeed find a function h such
that where h is defined we have that . This condition
involving the partial derivative is the key to the general case. Indeed we have
 
 the following result that is a special case of the general Theorem 6.9.2
 below.
 
6.9.1. Proposition. Let G be an open subset of , let ,
 and let  be a continuously differentiable function such that
 . If , then there exists an open interval I that
 contains a and a continuously differentiable function  satisfying
 the following.
 
(a)  .
 
(b)   for all x in I.
 
We aren't going to prove this now; indeed as was mentioned it is a corollary of
 Theorem 6.9.2. You will be asked later to prove this proposition as a consequence
 of the theorem.
 
Some of the difficulty in stating and understanding the general result stems
 from the complexity of the situation, so let's introduce some notation that might
 be helpful. We consider the Euclidean space  and express it as the direct
 sum . See Definition 6.3.7. Thus  has the elements 
where  and . This is the true orthogonal direct sum: when
  and , then the norm of  as an element of  is
 precisely . Note that the order is important. Though
 mathematically  and  are the same, we are making a distinction for
 the purposes of presenting the Implicit Function Theorem. This theorem
 gives a condition on a function  at a point a in  such
 that there is a function h defined in a neighborhood of a and taking
 values in  for which we have . In other words, in the
 equation  the function h locally solves for y in terms of
 x.
 
We introduce similar notation to that above but now for linear transformations.
 If  we write , where , ,
 and they are defined as
 


This means that . (At the risk of seeming pedantic
but to make sure all have the right idea about what's going on, we emphasize
that the  sign on the right side of this equation is not a mistake; it is not
.)
The idea here is that we have an open subset G of , a continuously
differentiable function , and we are interested in the set
. On this set y is implicitly defined as a function
of x. We would like to know conditions on f  under which we can make this
definition explicit. In other words, where can we define y locally as a
function of x? The following theorem gives a sufficient condition for this to
happen.

6.9.2. Theorem (Implicit Function Theorem). Let G be an open subset of
, let , and let  be a continuously differentiable
function such that . If  and 
is invertible, then there exists an open subset  of  that contains the
point a and a continuously differentiable function  satisfying the
following.
(a)  .
(b)   for all x in .
(c)  .
Proof. Begin by defining  by .
It follows that F is continuously differentiable. (Why?) Also note that
.
Claim.  is an invertible linear transformation in .
Since , we use Proposition 6.5.4 and the fact that 
to get that for  in  we have ,
where  as . Now

Since  as , we have that  is
the linear transformation in  defined by
 
 


So if , then  and . Since the hypothesis is that  is
 invertible, we also get that . Hence  is injective and therefore invertible. (Recall from linear
 algebra that an injective linear transformation on a finite dimensional space is invertible.) This establishes the
 claim.
 
The claim allows us to apply the Inverse Function Theorem to 
 and get an open neighborhood U of  on which F is a bijection,
  is open, and the inverse map  is continuously
 differentiable. Put ; since V  is open, it follows that  is
 open (Exercise 2). Since , . For x in
  we have that  and so  for some y. Hence
 . Because F is injective on U, this  is
 unique. Thus y must be unique. What we have shown is that for every x in  there
 is a unique y in  with . The uniqueness of this y for each
 x in  means we have defined a function  so that for each x in 


Note that h is continuously differentiable since H is (Verify!). Since , we have
 that (a) is satisfied. By definition , so that (b) is satisfied.
 
It remains to show that (c) holds. For convenience let  be the function
 defined by . So for each x in  we have that . In fact
 


where this 1 stands for the identity linear transformation on  and .
We know from (b) that  so the Chain Rule implies that . Now
let . From (a) we have that  so we get . Thus


Since  is invertible, . â 
At this point you should complete Exercise 1, which asks you to prove
Proposition 6.9.1 as a consequence of the theorem.
We will refer to the Implicit Function Theorem as the IPFT. Observe that the
IPFT gives a sufficient condition for the existence of the function h. This
condition is not necessary. This is like the situation with  on ,
where the function has an inverse even though . See Exercise 4. Let's
also note that in the statement of the IPFT rather than the condition
 we could have assumed  for some constant
c and then obtained the function h with  for all x in
. In fact we can do this by just substituting the function  for
f .
The condition in the theorem that  is invertible can be interpreted using
Jacobians. Since , we can write f  using its coordinate functions:
. When we write  in
, we get that the linear transformation  is given by the Jacobian
matrix


The invertibility of this matrix is guaranteed by having its determinant
 non-zero.
 
6.9.3. Corollary. Let G be an open subset of , let ,
 and let  be a continuously differentiable function such
 that . If , then there is an interval
  containing the point a and a continuously differentiable function
  satisfying: (a) ; (b)  for all x in
 ; and (c)
 


See Exercise 5.
 
6.9.4. Example. (a) Can the equation  be solved
 for y in terms of x and z near the point ? To do this write
 , where we reversed the alphabetical
 order of y and z to more easily interpret the IPFT. So . A
 calculation shows that
 


Since this is not 0 at  we can apply the IPFT.
(b) Can we solve the above equation for z in terms of x and y near the
point ? Again a calculation shows that


and we have that . Thus we cannot apply the IPFT.
Exercises

(1) Prove Proposition 6.9.1 as a consequence of the Implicit Function Theorem.
 
(2) Show that the set  in the proof of Theorem 6.9.2 is open. (See
Exercise 6.4.17.)
 
(3) Prove the following version of the Implicit Function Theorem for linear
transformations. If  and  is invertible, then the linear
transformation  satisfies


for every x in . (It's actually easier to just give a direct proof of this
 rather than showing how it follows from the IPFT, but seeing how it is a
 corollary of that result might be instructive.)
 
 (4)  Find a smooth function  with  but where
 there is an open interval  in  that contains 0 and a continuous
 function  such that  and  for all
 x in . Can you get such an example with h differentiable?
 
 (5)  Let G be an open subset of , let , and let  be
 a continuously differentiable function such that . (a) Give a
 sufficient condition on f  that there is an open subset  of  that contains
 a and a continuously differentiable function  such that 
 and  for all x in . (b) Can you express this condition in
 terms of Jacobians? (c) Write out a formula for .
 
 (6)  Consider the two equations
  and . Show that
 near the point  we can solve for u and v in terms
 of x and y.
 
 (7)  Let  and show that there is a continuously
 differentiable function h defined in a neighborhood U of 2 such that
  for all x in U. Compute  for x in U.
 
 (8)  Show that the Inverse Function Theorem can be derived as a consequence
 of the IPFT so that a different proof of the IPFT would yield the Inverse
 Function Theorem as a corollary. (Such a proof exists.)
6.10.  Lagrange Multipliers*
We want to investigate optimization problems for real-valued functions that
 involve constraints on the possible set where the extremum occurs. For example
 suppose we are given an open set G in  and two continuously differentiable
 functions ; and the objective is to maximize the value of
 subject to the constraint that . (We use  here
rather than  in order to be consistent with what comes later.) Such
a problem often arises in geometry, physics, and economics, as well as
other areas of science. You can consider the set  as
defining a surface in , and we are seeking to find the maximum
value of f  on this surface. (We haven't formally defined the concept of
a surface in , but when  this set is a traditional surface
in ; when  it is a curve in the plane. The general definition
will come later and, if you wish, you can just consider it as a subset of
.)
The approach for solving such a problem is to consider the function
 defined by  for some scalar . Why do this?
Suppose we can find a  such that  and c satisfies the constraint
. Since c is a critical point for F there is the possibility that F
has a relative extremum at c. But  since  and
there is the additional possibility that f  has a relative extremum at c.
Clearly this won't always work. Nevertheless in the result below (see
Corollary 6.10.6 and the more general Theorem 6.10.3) we show that under
reasonable conditions this is a necessary condition for f  to have a relative
extremum at c with . That is, we will see that when f  does
have an extremum at such a c then we can find a scalar  such that
. This discussion may seem abstruse, but after seeing
some examples it will become apparent that the method works in many
situations.



6.10.1. Definition. Assume  and G is an open subset of
,  is a continuously differentiable function, , and
 is a continuously differentiable function with . The
function f  is said to have a local maximum at c subject to the constraint
 if there is an  such that when  and ,
we have that . Similarly we can define f  to have a local
minimum at c subject to the constraint . f  is said to have a local
extremum at c subject to the constraint  if f  has either a local
maximum or minimum at c subject to this constraint.
It is probably needless to point out that the problem of finding
the local minimum of f  subject to the constraint  is the
same as finding the local maximum of  subject to the same
constraint. Also the use of 0 in the constraint is arbitrary; any constant
would do. Indeed we could have considered constraints of the form
, where h is another continuously differentiable function on G. This
 
 reduces to what was described in the preceding definition by simply replacing
 this constraint by the one .
 
6.10.2. Example. (a) Suppose in the definition above , , and
  is defined by . We note that the
 set  is the surface of the unit ball centered at the
 origin, the so-called unit sphere. So if we are given a function ,
 the object would be to maximize or minimize f  over this sphere.
 
(b) Find the maximum and minimum values of 
 on the ellipsoid . (We'll solve this problem below in
 Example 6.10.9 after we prove Corollary 6.10.6.) Note that f  does have a
 maximum and a minimum since it is continuous and the ellipsoid is compact.
 
Adopt the notation in Definition 6.10.1. As in Â§6.9 we write .
 That is, points in  are written as  with x in  and y in . In
 particular the distinguished point c in G is written as . For the set G
 let
 


Next define the function  by
 


Hence . The notation  seems more appropriate than , but for
  we write the coordinate functions  of 
 as


where  is the standard basis for . So the notation  is already
taken. With this notation established we can state the theorem, which gives a
necessary condition for the constrained extremum to exist.



6.10.3. Theorem (Lagrange7
Multipliers). Assuming the notation established in the preceding paragraph, if f
has a local extremum at c subject to the constraint 
and
 
â(6.10.4)

then there is a vector  in  such that
 
â(6.10.5)
We will only prove this result when . The proof of the general theorem
 is notationally complicated involving matrices and it isn't clear that it's worth
 the effort. The interested reader can see [15] or [11] for a proof. After stating and
 proving the corollary we give a more matrix oriented way of viewing the
 hypothesis and conclusion of the theorem.
 
6.10.6. Corollary. Let G be an open subset of , ,
  a continuously differentiable function, and  a
 continuously differentiable function with . If f has a local extremum
 at c subject to the constraint  and ,
  is defined as , and
 


then there is a  in  such that
 


Thus  has a critical point at c.
 
Proof. Writing out the components of the equation , we see
that we want to find a scalar  such that
 
â(6.10.7)

Using the hypothesis that  we define


We recognize that this definition of  is precisely (6.10.7) when ;
it remains to show that we have this equation for the other values of j. To do this
we will use the fact that f  has a local extremum at c subject to the
constraint.
We apply the IPFT. Since  there is an open neighborhood  of
a in  and a continuously differentiable function  such
that  and  for all x in . We will use the
observation that because f  has a local extremum at c subject to the constraint
 this implies that the map  of  into  has
an unconstrained local extremum at a. (Verify!) Therefore by Theorem
6.2.20 all the partial derivatives of the function  defined by
 must vanish at a. We need to compute. Since  is the
composition of f  and , the Chain Rule implies that for




Hence for 
 
â(6.10.8)
Now we need to apply the Chain Rule again. Since  on ,
 we have that the partial derivatives of  are all 0. Therefore for
 

Since , this last equation implies that
 


Again using the hypothesis, this implies that


Substituting this into (6.10.8) we get that

which is exactly the sought after (6.10.7). â 
 
Let's
 reflect
 on
 the
 preceding
 proof.
The challenge was to find one number  that simultaneously solved the
 equations (6.10.7). Perhaps it was surprising that we obtained the
solution for all the equations by solving one of them, the -st. To bring
this about we used the existence of the constrained extremum and the Implicit
Function Theorem. That will set the pattern for the solution of the general
theorem if you consult the references.


6.10.9. Example. Find the maximum and minimum values of 
 on the ellipsoid . This is the situation in the above corollary
 where , , and . Let  and note
 that
 

Setting these three coordinates equal to 0 we see we must find all possible values
 of  such that the following four equations have a solution for  and
 z:
 
 
â(6.10.10)

 If we have , we see that  while . Thus we have two
 critical points
 


Now assume . The first observation is that this forces . We also
see that we must consider the two cases when  and . In the first
case we get there are two more critical points


When  it has to be that ; consequently . Thus from the
last of the equations in (6.10.10) we have that . This produces two more
critical points


Now it's a matter of calculating the value of f  at each of the critical
points:

Therefore the function f  has constrained maximums at  and
constrained minimums at .
 
 
Let's examine what (6.10.4) and (6.10.5) mean in terms of matrices. When
 you apply the theorem, you are quite likely to use systems of equations. Let's
 start by using the Jacobian determinant to interpret the first of these, which is
 equivalent to
 
 
â(6.10.11)

 Now , so that . Hence when
  we have that  as is . Hence the conclusion
 (6.10.5) can be phrased as saying we want a  in  that
 satisfies the two sets of equations
 
 
â(6.10.12)

 and
 
 
â(6.10.13)
We can find a  in  such that (6.10.12) holds since this set of equations
translates to the requirement that


and in light of the assumption (6.10.4) we can find such a . The objective of
the proof of the main theorem is to show that for this same  the equations
(6.10.13) are also satisfied. As we did when we proved Corollary 6.10.6 this is
achieved by an application of the Implicit Function Theorem and the fact
that when a scalar-valued function has a relative extremum its gradient
vanishes.

6.10.14. Example. Minimize  subject to
 and . Let's point out that relative
to Theorem 6.10.3 , , and
.
Also the two sets in  where  and
 are affine hyperplanes (6.7.3). So the constraining set
where  is the intersection of these two affine hyperplanes. Therefore
this example asks to find the (square of the) distance from the origin in 
to the intersection of the two affine hyperplanes. This example is from [12]
where the reader can find the solution on page 14.
 
 
Exercises

 (1)  Find the extrema of  subject to .
 
 (2)  A rectangle has perimeter p. Find its largest possible area.
 
 (3)  A rectangle has area A. Find its smallest possible perimeter.
 
 (4)  (a) Show that
  has only one critical point on the surface 
 (b) Show that at that critical point f  has a constrained minimum. (c) Why
 isn't there a constrained maximum?
 
 (5)  Find the extreme values of  subject to
 .


1Pythagoras of Samos was born around 569 BC in Samos, a city in Ionia. Little is known about him,
especially since none of the work he wrote still exists. He was the leader of a society dedicated to science
and religion, and some of the ancient books claim that he had divine powers. When he was a
young man Thales introduced him to mathematics, and it is likely that Anaximander, a
student of Thales, gave a series of mathematical lectures that Pythagoras attended. All dates
here are dubious, but around 535 BC he traveled to Egypt. From here he adopted many
practices of Egyptian priests, which he later imposed on the members of his society. These
included the refusal to wear anything made from an animal skin and an abstinence from eating
beans. In 525 BC the Persians invaded Egypt and brought Pythagoras to Babylon. In 520 BC
he left there and returned to Samos; there is no explanation how he obtained his freedom.
After founding his society, in 518 BC he went to southern Italy. Apparently while he was in
Samos he used the "symbolic method of teaching" and the Samians did not approve. In
what is present day Crotone, half-way up the heel of Italy, he founded a mathematical and
philosophical society. One of their beliefs was that at its deepest level, reality is mathematical in
nature. This present theorem (in two-dimensions) was known to the Babylonians 1000 years
before Pythagoras, though it is likely he was the first to prove it. He introduced abstraction
into mathematics and made many other discoveries in geometry, including that the sum of
the interior angles of a triangle equals two right angles. He was also intensely interested in
numbers and discovered the irrationals. He died about 475 BC. The Pythagorean Society
continued after his death but they made powerful enemies. Eventually they were attacked and
some 50 or 60 members were killed. Those who survived took refuge at Thebes and other
places.
2Jorgen Pedersen Gram was the son of a farmer, born in 1850 in Nustrup, Denmark.
In 1868 he began his university education, receiving a masters degree in 1873. When he
received this degree he had already published his first paper in algebra. In 1875 he began
work with an insurance company, but this work led him into a study of probability and
numerical analysis. He soon published a paper on these topics. As a result of this paper
he was awarded a doctorate in 1879. His work here, which he also applied to forestry, led
him to study abstract problems in number theory. He continued working at the insurance
company but was invited to lecture in the Danish Mathematical Society. For his work the
Videnskabernes Society awarded him their Gold Medal in 1884. He married twice. The first time in
1879 and the second in 1896, just over a year after his first wife's death. He died in 1916 in
Copenhagen; he was on his way to a meeting of the Videnskabernes Society and was struck by a
bicycle.
3Erhard Schmidt was born in 1876 in what is today Tartu, Estonia. His early education was typical of
someone who was born to a professional family. (His father was a medical biologist.) He began his
university studies in Berlin and went to GÃ¶ttingen where he obtained his doctorate under the supervision
of Hilbert; his thesis was in integral equations. He went to Bonn and this was followed by several
academic posts before he was awarded a professorship at Berlin in 1917. He was quickly drawn into
administrative matters involved with filling recently vacated faculty positions. He is credited with
establishing applied mathematics at Berlin. Needless to say his role at the university was difficult during
the Nazi era. Many of his Jewish colleagues were forced out of their positions. Some have
criticized his role in this and others have defended it. In the final analysis his reputation
survived. The present result was obtained by Schmidt independently in 1907. There are
also the Hilbert-Schmidt operators named after him. He deserves a place as one of several
mathematicians who founded the abstract theory of functional analysis. He died in 1959 in
Berlin.
4Charles Hermite was born in 1822 in Dieuze, France, which is east of Paris near the German
border. In 1840 he went to school at CollÃ¨ge Louis-le-Grand in Paris, 15 years after Galois studied
there. His tendency was to read original papers of mathematicians rather than work to pass the
exams. Nevertheless, with a somewhat average performance on the entrance exam, he was admitted
to the Ãcole Polytechnique. Unfortunately he had a birth defect that resulted in a malformed foot
and because of this he was told he had to leave. (From today's perspective, this is truly amazing;
but such things happened.) An appeal led to a reversal of the decision, but strict conditions were
imposed on him and he decided to leave. On his own he pursued his studies, all the while doing
research. In 1847 he passed the exams to receive the baccalaurÃ©at. A year later he was appointed
to the faculty at Ãcole Polytechnique, the same school that had made life difficult for him. He
worked on number theory and algebra, orthogonal polynomials, and elliptic functions, with several
important contributions. The Hermite polynomials are named after him, and he was the first to
prove that the number e is transcendental - that is, it is not the zero of any polynomial with
rational coefficients. He had nine doctoral students, including PoincarÃ© and Stieltjes. He died in
1901 in Paris.
5Stefan Banach was born in 1892 in Krakow, presently in Poland but then part of Austria-Hungary
(Polish history is complicated). In 1922 the university in Lvov (a city that during its history has
belonged to at least three countries and is presently in Ukraine) awarded Banach his habilitation for a
thesis on measure theory. His earlier thesis on Integral Equations is sometimes said to mark the birth of
functional analysis. He was one of the stars in a particularly brilliant constellation of Polish
mathematicians during this period. Banach and his colleague Hugo Steinhaus in Lvov as well as other
mathematicians in Warsaw began publishing a series of mathematical monographs. The first to appear in
1931 was Banach's ThÃ©orie des OpÃ©rations LinÃ©aires, which had an enormous impact on
analysis and continues to hold its place as a classic still worth reading. Banach was one of the
founders of functional analysis, which had been brewing in academic circles for some time.
You will see Banach's name appear often if you ever study the subject. He died in Lvov in
1945 just after the end of World War II and has many results besides this one that bear his
name.
6Carl Jacobi was born in Potsdam, Germany in 1804. He was tutored at home by his uncle until he
was 12 and entered the gymnasium in Potsdam. After a year he was judged ready for the university, but
remained at the gymnasium for another three years because at the time the University of Berlin would
not accept students under the age of 18. Four years later he had completed his doctoral dissertation and
obtained a post at a prestigious gymnasium in Berlin. He soon became a Christian, permitting
him to obtain a position at the university in Berlin (you read that correctly) and then he
transferred to KÃ¶nigsberg. His early work on number theory attracted the attention of Gauss. He
also obtained results on elliptic functions that attracted Legendre. In 1831 he married and
in 1832 was promoted to a full professorship. He conducted fundamental work on partial
differential equations, but in 1843 he was diagnosed as a diabetic and this caused him severe
problems. He went to Italy to recover. The weather agreed with him and he resumed his
publications. It was around this time that he returned to a position in Berlin starting in 1844.
There followed a particularly turbulent period in Prussian history and Jacobi fell out of
favor because of his political beliefs. In January 1851 he caught the flu, which was a more
serious event then than now. In his weakened condition he also contracted smallpox and soon
died.
7Joseph-Louis Lagrange is claimed by many Italian mathematicians as their countryman, and with
justification in spite of his French name. Both his parents were Italian, he was born in Turin, Italy in
1736, and he was baptized Giuseppe Lodovico Lagrangia. He did have French ancestors and as a
youth called himself Lagrange. He studied at the college in Turin and came reluctantly to
mathematics. In fact he once wrote, "If I had been rich, I probably would not have devoted myself to
mathematics," which certainly seems like a non-sequitur to a modern reader. His early work on the
calculus of variations attracted the attention of Euler and at the age of 19 he was appointed
professor of mathematics at the Royal Artillery School in Turin. He continued to work on
analysis and astronomy. Eventually he succeeded Euler as Director of Mathematics at the
Berlin Academy in 1766. A year later he married his cousin, Vittoria Conti. She died in
1783 and they had no children. In 1787 he left Berlin to become a member of the AcadÃ©mie
des Sciences in Paris, where he remained for the rest of his career. His work covers a wide
range of topics from number theory to astronomy, with numerous publications. Napoleon
named him to the Legion of Honour and Count of the Empire in 1808. In 1813 he died in
Paris. 












7 Integration
in
Higher
Dimensions
Here we will extend the development of the Riemann integral of functions defined
on the real line, as seen in Chapter 3, to the integral of functions defined on
subsets of . The objective of this chapter is not to give the most exhaustive
treatment of this integral in , far from it. Those who wish to see such a
treatment can consult the books [11] and [15]. In the next level of a course in
analysis, a far more general theory of integration is developed. (It's called
Lebesgue integration after its discoverer.) What we want to do here is to
prepare the reader to tackle the uses of the integral in  that we'll
encounter later in this book. In many ways what we seek to do here
is to explore and understand situations in  where integration can
be reduced to what we did in Chapter 3. In that sense the key is Â§7.3
below where integrals in  are reduced to a succession of integrals in
.
We'll start with a much less complicated situation where we continue to
integrate over an interval in  but the functions we integrate will be vector
valued.
7.1.  Integration of Vector-valued Functions
In Â§6.1 we discussed continuity and differentiability of vector-valued functions
 and we saw there were few difficulties in this. Here we discuss
the integration of such functions and again we'll see that the theory is
 
almost the same as what we did when we defined the integral of functions
.
We could discuss Riemann sums of functions  in parallel with
what we did in Chapter 3, but rather than risk possible boredom we'll just use
what we developed there and go forward. Given a function , for
 define a function  by


where, as usual,  is the standard basis for . Now
define
 
â(7.1.1)

So  is a vector in . The reader can easily scan the results from Chapter
3 to see that they almost all carry over to this setting. In particular the FTC is
valid: If  is continuously differentiable, then .
One of the few exceptions to this idea that Chapter 3 results carry over to the
integration of vector-valued functions is the Mean Value Theorem for integrals
(Theorem 3.2.4). See Exercise 1. The interested reader can look as much as
(s)he wants at the details of this new integral, but we'll spend the rest of
this section looking at the integral from Chapter 3 as applied to a new
concept.
 
 
Recall (6.1.2) that a curve in  is a continuous function  and
  is called its trace.
 
7.1.2. Definition. If  is a smooth curve, then the length or
 arc length of  is defined as
 


If  is continuous on  and smooth on the intervals  for
 , where  is a partition on , then we
 define the length of  as
 


We should point out that since  is continuous as is the function 
 from  into , the function  is the composition of two
 continuous functions; thus it is integrable and the preceding definition is
 legitimate.
 
7.1.3. Example. (a) If , define 
by . So  traces out the straight line segment in
 from x to y. Here , as expected.
(b) Recall the definition of a polygon  in (Exercise
5.6.12). If  is this polygon, then  is piecewise smooth and
.
(c) If  is a continuously differentiable function and
 is defined by , then


In fact , so that .
(d) More generally, if  is a continuously differentiable
function and  is defined by ,
then


7.1.4. Proposition. If  is a smooth curve and ,
then there is a partition  such that
 
 


Proof. The lack of a MVT for vector-valued functions (Exercise 6.1.4)
 creates a bit of a complication for the proof and we must introduce an
 auxiliary function F. Let  for all t in ,
 let  be the cartesian product of the interval  with itself p
 times, and define  by .
 Observe that F is a continuous function on a compact set, and thus is
 uniformly continuous. Hence if  there is a  such that for
  in  with  we have that
 . In particular since , we have
 that if  satisfies  for ,
 then
 
 
â(7.1.5)

 Now we apply the one-dimensional MVT to each  to conclude that for
  we can find a point  in  with


Therefore for each  we have that


Note that for  we have that , so
that . Hence

Similarly
 
 


Combining these inequalities with (7.1.5) we get that
 


proving the proposition. â 
 
So this proposition says that  can be approximated as close as desired by
 the length of an inscribed polygon  (Example 7.1.3(b)). This
 justifies defining the length of the curve  as we did. Also see Exercise
 2.
 
A problem arises from defining a curve as a function. Is there a difference
 between the curve  defined by  and the
 curve  defined by ? These curves describe
 the same set of points and they should have the same length. Here is how we
 address this.
 
7.1.6. Definition. If  and  are two smooth
 curves, say that  is equivalent to  if there is a continuously
 differentiable, strictly increasing surjection  such that
  for all t in . In symbols we write . We also say
 that  is a reparametrization of .
 


Note that since the inverse of a continuously differentiable, strictly
increasing surjection is a continuously differentiable, strictly increasing
surjection, it easily follows that  is an equivalence relation on the set of
all smooth curves in . (Exercise 7). Clearly equivalent curves trace
out the same subset of . Now we show that the definition of the
length of a curve is independent of which parametrization of the curve we
take.

7.1.7. Proposition. If  and  are equivalent curves in , then
.
Proof. Adopt the notation of the preceding definition. By the COV
Theorem (3.2.5)


 â 
Strictly speaking we should have defined a curve as an equivalence class of
functions using the equivalence relation  defined above. Instead we opted for
a less stringent approach.
It might have been observed by the reader that the last proposition
remains valid if we allow the reparametrization function  to be strictly
decreasing. We insist that  for a reason that will appear in Chapter
8.
Exercises

(1) If  is defined by , then there is no point c in
 
  such that .
 
 (2)  Show that if  is a smooth curve, then
 


 (3) Are the curves  and  defined by
  and  equivalent?
 
 (4)  Let  be the helix defined by  and
 compute its length.
 
 (5)  Define  by  and compute .
 
 (6)  Compute the length of the graph of the function  with
 .
 
 (7)  Show that  defines an equivalence relation on the set of all smooth
 curves in .
7.2.  The Riemann Integral
In this section X always denotes a bounded subset of  and
  is a bounded function. 
A rectangle in  is a set of the form
 


where ,  are points in , and  for .
(The notation  is a convenient shorthand and the context will usually
prevent confusion with a closed interval in .) We will also refer to the volume
of R as the number 


Two rectangles in  are non-overlapping if their intersection has empty
interior. Equivalently, if , then R and S are
non-overlapping if , where I hope the meaning of 
and  as the open rectangles in  is clear. Equivalently they are
non-overlapping if , where this intersection could be empty.
When , say that a finite collection of rectangles  is a
R-cover of X if these rectangles are non-overlapping, , and
 for . (This last restriction is included to prevent
trivialities.) Note that the fact that we are assuming that X is always a bounded
set means we can always find a R-cover of X. More on this in the following
example.) In  a R-cover will play the role that a partition of an interval did
in Chapter 3.

7.2.1. Example. (a) An easy example of a R-cover of a bounded set X is
, where R is a rectangle that contains X.
(b) When , what we call a rectangle is just a closed interval and
its volume is the interval's length. A R-cover of  in this setting is
just a partition of the interval, though the way we defined a R-cover  of
 allows some of the intervals in  to extend outside of .
(c) In  a rectangle is what we usually call a closed rectangle and
two rectangles in  are non-overlapping if their intersection is contained
in the intersection of their sides. If X is a bounded subset of , then
we can form a R-cover of X as follows. Draw a grid consisting of vertical
 
 and horizontal lines such that these lines do not accumulate anywhere. (You
 could achieve this by requiring all the vertical and horizontal lines to be
 separated by at least some minimum distance, though this is not the only
 way to do this.) This grid defines an infinite collection of non-overlapping
 closed rectangles. Now discard all the rectangles that are disjoint
 from X. Because X is bounded, only a finite number of rectangles remain.
 For future reference note that by making the distance between the vertical
 and horizontal lines smaller we can make the R-cover finer, a term made
 precise below.
 
(d) In  a rectangle is a parallelepiped whose faces are two-dimensional
 rectangles; that is, it is a box. Two such rectangles are non-overlapping if
 their intersection is contained in the intersection of their faces.
 
(e) Extending what was done in (c), if X is a bounded
 subset of , then we can form a R-cover of X as follows.
 Fix each coordinate j, , choose a doubly infinite sequence
 , where  as . Now consider the
 countable collection of affine hyperplanes . The
 collection of these hyperplanes  forms a
 p-dimensional grid in  and the resulting rectangles that meet X forms
 a R-cover of X. You might follow this when  to see this is what we
 did in part (c) and then follow it through when .
 
 The conceptual difficulties in making the transition in integration 
 from the line to higher dimensional Euclidean spaces already manifest  
 themselves when we consider . 
Maybe that is somewhat contradicted for the reader when (s)he passed from
 part (c) in the last example to part (e); but that difficulty is more technical than
 conceptual. As the reader progresses, (s)he can achieve a good deal of
 understanding by thinking in terms of the plane and seeing what the results say
 there.
 
If  and  are two R-covers of X say that  is a refinement of  if
 each rectangle in  is contained in a rectangle from . Let's note
 that we have that , but, unlike when we consider
 partitions of a compact interval in , we do not insist that these two unions
 are the same. Indeed to require that as well as having every rectangle
 in the finer R-cover  meet X is often impossible. Let's note that if
  and  are any two R-covers of X,
 then  is a refinement of
 both  and . When we are given a R-cover  of X and ,
 let
 

and let


(We will use the notation  and  when we are discussing more
than one R-cover at the same time.) The term  is called the
upper sum of f  for the R-cover  and  is called the lower sum.

The proof of the next proposition is similar to the proof of Proposition 3.1.2
and is left to the reader as Exercise 2.

7.2.2. Proposition. Assume R is a rectangle in  that contains X.
If  with  for all x in X and  and  are
R-covers of X that both refine the R-cover consisting of R alone, then the
following hold.
(a)  .
(b)  If  is a refinement of , then


(c)  If  is a refinement of , then
 


7.2.3. Definition. Using the preceding proposition we have that for any
 bounded subset X of  and any bounded function 


When these two quantities are equal, we set
 

In this situation we say that f  is Riemann integrable or just integrable. The set of
 all Riemann integrable functions on X is denoted by .

Note that the above definition only applies to bounded subsets X and
bounded functions f . These assumptions may be omitted when we state results
but they are always assumed.
In the preceding definitions we see a hint of a difficulty in extending the
Riemann integral from the line to higher dimensional Euclidean space. In  we
restrict our attention to integrals over intervals and this allows us to partition
them. In  we want to integrate over sets that are not rectangles. (For
example, integration over balls and similar sets.) You might say that we should
consider covers by sets more general than rectangles, but then how do we
define their volume? This lack of simplicity will cause us difficulty as we
proceed.
As in Â§3.1 several results follow. Their statements and proofs follow their
analogues in Â§3.1. The first such result is similar to that of Proposition
3.1.4.

7.2.4. Proposition. If f is a bounded function, then f is Riemann
integrable if and only if for every  there is a R-cover  of X such
that . Moreover  is the unique number such
that for every refinement  of  we have


The next is the analogue of Corollary 3.1.5.

7.2.5. Corollary. If f is a bounded function, then f is Riemann integrable
if and only if there is a sequence of R-covers  of X such that each
 is a refinement of  and  as .
When this happens we have that
 
 


The next two results give some elementary properties of the integral that
 extend their counterparts in Â§3.1. No proofs will be given.
 
7.2.6. Proposition. Assume that X is bounded, R is a rectangle
 containing X, and .
 
(a)  If  for all x in X, then
 


(b)  If  for all x in X, then
 


7.2.7. Proposition.  is a vector space over . Moreover if
  and , then  and


There are some very complicated subsets of , to say nothing of higher
dimensional spaces. The interested reader might play with Exercise 3 for a
strange example. The difficulty in developing the Riemann integral for higher
dimensions occurs at the boundary of the set X. Here we introduce a collection of
sets which are simultaneously abundant and on which there are many integrable
functions.




7.2.8. Definition. If , say that E has volume zero if for every
 there is a R-cover  of E such that


A set X in  is called a Jordan1
set if it is bounded, , and its topological boundary, ,
has volume zero.
We'll see that Jordan sets are the proper places to do Riemann integration. As
we progress we'll establish several results implying that a set is a Jordan set. An
example of a set that is not a Jordan set follows. To find a closed set that is not a
Jordan set is more difficult. But, as we said at the start of this chapter, our aim
is not to explore the boundaries of the theory of integration in  but rather to
 
 establish places where the theory works and can be applied to the business at
 hand.
 
7.2.9. Example. (a) It is easy to see that any finite set in  has volume
 zero. So in  the union of a finite number of intervals is a Jordan set.
 
(b) The set  is not a Jordan set
 since . Also, adapting the argument used in Example
 5.3.8(a) we see that  and this certainly does not have
 volume zero.
 
(c) If  are sets of volume zero, then  has
 volume zero. Indeed if  let  be a R-cover of  such that the
 sum of the volumes of the rectangles is less than . We would like to put
  equal to the union of all the rectangles in each of the .
 However some of the rectangles in this union may not be overlapping.
 This, however, can be fixed by considering all the possible intersections of
 rectangles from the . See Exercise 5. Once this is done we have a R-cover
 and the sum of the volumes of its rectangles is smaller than , proving that
 X has volume zero.
 
7.2.10. Proposition. A closed rectangle in  is a Jordan set.
 
Proof. Let . If  there is a
  such that if we set , then
  and . The remainder of the proof consists in
 showing that there is a R-cover  of  that is contained in , thus
 implying that the sum of the volumes of the rectangles in  is smaller
 than . (You might want to draw pictures of the next argument when
 . The general argument is a bit cumbersome.) For each 
 consider the partition  of  and form the grid
 of hyperplanes (as in Example 7.2(e)) determined by these values in each
 dimension. Let  be the rectangles determined by this
 grid that intersect . Thus  is a R-cover of , and, moreover, each
 . It follows that . â 
 
To prove that a set is a Jordan set we need results that tell us when a set has
 volume zero. The next one will be useful.
 
7.2.11. Proposition. If Y is a compact subset of  and 
 is a continuous function, then  is a compact subset
 of  having volume zero.
Proof. The fact that W  is compact follows from the observation that
 is a continuous function from Y  onto W . Let  and let
R be a fixed closed rectangle in  such that ; put .
Because Y  is compact and g is continuous it follows that g is uniformly
continuous. Hence there is a  such that  when
 with . Let  be a R-cover of Y  such
that each  and . For  choose a point 
in  and put


Observe that . In fact,
if , then  and there is a j such that . Thus
 and so . Hence . Also
. Thus . Since  was
arbitrary this proves that W  has volume zero. â 
Let's point out that if  and we can cover X by a finite number of sets
having the form of W  in the preceding proposition, then X has volume zero. (See
Example 7.2.9(c) and Exercise 4.)

7.2.12. Corollary. If  and , then  is a Jordan
set.
Proof. Let  and . Define
 by . By the proposition
 has volume
zero. It follows that  and  have volume zero (Why?). Since
,  has volume zero. â 
 
 
We might mention that the continuous image of a set of volume zero need not
 have volume zero. Indeed look at the preceding proof and examine the continuous
 function  from W  onto Y . However when the continuous function
 has its image in the same Euclidean space the story is sometimes different. See
 Proposition 7.4.2 below.
 
The next result is crucial for our progress. It also illustrates how assuming X
 is a Jordan set can be used to overcome some natural difficulties.
 
7.2.13. Theorem. If X is a Jordan set in  and  is uniformly
 continuous, then f is integrable.
 
Proof. As usual X is bounded and R is a rectangle such that ;
 put . Let  such that  for all x in X. If
 , the uniform continuity of f  implies there is a  such that
  for all  in X with .
 
Let  be a R-cover of X such that each rectangle that belongs to  has
 diameter smaller than . (Do this first when  and then examine
 the technique in Example 7.2(e).) Consider . This
 forms a R-cover of . Since X is a Jordan set we can find a refinement
  of this R-cover of  with . Let
  be a collection of non-overlapping rectangles such that
  is a R-cover of X that refines  (Exercise 12). Note that each
 rectangle in  has diameter smaller than .
 
For  and  let  be defined by
 , etc. Because of the choice of  and the fact
 that each rectangle in  has diameter smaller than , we get that
  for . Hence
 

By Proposition 7.2.4, f  is integrable. â 
Also see Exercise 11.

7.2.14. Corollary. If X is a compact Jordan set and  is a
continuous function, then f is integrable.
The next result and its corollaries will be used later in this chapter.

7.2.15. Proposition. If U and X are Jordan sets with U open, X compact,
and , then  is a Jordan set. If  is a continuous
function, then


Proof. Note that  because . So  is
the union of two sets having volume zero and thus has volume zero (Exercise
 
 4). Hence  is a Jordan set.
 
Now let  be a continuous function. Since every continuous
 function can be written as the difference of two continuous non-negative
 functions, without loss of generality we may assume that . Let
  for all x in X, , and let . Since X is
 compact, f  is uniformly continuous and there is a  such that
  when . Begin by making a R-cover 
 of X such that the diameter of every rectangle in in  is less than
 . Because of this restriction no rectangle in  can
 meet both  and . Let  be a R-cover of  that
 refines  and such that . Let
  be a R-cover of  that refines 
 and such that . Now let  be a R-cover of X that
 refines , , and . That is, every rectangle in  is the union
 of rectangles from . Note that  is a R-cover of X and we still have
 that each rectangle in  has diameter less than .
 Let  be the rectangles in  that meet  and let
  those rectangles in  that are contained in . It
 follows that .
 
Now let , which is a R-cover of U.
 Since the closed set  contains U, it contains . Let
  be those rectangles in this R-cover that meet  and
 let  be those contained in U. Hence .
 

 Let . Since 
 are the rectangles in  that meet  and 
 those that meet , this makes  a R-cover of . Put
 . Hence .
 
Now  and , and  are pairwise disjoint
 collections. Similarly  and . Therefore
 

Now

Also


So  belongs to the interval  and 
belongs to the interval . So the distance between 
 
 and  is at most . Since  was arbitrary, this completes
 the proof. â 
 
Also see Exercise 13.
 
7.2.16. Corollary. If X is a compact Jordan set and  is a
 continuous function, then
 


Proof. Let  in the preceding proposition and use the fact that
 because  has volume zero, . â 
 
7.2.17. Corollary. If  are pairwise disjoint open Jordan sets,
 , and  is uniformly continuous, then U is a Jordan
 set and
 


Proof. It follows that  and so U is a Jordan set. If ,
put . Then Proposition 7.2.15 and the preceding corollary imply


Now use induction. â 

7.2.18. Corollary. If  are compact Jordan
sets such that for , , ,
and if  is a continuous function, then X is a compact Jordan set
and


Proof. Since X is the union of a finite number of compact sets, it is compact.
Also the hypothesis implies that ; hence X is a Jordan set.
Note that the open sets  are pairwise disjoint. Using
the preceding results we have that
 
 


 â 
We conclude this section with a definition.
 
7.2.19. Definition. If  and the constant function 1 is integrable on
 X, then define the volume of X as
 


We note that this means that in light of Theorem 7.2.13 we can define the
 volume of every Jordan set. Also since each rectangle is a Jordan set (7.2.10) we
 have just given a second definition of the volume of a rectangle. However in the
 next section on iterated integrals we'll show that the two definitions
 are the same (Theorem 7.3.9). The proof of the next result is Exercise
 17.
 
7.2.20. Proposition. (a)  If  are pairwise disjoint open
 Jordan sets and , then .
 
(b)  If  are compact Jordan sets such that for ,
  and , then .
 
 
Exercises

(1) If R and S are two rectangles and , show that .
 
(2) Prove Proposition 7.2.2 using Proposition 3.1.2 as a guide.
 
(3) Show that there are open disks  in  of
radius  having the following properties: (i) 
and  for ; (ii) ; (iii)
 has no interior. The set K is called a Swiss
cheese2.
Does K have zero area? 

(4) Prove that the union of a finite number of sets having volume zero also has
volume zero.
 
(5) If  are bounded sets and for  we are
given a R-cover  of , show that there is a
R-cover  of  such that if , then
. Apply this to verify Example 7.2.9(c).
 
(6) Can you use Proposition 7.2.11 to give an induction argument that shows
that a rectangle is a Jordan set?
 
(7) If X is a bounded subset of  and we consider X as a subset of ,
show that X has volume zero as a subset of .
 
 
 (8)  Let , , . If g is integrable on Y ,
  for all y in Y , and  has volume zero, show that f  is
 integrable on X and .
 
 (9)  (a) If X and Y  are Jordan sets in  and , respectively, then 
 is a Jordan set in . (b) Use part (a) to give another proof of Proposition
 7.2.10.
 
 (10)  Can you use Exercise 3 to manufacture a compact set that has no interior
 and does not have volume zero?
 
 (11)  If X is a Jordan set and  is a uniformly continuous function,
 show that for every  there is a R-cover
  of X such that: (a)  are the
 rectangles in  that meet  and ; (b) 
 are the rectangles contained in  and if  for , then
  (Hint: See the proof of Theorem 7.2.13.)
 
 (12)  Show that the collection of non-overlapping rectangles  in the proof of
 Theorem 7.2.13 exists.
 
 (13)  Let  and  be disjoint Jordan sets and assume that
  is uniformly continuous. Is it true that  is a
 Jordan set and ?
 
 (14)  If V  is an open set in ,  is a bounded continuous function,
 and 
 for every compact Jordan set X contained in V , show that  for
 every x
 in V .
 
 (15)  Assume X is a Jordan set and for each ,  is an integrable function
 on X. If  converges uniformly on X to a function f , show that f  is
 integrable on X and .
 
 (16)  Let X be a Jordan set and assume f  is an integrable function on X. If
 there is a compact subset K of  with  and  is
 continuous, show that  is integrable on X.
 
 (17)  Prove Proposition 7.2.20.
7.3.  Iterated Integration
Here we want to examine certain compact Jordan subsets of  and show that
we can calculate the integral of a continuous function as we did in calculus by
iterating the integrals; that is by putting together integrals over subsets
contained in subspaces of smaller dimension. To get started, however, we
establish a result that doesn't involve integration.

7.3.1. Proposition. If X and Y are compact subsets of  and ,
respectively, Z is a compact subset of , and  is the linear span in
 of the set of restrictions


then  is dense in .
Proof. This
proof is an easy consequence of the Stone-Weierstrass Theorem (5.7.11).
Observe that  is a subalgebra of  that contains the constant
functions and separates points in Z (Verify!). Hence the same holds for its
closure, so the Stone-Weierstrass Theorem implies . â 

7.3.2. Corollary. If X and Y are compact subsets of  and ,
respectively, and  is the linear span in  of


then  is dense in .
 
7.3.3. Corollary. Let X be a compact subset of  contained in the
 rectangle . If  is the linear span of
 


then  is dense in .
 
Proof. This follows from Corollary 7.3.2 by using induction (See Exercise
 2) or you can give a direct argument using the Stone-Weierstrass Theorem.
 â 
 
We might also mention that in the definition of  in Proposition 7.3.1 we
 could replace  and  by dense subspaces of these algebras.
 Consequently in the statement of the last corollary we could assume that each
  is a polynomial. Now to return to integration.
 
7.3.4. Proposition. If X and Y are compact subsets of  and ,
 respectively, Y is a Jordan set, and  is a continuous
 function, then the function  defined by
 


is continuous.
Proof. Because Y  is a Jordan set it follows from Theorem 7.2.13 that
the integral defining the function  makes sense. Let R be
a rectangle such that  and put . Since f  must
be uniformly continuous, for any  there is a  such that
 when . Thus when



and the proposition follows. â 
The main reason for proving this last proposition is that, as a consequence, F
is a bounded uniformly continuous function on X and hence integrable if we also
assume that X is a Jordan set. This is needed for the conclusion in the next
theorem to make sense. To do this important theorem the reader should complete
Exercise 7.2.9. 

7.3.5. Theorem (Fubini's3
Theorem). If X and Y are compact Jordan sets of  and ,
respectively, and  is a continuous function, then
 
 


Proof. Let R and S be rectangles in  and  such that  and
 . We first consider the case that  where 
 and . Here we want to show that
 
 
â(7.3.6)

 Observe that a R-cover of  can be written as ,
 where  and  are R-covers of X and Y . (Verify!) Since f  is integrable,
 Proposition 7.2.4 implies there is a R-cover  of  such that
 . Moreover  is the unique number such
 that whenever  and  are refinements of  and , respectively, then
 . Thus to prove (7.3.6) we need only show
 that for all such  and 

â(7.3.7)
Let's begin. (This argument is notationally cumbersome but conceptually
straightforward, so be patient.) Let  and  and
define the numbers  in the usual way. Note that
.
Similarly . Therefore
since both g and h are integrable we have that

proving (7.3.7) and hence (7.3.6).
Now that we have the theorem when  as in (7.3.6), it is a
trivial matter to extend the theorem to the linear span  of all the functions of
the form  where . If f  is any function in
, then Proposition 7.3.1 implies there is a sequence 
in  that converges uniformly on  to f . For each , set
. So each  is in (7.3.4).
Claim.  uniformly on X.
In fact, if  there is an N such that  for all
 and all  in . Hence for all  and all x in X we have
that . This establishes the
claim.
By Exercise 7.2.15,  and . Therefore

completing the proof. â 
 
Reversing the roles of X and Y  in Fubini's Theorem we get the next corollary,
 which is also referred to as Fubini's Theorem.
 
7.3.8. Corollary. If X and Y are compact Jordan sets of  and  and
  is a continuous function, then
 


It has to be mentioned that Fubini's Theorem holds in much greater
 generality than is stated here. The more general result involves the dramatic
 extension of integration from what is presented in this book. See [3].
 
By using induction, Fubini's Theorem can yield other results such as the
 following one.
 
7.3.9. Theorem. If R is the rectangle 
 and , then for any permutation  of 



The preceding results say something about the concept of the volume of a
Jordan set (7.2.19). First Fubini's Theorem says that if X is a Jordan set in
 and Y  is a Jordan set in , then . In
particular the last theorem says the two definitions of the volume of a
rectangle are the same. That is, using the notation of Theorem 7.3.9,
.
Now we consider a different type of iterated integration, but first we need a
preliminary result.

7.3.10. Proposition. If X is a compact Jordan set in  and
 are continuous functions such that  for all x in
X, then


is a compact Jordan set in .
Proof. We begin by defining the sets

Claim. 
(This argument is a bit cumbersome so you might want to follow along by
 assuming  and drawing a picture.) We start by showing the containment
 . If  and , consider the ball .
 Since  there is a point  in  such that .
 It follows that . Thus  and we
 have that . Now assume that  and . If
 , then ; hence .
 Similarly .
 
Now assume  and let's show that . Since 
 is a part of Z, we have that  and . Assume
 that  and that . Let  and  such
 that  and . It follows that
  is an open set contained in Z, contradicting the fact
 that . Thus either  or  or . In the first
 case, ; in the second, ; in the third, , thus
 establishing the claim.
 
According to Proposition 7.2.11, B and C have volume zero. If we can show
 that A has volume zero, it follows from Exercise 7.2.4 that Z is a Jordan set. To
 show that A has volume zero first observe that since  and  are
 continuous functions on a compact set there are real numbers a and b such
 that  for all x in X. Thus ; we
 show that  has volume zero. If  there is a R-cover
  of  such that . It follows
 that  is a R-cover of  and the sum of
 the volumes of these rectangles is less than . â 
 
7.3.11. Theorem. If X is a compact Jordan set in  and
  are continuous functions such that  for all x in
 X, and
 


then for any continuous function 


Proof. First we show that if we define


as , then F is continuous and so the integral in the
statement of the theorem is legitimate. Let  in X and observe
that

Let  for all  in Z and let . We can choose N such that
 when ,  and . From the
 preceding equation we get that  when .
 
Let  be an interval such that  for all x in X, let S be
 a rectangle in  that contains X, and let . Define 
 by setting  when  and  otherwise.
 
Claim.  is integrable on R and 
To prove the first part of the claim we let  and invoke Exercise 7.2.11 to
 find a R-cover  of Z such that the following two
 conditions hold: (a)  are the rectangles in  that meet  and
 ; (b)  are the rectangles contained in 
 and if  for , then 
 Let , where  are rectangles contained in R
 chosen such that  is a R-cover of R. It follows that  vanishes on each 
 since it is disjoint from Z. Thus . It
 follows that  is integrable and . Though the function  is
 not continuous on R we can adapt the proof of Fubini's Theorem to
 complete the proof of the claim. The proof is left to the reader in Exercise
 7.
 
Using the claim we get
 


 â 
7.3.12. Corollary. Assume  and  are continuous
functions such that  for all x in . If


and  is a continuous function, then


Exercises

(1) Show that Proposition 7.3.1 can be strengthened a little by replacing
 and  by dense subalgebras of these two spaces.
 
 
 (2)  Give the details needed to prove Corollary 7.3.3.
 
 (3)  If  and , find .
 
 (4) If , evaluate  for the following
 examples of the function : (a) ; (b)
 ; (c).
 
 (5) Find  in each of the following cases: (a) , X
 is the triangle with vertices ; (b) ,
 .
 
 (6) Find  in each of the following cases: (a) ,
 ; (b) ,
 .
 
 (7)  Establish the claim in the proof of Theorem 7.3.11.
7.4.  Change of Variables
Recall the Change of Variables Theorem for integration on intervals  in 
 (Theorem 3.2.5). There we are given a continuously differentiable function
  and an interval I such that . If  is a
 continuous function, then
 


In this section we'll see an extension of this result to the integral in . The
 proof of this theorem is very involved and necessitates some preliminary work and
 several lemmas. We begin by showing that under suitable restrictions the image of a
Jordan set is again a Jordan set, but establishing this also requires a few preliminary
results.
Let's set some notation. We are given an open subset G of  and a
continuously differentiable function . For each of the standard basis
elements  in  let  be defined by . The
statement of our first lemma is highly technical, but many lemmas are that
way.

7.4.1. Lemma. Let R be a rectangle in  whose shortest side has length s,
whose longest side has length , and assume these lengths satisfy . If
G is an open set containing R,  is a continuously differentiable
function, and there is a constant M such that  for all
 and all x in G, then there is a rectangle Q in  such that


Proof. Let  be the center point of R. If , consider the straight
line from  to x: . By the Mean Value Theorem
6.2.15, for  there is a point  in  such that


By hypothesis for each i, .
 In addition . Thus we have that
 ;
 so the image of the rectangle R under the scalar-valued function  is
 contained in the interval with center  and length . That is,
 


Therefore if we let Q be the rectangle in  with center  and
 with each side of length , we have  and .
 Now since , . Hence
 


as we wanted to show. â 
 
Let's point out that in the preceding lemma the existence of the constant M is
 not a formidable restriction. In fact R is a compact subset of G and so we can
 always find an open set  such that  and  is
 compact (Exercise 5.5.8). Since  is continuously differentiable, the constant M
 exists for the open set .
 
7.4.2. Proposition. If X is a compact subset of  having volume
 zero, G is an open set containing X, and  is a continuously
 differentiable function, then  has volume zero.
 
Proof. From the comments preceding the statement of this proposition,
we may assume that there is a constant M such that  for
all  and all x in G as in the hypothesis of Lemma 7.4.1. Let
. Since X has volume zero there is a R-cover  of
X such that . By Exercise 1 we can write each
 as the union of non-overlapping rectangles having the property that
the length of the longest side of each is at most twice the length of its
shortest side. But the volume of each  is the sum of the volumes of
these smaller rectangles. Hence, without loss of generality, we can assume
that each  in the R-cover  has the property that the length of
its longest side is at most twice the length of its shortest side. By the
preceding lemma, for  there is a rectangle  in  such that
. Hence


Since , we have that  has volume
zero. â 
We want a result that gives conditions on a function  such that
when X is a Jordan set contained in G,  is a Jordan set. If we knew that
, the preceding proposition yields the result. Corollary
6.8.5, a consequence of the Inverse Function Theorem, gives us what we
need.

7.4.3. Proposition. If X is a compact Jordan set in , G is an open
set containing X, and  is a continuously differentiable function
such that  is invertible for every x in , then  is a
Jordan set.
Proof. First observe that  is compact. If , let U
 
 be an open set such that . By Corollary 6.8.5,  is
 open. Since , it must be that . Hence
 . If , let  such that
 . By what we just proved, it cannot be that ; thus
  and we have that . But  has volume zero
 by Proposition 7.4.2 and the fact that X is a Jordan set. Therefore 
 is a Jordan set. â 
 
7.4.4. Theorem (Change of Variables Theorem). Let X be a compact Jordan set
 in . If G is an open subset of  such that  and  is a
 continuously differentiable function such that  is injective on  with
  for all x in , then for any continuous function
 
 
â(7.4.5)
Note that according to Proposition 7.4.3,  is a Jordan set so that the
 first integral in (7.4.5) makes sense. We might compare this result to the
 previously quoted result for  and note the differences. The first thing that
 stands out is the absolute value around the  as opposed to not having
 one around  in the case when . This is due to the fact that in
 one-dimensional integration there is a natural direction involved in the
 integral and this does not happen when . Since  on
 the interval  we have either  for all x or  for
 all x. In the latter case the effect is to use  in the equation but switch the
 limits of integration. So we could write the COV Theorem when  as saying
 that when  on  then


and so the theorem above is indeed a generalization of the COV Theorem we
proved in Chapter 3.
We still need some more lemmas. The next one can be phrased as saying that
if the Change of Variables Theorem is true for every rectangle, it is true for
an arbitrary compact Jordan set. The proof is rather technical so be
careful.

7.4.6. Lemma. Assume , and  are as in the statement of Theorem
7.4.4. If for every closed rectangle R contained in  and every
continuous function  we have that


then (7.4.5) is valid.
Proof. We begin the proof by making some simplifying assumptions that
do nothing to interfere with the generality of the situation. First, since
any continuous function can be written as the difference of two positive
continuous functions and (7.4.5) remains valid for the difference of two
functions, without loss of generality we can assume that  on .
Define a new function  for all x in X, which
we observe is also positive on X. We can also assume that G is a
bounded Jordan set with  defined and continuously differentiable in
 
 an open set that contains . To see this first realize that since X
 is compact and contained in an open set, there is a  such that
  (Exercise 5.5.7). Let  be a R-cover
 of , where each each rectangle in  is contained in G. Replace G by
 , a bounded open Jordan set. (We needed the bigger
 set  to be sure that X is contained in the replacement open set.)
 With this replacement we have that  is defined in a neighborhood of
 . Since G is a Jordan set we can define .
 
Because  and X are both compact, we have that both f  and g are
 bounded on these domains. Also since  and its derivatives are continuous on
  we have that there is a constant M such that
 

Let .
 
Claim. There is a R-cover
 


of X, where  meet ,  are contained in
 , and the following hold: (a) the longest side of each rectangle in  is
 less than twice the length of its shortest side; (b)
 


To verify this claim we use methods we have used before and so the details
are left to the interested reader. Suffice it to say that (a) follows from
Exercise 1 and (b) is a consequence of the fact that  has volume
zero.
Let


Note that  is a Jordan set by Proposition 7.4.3. Also the Inverse
Function Theorem and its corollary imply that . By the
corollaries of Theorem 7.2.13, in particular Corollary 7.2.18, we have
that

If we set , the hypothesis implies
 
 


Lemma 7.4.1 implies that for each rectangle  there is a rectangle  such
 that  and . Now
 


so
 

Therefore
 


On the other hand . But  and
so


Thus


Therefore


Since  was arbitrary this completes the proof. â 
 
Now we parlay the preceding lemma to show that if we prove the COV
 Theorem locally, then we have a proof of the general theorem.
 
7.4.7. Lemma. Assume , and  are as in the statement of Theorem
 7.4.4. If for every point x in  there is an open ball  such that
  with the property that for any Jordan region Y contained
 in  and any continuous function  we have that
 


then (7.4.5) is valid.
 
Proof. We only sketch the proof as it follows lines similar to previous proofs.
 The reader is asked in Exercise 3 to supply the details. Let  be a
 continuous function. To show that (7.4.5) is valid, the previous lemma says we
 need only show that  for every rectangle
 . Let  be an open ball as in the hypothesis, and let  be a
 rectangle that contains x in its interior and such that .
 Since the rectangle R is compact we can find a finite number of points
  such that R is covered by . Now find
 non-overlapping rectangles  such that  and each  is
 contained in one of the rectangles . Note that for ,
 . Hence
 

By the preceding lemma this completes the proof. â 
The next phase of the proof consists of showing that the theorem is true when
 is a special type of function. After this we'll show that these special maps
can be combined to get any eligible  and then we will complete the
proof.

7.4.8. Definition. If G is an open subset of  and , then H
is called a simple mapping if there is an integer k with  and a
function  such that for all x in G


Thus a simple function is one that disturbs only one coordinate. Notice that the
continuity or differentiability of H is determined by that of h. If H is differentiable
at a point a in G then the matrix of  has the following properties.
When , the i-th row of  has a one in the i-th spot and zeros
elsewhere. That is  when  and . The k-th row has entries
. So the Jacobian determinant takes on the
form
 
 


Hence the simple function H has  invertible if and only if
 .
 
7.4.9. Lemma. The Change of Variables Theorem is true if we assume that
  is a simple function.
 
Proof. By Lemma 7.4.6 it suffices to prove this when X is a rectangle . To
 simplify the notation we assume that the simple function  has the form
 ; that is, in the above definition we take . Let
 , the rectangle in  such that .
 As we pointed out,  and the hypothesis guarantees
  for all x in X. X being a rectangle and hence connected, it must be
 that  is either always positive or always negative; we will assume that
  for all x in X. (The reader can carry out the similar proof in the
 other case.) We have that . Hence by Fubini's
 Theorem
 
 
â(7.4.10)

and
 
â(7.4.11)

For the moment fix  in R and define  by
. It follows that . So by the COV
Theorem for one variable (3.2.5) we get that

If we substitute this into (7.4.10) and (7.4.11) we see that the proof is complete.
â 

7.4.12. Definition. A linear transformation in  is called a flip if it
interchanges two elements of the standard basis and leaves the others fixed.

So a T in  is a flip if there are distinct i and j, , such that
, , and  when . Notice that if T is a flip,
then . We observe that with ,  and so
.
 
 
7.4.13. Lemma. The Change of Variables Theorem is true if we assume
 that  is a flip T.
 
Proof. Again we need only prove this for a rectangle. As in the proof of
 Lemma 7.4.9 let  and, to simplify the notation, we assume that T
 flips the first two basis vectors. So , and  for
 . Let , the rectangle in  such
 that . Thus , and
 


and
 


Fubini's Theorem shows these two integrals are the same. â 
 
7.4.14. Lemma. If G is an open subset of  that contains the origin,
  is continuously differentiable with  and 
 invertible, then there is a neighborhood W of 0 such that for all x in
 W
 
â(7.4.15)

where: (i) each  is either a flip or the identity linear transformation;
(ii) each  is a simple mapping satisfying  and  is
invertible.
Proof. We start by introducing the linear projections  on ,
where for all x in :  and . So
 projects  onto the subspace defined by the first k members of the
standard basis.
Claim. For  there is a neighborhood of 0, , and a
continuously differentiable function  such that ,
 is invertible, and for all x in 


We show this by induction. Take  to be the given function  with
. Since , this works. Now assume  and that we have
the function  and neighborhood  as in the statement of the claim. From
the equation  it follows that for each x in  we
have
 
 


for some scalar-valued functions  defined on . Since
  is continuously differentiable, so are each of the functions .
 Thus
 


Because  is invertible, there must be a first integer q, ,
 with . Fix such a q and let  be the flip that interchanges
 this  and . (If , then .) Define 
 by
 


It follows that  is a simple function on  that is continuously
 differentiable and  is invertible. (Verify!) Since 
 it follows that  so that . We apply the Inverse
Function Theorem to  and conclude the following: (a) there is an
open set  with ; (b)  is injective on  and
, an open set containing 0; (c)  is
continuously differentiable.
Define  for all y in  by
 
â(7.4.16)

Clearly  is continuously differentiable with . By the Chain Rule
we have that ,
so that  is invertible. Finally, if ,

Hence  for all y in , establishing the claim.
Finishing the proof of the proposition now goes quickly. Revisit (7.4.16) with
 for some x in  and use the fact that  to conclude that
. Applying this for successive
values of  shows that in some neighborhood of 0 we have
that
 
 


But according to the claim we have that . Now 
 projects  onto the subspace defined by the first  members of the
 standard basis. This means that there is a function g defined in a neighborhood
 of 0 such that  so that  is a simple function.
 â 
 
Proof of the Change of Variables Theorem. By Lemma 7.4.7 we need
 only show that for any point  in  there is a neighborhood
 of  on which (7.4.5) is valid. If we replace G by  and
  by , we note that , ,
 and  is invertible. Hence it suffices to assume that ,
 , and  is invertible.
 
Combine the preceding lemma with the fact that the theorem is valid if  is
 a simple function (Lemma 7.4.9) as well as if  is a flip (Lemma 7.4.13),
 and we see that we need only show that when the theorem is true for
 functions  and , then it is true for . In this case we have
 that
 

where the last equality is from the Chain Rule and the multiplicativity of the
 determinant. â 
 
7.4.17. Proposition. If  and T is invertible, then for any
 rectangle R in ,


Proof. This is immediate from the Change of Variables Theorem and the
fact that if  is defined by , then 
for all x in . â 

7.4.18. Example. [Polar Coordinates] (a)
Define  by . A simple computation
shows that . Thus if we have any compact Jordan set X
in the plane such that  does not contain the origin and  is injective
on  and if  is continuous, then


Note that for  to be injective on  it must be that if
, then .
(b) Let  and evaluate .
If we let  and define  as in (a), then
 and, on ,  is injective and . Using Fubini's
Theorem we get that

See Exercise 4.
 
7.4.19. Example. [Spherical Coordinates] (a) Denote the origin in  by
 . For any point P in  let Q be the projection of P onto the
 xy-plane. We associate the spherical coordinates  as follows: r is the
 distance of P to the origin;  is the angle from the positive x-axis to the line
 segment OQ;  is the angle from the positive z-axis to the line OP. Using
 these quantities we get that .
 We define
 


A computation shows that
 


and so . Hence the Change of Variables
Theorem applies to any Jordan set X such that  on .
(b) Find the volume of a sphere in . The volume of a sphere of radius a is
, where . If we
define , then the function
 in (a) maps X onto Z. Using the Change of Variables Theorem and Fubini's
Theorem we have that

Therefore the volume of the sphere is .
 
 
Exercises

 (1)  If R is any rectangle, show that R can be written as the union of a finite
 number of non-overlapping rectangles  such that each 
 has the property that its longest side is at most twice the length of its
 shortest side
 
 (2)  In the proof of Lemma 7.4.6 show that .
 
 (3)  Supply the details of the proof of Lemma 7.4.7.
 
 (4)  Give the details of the calculation in Example 7.4.18(b).
 
 (5) Let X be the set in  bounded by the x-axis and the curve 
 where ; find .
 
 (6) Find the area of the
 following subsets X of . (a) .
 (b) .
 
 (7) Let X be the top half of the unit ball in  and find .
 
 (8) Let X be the sphere in  centered at the origin with radius 3. When
 , show that .
7.5.  Differentiation under the Integral Sign
Here we want to explore the idea of the differentiation of functions that are
 defined by an integral. The proof of the main result (7.5.2) is technically
 complicated because there are so many things to keep track of. Instead of
 starting with that we will begin with a special case which is a corollary of the
 main result. We do this because the proof of this special case is straightforward
 and it is this result that seems to be used more frequently.
 
7.5.1. Theorem. If , G is an open subset of  that
contains , and  is bounded and continuously
differentiable, then


Proof. We only give the proof for the case that . Set
 so that . Fix x in  and
let  such that . Put K equal to the
rectangle . Note that since  is continuous, it is
uniformly continuous on K. Thus we can find  such that
 when . Also
the MVT applied to  says that for any y and t with  there
is a  between x and  with


We note that  depends on x, y, and t. Let .
Note that for any y in ,  so that
. Hence for  and any y in  we have
that

Therefore when , we have that
 

Since  was arbitrary, this completes the proof. â 
 
Now we present a more general result.
 
7.5.2. Theorem. Consider  in  and suppose  are
 continuously differentiable with  for all x in . If G is an open
 subset of  that contains  and
  is continuously differentiable, then  is
 differentiable and
 

Proof. Define  by


Fix x in  and let  such that . (We leave
the proof of the theorem when x is an endpoint of  to the reader as
Exercise 1.) When , we have that

We now apply the MVT to the first and second of these three integrals. So for
any t with  we obtain a point  between  and  and
 between  and  such that

(The point x is fixed but be conscious of the fact that the points  and 
 depend on t.) Dividing both sides by t gives that
 

Fix  and let's make a few observations. First, since both  and 
 are continuous, there is a constant C such that  and 
 for all w in . Second, the set  is
 compact (Why?). This tells us two things: since f  is continuous it is bounded on
 K and it is uniformly continuous there. So there is a constant M with
  whenever  and there is a  such that
  when  and these points
 belong to K.
 
Consider the first summand in the last equation above; so we are focusing on
 the function . There is a  with  such that when
 ,
 


Because  is uniformly continuous on  there is a  such that
 when . Put .
If , then with the choice of  made as above we have
that

Now

Thus  and so the above inequality becomes
that for  we have that


Similarly if we focus on the function  there is a  such that when
 


Combining what we have done above we get that when 


We're almost done. Note that since  is continuous, it is uniformly continuous
 on K. Thus we can find  such that 
 when  and these points belong to K. Also the MVT
 applied to  says that for any y and t there is an  between x and 
 with
 


Let . Fix any y and let . Since
, we have for the appropriate 
that

Putting this together with our previous estimates we have that for 

Since  was arbitrary, this completes the proof. â 
One of the important uses of differentiating under the integral sign is that it
enables us to compute certain integrals over  that are very difficult to compute
otherwise. Here is an example.

7.5.3. Example. Of importance in probability and Fourier analysis is the
improper integral
 
 


which we want to verify. It isn't clear how to use the above theorems to
 obtain this, but be patient. Let's first observe that by the symmetry of the
 integrand we need only prove
 


If you play with this integral using the standard tools from calculus,
 you'll see they all fail you. We take a different approach. Define the function
  by
 


so we want to find . Note that


Now we make a change of variables , where , and get
that


After staring at the integrand and thinking, we see that


Using Theorem 7.5.1 we therefore have that
 
 


Putting  equal to the integral in this last equation, this means that
  so that , for some constant C. We need to
 evaluate this constant. In fact
 

since this last integral can be evaluated because  has  as its
 primitive. Putting it all together we have that
 


Letting  shows that , whence the result.
 
This example was accessed at www.math.uconn.edu/~kconrad/blurbs/analysis/diffunderint.pdf
 on 21 Jan 2015. This site contains other examples involving differentiating under
 the integral sign.
Exercises

(1) Prove Theorem 7.5.2 when x is an endpoint of .
 
(2) Can you formulate and prove a version of Corollary 7.5.1 for ?
 
(3)Show that  by using the function


and differentiating under the integral sign.
 
(4)Show that



1Camille Jordan was born in 1838 in Lyon, France. He was educated as an engineer at
Ãcole Polytechnique and pursued that profession while continuing to explore mathematics. He
defended his doctoral thesis in 1861. He continued working as an engineer, though taking
time in 1862 to marry. He and his wife had eight children. He made his way back to Paris
and became a professor, first at Ãcole Polytechnique in 1876 and then at CollÃ¨ge de France
in 1883. His mathematical contributions spanned the list of fields under study at the time,
from algebra to analysis to the emerging field of topology. He is the author of the Jordan
Curve Theorem and Jordan Normal forms of matrices. (To be clear he is not the Jordan in
Gauss-Jordan elimination or Jordan algebras.) He also introduced the notion of homotopic paths
and worked extensively on finite groups. He retired in 1912. During World War I three of his
sons were killed. Another son was a government minister, another a professor of history, and
the last son was an engineer. He received many honors during his life, which ended in 1922
in Paris.
2The Swiss cheese was first discussed by the Swiss mathematician, Alice Roth. She was born
in 1905 in Bern, where she spent her entire life. The history of mathematics has few women
as contributors. Indeed it was almost impossible for a woman to enter higher education until
well into the twentieth century. Today this situation has changed significantly and outstanding
women mathematicians are numerous. Alice Roth made contributions to rational approximation
of analytic functions of a complex variable. She died in Bern in 1977.
3Guido Fubini was born in Venice in 1879. He received his doctorate in 1900 from the University of
Pisa, writing a thesis in differential geometry. He took up a position at the University of Catania in
Sicily. Shortly after that he was offered a professorship at the University of Genoa and then in 1908 he
went to Turin. He began to change the course of his research, gravitating to analysis. During the 1930s
he saw the political situation in Italy deteriorating with the rise of Mussolini and anti-semitism. He
decided the future was looking bleak for his family, and in 1939, in spite of his deteriorating
health, the Fubini family emigrated to New York. His contributions were in several different
areas including integral equations, group theory, geometry, continuous groups, and applied
mathematics. He was influential in the development of mathematics in Italy. He died in 1943 in New
York. 












8 Curves
and
Surfaces
The next two chapters are on the same topic, one where geometry and analysis
overlap. This present chapter will focus on  and , covering curves
and surfaces in those spaces including the theorems of Green, Gauss,
and Stokes. Initially, however, we'll encounter the concepts in  since
in the basic material there is little difference between what happens in
the lower dimensions and the general space. When, however, we discuss
in this chapter the concepts leading to the three big theorems, we will
focus on  and . Be aware that we will often use heuristic
arguments in the present chapter, something that is facilitated by these small
dimensions. This is not true in the following chapter where we adopt a different
approach that leads to greater rigor. In fact, you could begin reading
Chapter 9 after the first section of this chapter and refer back to the
present chapter for the heuristics. I don't advise this as I believe seeing
the material in this chapter first will better prepare you to understand
Chapter 9. Moreover Chapter 9 is not written with this approach in mind
so it might be awkward to do this. At the end of the next chapter we
will revisit these lower dimensions to supply whatever rigor is absent
here.
The historical origins of much of what we do in this chapter and the next
started with an effort to use mathematics to study physics. That same statement
can be made about most of the mathematics that appears in textbooks. As we
progress in this chapter the connection with these historical roots will be evident
in some of the language used. For example in the first section we will talk
about a particle moving along a curve. You need not know any physics to
understand the next two chapters since we deal in abstractions of the
physical concepts. Indeed we see the virtue of this abstraction as the
mathematics has application to the social and biological sciences as well as the
physical.
8.1.  Curves
In Â§6.1 we defined a smooth curve in  as a continuously differentiable function
. In Â§7.1 we introduced the length of a smooth curve, defining it as
. We also said that  and a second smooth curve 
are equivalent, , if there is a continuously differentiable, increasing surjection
 such that  for all t in . Proposition 7.1.7
showed that equivalent curves have the same length. In this section we continue
the study of smooth curves and go more deeply into their analysis. In particular we
will explore the orientation or direction of the curve and introduce another integral
associated with these curves. Some of the examples and exercises here are from [15].
We begin with some terminology that could have appeared earlier.

8.1.1. Definition. Let  be a curve. We say that  and
 are the starting and final points, respectively. The curve  is said
to be a simple curve if  is injective on the open interval . Curve
 is a closed curve if . A simple closed curve is also referred
to as a Jordan curve. As usual the trace of  is its range and is denoted
by .







8.1.2. Example. (a) Fix  and define  by
. So  is a Jordan curve and it traces out the circle
centered at the origin of radius r that moves in the counter clockwise
direction.
(b) Let  and define  by .
The trace of  is an ellipse centered at the origin. What are its two axes? See
Exercise 2. The length of this curve is what is called an elliptic integral and
it can seldom be evaluated explicitly; usually it can only be approximated
numerically.
 
 
(c) If  is continuously differentiable, define
  by . So  is the curve in  that traces
 out the graph of the function f . We note that .
 
8.1.3. Proposition. Let  be a smooth curve with
 . If we define  by
 


then  is an increasing, continuously differentiable function that maps
  onto  and with .
 
Proof. We begin by noting that the function  is a continuous
 function. Hence the FTC can be applied to conclude that  is continuously
 differentiable and . Since  has a positive derivative, it is
 increasing. Clearly it is a surjection onto . â 
 
The preceding proposition, in spite of the brevity of its proof, tells us a lot. At
 any point t in ,  measures the length of the curve  from the
 beginning of the curve to the time t. Thus at any t in ,  is
 the rate of change of the arc length of the curve with respect to time; that is,
  is the speed of a particle moving along the curve  while the vector
  is tangent to the curve and points in the direction the particle is
 moving.
 
8.1.4. Definition. If  is a smooth curve and  is
 a continuous function, the integral of f  along  is defined as


We point out that if in this definition we take f  to be the constant function 1,
then we get the length of the curve . This is symbolically captured by using
the ds in the integral. The notation is traditional and is related to Proposition
8.1.3 as follows. If  is as in that proposition and if  is injective, we could
take the inverse  to give a reparametrization of the curve. This
is often called the natural parametrization of the curve when it exists.


8.1.5. Definition. Say that a curve  is regular if  is smooth
and  for all t in . The curve  is piecewise regular if
there is a partition  such that  is regular on
 for . We denote this by saying that ,
where for ,  is defined by .



Observe that the curve in Example 8.1.2(c) is regular. If  is regular and 
is as in Proposition 8.1.3, then according to that result  for all t. Hence
 is injective and we can form its inverse, thus producing the equivalent
curve (Definition 7.1.6)  defined on . This proves the
following.

8.1.6. Proposition. A regular curve can be given its natural
parametrization.

8.1.7. Example. (a) The curve 
defined by  with . Thus
. If  is as in (8.1.3), we have that , so
this form of the equation of the unit circle is already in its natural
 
 parametrization.
 
(b)
 If  is continuously differentiable and  as in
 (8.1.2(c)), then . So  is regular and has a
 natural parametrization. If  is a continuous function, then
 


8.1.8. Definition. If  is a regular curve, then the unit tangent
 vector for  at the point  is the vector
 


If  is a continuous function, the line integral of F along
  is defined as
 


If  is piecewise regular with , then


where for ,  when .





Strictly speaking we should have used the notation  for the unit
tangent vector, but the notation  is traditional and assumes we
have specified the curve . Similarly the notation  is also
traditional and is sometimes called the path integral. The term line integral is
frequently also used for the integral in Definition 8.1.4, where we integrate
a scalar-valued function. We chose not to use that term to avoid the
possibility of ambiguity, but in actuality there is little possibility of this
since in one case we integrate a scalar-valued function and in the other a
vector-valued function. In fact the earlier definition is used in the preceding one.
Indeed

There is a symbolic representation of  that we will use and the
 reader will see in the literature. Namely if  and
 , then
 
 
â(8.1.9)

 To see where this comes from observe that it means
 


Symbolically,  and so . (We'll say more about this in
the next chapter when we study differential forms.)
Consider what happens if we have equivalent curves (Definition 7.1.6). That
is suppose  and  are two smooth curves and there
is a continuously differentiable, increasing surjection  such that
 for all t in . So . Note that if  is regular,
then unless  is strictly increasing so that  for all t in , it does
not follow that  is regular. See Exercise 1. On the other hand if  is regular and
, then it must be that  is regular and  is strictly increasing. It also follows
that


With the same notation if both  and  are regular, then
 

Similarly
 


8.1.10. Example. (a) Let  be defined by ,
 so that  represents the unit circle in the plane traversed once in the
 counterclockwise direction. If  is defined by ,
 then
 

(b) Let  be as in part (a) and put . So


(c) Define  by  and let  be
defined by . Here

(d) Let  be the boundary of the square  in  in the
counterclockwise direction and . Here ,
where each of these pieces is a straight line defined on  as follows:
. So the derivatives of
these curves are .
Hence

We conclude this section with a brief discussion of curves in . If
  is a regular curve and , then we have
 functions  and  from  into . It is easy to
 check that each of these functions is smooth and . If
  is a continuous function with ,
 then
 
 
â(8.1.11)

 We will frequently encounter expressions such as the right-hand side of the last
 equation when we study differential forms in the next chapter.
 
Exercises

(1) Find an example of a regular curve  and an increasing
function  such that the curve  is not regular.
 
(2) Verify the statements in Example 8.1.2(b).
 
(3) Let  and find  for the following choices of
: (a)  with ; (b)  for ;
(c)  is the square  in the counterclockwise direction.
 
(4) Let  and find  for each of the following
curves : (a)  for t in ; (b) 
for . (c)  is the closed polygon whose successive vertices are
.
 
(5) Find  for each of the following choices of F and .
(a)  and  is the parabola  from  to
. (b)  and  is the intersection of
the elliptical cylinder  with the plane  that is oriented
in the clockwise direction when viewed from far out along the positive x-axis.
(This last will test your viewing skills.)

(6) If  is a regular curve, let  be the curve defined
on  by . Show that if  is a
continuous function, then . What is the
relation between  and ?
 
(7) If f  and g are continuous functions of a single variable and F is defined on
 by , show that  whenever  is
a regular closed curve in .
8.2.  Green's Theorem
In this section we will focus on curves in . They differ quite a bit from curves
in  when , and we begin with a result that is unique to the
plane. It is a famous result from planar topology that is highly intuitive
 
 but difficult to prove. A moment's thought reveals that this theorem is
 decidedly false in higher dimensional spaces. Recall the definition of Jordan
 curve as a simple closed curve, which was given at the start of the last
 section.
 
8.2.1. Theorem (Jordan1
 Curve Theorem). If  is a Jordan curve in , then  has two
 components, only one of which is bounded. Moreover  is the boundary
 of each of these components.
 
We won't prove this theorem. For a proof see [14]. If G is the bounded
 component of the complement of , then G is called the inside of the curve 
 and  is the boundary of G. The unbounded component is called the outside of
  and its boundary is also . 
If we assume  is a regular curve, then it has a natural direction given by its
 unit tangent vector. Thus  has a direction - as the variable t goes
 from a to b,  goes from  to . What we want, however, is to
 discuss the direction of a curve relative to an open subset of  when
 the curve forms part of the boundary of the set as, for example, is the
 case with the Jordan Curve Theorem and G is the inside of the curve.
 Intuitively we want to say that  is positively oriented relative to G if
 when we walk along  in the direction of , equivalently in the
 direction of , then G lies to our left. We saw this for the curve  in
 Example 8.1.10(a). We want to make this mathematical. In doing so we
 generalize the concept to all regular curves, not just those that are Jordan
 curves.
 
If  is regular and , we have that for each t in  at
 least one of  and  is not zero. It follows that
 


is a unit vector orthogonal to . In fact,  results from rotating
   in the counterclockwise direction. For each t the vector  is
 called the unit normal vector to the curve. 
8.2.2. Definition. If a piecewise regular curve  forms part of
the boundary  of an open subset G of the plane, say that  is positively
oriented relative to G, if for every t in  where  exists there is an
 such that when  we have that .

Intuitively,  is positively oriented if  is pointing inside G. Just for
emphasis, in the preceding definition we are not assuming that  is a
Jordan curve or that it is the entirety of the boundary. Let's look at an
example.

8.2.3. Example. Let  and put
, an annulus. If 
and  for , then both 
and  are positively oriented relative to G. See Exercises 1 and 2.
Now that we have established the idea of orientation of a curve relative to a
set, we want to prove one of the fundamental theorems on integrating
around a curve in the plane. In fact this is the Fundamental Theorem of
Calculus for . First we need to set the stage with a few additional
concepts.

8.2.4. Definition. A subset X of  is said to be of Type I if
there is an interval  and piecewise regular real-valued functions
 defined on  such that  on  and
. X is said to be of
Type II if there is an interval  and piecewise regular real-valued
functions  defined on  such that  on  and
.


The term Type I is traditional though it usually requires only that  and
 be continuous functions, as we did when we discussed Fubini's Theorem
(7.3.5). We say they are piecewise regular in the definition of Type I
because this is the only context in which we will use the term. Similar
comments apply to Type II. There are Type I sets that are not also Type
II (Why?); but there are sets, for example a disk or a square, that are
simultaneously Type I and Type II. Such sets will hold special interest for
us.

8.2.5. Proposition. If X is either Type I or Type II, then X is a compact
Jordan set and there is a piecewise regular curve  whose trace is 
 
 and  is positively oriented relative to .
 
Proof. Here is the proof for a Type I set; the proof for a Type II set is similar.
 Use the notation established in the definition above. Proposition 7.3.10
 establishes that X is a compact Jordan set. Define the following four curves on
 , where  and  trace the graphs of  and , respectively, but in
 opposite directions; while  and  trace vertical straight line segments, but
 again in opposite directions.
 

If we set , then  is a piecewise regular curve (Verify!)
 that traces . It easily follows that  is positively oriented relative to
 . â 
 
If, in the case of Type I,  for , then the curve
  in the proof of the preceding proposition is also a Jordan curve and
  is its inside. A similar statement applies to a Type II set. See
 Exercise 3.
 
8.2.6. Definition. Let X be a compact Jordan set in  whose boundary is
 a finite collection of piecewise regular curves. A collection 
 of closed subsets of X is called a Type I cover of X if each  is a set
 that is Type I and the following are satisifed: (a) ; (b) when
 , ; (c) if , and  are three
 distinct sets, then  is either empty or a finite set. The
 collection  of closed subsets of Y  is called a Type II cover
if each set  is a Type II set and conditions (a), (b), and (c) above are
 also satisfied.
 
The set X is a G-set if it has a Type I cover as well as a Type II cover.
 
The terminology is not standard. It is given to facilitate the proof of the next
 theorem. Let's point out that from what we did in Chapter 7 it is automatic that
 
X is a Jordan set if we assume that  is a system of curves as described. We
added the assumption that X is a Jordan set for emphasis. To be clear, condition
(b) in the definition includes the possibility that . Note
that (b) also implies that  when . Condition
(c) prevents the boundary of one of the sets  from doubling back on
itself.
Examples of G-sets abound. Of course any set like an ellipse that is already
both Type I and II is an example of a G-set. Here is a description of a general
class of G-sets.
Suppose X is a compact subset of  such that  and 
 consists of a finite number of non-intersecting regular Jordan curves .
 Suppose there is a R-cover  of X that has the following properties. If 
 and , then R meets exactly one of the boundary curves . (See
 Figure 8.2.1.) Further assume that if R meets , then  is a Jordan
 curve consisting of three regular curves: a vertical and a horizontal line segment
 that meet at some point  in  and a part of  that joins
 the endpoints of these two segments that are different from . (In
 Figure 8.2.1,  is .) The vertical and horizontal line segments form an L
 and, after suitable rotation, there are four different positions for this
 L. If we also have that  has the property that for any two
 points in this set the line segment joining them is also contained in the
 set, then  is simultaneously a Type I and a Type II set. Since
 every rectangle is simultaneously a Type I and Type II set, we have that
  is both a Type I and a Type II cover of X. Hence X is a
 G-set.
 



 Figure 8.2.1 

Frankly it seems to me that we can carry out the procedure described in the
 preceding paragraph for any set whose boundary consists of a finite number of
 pairwise disjoint regular Jordan curves. Attempting to write a proof of this with
 all the details of the argument required, however, doesn't seem worth
 it.
 
The following idea will be useful in our discussions for showing a set is a
 G-set. If X is a compact subset of  with , then a cut of X is a
 simple piecewise regular curve  such that  and
  for . So a cut literally cuts the set X. If  is
 connected and  is a cut, then  has two components. In practice
 we will show that a set X is a G-set by making a judicious choice of cuts. See the
 next example.
 
8.2.7. Example. Let 
 and put , an annulus. Let 
 be the cuts defined on  as follows; ,
 , ,
 . If  are the sets whose interiors
 are the components of , then these sets show that X is a
 G-set. Also see Exercise 5.
 
If X is a G-set and  consists of the traces of the disjoint piecewise regular
 curves , we adopt the notation that for any continuous function
 
 
â(8.2.8)

Before stating and proving the main theorem, here is a lemma, which is little
more than an observation.
8.2.9. Lemma. Let X be a G-set with  either a Type I or Type II
cover.
(a)  If  is a smooth function, then
.
(b)  If  is a continuous function, then .
Proof. We only do this for a Type I cover; the proof for a Type II cover
is similar. The proof of (b) is immediate since if  is a
Type I cover of X the area of  is zero. To prove (a) observe what
happens when  and . If this intersection
contains a piecewise regular arc , then from Proposition 8.2.5 we know
that when  appears as part of  its direction is opposite to that
of its direction when it appears as part of . So the contributions of
 to the two integrals  and  are the negative of one
another. If  has an isolated point, this does not contribute to
the corresponding line integrals. This establishes (a). â 


8.2.10. Theorem (Green's2
Theorem). If X is a G-set and  is a smooth function with
, then
 
 


Proof. Using (8.1.11) we want to show that


Separating the sides of the equation we'll show that
 
 
â(8.2.11)
Let's show the first of these. Since X is a G-set it has a Type I cover. The
 preceding lemma says it suffices to prove this under the additional assumption
 that X is a set of Type I; let .
 Let the positively oriented piecewise regular curve ,
 where these four curves are defined as in Proposition 8.2.5. Note that since 
and  are vertical line segments, the value of x is constant (either a or b).
Hence . As we pointed out in the proof of Proposition
8.2.5,  traces the graph of  from left to right while  traces the graph of
 but in the opposite direction. Remember this in the next step of this
proof.
We now apply Fubini's Theorem to get

The next step is to show that
 
â(8.2.12)

This is left to the reader as Exercise 6. â 

8.2.13. Example. (a) Find  when  is the perimeter of
the rectangle  with the counterclockwise direction
 
 and . We could parametrize  and carry out
 the process, but it's a bit easier to use Green's Theorem. Here
 , so .
 
(b) Let  and let X be any G-set. Green's Theorem says
 that
 


Exercises

 (1)  Verify Example 8.2.3.
 
 (2)  Evaluate  when X is the annulus described in Example 8.2.3
 and .
 
 (3)  If  as in the definition of
 a Type I set, show that  is a Jordan curve if  when
 .
 
 (4)  (a) Show that a disk is both a Type I set and a Type II set. (b) Give an
 example of a Type I set that is not Type II. (c) Give an example of a Type
 II set that is not Type I.
 
 (5)  (a) Show that  is a G-set. (b) Let
 X be the set in  bounded by the three circles  and
  and show that it is a G-set.
 
 (6)  Prove (8.2.12) as part of the proof of Green's Theorem.
 
(7)In Green's
Theorem what happens if you take  and ?
Suppose  and ?
 
(8) Find  when  and  is the positively
oriented perimeter of the triangle with vertices .
8.3.  Surfaces
We are predisposed to think of a surface as a two-dimensional object inside
three-dimensional space and that's what we'll do in this section. Later in Â§9.1
we'll discuss q-dimensional surfaces that are contained in p-dimensional
spaces.

8.3.1. Definition. A surface domain in  is a compact Jordan subset R
of  such that  is connected, , and  is a finite
collection of pairwise disjoint piecewise regular curves. A 2-surface in ,
or just a surface, is a pair  where R is a surface domain in  and
 is a continuous function that is smooth on a neighborhood of
R. The trace of  is the set .



Now that we have stated that a surface is a function, let's mention that we
will sometime violate this and refer to a surface as a set S. When we do this,
what we mean is that there is a surface  whose trace is the set S. In such
a situation  is called a parametrization of S. (See Exercise 1.) As you
might expect from the treatment of curves, we'll see that such a parametrization
is not unique.
To be completely precise, always a virtue, we should have defined an object
(with some name) as we defined a surface above, then define an equivalence
relation between these objects, and define a surface as an equivalence class of
such objects. On the other hand there is another virtue, simplicity of exposition.
It seems to me in this case that this latter virtue is more important than the
first. We will soon define, however, an equivalence relation between surfaces and
show that equivalent surfaces have the same properties we will be interested in
exploring.


8.3.2. Example. Let
  and call the set  the corona. Note
 that . Each component of
 this boundary is a surface (Exercise 1), but since  is not connected it
 is not a surface. Each component, however, is.
 
We'll see more examples of surfaces shortly; we gave the preceding one to
 underline a facet of the definition. As we noted the definition of a surface 
 requires that , and hence R, be connected and this implies that
  is connected as well as compact. Hence the boundary of a corona is
 not, strictly speaking, a surface. This is not significant. We want the
 interior of a surface domain to be connected to apply previous results,
 but we could have dropped the connectedness assumption and treat one
 component at a time. Later, in the following section, we'll broaden the concept
 of a surface where we drop this insistence on connectivity. We'll stick
 for the moment with the approach taken here, however, as it is more
 efficacious.
 
8.3.3. Example. (a) If R is a surface domain in  and , then
 define  by . If the function f  is smooth
 in a neighborhood of R, then  is a 2-surface.
 
(b) If , let . This
 set is a hemisphere centered at the origin. If we defined  by
 , then  but  fails to be smooth in a
 neighborhood of R. Exercise 2 gives a parametrization  that is
 smooth in a neighborhood of the surface domain T and has this hemisphere
 as its trace.
 
(c) A truncated cylinder is the trace of a 2-surface. For example,
 let , , and
 define the surface  by .
 
(d) The torus in  is a 2-surface. In fact
 let , let , and define 
 by . The reader can
 verify (Exercise 4) that the image of  is a circle in the xz-plane
 centered at  and having radius b and that  is a torus.
 
In analogy with what we did for curves in the last section, we seek a way to
 orient surfaces. A moment's thought shows this is not as straightforward a task
 as it was for curves where we oriented by establishing the unit tangent vector
  for a regular curve. As an introduction, let's consider a special kind of
 surface.
 
Let R be a surface domain in  and suppose we have a function
  smooth in a neighborhood of R. We define a 2-surface  on R by
  as in Example 8.3.3(a). In Â§6.7 we examined a
smooth curve  and the induced curve 
defined by  in . We
computed


a vector in  that is tangent to the curve  at . In Proposition 6.7.8
we proved that if , then the vector  is
orthogonal to . Note that  does not depend on the curve
 and so it is perpendicular to every curve in  passing through
. Thus we have (Definition 6.7.10) that


is the tangent affine hyperplane to the surface  and


is a unit normal vector to the surface at the point . So we see
 that when a 2-surface in  is the graph of a smooth function, it has a
 unit normal vector. We seek to extend this to arbitrary 2-surfaces in
 .
 
If  is a 2-surface in , then write 
 for  in R. We want to consider the Jacobians
 


The next result hints at the reason for our consideration of these Jacobians.
 The idea is that under a mild restriction we can use what we did above to show
 that the surface has a unit normal vector.
 
8.3.4. Proposition. If
  is a smooth 2-surface with  and 
 such that , then there is an open set  in  and a
 smooth function  such that
 


Proof. Define  by . Observe that
 the hypothesis implies that the derivative of  at  is an invertible
linear transformation from  into itself. By the Inverse Function Theorem
(6.8.2) there is an open set G with  that contains  such
that  is open,  is injective on G, and 
is continuously differentiable. Define  by


and note that f  is a smooth function on . If  and
, then  and

completing the proof. â 
Observe that the hypothesis in the preceding result that 
can be replaced by  for any  and the conclusion will
remain that the point  is contained in a small relatively open
subset of  that is a graph. For example if  we will
have an open subset  of  and a smooth function  such
that


A similar conclusion holds if the hypothesis is that .
 
Before we can state a condition for there to be a unit normal vector, we need
 to briefly review the cross product of vectors in .
 
Recall that if , then
 


There is a certain cyclic pattern in this definition, but the easiest way to
 remember it was given in Calculus as the determinant
 


where the unit vectors  are now being labeled . You can see
 that these equations are the same as the definition above by expanding the
 determinant by minors using the first row. Here are the basic properties of the
 cross product.
 
8.3.5. Proposition. If  and , the following hold.
 
(a)   and .
(b)  .
(c)  .
(d)  .
(e)  .
(f)  .
(g)  If , then  is orthogonal to both x and y.
Proof. The proof of much of this proposition is routine and in Exercise 6
the reader is asked to supply the details. (a) Regard the determinant
definition of the cross product and realize that part (a) is a consequence
of two facts about determinants.  is a consequence of the fact
that a determinant is 0 when two rows are identical. 
is a consequence of the fact that when two rows in a determinant are
interchanged, the new determinant is the negative of the other.
(b) and (c). Just use the definition of the cross product,
(d), (e), and (f). By the definition of the cross product,
. Take the inner product
with z. Now write out the cross product of  and take its inner product
with x. Compare the two calculations to see that they are equal. Expand
the determinant in (d) by minors using the first row to see that this equals
the formula for . (e) Compute both sides and compare. (Ugh!)
Follow the same instructions to show (f).
(g) By (d) and (a), . Similarly,
. â 
Now to fix some notation that will help us explore what we mean by an
orientation of a 2-surface.
8.3.6. Definition. If  is a 2-surface in  with ,
then

Note that  and  are precisely the first and second columns in the
 matrix of  in . So  are continuous functions from R
 into . Thus we obtain another function ; by a
 calculation
 

For any point  in R, define
 
 
â(8.3.7)



8.3.8. Example. Let  be an open subset of , let R be a surface
 domain contained in , and assume  is a smooth function.
 If  is given by , then  and
 . It follows that . See Exercise 7.
 
8.3.9. Proposition. If  is a 2-surface in  and there is a
 point  in  such that , then  is
 orthogonal to every smooth curve that lies in  and passes through the
 point .
Proof. Let  and let . First note
that if , then at least one of its coordinates is not 0; without
loss of generality we may assume that . By Proposition 8.3.4
there is an open set  in  and a smooth function  such that


Thus to prove the proposition it suffices to assume that  is given
by  for a smooth function  as in
Example 8.3.8. Using that example and Proposition 6.7.8, this finishes the
proof. â 
In analogy with Definition 6.7.10 we present the following.

8.3.10. Definition. If  is a 2-surface in  and 
such that , then the tangent plane to  at the point
 is defined as


Here is another definition.
 
8.3.11. Definition. A 2-surface  in  is said to be regular if
  for all  in .
So for a regular surface we have a well-defined normal vector at every point of
 the interior of its domain. Now we want to examine what happens when we
 change variables.
 
8.3.12. Proposition. If  and  are 2-surfaces in  and
  is a mapping that is smooth in some neighborhood of Q such
 that , then for all  in  we have that
 


Proof. This is basically an application of the Chain Rule. As usual
 we set  and . For 
 and the fact that , a computation shows that
  for all  in Q. The result now
 follows directly by computation. â 
 
8.3.13. Definition. Two regular 2-surfaces  and  in  are
 equivalent if there is a neighborhood  of Q and a bijective regular
 mapping  from  onto a neighborhood of R such that  and
 .
 
It follows that this is indeed an equivalence relation between 2-surfaces
 (Exercise 8). Technically we should define a 2-surface as an equivalence class of
 what we have defined as a 2-surface. Indeed in many books this is the
 approach taken. Our approach of defining a surface as a function was taken
 for simplicity and ease of exposition. Nevertheless we will still have to
show that various properties of surfaces remain the same for equivalent
surfaces.
Note that in practice when we want to define a map  to demonstrate that
two surfaces are equivalent, we won't specify the neighborhood  on which 
is defined but only define  on the set Q. The definition of  on a
neighborhood will be clear.
Exercises

(1) Let  and put . Find a surface  such
that
.
 
(2) Let  and define  by


Show that  is a surface whose trace is the hemisphere as in
Example 8.3.3.
 
(3) Verify the statement in Example 8.3.3(c).
 
(4) In Example 8.3.3(d), what is the image of the segment ?
What are the images of the segments ? Verify that
 is a torus.

(5) If  and  is defined
by , show that  is a 2-surface whose trace is
the truncated cone .
 
 
 (6)  Supply the missing details in the proof of Proposition 8.3.5.
 
 (7)  In Exercise 2 above calculate .
 
 (8)  Show that the concept of equivalence defined in Definition 8.3.13 is an
 equivalence relation on the collection of all 2-surfaces in .
8.4.  Integration on Surfaces
In this rather long section we'll define an integral on a regular 2-surface using the
 normal vector and explore its properties. We'll also introduce orientable surfaces
 and the concept of the positive orientation of a surface relative to a solid it
 surrounds.
 
8.4.1. Definition. If  is a regular 2-surface in  and 
 is a continuous function, define the surface integral of f  over  as
 


and define the surface area of  as
 


Why
 define
 the
 integral
 this
 way?
It is possible to look at this formula in a way that makes it seem natural once
we justify the the formula for ; let's undertake this. Imagine approximating
the area of  by the sum of small rectangles contained in the tangent planes to
the surface. The area of each of these small rectangles is close to the length of the
normal vector  times the area of the underlying rectangle in the surface
domain R. Once you accept this we see that this leads to the integral defining
 in the definition. We'll avoid the details but a web search may shed some
light on such an undertaking. Once this is established we see that the
definition of  is obtained by approximating by the sum of the
values of the function f  times a small amount of area of the underlying
surface.
The reasons for looking at this integral are rooted in physics, but we won't go
into this; the interested reader can do a web search for "vector fields" and
"surface integral."
We'll look at some examples below that show that the above formula gives
the value of the surface area we expect. First let's point out that the
surface area and surface integrals for equivalent regular surfaces are equal
(Exercise 6).

8.4.2. Example. (a) Let's start with a rectangle in the xy-plane
considered as a subset of . Let  and define
. Here  and  for
all . It follows that . Thus
 
 


as expected. We might give a preview here of something we will soon do,
 namely discuss the surface area of a box in . This is an example of a
 non-smooth surface, but we can call it a piecewise smooth surface. We can
 approach the calculation of this surface area by partitioning the surface of
 the box into six smooth surfaces, calculating each of their areas and adding
 them together.
 
(b) How about a circular disk in the xy-plane? The approach is similar
 to what we did in part (a) and this is left for the reader as Exercise 1.
 
(c) Calculate the surface area of a truncated cylinder of
 radius 1. Recall from Example 8.3.3(c) that we let 
 and define the surface  by ; and
 . So
 
 and . Hence  for all  in
 R and . Thus . If you slit the cylinder
 vertically and lay it flat, you get a rectangle with sides of length  and 2.
 So again the formula from Definition 8.4.1 yields the correct answer.
 
(d) The area of a graph of . Here ,
 so that . Thus
 


We
 need
 to
 introduce
 additional
 concepts.
I ask the reader to be patient when (s)he reads the next definition as it
may seem strange. We'll have a discussion after the statement that I
think will help. Remember that an open disk in  is a set of the form
.

8.4.3. Definition. If  is a smooth surface in  and  is a
point in , say that  is an interior point of  if there is a
homeomorphism of an open disk in  onto a relatively open subset of
 that takes the center of the disk onto . Let  denote the
set of interior points of . A point of  is a boundary point if it is not
an interior point. We denote the set of boundary points by . The surface
is said to be closed if it has no boundary points.





The first comment is that this terminology is standard even though it
introduces an ambiguity with the topological terms interior, boundary, and closed
as well as the notation for the interior and boundary. On the other hand the
definition of an interior point and boundary point of a surface is consistent with
the topological notions if we think of the relative topology. The definition of a
closed surface is completely at odds, however, with its topological cousin. This all
seems unfortunate but in practice it should not lead to confusion. We'll see some
examples shortly.
Realize that the trace of a two-surface, , is the continuous image of the
compact set R so topologically it is always closed in . Also it is a
two-dimensional object sitting inside  and so it cannot have any
interior points in the topological sense. Thus in the topological sense,
every point is a boundary point. With such observations we see that to a
large extent the topological versions of the words are irrelevant for a
discussion of a surface and won't arise very often. Nevertheless to aid
in making this distinction we wiil use the symbols  and  for
the interior and boundary points of the surface as defined above and
always use  to discuss topological properties of the trace of the
surface.
It is useful to be aware of an intuitive or visual way of defining the
interior points of a surface. Imagine (and do not take this literally) you are
standing at some point of the surface and you decide to move a small
amount. If it is the case that you can move in any direction while remaining
on the surface, then you are standing at an interior point. If there is
 
 some direction such that no matter how small a step you take in that
 direction you must fall off the surface, then you are standing at a boundary
 point.
 
Now let's consider a few examples. Consider the surface  whose trace is the
 rectangle sitting inside the xy-plane in  as introduced in Example 8.4.2(a)
 above. Here  is the set of four edges while the other points are in . The
 sphere in  is a closed surface since every point is an interior point.
 The same is true of the torus. The hemisphere, however, is not a closed
 surface.
 
The proof of the next result is an application of the Inverse Function Theorem
 and is left to the reader as Exercise 7.
 
8.4.4. Proposition. If  is a regular 2-surface, then the image of
 the topological interior of R is contained in .
 
8.4.5. Definition. Say that a regular surface  is oriented if  is a
  function and for  in R with  in
 , it follows that
 


If  is oriented and , we define the
 unit normal to be the vector-valued function  by
 


When  is oriented with unit normal  and  is a
continuous function, then the oriented surface integral of F on  is defined
as


See Exercise 8.
The condition that  is the same unit vector at points where
 takes on the same value means that the vector  points in the same
direction at such points. Hence the definition of  is unambiguous.
The reader may be perplexed when  is defined since  is not
normalized in the integral on the right-hand side of the formula. But this
happens because we defined  in (8.4.1) so that this
occurrence of  cancels the one in the denominator of the definition of
. Finally we have used the boldfaced notation  for unit normal after having
said previously that we won't use boldface to denote vectors. Alas, sometimes
clarity must trump doctrine. The letter n is used too often as a subscript or as
the number of elements in a set to let it be used in its naked state as
an important vector-valued function. In addition this is the traditional
notation.

8.4.6. Example. When  is a regular surface in  , suppose the
continuous function  is given by
 
 


Using (8.3.7) we have that  equals
 

Symbolically we write this as
 
 
â(8.4.7)

 We'll have more to say about this when we encounter differential forms in the
 next chapter.
 
8.4.8. Example. The MÃ¶bius3
 Strip is the most famous of all non-oriented surfaces. I suspect that every
 reader has come across this surface in some form, and many of you may
 have constructed one by giving a strip of paper a single twist. If you do
 this you see that you obtain a surface with "one side." This is the trait
 of not being oriented, but let's examine this strip from a mathematical
 point of view and match it with the definition of an oriented surface
 given above. Let  and define 
 by .
Sketching any surface in  is a challenge, but doing this one is particularly
difficult and will tax your artistic abilities; but it does give the MÃ¶bius
Strip. Note that if u is a constant, then as v varies from  to 1 a straight
line segment  is transcribed. As u progresses from  to  this
segment  rotates. It is this rotation that creates a lack of orientation
and leads us to say it is a surface with only one side. In Exercise 9 the
reader is asked to show the  is not an oriented surface.

8.4.9. Definition. If two oriented surfaces  and  are
equivalent with a smooth, bijective mapping  such that
 as in Definition 8.3.13, then they are orientation equivalent if
the Jacobian of  satisfies  for all  in Q.
As we pointed out when we defined equivalent surfaces earlier, since the
surfaces are regular it follows that  for all  in Q. But because
Q is connected it follows that the Jacobian must be always positive or always
negative.

8.4.10. Proposition. Let  and  be equivalent oriented
surfaces with a smooth, bijective mapping  such that 
and let F be a continuous function from  into .
(a)  If the surfaces are orientation equivalent, then
.
(b)  If the surfaces are not orientation equivalent, then
.
Proof. (a) Assume  is always positive. By Proposition 8.3.12,
. Hence

where  is defined by . Now using
 
 the COV Theorem (7.4.4) we get that
 


The proof of (b) is Exercise 10. â 
 
8.4.11. Example. (a) Let  and . Define
 by


A calculation shows that  everywhere on
the unit square. Thus every regular surface with surface domain a rectangle
is orientation equivalent to a surface with domain the unit square.
(b) Let  be a regular surface and put .
Define  by . A computation shows that
 so that  everywhere on Q. If  is the
regular surface defined by , then this surface is equivalent to
 but not orientation equivalent. In fact . In
other words, if we are given any regular surface  there is an equivalent
surface  such that at every point of , .
In (8.2.2) we defined what it means for a piecewise smooth curve  in
 that forms part of the boundary of an open set G in  to be
positively oriented relative to G. We'd like to extend this to curves that
form part of the boundary of an oriented surface . In fact for an
oriented surface  it is often the case that  consists of a finite
number of piecewise smooth curves. (For example, if  is a hemisphere or
a rectangle.) We would like to induce an orientation on the curves in
 relative to the orientation of . This can be done in a precise
manner, but that requires more concepts and will be postponed until the
next chapter when we discuss differential forms in higher dimensional
Euclidean space. Here we give a heuristic description of this induced
orientation.
Suppose we are given a point  on the surface. Near this
point the surface has two sides, including one where the normal vector  is
pointing. That side where  is pointing is called the positive side of  near
this point. Assume  is one of the curves that make up , and imagine you
are walking along  with your head pointing in the direction of ; that is, your
head is in the positive side of . We say you are going in the positive direction
 
 of  relative to  provided  is on your left. This is also called the
 right-hand orientation of . Notice that this is consistent with our definition
 of the positive direction of a curve in  given in (8.2.2). In fact let  be
 a surface with  a subset of the xy-plane in  and  is a piecewise
 regular curve . Assume the unit normal vector  for  points upward
 into the half-space . Then the positive direction of
  as discussed above is the counterclockwise direction as discussed in
 Â§8.2.
 
It must be emphasized that the positive direction of  depends on the
 orientation of the surface whose boundary includes . We'll see that in the
 following example, especially part (b).
 
8.4.12. Example. (a) Consider the hemisphere centered at the origin of
 radius r that lies above the xy-plane; so 
 and . (This  is not regular in a
 neighborhood of R as required; a correct parametrization can be found
in Exercise 8.3.2.) Here  is the circle . It
follows that


(See Exercise 2.) So the positive direction for this surface is upwards
and the positive direction for  is to go along this circle in the
counterclockwise direction.
(b) Suppose , ,
and .
So  and  consists of two circles  and  with
.
The unit normal vector for  is , the positive direction for  is
counterclockwise, and the positive direction for  is clockwise.
Now we extend the ideas of regular surfaces and oriented surfaces to piecewise
versions to accommodate examples such as the boundary of a cube in
.

8.4.13. Definition. If  is a surface for  and
, then  is called a piecewise regular surface if the following
conditions are satisfied: (i) each  is a regular surface; (ii) for
 either  or ; (iii) for three
distinct indices in  is either empty or finite.
The boundary of , , is defined as the closure of the set of points x in
 such that for some index i,  but  for all .
The surface area of  is defined by


If  is a continuous function, then
 


There is a certain inconsistency in the above definition in that the surface
  is described as a set of points rather than a function. There are some things
 we could do to make it a function, but they could easily be considered
 contrived and it doesn't seem worth the effort. It's better to live with this
 inconsistency. Besides the surface of a cube, there are other examples of sets
  that we want to consider that are not surfaces as in Definition 8.3.1
 since they are not connected. The first such example is  where S
 is the corona of Example 8.3.2. Since  is not connected it is not a
 surface but it does satisfy the definition of a piecewise regular surface.
 Let's point out a similarity to the definition above and that of a G-set
 (8.2.6).
 
The preceding definition seems plain enough, but if  is described
 geometrically as a set of points in , it may be difficult to find the regular
 surfaces  needed to make the piecewise regular surface fit the definition.
 Let's look at an example taken from [15].
 
8.4.14. Example. If  is the surface of the tetrahedron in  resulting
 from taking the topological boundary of the solid bounded by the four
 planes , and , compute  when
 .  has four faces , where
 each face has the
 same surface domain  (the
 triangle in  with vertices ); and for each  in
R we define , , ,
.
A computation shows that  for  and .
Setting up the integrals and performing the computations (Exercise 15)
shows that


Defining what is meant by a piecewise regular surface to be orientable is
tricky. For  let  be a surface such that  is a
piecewise regular surface. If we want to have  orientable, we clearly must have
each  orientable; this is not sufficient as the reader can see by using the
MÃ¶bius Strip (Exercise 19). We need to be sure the direction of the
various normals  are consistent. This is easy with something like the
surface of a box where for each of the six surfaces that correspond to the
surfaces of the box we can choose the outward (or inward) pointing normal
vector.
The next definition is again heuristic, but it suffices for the examples we will
see. In the next chapter we will use a different approach and make it all
precise.

8.4.15. Definition. For  let  be a surface such that
 is a piecewise regular surface and each  is a piecewise
regular curve that is positively oriented relative to .  is a a piecewise
orientable surface if the following hold: (a) each  is oriented; (b) if
 and , then the positive direction of any curve
in this intersection relative to  is the opposite of the positive direction
of this curve relative to ; (c) the surfaces  are so oriented that
the directions of the normal vectors  are consistent on each component
of .
When  is an oriented piecewise regular surface and
 is a continuous function, define the surface integral by
 
 


The meaning of condition (c) is imprecise, but for most examples it becomes
 clear. For example with a box it must be that the normal vectors for each face
 must point outward or they must all point inwards. Or consider the boundary of the
 corona, , a piecewise regular surface. Here we could make the normal vector on
 the outer boundary point away from the origin and the normal vector on the inner
 boundary point toward the origin. We can similarly orient the boundary of a cylinder.
Exercises

(1) Give the details to show that the definition of surface area in (8.4.1), when
applied to , yields .
 
(2) Let  be the hemisphere of radius r as in Example 8.4.12(a).
(a) Verify the formula for  given there. (b) Find . (c) Find
 when  is the hemisphere of radius r centered at the origin
and lying above the xy-plane and .
 
(3) Find the surface area of the torus (Example 8.3.3(d)).
 
(4) Find , where  is the upper half of the sphere centered at the
origin in  and having radius 2.
 
(5) Find  if  is the surface of the circular cone sitting
on the xy-plane with base  and height 3.
 
(6) If  and  are equivalent regular surfaces, show that
; and if f  is a continuous real-valued function on
, then show that .
 
(7) Prove Proposition 8.4.4.
 
(8) If  is given as the graph of a smooth function 
(Example 8.4.2(d)), is it oriented?
 
(9) In the MÃ¶bius Strip (Example 8.4.8) find distinct points  and
 in R such that  but



 (10)  Prove part (b) of Proposition 8.4.10.
 
 (11)  Show that there is an oriented surface 
 such that  and determine the
 positive direction of .
 
 (12)  Consider the surface  where
  and . Determine the positive
 direction of each curve that makes up .
 
 (13)  Let  and define  by .
 If , find .
 
 (14)  (a) Find a surface  such that
 , show that it is oriented, and
 determine the positive direction of the curves comprising . (b) Find
  when .
 
 (15)  Carry out the computations in Example 8.4.14.
 
 (16)  Find  when  and  is the topological
 boundary of the box .
 
 (17)  Find  where  is the surface in  bounded by the
 cylinder , the plane , and the disk .
 
 (18)  If 
 and , find .
 
 (19)  Consider the MÃ¶bius Strip X (8.4.8) and
 for  let . Show that for the map
  we can consider X as the piecewise regular surface 
 and each  is orientable.
8.5.  The Theorems of Gauss and Stokes
This last section of the chapter contains two important theorems, but first we
need two pieces of notation that the reader may recall from Calculus.

8.5.1. Definition. Let X be an open subset of  and suppose
 is a smooth function with . The curl and
divergence of F are the functions  and 
defined by


and


The readers who have not seen these before can be forgiven their
bewilderment, but realize that to remember the formulas we can do the following.
Recall the definition of the gradient of a differentiable function ,
where G is an open subset of , and define the symbol
 
 


Treating  as a vector in  we have that symboically
 


The concepts of the curl and divergence of a function originated with the
 study of fluid flow.
 
Just as we did when we proved Green's Theorem, we want to discuss
 particular types of Jordan sets in .
 
8.5.2. Definition. Here we say that a Jordan subset X of  is
 Type I if there is a compact rectangle S in  and regular
 functions  such that  for all  in
 S and ; X is Type
 II if there is a compact rectangle S in  and regular functions
  such that  for all  in S
 and ; X is Type III
 if there is a compact rectangle S in  and regular functions
  such that  for all  in S and
 .
 


Once again, as we said in the preface to this chapter, at a few points in the
 remainder of this section we will rely more on the reader's intuition and, perhaps,
 call on him/her to fill in more of the details. Most of this will occur when we
deal with orienting piecewise regular surfaces. In the next chapter these
things will be rectified. The next proof is a dramatic example of this
approach.

8.5.3. Proposition. If X is either a Type I, Type II, or Type III set as
defined above, then  is a piecewise orientable surface.
Proof. We only prove this for Type I sets, so let X be such a set with the
notation as in the definition and assume the rectangle .
Put

It follows that  is the union of these six surfaces, now called faces, and is a
piecewise regular surface. Moreover we leave it to the reader to show that each
face is orientable and if we take the normal vector to each face pointing
outward from X (that is away from ),  is positively oriented.
â 
In analogy with Definition 8.2.6 we make the following definition.

8.5.4. Definition. Let X be a compact Jordan subset of  whose
topological boundary is a piecewise regular surface that is positively
oriented. Let  be a collection of closed subsets of X.
We say that  is a Type I cover of X if each set 
is Type I and the following are satisfied: (a) ; (b) when
, ; (c) if , and  are three
distinct sets, then  is either empty or a finite set; (d) each
 is oriented and if  and  is not finite, then
 for each  in . The collection
 is called a Type II cover (respectively, Type III cover) if
 
 each set  is a Type II (respectively, Type III) set and the analogues of
 conditions (a), (b), (c), and (d) above are also satisfied.
 
A G-set X in  is a compact Jordan subset of  whose topological
 boundary is a piecewise regular surface with positive orientation and such
 that it has a Type I cover as well as a Type II cover and a Type III cover.
 
Note that as a consequence of condition (d) in the above definition it follows
 that for any smooth function  we have that
 
 
â(8.5.5)


8.5.6. Theorem (Gauss's4
Theorem). If X is a G-set in  and  is a smooth function,
then


(Gauss's Theorem is also called the Divergence Theorem.)
Proof. If , then we have that


and from (8.4.7)


This reduces the proof to establishing three separate equalities that only
 involve the scalar-valued functions , or R one at a time:
 

Let's show that
 


Since X is a G-set there is a Type I cover . Since the
 volume of each  is zero, we have that
 


Therefore by (8.5.5) we need only prove that for 


To simplify the notation we can assume that X is Type I and use the notation
of Definition 8.5.2. From Fubini's Theorem and the Fundamental Theorem of
Calculus we have that

Now let's examine . As in Proposition 8.5.3,  is
composed of six faces: . Note that on the first four of
these faces either the variable x or variable y is held constant. Thus
the integral of R over these faces is 0. Therefore we have (Exercise 1)
that
 
â(8.5.7)

 (Why the minus sign?) We note this is the same as the value of .
 
Now X also has a Type II and a Type III cover and we can use these to give
 proofs that  and .
 â 
 
8.5.8. Example. This example shows how Gauss's Theorem can be used to
 simplify the evaluation of an integral.
 
(a) Define  by  and let X be the
 unit sphere in  centered at the origin and having radius 2. So X is
 a G-set. (Why?) Find . Note that .
 So . From Example 7.4.19(b) we know
 the formula for the volume of this sphere is , so
 . This was easier than parametrizing the boundary
 of the sphere.
 
(b) Let  and 
 and evaluate . Here  so
 


This is easier than integrating  over the six different sides of .
 
8.5.9. Example. Find  when X is the unit sphere in  centered
at the origin. Here we want to use Gauss's Theorem to express
this as an integral over . To start we need a function F on
 such that . We're free to choose any so let's pick the
easiest: . Now we need to parametrize . Let
 and define  by


It follows that

Hence

The next celebrated theorem examines the case of a surface like a hemisphere
 in  whose boundary is a curve. We only prove this theorem for a
 special case where the surface is the graph of a smooth function. Later
 in Theorem 9.5.1 we'll prove a generalization of this theorem and so it
 doesn't seem justified to do the extra work to prove the result here in .

8.5.10. Theorem (Stokes's5
 Theorem). If R is a G-set in  and  is a regular surface in
  such that  is a piecewise regular curve with positive orientation
 relative to , then for any smooth function ,
 


Proof of a Special Case. Assume , where f  is
 a twice continuously differentiable function  defined on the
G-set S. Thus for  the unit normal vector is  where
. Putting  and using (8.1.9) we have that


To simplify matters we'll assume that the topological boundary of the
G-set S is parametrized by a single piecewise regular curve  defined
on  with . (If  consists of a finite number of
such curves, the argument that follows is the same but notationally more
cumbersome.) Thus  is parametrized by the function on  defined
by .
Now in the integral above we have


so that symbolically the integral above becomes


To evaluate this integral we will use Green's Theorem. To do this we need
 to calculate the partial derivatives of the functions in parentheses, and to
 do this we use the Chain Rule to get
 


and
 


Now because f  has continuous second partial derivatives, .
 Therefore
 

Putting all this together with Green's Theorem, we have that


 â 
8.5.11. Example. Green's Theorem is a special case of Stokes's Theorem, at
least when the G-set X has its boundary as a single piecewise regular curve.
In that case using the notation of both Green's Theorem, let  and
. Define  by .
In this case  and , the term that appears
in Green's Theorem. The formula in Stokes's Theorem now yields Green's
Theorem.

8.5.12. Example. Let  be the upper hemisphere  with
upper pointing normal vector and evaluate . If
we want to do this using Stokes's Theorem we must find a surface 
such that  and a function F such that .
The surface is the easiest: let  and define
. To find  we want the partial
derivatives to satisfy
 
 


The process here is trial and error, so using the last of these three equations
 let's start by guessing that . If we do this the first two equations
 become , . Aha!  works. The appropriate
 curve for  is the unit circle in the xy-plane in the counterclockwise
 direction; that is,  given by . By Stokes's
 Theorem we have
 

since z is constant along .
 
Exercises
Some of the exercises below were taken from websites where I could find no
 authors or other attribution.
 

 (1)  Verify (8.5.7).
 
 (2)  Let S be the sphere  in  and let 
 be defined by . (a) Find a G-set X in  with
 . (b) Use Gauss's Theorem to evaluate .
 
 (3) Let S be the boundary of the unit ball in  with positive orientation. If
, evaluate 

(4)Let  and define
 by . Find .
 
(5)If X is the unit sphere in  of radius 1, use Gauss's Theorem to evaluate
.

(6)Let S be the boundary of the unit ball in  with positive orientation. If
, evaluate .
 
(7)Compute
 where  is the circle in  
with the counterclockwise direction and
.
 
(8)Define  by  and define
 by . Evaluate  by
using Stokes's Theorem.
 
(9)Let S be the hemisphere . If  is the outward pointing
normal, and , find .
 
(10)Let .
(a) Give a parametrization  for S. (b) Use Stokes's Theorem to
evaluate .
1A biographical note for Camille Jordan can be found in Definition 7.2.8.
2George Green was born in 1793 in Sneinton, England. His father was a baker and George's formal
schooling was rather limited. In fact he had only about a year's formal education starting when he was
eight. He had to withdraw from school when he was needed back in the bakery. With time his father
prospered and purchased several other bakeries and even established his own mill where George worked.
Somehow through all this, George continued to study mathematics. How he became familiar with
the forefront of mathematics is not known. He never married Jane Smith, the daughter of
the manager of his father's mill, but they lived together and eventually had seven children.
In 1828 Green published one of his landmark papers on electricity and magnetism. It was
offered "on subscription," meaning that to obtain a copy you had to pay a fee. One of the
subscribers was Sir Edward Bromhead, an established mathematician, who immediately contacted
Green and offered to communicate his future papers to the Royal Society of London. After
a delay by Green, he and Bromhead began regular meetings. Green soon produced three
new papers, two on electricity and one on hydrodynamics, all of which were published in
leading journals. Later Bromhead suggested Green study at Cambridge, where he enrolled
in 1833; he became an undergraduate at the age of 40. He graduated four years later and
in 1839 he became a Perse fellow. (The fellowship required that the holders be unmarried,
which Green was in spite of his having six children at the time. His seventh was born shortly
after receiving the fellowship.) Unfortunately his health deteriorated and he died in 1841 in
Sneinton.
3August Ferdinand MÃ¶bius was born in 1790 in Schulpforta, Saxony; his father was a dancing
teacher and died when MÃ¶bius was three years old. He was educated at home until he was 13 and
then was enrolled in school. In 1809 he entered the University of Leipzig. In spite of his interest
in mathematics, he began by studying law at the urging of his family. He soon decided to follow
his own inclinations and switched to mathematics, astronomy, and physics. In 1813 he went to
GÃ¶ttingen to study astronomy with Gauss. He then went to Halle to study mathematics with
Pfaff, Gauss's teacher. He soon completed a doctoral thesis in mathematics and astronomy and
in 1816 he was appointed to the faculty at the University of Leipzig. In spite of not being able
to secure a post at Leipzig that was more prestigious than the one he had and in spite of offers
from other universities, he remained at Leipzig. (Apparently he was not a good teacher.) Finally
in 1844 he received an offer from the University of Jena; to counter this, Leipzig offered him a
full professorship in astronomy. He made contributions to projective geometry and other areas of
mathematics and astronomy. His discovery of the strip described here was part of a larger work
on one sided surfaces. It must be mentioned that the strip was independently discovered at about
the same time by Johann Listing. MÃ¶bius died in 1868 in Leipzig.
4Johann Carl Friedrich Gauss was born in Brunswick, Germany in 1777. At the age of seven he began
his schooling and from the start exhibited extraordinary talent in mathematics, making small
discoveries of known results. As a teenager he discovered the law of quadratic reciprocity
and the prime number theorem. In 1795 he enrolled in GÃ¶ttingen University, but left in
1798 without a diploma in spite of great success that included the construction of a regular
17-gon with ruler and compass, the first progress in such questions since the time of the
ancient Greeks. He returned to the university and received the degree the next year. In 1801
he published his book Disquisitiones Arithmeticae, which was devoted to number theory
except for the last section that contained his work on the 17-gon. He also began extensive
work in astronomy and made many significant contributions, leading to his appointment as
director of the GÃ¶ttingen observatory in 1807. Two years earlier he married. Sadly his wife
died four years later after giving birth to their second son, who also died shortly after his
mother. A year later he married his first wife's best friend and they had three children. Gauss's
professional life was long and filled with discoveries. His motto was "Few but Ripe." This
meant he never published anything unless he had fully developed the subject. He kept a
notebook in which he wrote his ideas, many of which were eventually rediscovered and were
significant for the progress of mathematics. He is thought by some to have been the greatest
mathematician ever. While there is no doubt that he was one of the giants of the profession,
I've always thought the comparison of achievement of people from different epochs to be
unwise. Suffice it to say that he did work in different areas of mathematics and whatever
he turned his attention to resulted in extraordinary advancement. He died in GÃ¶ttingen in
1855.
5George Gabriel Stokes was born in County Sligo, Ireland in 1819. His father was a church minister
and he remained deeply religious his entire life. His early education was near home, but at the age of 13
he went to school in Dublin where he stayed with his uncle. At 16, in 1835, he enrolled in
Bristol College in England where his mathematical talent was recognized. Two years later he
entered Cambridge University where he remained as a student and then a faculty member
for the rest of his life. In 1842 he published papers on hydrodynamics, and in particular
incompressible fluids, a subject he focused on for much of his life and from which the present
theorem emerged. He also made significant contributions to the study of light. In 1857 he
began a courtship with Mary Susanna Robinson, the daughter of an astronomer at Armagh
Observatory in Ireland. The courtship followed a path different from romances today in that
it was accompanied by an extensive exchange of letters. They married that year and this
meant he had to resign his fellowship at Cambridge. (Five years later the university did away
with the rule that prohibited fellows from being married.) He and his wife had five children.
As his career progressed he turned his attention to administration and from 1887 to 1892
he was one of three members of Parliament from the university. He died in Cambridge in
1903. 












9 Differential
Forms
Differential forms constitutes an approach to multivariable calculus that
simplifies the study of integration over surfaces of any dimension in . This
topic introduces algebraic techniques into the study of higher dimensional
geometry and allows us to recapture with rigor the results obtained in the
preceding chapter.
There are many approaches to defining and exploring differential forms, all
leading to the same objective. One is to just define a form as a symbol with
certain properties. That was the approach taken when I first encountered the
subject. Though this appeals to many and ultimately leads to the same objective,
it strikes me as inconsistent with the approach we have taken. So in this chapter
I have decided to follow the approach in [7] where a form is defined in terms that
are more in line with what I think is the background of readers of this book. The
reader might also want to look at [1], [9], and [10] where there are different
approaches.
9.1.  Introduction
Here we will define differential forms and explore their algebraic properties and
the process of differentiating them. The first definition extends that of a surface
as given in the preceding chapter.

9.1.1. Definition. Let . A q-surface domain or just a surface domain
is a compact Jordan subset R of  such that  is connected and
. A q-surface in  is a pair  where R is a q-surface
domain and  is a function from R into  that is smooth on some
neighborhood of R. The trace of  is the set . If
G is an open subset of  and , we say  is a q-surface in
G; let  be the collection of all q-surfaces contained in G. We define
a 0-surface in G as a constant function with value in G.







A comparison of the above definition with the definition of a 2-surface in
(8.3.1) reveals a difference. In (8.3.1) we required the boundary of the
surface domain to consist of curves; here we do not. Indeed we cannot. If
, for example, this would prohibit all but a few possible choices of R. As
in the last chapter we will sometimes describe a set S in  and say it is a
q-surface. What we mean by this is that there is a q-surface  as defined
above with ; again  will be called a parametrization of
S.
9.1.2. Example. Of course all the examples from the previous chapter are
available, but here are two
more. (a) Let  and let S be the unit hemisphere
in : . This is
a  surface in , though as we mentioned in Example 8.3.3(b)
the function  defined by  is not a
parametrization since it fails to be smooth in a neighborhood of R. In
Exercise 8.3.2 a parametrization when  was given, here is one when
. Let  and define  by


The reader can check that  is a parametrization of S when .
 Also see Exercise 1.
 
(b) Let , let R be any surface domain in , fix indices
  in , and let  be a fixed vector in . If
  is defined by , where  is
 the standard basis for , then  is a q-surface in . (Exercise 2)
 


9.1.3. Definition. Let G be an open subset of . A 0-form on G is a
 continuous function . When , a differential form of order q or
 simply a q-form on G is a function  defined as follows. Let
  be a finite collection of subsets  of , each of
 which has q elements, and suppose that for each I in  we are given a
 continuous function . For any  in  we
 define
 
 
â(9.1.4)

 This is symbolically written as
 


The q-form  is smooth if the coefficient functions  are continuously
differentiable. If each coefficient function is continuously differentiable up to and
including the derivatives of order , then  is said to be a q-form of order
n.





Whew!
 That's
 a
 complicated
 definition.
 
Let's take it apart and examine it and then we'll look at some examples. First
note that a q-form is a function defined on the set of functions . This is
not the only example you'll ever see of a function whose domain is another
collection of functions. In fact you can interpret an integral as being just such a
function. As we said , so a 0-form f  on G acts on a point in G
by evaluating the function at the point. Next, for any  the term
 in the definition can be treated at this stage solely as notation.
(The symbol  is read "wedge.") Later we will give it more content and
develop  as a form of multiplication for differential forms, but now
it's just notation. The first equality in (9.1.4), , is just an
alternate way of writing the value of the function  at an element of its
domain. It is, however, a useful way of interpreting the value of  at a
point in its domain and this interpretation will be amplified later. As
stated, the indices  are contained in , and there is no
guarantee that they are distinct; again, we'll see more on this in the next
paragraph. There are, however, only a finite number of the continuous
functions . Yes, the sum inside the integral in (9.1.4) could have
been put outside the integral sign; that's just the way we chose to do
it.
The Jacobian that appears in (9.1.4) arises as follows. If 
has coordinate functions , then the Jacobian
is the determinant of the mapping from R into  defined by
 
 . That is,
 
 
â(9.1.5)

 Remember that  is assumed smooth in a neighborhood of R so the derivatives
 present no problem and the Jacobian is a continuous function. Also note that if
 the indices  are not distinct, the Jacobian is the determinant of a
 matrix with identical columns and so it must be 0. Finally, if the formula in
 (9.1.4) reminds you of the Change of Variable Theorem (7.4.4), it should.
 Suppose  and . So here we have a surface domain R contained
 in  and a function  that almost satisfies the hypothesis of
 Change of Variable Theorem (7.4.4). If  does indeed satisfy this hypothesis,
 then for ,
 


Except for the absolute value sign around the Jacobian of , this is precisely
 the formula for  when  is the p-form . For a q-form
  with , as the notation  suggests, we want to think of
 integrating  over the surface  where we define such an integral by
 transferring to the integral over the surface domain in the way stipulated in
 formula (9.1.4).
Now for some examples. Study them carefully. You will notice that we have
seen differential forms many times before without ever calling them by this
name.

9.1.6. Example. (a) Suppose , , and G is
an open subset of . Here the only 1-form possible is . A
1-surface in G is a continuously differentiable function  and,
using the Change of Variables Theorem,


We therefore see again the idea mentioned in the paragraph preceding
this example that differential forms are a way of defining an integration of
functions over a surface. This will be reinforced as we develop the theory.
(b) Let  be a regular curve. As we pointed out,  is a
1-surface if we assume  is smooth in a neighborhood of . Assume the
trace of  is contained in the open set G, and let  be a continuous
function. If  is the usual basis for , then we set 
and . So if we define the one form  on G,
then by definition

So we see that the line integral defined in (8.1.8) is an example of a 1-form. In
fact the general 1-form on  is  for continuous functions
 
 .
 
(c) Let  be a 2-surface in  and recall the definition of
  (8.3.7). Consider the 2-form .
 So
 


the surface integral defined in (8.4.1).
 
(d) Again let  be a regular 2-surface in  with , an
 open subset of . If  is a continuous function denoted by
 , let  be the 2-form on G defined by
 


It follows that , the oriented surface integral as in
 (8.4.7).
 
(e) Let  be a 1-surface in  and let  be the 1-form
 . It follows that
 


(f) A general -form on  is


where the notation  means that the term  is missing. 
We now proceed to develop some basic operations on q-forms, first an
arithmetic and then a differential calculus for forms. To set the scene fix an open
subset G in  and define to be the set of q-forms on G. If
, then, since they are all functions on , for  we
define


for every  in . With these operations we see that  is a vector
space.
We want to define a multiplication of forms, which is more complex. To do
this we first examine the representation of differential forms.

9.1.7. Proposition. Let  and let k
and m be distinct integers in .
 
 
(a)  If , then .
 
(b)  If k and m are distinct integers in  and
 


with , , and  when  then
 .
 
In words, part (a) of this proposition says that if any two indices in the
 definition of  are equal, then ; part (b) says that interchanging
 exactly two indices produces the q-form . In particular, when ,
 .
 
Proof. (b) This follows from Corollary 6.4.22: if A and B are two 
 matrices such that B is the same as A except that two rows are interchanged,
 then . Therefore if  and if
 , then
 

(a) We again use Corollary 6.4.22 to get that when a  matrix has two
 identical rows, its determinant is 0. If , then in the definition of
  the Jacobian in that definition has two identical rows; so that .
 â 
 
9.1.8. Corollary. If  and , then


where  and .
The preceding proposition and its corollary allow us to give a canonical
representation of q-forms. First observe that by (9.1.7(a)), when  we have
that  for any open subset G of . Next if ,
we put  and set


This is called a basic q-form. A small counting argument shows there are
 different basic q-forms on . 

9.1.9. Corollary. If  is a q-form on G, then


where I ranges over all strictly ordered q-tuples of the integers 
 and each .
 
Proof. If we are given any  in , by Corollary 9.1.8 we can replace
 the coefficient functions in the representation of  as it appears in the
 definition as follows. (i) Put  if no permutation of the index set
 I appears. (ii) If some permutation of the strictly increasing q-tuple I
 does appear, then let  be sum of all the functions  where
  is a permutation of I and the  sign is chosen according to
 how  is permuted to obtain I. If this is done, we obtain the
 representation as it appears in the corollary. â 
 
Such a representation of a q-form is called its standard representation.
 

9.1.10. Proposition. If  is a q-form in its standard
 representation, then  in  if and only if  for every I.
 
Proof. One way is clear: if each , then  is the zero q-form.
 Conversely assume that  for every  in  and assume
 there is a strictly ordered q-tuple  and a point x
 in G with . By the continuity of  there is a positive
 number  such that  when  for .
 Let , note that the rectangle R is a
 surface domain, and define  by . As in
 Example 9.1.2(g), .
 
Now a computation shows that
 


while for ,


since it is the determinant of a matrix having at least one row of zeros.
Thus


a contradiction. â 
If you know the language of modules, the preceding proposition says that
the basic q-forms constitute a basis for  as a module over the
ring . If you don't know this language, don't worry about it. The
comment was made for the edification of those who know the language
and nothing later in this book depends on what was just said. What is
important about the preceding proposition is that when a differential
form is expressed in its standard representation that representation is
unique.
 
 
Now we want to multiply forms. Since each  in  is a function taking
 values in , we might be tempted to define this as we would the product of any
 such functions: . That's legitimate as a definition, but
 there is a big problem with this. Namely this product is not always a differential
 form as a little experimentation will show. We need a definition where the
 product of two forms is again a form. What we will define is the product of
 forms of different dimensions. We start with the case of a 0-form times a
 q-form.
 
9.1.11. Definition. If  and , define
 


That was natural enough. To define the product of other forms we need to
 start with basic forms of different dimensions and, when we multiply them,
 produce a form in the sum of the dimensions.
 
9.1.12. Definition. Let  and suppose  and
 , where  and . The product or
 wedge product of the q-form  and the r-form  is the (q+r)-form
 denoted by  and defined by
 


In analogy with this definition and notation we could denote the product of
a 0-form f  and a q-form  by . Also note that we have that
. Maintaining the notation of this definition, we observe that if
, then  since at least one index is repeated
(9.1.7a). In particular if , . If ,
let  be the reordering of  into an increasing sequence.
It follows that


(See Exercise 3.)

9.1.13. Proposition. If  are, respectively, an ordered q-index, an
ordered r-index, and an ordered s-index; then


Proof. The proof of this proposition is not difficult, but it is somewhat tedious.
The first step is, however, easy: if any pair of the sets  have an element in
common, then both sides of the above equation are 0. Assuming that  are
pairwise disjoint, the idea is to let  as in Exercise 3,
 
 and analogously  and . If
  is the ordering of , we must show that
 

Thus completing the proof. Carrying out the details is left to the reader
 (Exercise 4). â 
 
9.1.14. Definition. If  and
 , each in its standard representation, then their
 product, denoted by , is defined as the (q+r)-form on G


Let's underline that in the preceding definition we took two forms in their
 standard representation and multiplied them, but the form that is the product is
 not in its standard representation.
 
9.1.15. Proposition. If , , and
 , then:
 
(a)  ;
 
(b)  ; and
 
(c)  .
 
The proof of this proposition establishing the distributive and associative laws
 for the multiplication of differential forms is left to the reader (Exercise 5). As
 we have already seen, the multiplication is not commutative.
 
Now we discuss differentiating smooth q-forms.

9.1.16. Definition. If f  is a smooth 0-form on G, then its derivative is the
1-form


If  is the standard representation of a smooth q-form
on G, then its derivative is the (q+1)-form


9.1.17. Example. (a) Return to Example 9.1.6(a) where . If
 is the 1-form  where f  is a smooth function on , then
 since it is a 2-form on the one-dimensional space. If
we consider the 0-form f , then . Thus we can interpret the
Fundamental Theorem of Calculus as saying that the integral of the 1-form
df  over the 1-surface equals the integral of the 0-form f  over its boundary,
though we would have to give  an orientation to obtain the minus
sign in .
(b) Let , suppose , and assume  is a
smooth function given by .
Put  as in Example 9.1.6(d). So
using the fact that  and



Recall Gauss's Theorem where for an appropriate solid X with  a 2-surface
 we have . Rephrasing this using the form  and its
 derivative we have that Gauss's Theorem says that
 


That is, the integral of the derivative  over the inside of X equals the
 integral of the  over the boundary of X. With this interpretation we can
 rightfully call Gauss's Theorem an extension of the FTC to .
 
(c) As in part (b) let , suppose , and assume 
 is a smooth function given by . This
 time put , and compute . Using the rules for
 differentiating and multiplying forms we obtain
 

You may recognize the coefficients of the basic forms ,
which have been arranged here in a certain rotational pattern, as forming the
components of . We will return to this later in this chapter when we
prove a generalized version of Stokes's Theorem.
(d) Suppose  is a basic q-form: . It follows that
. In fact using the definition of differentiation of q-forms shows
.
(e) Consider , the 1-form on  where  and f  is
smooth. So

We now examine how differentiation of forms interacts with the algebraic
operations as well as what happens when we take multiple derivatives. Regarding
this latter statement, if , say that  is a form of
class  if each  has two continuous derivatives. That is, for each I,
 exists and also  exists
and is continuous. Equivalently, each  has continuous second partial
derivatives.

9.1.18. Theorem. If G is an open subset of ,  a smooth element of
, and  a smooth element of , then the following hold.
(a)  When , .
 
 
(b)  
(c)  If  is of class , then
 


Proof. The proof of (a) is routine. To prove (b) it suffices to show this under the
 assumption that  and . (Why?) First if  so that
  and , then the product rule for differentiating functions shows
 that (b) holds here. When , we have . If I and J
 have a term in common, then both sides of the equation in (b) are 0. So assume
 . Thus
 

where at each stage of these equalities the choice of a plus or minus sign is the
 same. Now using the fact that dg is a 1-form and applying Proposition 9.1.7(b) q
 times we have that . Therefore the above equalities
 become
 

proving (b).
 
 
(c) First we prove this when , a 0-form. In this case, remembering that
  since f  has continuous second partial derivatives and that
 ,
 

so that it must be that .
 
Now let  and assume that  so that, by
 definition, . Using part (b) this implies that
 . But from
 Example 9.1.17(d) we know that . So that 
 when . The case of a general q-form now follows from part (a).
 â 
 
9.1.19. Example. (a) Let G be an open subset of  and suppose f  is a
 continuously differentiable function on G. If  is any regular curve
 and , then Example 9.1.6(b) and the Chain Rule applied to  shows
 that
 

So the value of  does not depend on the precise curve  but only on its
starting and final points,  and . Note that we can interpret this as an
analogue of the Fundamental Theorem of Calculus.
(b) Consider the 1-form  in . If  is defined by
, then  traces the unit circle in the counterclockwise
direction. We have that


From part (a) of this example we see that there is no continuously
differentiable function f  on  such that . More on such a
phenomenon in Â§9.6.
 
 
Exercises

 (1)  (a) Give the details for Example 9.1.2(a). (b) In Example 9.1.2(a) give a
 parametrization
 of the hemisphere S when . Can you give a parametrization for
 arbitrary p?
 
 (2)  Verify Example 9.1.2(b).
 
 (3)  In the definition
 of two basic forms  show that , where
  is the number of differences  that are
 negative.
 
 (4)  Supply the details in the proof of Proposition 9.1.13.
 
 (5)  Prove Proposition 9.1.15. (I know this is tedious, but this is one of those
 instances where if you just read the proof it does no good and does not have
 any meaning. If, on the other hand, you work it out on your own you will
 gain extra familiarity with the concepts.)
 The next two exercises are from [1].
 
 (6) Let  be the 2-form on  defined by ;
 let  be the 2-surface in  where  and
 . Compute .
 
 (7) Let  be the 3-form in  defined by ; let
  be the 3-surface where  and
 . Compute .
 
 (8) For each of the following choices of forms  and , compute 
 and write the product in its standard representation. (a) 
 and . (b)  and
 .
 
 (9) For each of the following choices of the form  compute  and write it
 in its standard representation. (a) .
 (b) .
9.2.  Change of Variables for Forms
Suppose G is an open subset of  and H is an open subset of . If
 is a continuously differentiable mapping and 
is in , then  is in . If , we
want to show that this change of variables leads naturally to a q-form
 in  and to explore the relation between these forms. This is
a fundamental step in exploring forms and also in the orientation of
q-surfaces.
Note that we automatically have a function  with domain
. This does not mean, however, that this is a q-form on G. To be a q-form
it must satisfy additional properties as stated in the definition. The process of
finding what we will define as the change of variables for  is rather
straightforward, nevertheless you must be careful because the notation gets a bit
complicated.
Let , written in its standard representation. To get
the sought for q-form  on G, two things seem clear: the index sets should
remain the same and the coefficient functions should be  for
each x in G and each index set I. The more complicated step will be to get the
corresponding basic q-forms on G. To do this examine the components of
,


where it follows that for ,  is continuously
differentiable. Thus we can obtain the 1-forms


for . This leads us to the following.
 
9.2.1. Definition. If G and H are open sets in  and , respectively,
 and  expressed in its
 standard representation, then for any continuously differentiable mapping
 , define the q-form  on G as
 


where .
 
Observe that since each  is a 1-form and the indices  are distinct,
  is a q-form so that  is indeed a q-form on G. Also each part
 of the definition of  involves the mapping T as well as the given q-form
 .
 
To simplify the statements and notation below, maintain the notation
 we have used so far: G always denotes an open subset of , H an
 open subset of , and  is a continuously differentiable
 function.
 
9.2.2. Proposition. If  and , the following hold.
 
(a)  When , .
 
(b)  .
 
(c)  If  is continuously differentiable and T is a twice continuously
 differentiable function, then .
 
Proof. (a) This is a matter of examining the definition and is left to the
reader
(Exercise 1(a)).
(b) This proof is also easy, though it is cumbersome. Let's first examine what
happens to basic q and r-forms. If , ,
, and , then .
So

So clearly (b) is satisfied for basic forms. To show that (b) holds for all q-forms is
now routine (Exercise 1(b)).
(c) First assume  is a 0-form:  for a continuously differentiable
function g. So  and . Hence. using
the Chain Rule, we get

Now assume  is a basic q-form on H:  so that
. As we saw in Example 9.1.17(d),  and also
.
Finally assume  so that . Therefore

The general case now follows by using part (a). â 
 
See Exercise 2.
 
9.2.3. Proposition. Let G, H, and W be open sets with ,
 , and ; let  and  be
 continuously differentiable mappings. If  and  is
 the composition of S and T, then .
 
Proof. Just to be clear,  and both  and .
 To set the notation let  for each x in G,
  for each y in H, and 
 for each x in G. Let's note that for ,
 


so that by the Chain Rule
 


For  a 0-form, the result is the usual chain rule for functions. Now let's
prove the proposition when  is the 1-form  on W , where .
So  and . Using the Chain Rule we
have that

Now if  and  are forms on W , Proposition 9.2.2 shows that
. Since the result holds when  is a
0-form, this observation combined with what we did above completes the proof of the
proposition. â 
Assume  and  is in . So we can consider  as
a change of variables to obtain a q-form on R, the surface domain for
 that is contained in . That is, using the notation in Definition
9.2.1 we have . So for any q-surface  in  we can
form . After thinking about the hypothesis of the next
result, you might predict the conclusion though the proof takes some
effort.


9.2.4. Proposition. If ,  is in  with
 , and  is defined by  for all u in R, then
 


Proof. It suffices to prove the proposition under the assumption that
 


(Why?) Assume  with  for .
 Recall from the definition of a q-form and (9.1.5) that
 
 
â(9.2.5)

Let  be the Jacobian in the preceding equation; recall that this is the
determinant of the matrix , where for 


Thus . By a herculean manipulation of symbols we
get that


where in this sum  ranges independently over . Now
 for  defines a permutation in . From Theorem 9.1.18
we know that . Thus when  for
,


Remembering that  and using Definition 6.4.18, we
 get
 

Applying this equation to (9.2.5) we get
 

 â 
 
Combining Proposition 9.2.3 and Proposition 9.2.4 will prove the following,
 which is the Change of Variable Formula for forms.
 
9.2.6. Theorem. Let G be an open subset of  and assume 
 is a continuously differentiable mapping with H an open subset of  that
 contains . If  and , then
 


Proof. Suppose  with , and let  be
defined by  as in Proposition 9.2.4. By that proposition
. But Proposition 9.2.3 says this last integral becomes
. Applying (9.2.4) once again we have that the last
integral becomes , whence the theorem. â 
See Exercise 3.
Exercises

(1) (a) Give the details of the proof of Proposition 9.2.2(a). (b) Supply the
missing details in the proof of Proposition 9.2.2(b).
 
(2) Where in the proof of Proposition 9.2.2 was use made of the assumption
that T is twice continuously differentiable?
 
(3) Show that both Proposition 9.2.3 and Proposition 9.2.4 are special cases of
Theorem 7.4.19.
9.3.  Simplexes and Chains
Before getting into the heart of this section, we introduce an elementary concept
that will play a role.

9.3.1. Definition. A subset X of  is convex provided that when
, the line segment .

9.3.2. Proposition.
(a)  Every ball in  is a convex set.
(b)  A convex set is connected.
(c)  The intersection of any collection of convex sets is convex.
The proof of the preceding proposition is left to the reader in Exercise 1,
 
 where a few additional facts about convex sets also appear. Part (c) of the
 proposition leads us to an additional concept. For any non-empty subset E of
  we define the convex hull of E as the intersection of all convex subsets
 containing E. This is denoted by . Note that the collection of all convex
 subsets containing E is non-empty since  is one such set and  is
 convex by (c).
 
9.3.3. Lemma. A subset X of  is convex if and only if when
  and  with  we have that
 .
 
Proof. If X satisfies the stated condition of the lemma when ,
 then this is the definition of convexity. Conversely, assume X is convex
 and  and  with . The proof that
  is by induction.
The statement  is trivial and  is the definition. Assume 
and the statement for  is true. Note that


But by the induction hypothesis, . The case n now
follows. â 

9.3.4. Proposition. If , then


Proof. Denote the set on the right of the above displayed equation as S. It
is left as Exercise 2 to show that S is convex. Since  it follows that
. Now assume that X is a convex set that contains E. By the
preceding lemma,  and the proposition follows. â 

9.3.5. Corollary. If E is a finite subset of , then  is compact.
Proof. If , let
 


If we define  by , then f  is
 continuous and  by the proposition. On the other hand it is
 immediate that T is a compact subset of  since it is closed and bounded,
 so  is compact. â 
 
Now we define a convex subset of  that will be very important for our
 discussion, in fact a key building block in this development.
 
9.3.6. Definition. If  is the standard basis in , the unit simplex
 in  is the set
 




So  and , the triangle
 in the plane with vertices .  is the tetrahedron
 in  with the four vertices . We
 easily see that  is a convex set. In fact,  is the convex hull of
 .
 
Now for the next building block. Say that a mapping  is affine if
 there is a linear transformation  and a vector  in  such that
 for all u in . Equivalently  is an affine
mapping if , defined by , belongs to
. (Exercise 3.) We note in passing the connection between affine maps
 
 and the notion of an affine hyperplane defined in (6.7.2): if  and
  is an affine mapping, then  is an affine hyperplane. The
 proof of the next proposition is Exercise 4.
 
9.3.7. Proposition. If  is an affine map and X is a convex
 subset of , then  is a convex subset of .
 
9.3.8. Definition. An affine q-simplex is a q-surface  such that  is
 an affine map.
 

Of course an affine map is defined on all of , but in the preceding
 definition we are restricting  to the unit simplex. Also there is a double usage
 of the term "simplex" here: once when we discuss the unit simplex (a set) and
 then when we define an affine q-simplex (a function). This shouldn't cause
 any confusion as long as we consider the context in which the terms are
 used.
 
So the trace of an affine q-surface is a convex set, but there are convex subsets
 that are not the trace of an affine q-simplex; for example the closed disk in 
 (Why?). Note that every line segment in  is the trace of an affine
 1-simplex. For the ease of notation in the remainder of this chapter,
  will always denote the standard basis elements in  and we set
 .
 
9.3.9. Proposition. Let  be an affine q-simplex and for  put
 .
 
(a)   is uniquely determined by the  points . That is, if
  is also an affine q-simplex and  for , then .
 
(b)  If , then
 


Proof. Clearly part (a) follows from part (b). To prove (b) let
. Since  is affine, . If
, then , from which (b) follows. â 
In light of the last proposition we can also define  as the ordered
(q+1)-tuple of points in :


Our use of the word "ordered" in the last sentence is a precursor of our next
undertaking: giving an affine q-simplex  an orientation, determined by
the order of the points  when we write .

Suppose  is a permutation of  and  for . Let
. So  is a new affine q-simplex with the
same trace as  but a different orientation. If  is an oriented affine
1-simplex in  and  is the permutation , then 
is the same line segment traced in the opposite direction. As another
example consider . As mentioned previously this is the triangle
with vertices , and . So if we take
 this orients  in the counterclockwise or positive
direction. Considering  orients the boundary in the clockwise
direction. More complicated interpretations apply to higher dimensional affine
q-simplexes.
Recall (6.4.16) that for any permutation  of  we have .
If , we say that  and  have the same orientation and they
are equivalent affine q-simplexes. If , the two q-simplexes are said
to have the opposite orientation. 
The next result establishes the effect that changing the orientation of an affine
q-simplex has on the value of a differential form when it is evaluated at
the simplex. To start, let's examine the interaction between a q-form
and an affine q-simplex. As above let  for some A in
 and all u in , and let G be an open subset of  that contains
 
 the trace of , . Recall that  and we let  be the
 subsets  of . The typical q-form on G in
 its standard representation is given by . We
 seek to give specificity to the formula (9.1.4) for  when  is an
 affine q-simplex. In this the important thing is to calculate the Jacobians
 involved.
 
The matrix of the linear transformation A has size . Using the
 explication and notation employed to obtain (9.1.5) we have that for every u in
 , . Thus for ,  corresponds to
 the i-th row of the matrix of A. Since  is an affine map, each  is
 an affine map. If for  in  we let  be the  matrix
 with the same columns as A and the  rows we get, using the notation
 of (9.1.4) and (9.1.5),
 


Thus (9.1.4) becomes
 
 
â(9.3.10)


9.3.11. Proposition. If  is an affine q-simplex,  is a permutation
of , and  is as above, then for any q-form on an open set G
containing  we have that .
Proof. Let  so that for all u in , 
for some A in . First we assume that  is the following
transposition; fix j with  and let , and
 when . So  is a transposition and .
Hence  where  and is defined by
 and  when . (Pay close attention
as the following argument requires it.) Note that in arriving at the formula
(9.3.10) above and the definition of the  matrix , the columns of
A were not disturbed and the choice of I in  determined the q rows. We
therefore concentrate on relating the columns of B to those of A so we can
establish that  for each I in .
The columns of A are the vectors
 for . The columns of B are
.
Now form the matrix  by subtracting the j-th column of B from each
of the others. Thus the columns of  are .
Note that for each I in , . But the columns of  are
identical to those of A except for the j-th, which is the negative of that
column in A. Therefore we have that  and we therefore
have that .
The case where  is any transposition is similar, though the notation
is more cumbersome. Since every permutation  of  is the
composition of transpositions, the proposition follows by combining this
result for transpositions with Proposition 9.2.3. â 
 
The
 plot
 thickens.
In fact I'm afraid the plot gets quite thick with an exceptionally high
concentration of definitions before we get to the main result of this section.

9.3.12. Definition. Let G be an open subset of . An affine q-chain  in
G is a finite collection  of oriented affine q-simplexes in
G. An affine q-simplex may appear more that once in  and the number
of times it is repeated is called its multiplicity. If , then we write
 
 


The trace of  is defined as
 


We define
 


This is the definition of addition on the set of affine q-simplexes in an
 open subset G of . In fact just as we defined q-forms as a certain
 type of function on the set of q-surfaces, each affine q-simplex  in
 G can be thought of as a function defined on the set , where
 for all  in . If  and  are two such affine q-simplexes,
then  is an affine q-chain in G and for each  in  we
define
 
â(9.3.13)

Notice that Proposition 9.3.11 says that when  is an oriented affine
q-simplex, we have a negative for this addition. Indeed if  is an odd
permutation of , then in this definition of addition . That is
.
I think the following examples hint at the usefulness of introducing affine
q-chains.

9.3.14. Example. (a) The unit square  in  is the trace
of a
2-chain. In fact the four vertices of  are , and . Define
 on  by  and  for all u in . So
these are the affine simplexes  and . We
have that . We might point out that the directions given the
line segment joining the vertices  and  by  and  are the opposite
of one another.
(b) Generalizing part (a), the unit cube in , , is the trace of
a q-chain in . This follows as in part (a). Note that if  and
, then  and
 (Exercise 6). Define  and  on
 by  and . So  and
a calculation reveals that . Hence
 
 


Thus , the trace of a q-chain.

9.3.15. Definition. If  is an oriented affine q-simplex, its
 boundary is defined to be the affine -chain
 


So once again we are using the addition of affine simplexes with emphasis on
 their orientation. Let's call attention to the ambiguity in the notation: the use of
 the symbol  in . The trace of , , has no interior if . Hence
 the topological boundary of  is the trace itself. However the trace
 of  consists of the image under  of the topological boundary of
 .
 
9.3.16. Example. (a) If  is the 1-simplex  in , then
 , where this is the difference of two 0-simplexes.
 
(b) If ,
 an affine 2-simplex, then . Note that 
 is a triangle in  and this formulation of its boundary gives its customary
 counterclockwise (positive) orientation.
 
(c) Using the notation in the preceding definition, let .
 So  is an affine -simplex defined on the unit simplex
  by , where  is the linear
 transformation from  into  defined by  for
 . Similarly for  if 
as in Definition 9.3.15, then  is an affine -simplex defined
on the unit simplex  by , where
 is the linear transformation defined by 
when  and  when .
The exploration of the idea of a q-simplex and affine q-chains was
preliminary to the next concept and that in Definition 9.3.18 that follows. The
idea is to first take a q-simplex in  and then apply a  map to
it.

9.3.17. Definition. If H is an open subset of , an oriented q-simplex of
class  in H is a q-surface  in H that arises as follows. There
is an open subset G in , a  mapping , and there is an
oriented affine q-simplex  such that


The boundary of  is defined by


Let's note a few things. First,  is just a shorthand notation for ;
similarly for . Second, the surface domain of  is the unit q-simplex
. Next  is usually not an affine q-simplex, hence the word "affine" does
 
 not appear in its name. What we have done is to introduce a collection of
 q-surfaces in H that we can orient by using the orientation of an affine
 q-simplex.
 
9.3.18. Definition. If H is an open subset of , an oriented q-chain of
 class  in H is a finite set  of oriented q-simplexes of
 class  on H. If , then
 


and we use the notation . The boundary of  is defined
 as
 


Note that in the notation  we are introducing an addition for
 oriented q-simplexes of class . In fact we have begun to consider a duality between
 q-simplexes of class  and differential forms. We defined a q-form as a certain type
 of function from surfaces into . We also want to think of surfaces and oriented
 q-chains of class  as functions from q-forms into . So if 
as in the preceding definition, we can consider the function 
defined by


So when we say that


we mean the value of every q-form at  is 0. Let's also point out that in
some ways an oriented q-chain is a generalization of a piecewise regular surface
(8.4.13) to surfaces in . (In which ways is it a generalization and in which
ways is it not?) If we look at Example 9.3.14 above we see a hint of
this.

9.3.19. Example. Again let G be an open subset of , H an open subset
of , and  a  mapping. If  is an affine
q-chain in G, and  for , we will write


and
 


9.3.20. Example. Here we want to show how some of the examples seen in
 the preceding chapter fit into the current landscape. Since many of those
 examples had surface domains that were rectangles (see Exercise 8.3.2),
 Example 9.3.14 will be useful. For example let's see how a 2-surface
 whose surface domain is the square  can be handled. We start by
 assuming the surface is , T is , and this surface lies in an
 open subset H of . So there is an open subset G of  that contains
  and on which T is . Adopt the notation in Example 9.3.14(a)
 and let  and  so that . Write
 , where  is open and contains  for . If
  and , then  and  are
 oriented 2-simplexes and  is an oriented q-chain of class .
 Observe that  and .
 
Now suppose we are given a rectangle  and a surface
  of class  that lies in the open subset . If we
 define  by , then A
 is a linear transformation and . Thus 
 is of class  and the discussion in the preceding paragraph applies.
 For use in the next section when we discuss orientation, note that
 .
 
Exercises

(1) (a) Prove Proposition 9.3.2. (b) Give three examples in  of compact
convex sets that are not balls. (c) Show that the union of two convex sets
may not be convex.
 
(2) Show that the set S defined in the proof of Proposition 9.3.4 is convex.
 
(3) Show that a function  is an affine mapping if and only if
, defined by  is linear.
 
(4) Prove Proposition 9.3.7.

(5) Let  and  be two affine q-simplexes. If we
define  for all u in , is  the same as
 as defined in 9.3.12?
 
(6) Supply the details needed for Example 9.3.14(b).
 
(7) Write out the details of Example 9.3.20 for the hemisphere in  as
parametrized in Exercise 8.3.2. What can be said about the common parts
of  and ?
 
(8) Can you represent the 3-cube in  as the trace of a 3-chain?
9.4.  Oriented Boundaries
In the preceding section we introduced the idea of an oriented q-chain of class
, which was a finite set of functions. Now we want to use this and
the natural orientation of an affine simplex to orient the boundary of
certain smooth surfaces. This is similar to what we did in Definition
8.2.2 when we oriented a closed curve in  relative to the open set it
surrounded and Definition 8.4.15 when we introduced a piecewise orientable
surface. The first step is to orient the boundary of the unit simplex  for
.
 
 
9.4.1. Definition. If  and  is the identity map on , then  is
 an oriented p-simplex. Indeed, using the notation of the preceding section,
 . Thus the -chain  orients the boundary of
 . We refer to this as the positive orientation of . Whenever we use
 the notation  we assume it has this positive orientation.

9.4.2. Example. (a) Recall Example 9.3.16(b) where we saw that the
 positive orientation orientation of the boundary of the 2-simplex  is
 . This
 gives the boundary of the simplex  the direction of going from 0 to 
 to  and back to 0, the counterclockwise direction.
 
(b) The positively oriented boundary of  is
 .
 
Now suppose that G is an open subset of  that contains  and
 that  is a  mapping that is injective on  and whose
 Jacobian is positive on . It follows from the Inverse Function
 Theorem that  and that  is an open
 set.
 
9.4.3. Definition. Let G be an open subset of  that contains  and
 let  be a  mapping that is injective on  and whose
 Jacobian is strictly positive there. If , then the positively
 oriented boundary of X is the -chain
 


where  is the identity map on .
 
If  is such a map for , , and
  for , put . Then
 


is called the positively oriented boundary of .
Before going further we must point out that when , we now have two
definitions of the positive orientation of  when X is as above. Indeed if
,  is a curve. Since  is smooth on G with a strictly positive
Jacobian, this Jacobian is strictly positive in a neighborhood of . Thus this
curve is piecewise regular and so Definition 8.2.2 gives a concept of  being
positively oriented. Are these two concepts the same? Yes! Using linear algebra
and some effort we can prove this. We choose, however, not to do this proof.
Why? The use of these concepts of orientation when  is, in both
cases, for the statement and proof of Green's Theorem. This was done in
(8.2.10) when  and will be extended below in Theorem 9.7.1 as a
consequence of a generalization of Stokes's Theorem. In each case the value of
the integrals over the boundary of the set is the same, whereas if the
orientations differed they would be the negative of one another. (This is
established in this more general setting for  in Proposition 9.3.11; in
two-space it is immediate from the definition of the integral over a curve
(8.1.8).) Thus the two concepts of positively oriented curves must be the
same.
 
Why
 have
 we
 introduced
 oriented
 q-chains
 andthe
 concepts
 in
 the
 preceding
 definition?Where
 is
 all
 this
 leading?
 
 
As we said in the preceding paragraph we are headed towards obtaining a
 Generalized Stokes's Theorem (9.5.1), for which we now have all the terminology
 needed to read the statement but not to begin the proof. What we will see is that
 this result also yields Green's Theorem (8.2.10) and Gauss's Theorem (8.5.6) as
 consequences. How? What is the relationship? You may recall that when we gave
 the versions of these results in  and  we needed to express surfaces as the
 union of non-overlapping surfaces of a special type. (Especially recall the
 introduction of a G-set in connection with Green's Theorem.) In defining sets of
 the type  in the last definition we have extended and made precise the
 concept of a G-set in higher dimensions. Realize that  is both a Type
 I and a Type II set, while  is simultaneously Type I, II, and III.
 We saw that each of the expressions in Green's, Gauss's, and Stokes's
 Theorems are examples of differential forms. Now we must explore the
 interaction between these extended notions and arbitrary differential
 forms.
 
9.4.4. Proposition. Let G be an open subset of  that contains
  and for  let  be a  mapping that is injective
 on a neighborhood of  and whose Jacobian is strictly positive on .
 If  and if  is a -form defined on some
 open set containing X, then .
 
 
The complicated proof of this proposition, which won't be used in the rest of this
chapter, is left to the interested reader. Here is an outline of the proof. Let H be an
open subset of  that contains  and on which  is defined.
Let  be defined by . Note that . By
Theorem 9.2.6 we have


Now we need to use the properties of T and the definition of 
to show that , and here is where the complications
arise.

9.4.5. Example. (a) Recall Example 9.3.14 on the unit square 
in , where we defined  and  and observed
that . Therefore

When we add these boundaries together we get  so
that


and this orients the boundary of  in the counterclockwise direction.
 
(b) This is actually a continuation of the preceding part. Assume  is a
 2-surface with surface domain . As a function on 2-forms we have
 . Thus .
 
(c) We continue with the preceding parts. Recall from Â§8.2 where we defined a
 subset  to be Type I. Let  be  functions such that
  on  and set .
 Assume that  is defined by
 

It is easy to check that  is injective on .
 
We have that
 

A further computation shows that
 


on . So if we let  be defined by , we have the
situation of Definition 9.4.3.

9.4.6. Example. Let  and define  by


The reader might note that  is the unit sphere in . Here
, where these are the four curves in
 defined on , , , , respectively, by the
formulas

Let  be any 1-form defined in a neighborhood of . Since  and  are
constant we have that . Observing that , it
follows by an application of Example 9.1.6(a) that . Therefore
we have that


for any 1-form. Equivalently,  (as a function on forms).
 
Exercises

 (1)  Carry out an analysis similar to that in Examples 9.4.5(a) and (b) for .
 
 (2)  Repeat Example 9.4.6 but this time for a parametrization of the unit
 hemisphere above the xy-plane.
9.5.  Stokes's Theorem
Here is the main result of this chapter, whose proof will occupy us for the rest of
 the section.
 
9.5.1. Theorem (Generalized Stokes's Theorem). If H is an open subset
 of  and  is a q-chain of class  in H, then for every smooth
 -form  in H,
 


In Â§9.7 we'll see how the theorems of Green, Gauss, and Stokes from Chapter
8 follow from this theorem, but now let's point out that the above result
extends the Fundamental Theorem of Calculus. (You might want to look at
Example 9.1.6(a).) In Theorem 9.5.1 take  and let  be the 0-form
defined by the smooth function . For H take any open set that
contains  and for the 1-chain let  be the identity map,
. Consequently  and ;
Theorem 9.5.1 says they are equal, thus establishing the FTC. (Of course the
number of times the FTC was used to get to this point is probably large, so this
is not an independent proof. In fact the FTC is used directly in the proof of
Theorem 9.5.1 below.)
Proof of The Generalized Stokes's Theorem. To begin we show that
what has to be proved can be reduced to a simpler environment. To begin
note that it suffices to show that  when  is a single
d-simplex of class . By definition  where 
defined on  and  is a mapping of class  on an open
subset G of  that contains . By the rules for differentiating forms
(9.2.2(c)) and the Change of Variables Theorem for forms (9.2.6) we have
that


Since , we also have that


This means that to prove the theorem we need only prove
 
 
â(9.5.2)

 for every smooth -form .
 
As we saw prior to the proof, if  this amounts to the Fundamental
 Theorem of Calculus. So we can assume that . Suppose  and f 
 is a smooth function on G. It suffices to establish (9.5.2) when
 


since the arbitrary -form is the sum of such forms as this.
 Now


where  for .
We now need to do some tedious calculations. Put


and observe that  can be obtained from  by  successive
interchanges with its left-hand neighbor. Hence


Recall that for  each  is defined on . Consider  and
fix  in . We have from (9.3.9) that
 
 


Thus if  and we put , then
 
 
â(9.5.3)

 Similarly if  and  for some u in , then
 
 
â(9.5.4)

For  let  be the Jacobian of the map


as defined above using the simplexes . Observe that when  or ,
this is the identity map. (Verify!) Hence . When , then the
fact that the above formula for x has  implies that when we compute the
determinant , its associated square matrix has a row of zeros. Thus 
when . From the definition of the action of  this implies that
 when . Therefore

But we also have that

so that
 
 


To evaluate this last integral we use Fubini's Theorem and first integrate with respect
 to  over the interval .
 Doing this we get
 

Using (9.5.3) we see that
 


Hence
 


Now using (9.5.4) we have that


Therefore


completing the proof. â 
9.6.  Closed and Exact Forms
In  every continuous function has a primitive by the FTC. Namely, if f  is a
continuous function on some interval  that contains the point c, then
 has the property that  for all x in . In this
section we will be concerned with an analogous problem of deciding if a form in
 has a primitive. This is not always the case, as we will soon see. Here is the
basic language.


9.6.1. Definition. Let G be an open subset of  and let  be a q-form
 on G. The form  is closed if it is smooth and ;  is exact if
 there is a smooth -form  on G such that .
 

We know from Theorem 9.1.18 that if  is smooth and exact, then it is
 closed. When  there are closed forms that are not exact, and the
 analogous problem referred to in the introduction to this section is which
 closed forms are exact. Before giving an example let's establish a few
 facts.
 
9.6.2. Proposition. Let G be an open subset of  and let  be a 
q-form on G.
 
(a)  If  and , then  is closed if and only if
  for all .
 
(b)  If  is closed and  is a -chain of class , then
 .
 
(c)  If  is exact and  and  are two q-chains in G with ,
 then . Consequently, if , then  for every
 exact form .
 
Proof. (a) This is straightforward. Note that
 

(b) This is a direct application of Stokes's Theorem (9.5.1). (How is
 Example 9.1.6(e) related to this part?)
 
(c) Let . Again we apply Stokes's Theorem to get that
 . â 
Note that showing that a form  is exact means solving several partial
differential equations simultaneously. For example if we have a 1-form
 on , then to show that  is exact we must find a
smooth function  such that ; this means that  for
. When  is a q-form and , the differential equations that are
to be solved are more complex. See Exercise 1.

9.6.3. Example. If G is an open subset of , note that when  is a
smooth curve in G we have that  is a 1-chain in G. If  is a closed
curve, then . Thus if  is an exact 1-form on G it must be that
 by part (a) of the preceding proposition. Let G be the punctured
plane . Define  on G by


It is left to the reader to verify that  is a closed form. Now define
 by . So  is the unit circle in the
positive direction. The reader can verify that  (Exercise 2).
By what we said at the start of this example,  cannot be exact. The
impediment to exactness of closed forms is that puncture at the origin.
Proposition 9.6.2(c) gives a necessary condition for a form to be exact. We
want to discover sufficient conditions on an open subset G of  such that every
closed form on G is exact.
At the beginning of Â§9.3 we discussed convex subsets of . We revisit
this topic here. The proof of the next proposition is left to the reader
(Exercise 4).

9.6.4. Proposition. (a)  Any ball in  is convex as is any affine
hyperplane or half-space.
(b)  If X is a convex subset of  and , then  is a
convex subset of .
(c)  If Y is a convex subset of  and , then 
is a convex subset of .
 
 
Note that the punctured plane is not convex.
 
It holds that whenever G is an open convex subset of , every closed form
 on G is exact. To establish this would involve more background than we deem
 appropriate, because the argument is very involved and after all the effort
 convexity is not the most general hypothesis we can impose on G to have the
 same conclusion. Instead we will focus on , where the proof is straightforward
 but not trivial. A proof of the convex case in  can be found in [7], page 278.
 A statement and proof of the more general result can be found in [9], page
 457.
 
If  and  are two points in , let  denote the straight line
 segment from  to . We begin the proof for  with a lemma.
 
9.6.5. Lemma. Let G be an open disk in , let , and let
  be a smooth closed form on G. If , then
 


Proof. First note that
 


and . Now note that the line
segments , and  form the sides of
a triangle; denote by X this triangle together with its inside. By Green's
Theorem we have that


But Proposition 9.6.2(a) says the condition that  is closed is equivalent
to the condition that . So we have that 
and the lemma follows. â 

9.6.6. Theorem. If G is an open convex subset of , then every smooth
closed form on G is exact.
Proof. Assume that  is a smooth form on G that is closed. Thus
. So

Thus we see that the 1-form  is also closed.

9.6.7. Claim. The form  is exact.
 
 
First assume that G is an open disk with center . Define 
 by
 


We claim that . To show this we must show that
  and . By the lemma and the FTC we have that
 . On the other hand first employing
 Theorem 7.5.2 about differentiating under the integral sign and then the
 assumption that  is closed, we get
 

Now assume G is any open convex set and fix a point  in G. By convexity
  for every  in G. Define .
 Note that the line segment  can be covered by a finite number of
 open disks, each contained in G. By what we did before we have that 
 and  in each of these disks (Why?). It follows that  in all of
 G, establishing the claim.
 
It remains to show that  is exact. Let .
 Since U is the projection of G onto the first coordinate, it is open and connected.
 Hence it is an open interval. Fix a point c in U and define 
 by


The FTC implies . Hence .
Letting , we get that  and so  is exact. â 

9.6.8. Proposition. Let G be an open subset of  such that every closed
form on G is exact. If U is an open subset of  such that there is a 
bijection , then every closed form on U is exact.
Proof. Let  be a closed form on U. Thus  is a form on G
and, by Proposition 9.2.2(c), . By hypothesis there
is a form  on G such that . If , let
, which is a form on U. Using Proposition 9.2.3 we have that
, so that  is exact. â 
See Exercise 5.
Exercises

(1) In  if  is the 2-form , phrase
the problem of showing that  is exact in terms of solving differential
equations.
 
(2) Show that  in Example 9.6.3.
 
(3) Let , punctured three-space, and put
 
 

(a)
 Show that  is closed. (b) Let  be as in Example 9.4.6 and show that
 . (c) Conclude that  is not exact.
 
 (4)  Verify the statements in Example 9.6.4.
 
 (5)  Let U be the open half-annulus  or ,
  and show that every closed form on U is exact.
9.7.  Denouement
In this section we want to derive the theorems of Green, Gauss, and Stokes in
  and  as a consequence of the generalized Stokes's Theorem. We begin
 with Green's Theorem 8.2.10. The setup for Green's Theorem is as follows. Let
 G be an open subset of  that contains  and for  let
  be a  mapping that is injective on  and whose Jacobian
 is positive there. Put , and assume 
 for ; put . Give  the positive orientation as in
 Definition 9.4.3. We note that each  is a smooth closed curve in
 . The reader can mull over the connection between this setup and
 the assumption that  is a G-set given in (8.2.10). Establishing this
 connection is left to the inclined reader. (Exercise 1.) Be sure to first go over
 Example 9.4.5(c).
 
9.7.1. Theorem (Green's Theorem). Let G be an open subset of  that
 contains , let  be as described above, and let  be an open
 subset of  containing . If  is a smooth function with
 , then


Proof. Put . By the Generalized Stokes's Theorem (9.5.1)


Now


so
 
 


From Example 9.1.6(b) we know that  for any smooth
 curve . Given that  consists of smooth curves, this completes the
 proof. â 
 
Again we adopt the setup from Definition 9.4.3, this time in . Let G be an
 open subset of  that contains  and for  let  be a
  mapping that is injective on  and whose Jacobian is positive there.
 Also assume that with  we have that  for
 ; put . Give  its positive orientation as in (9.4.3). Again
 there is a connection between this setup and the assumption in Theorem 8.5.6
 that  is a G-set; it is left to the reader to explore this connection (Exercise
 2).
 
9.7.2. Theorem (Gauss's Theorem). Let G be an open set in
  containing , let  be as described above, and let  be an open
 subset of  containing . If  is a smooth function, then
 


Proof. Let


In Example 9.1.17(b) we saw that for the 2-form
,


So using (8.4.7) and the generalized Stokes's Theorem we have that

 â 
Coordinating the statement in the theorem below with Theorem 8.5.10 is up
to the reader.

9.7.3. Theorem (Stokes's Theorem). Let  be an open subset of  and
let  be a regular 2-surface contained in . If  is a smooth
function, then
 
 


Proof. Put . For efficiency in expression we write
 . Let  and
 . As in
 Example 9.1.17(c), we have that . From Example 9.1.6(b) applied
 to a chain of curves rather than one, we know that
 


From (8.4.7) we know that
 


Therefore Stokes's Theorem (8.5.10) follows from the generalized version.
â 
Exercises

(1)This is a rather involved exercise. Can you show that a G-set (8.2.6) in
 is an oriented q-chain for an appropriate value of q?
 
(2)This is also a rather involved exercise. Can you show that a G-set (8.5.4) in
 is an oriented q-chain for an appropriate value of q?
 














Bibliography


 1.    K. Bryan, "Differential Forms,"
 www.rose-hulman.edu/~bryan/lottamath/difform.pdf
 
 2.    P. Cameron, "Ten Chapters of the Algebraic Art,"
 www.maths.qmul.ac.uk/~pjc/notes/intalg.pdf
 
 3.    J. B. Conway, A Course in Abstract Analysis, AMS (2012).
 
 
 4.    J. B. Conway, A Course in Point Set Topology, Springer-Verlag
 (2013).
 
 
 5.    K. Hoffman and R. Kunze, Linear Algebra, Prentice Hall Publishing
 (1971).
 
 
 6.    E. Landau, Foundations of Analysis, AMS Chelsea Publishing
 (2001).
 
 
 7.    W. Rudin, Principles of Mathematical Analysis, McGraw-Hill
 Education; 3rd edition (1976).
 
 
 8.    R. Schwartz, "Dedekind cuts,"
 www.math.brown.edu/~res/INF/handout3.pdf
 
 9.    J. Shurman, Multivariable Calculus,
 http://people.reed.edu/~jerry/211/vcalc.pdf
 
10.    R. Sjamaar, "Manifolds and differential forms,"
 www.math.cornell.edu/~sjamaar/manifolds/manifold.pdf
 
11.    William F. Trench, Introduction to Real Analysis (2013). Books and
 Monographs. Book 7. http://digitalcommons.trinity.edu/mono/7
 
12.    William F. Trench, "The Method of Lagrange Multipliers" 2013
 Available at: http://works.bepress.com/william_trench/130
 
13.    H. A. Thurston, The Number System, Dover (2012).
 
 
14.    H. Tverberg, "A proof of the Jordan Curve Theorem," Bull. London
 Math. Soc. 12 1980, 34-38.
 
 
15.    W. R. Wade, An Introduction to Analysis, Pearson (2009).

 












Index of Terms
-chain, 144 
-compact, 140 
0-form, 294 

absolute value, 14 
absolutely integrable, 87 
adjoint, 177 
affine hyperplane, 198 
affine mapping, 310 
affine q-chain, 313 
affine q-simplex, 311 
algebra, 65, 148 
alternating harmonic series, 26 
anti-derivative, 79 
arc length, 220 
Arzela, Cesare, 152 
Arzela-Ascoli Theorem, 152 
Ascoli, Giulio, 152 

Banach Fixed Point Theorem, 201 
Banach, Stefan, 201 
basic q-form, 298 
bijective, 5 
Bolzano, Bernard, 19 
Bolzano-Weierstrass Theorem, 19, 134 
Borel, Emile, 137 
boundary, 123 
boundary of , 281 
boundary of an affine q-simplex, 314 
boundary of an oriented q-chain, 315 
boundary of an oriented q-simplex, 315 
boundary point of a surface, 276 
bounded, 7 
bounded above, 7 
bounded below, 7 
bounded function, 133 
bounded set, 127 
bounded variation, 94 

Cantor, Georg, 35 
Cantor's Theorem, 35, 126 
cartesian product, 30 
Cauchy, Augustin Louis, 21 
Cauchy sequence, 21, 120 
Cauchy-Schwarz Inequality, 117 
Chain Rule, 56, 165, 190 
Change of Variables Theorem, 79 
characteristic function, 5, 146 
characteristic polynomial, 183 
closed ball, 122 
closed curve, 258 
closed form, 323 
closed interval, 16 
closed relative to, 122 
closed set, 33, 121 
closed surface, 276 
closure, 123 
compact, 133 
Comparison Test, 26, 87 
complement, 3 
complete, 120 
Completeness Property, 7 
component, 143 
composition, 5 
conditionally convergent, 28 
connected, 140 
constant function, 5, 37 
constraint, 212 
contained in, 2 
contains, 2 
continuous at a point, 129 
continuous function, 37, 129 
continuously differentiable, 63, 190 
convergent series, 24 
converges, 119 
converges absolutely, 26 
converges uniformly, 146 
convex, 309 
convex hull, 309 
corona, 269 
countable set, 29 
countably infinite, 29 
COV, 80 
cover, 133 
critical point, 62, 167, 192 
cross product, 272 
curl, 284 
curve, 156 
cut, 10, 266 

Darboux, Jean Gaston, 64 
Darboux's Theorem, 64 
De Morgan, Augustus, 4 
De Morgan's Laws, 4, 121, 127 
decreasing function, 49 
decreasing sequence, 18 
Dedekind cut, 10 
Dedekind, Richard, 10 
dense, 124 
Density Property, 7 
denumerable, 29 
derivative, 52, 156, 163, 188 
determinant, 180 
diagonal matrix, 178 
diameter, 35, 126 
difference, 3 
differentiable, 52, 53, 156, 163, 188 
differential form of order q, 294 
Dini, Ulisse, 139 
Dini's Theorem, 139 
directional derivative, 166 
disconnected, 140 
discrete metric, 116 
disjoint, 2 
distance, 126 
distance from A to B, 140 
distance from a point to a set, 36 
divergence, 284 
Divergence Theorem, 286 
divergent series, 24 
domain, 5 
dot product, 117 
dyadic expansion, 31 

eigenspace, 183 
eigenvalue, 183 
eigenvector, 183 
element, 1 
empty set, 2 
equal sets, 2 
equicontinuous, 151 
equivalent affine q-simplexes, 312 
equivalent curves, 222 
Euclidean space, 116 
even function, 57 
EVT, 39 
exact form, 323 
exponential function, 82 
extended real numbers, 15 
extension, 42 
Extreme Value Theorem, 39, 134 

final point, 258 
finite intersection property, 135 
FIP, 135 
fixed point, 201 
flip, 246 
FTC, 78 
Fubini, Guido, 235 
Fubini's Theorem, 234 
function, 4 
Fundamental Theorem of Calculus, 78 

G-set, 265, 285 
Gauss, Johann Carl Friedrich, 286 
Gauss's Theorem, 286 
Generalized Mean Value Theorem, 59 
Generalized Stokes's Theorem, 320 
geometric series, 25 
gradient, 164 
Gram, Jorgen, 170 
Gram-Schmidt Process, 170 
greatest lower bound, 7 
Green, George, 267 
Green's Theorem, 267 

half-open interval, 16 
harmonic p-series, 89 
harmonic series, 25 
Heine, Heinrich Eduard, 137 
Heine-Borel Theorem, 137 
Hermite, Charles, 177 
hermitian, 177 
hyperplane, 198 

idempotent, 178 
identity function, 37 
image, 5 
Implicit Function Theorem, 208 
improperly integrable, 86 
increasing function, 49 
increasing sequence, 18 
indefinite integral, 79 
index set, 121 
indicator function, 5 
infimum, 7 
infinite series, 24 
infinitely differentiable, 63 
injective, 5, 173 
inner product, 117 
inside of a curve, 263 
integrable, 73, 86, 225 
Integral test, 88 
Integration by Parts, 80 
interior, 123 
interior point of a surface, 276 
Intermediate Value Theorem, 39, 142 
intersection, 2, 121 
interval, 16 
inverse function, 60 
Inverse Function Theorem, 202 
IPFT, 210 
isolated point, 37, 125 
IVT, 39 

Jacobi, Carl, 205 
Jacobian, 205 
Jacobian determinant, 205 
Jacobian matrix, 205 
Jordan, Camille, 226 
Jordan curve, 258 
Jordan set, 226 
jump discontinuity, 49 

kernel, 173 

L'HÃ´pital, Guillaume FranÃ§ois Antoine, 65 
L'HÃ´pital's Rule, 65 
Lagrange, Joeseph-Louis, 213 
Lagrange multiplier, 213 
lattice, 40 
least upper bound, 7 
Lebesgue, Henri LÃ©on, 91 
Lebesgue's Theorem, 91 
left-continuous, 99 
left-hand limit, 48 
length of a curve, 220 
liminf, 22 
limit, 47, 50, 51 
limit inferior, 22 
limit point, 37, 125 
limit superior, 22 
limsup, 22 
line integral, 260 
linear functional, 161 
linear transformation, 173 
Lipschitz function, 41, 132 
Lipschitz, Rudolph, 41 
local extremum, 167, 212 
local maximum, 57, 167, 212 
local maximum subject to a constraint, 212 
local minimum, 57, 167, 212 
local minimum subject to a constraint, 212 
locally integrable, 86 
logarithm, 81 
lower bound, 7 
lower limit, 22 
lower sum, 71, 225 

MÃ¶bius, August Ferdinand, 279 
MÃ¶bius Strip, 279 
map, 5 
mapping, 5 
maximum of functions, 40 
Mean Value Theorem, 58, 79, 166 
measure zero, 90 
mesh, 95 
metric, 115 
metric space, 115 
minimum of two functions, 40 
modulus of continuity, 96 
monotonic function, 49 
multiplicity, 183, 313 
MVT, 58 

natural logarithm, 81 
natural numbers, 1 
natural parametrization, 259 
negative definite, 193 
negative matrix, 193 
non-connected, 140 
non-decreasing sequence, 18 
non-overlapping, 223 
norm, 155, 162, 174 
normalization, 100 

odd function, 57 
open ball, 122 
open cover, 133 
open interval, 16 
Open Mapping Theorem, 204 
open relative to, 122 
open set, 33, 121 
opposite orientation, 312 
orientable piecewise regular surface, 282 
orientation, 311 
oriented affine q-simplex, 311 
oriented q-chain of class , 315 
oriented q-simplex of class , 315 
oriented surface, 277 
orthogonal, 168 
orthogonal projection, 172, 178, 179 
orthonormal, 168 
orthonormal basis, 168 
oscilation, 90 
outside of a curve, 263 

pairwise orthogonal, 168 
Parallelogram Law, 172 
parametrization, 293 
parametrization of a surface, 269 
parity, 180 
partial derivative, 158 
partial sum, 24 
partition, 71 
path integral, 260 
permutation, 179 
piecewise orientable surface, 282 
piecewise regular, 259 
piecewise regular surface, 281 
point, 1 
pointwise convergence, 103 
polar coordinates, 248 
polar identity, 169 
polygon, 146 
positive definite, 193 
positive direction relative to , 280 
positive matrix, 193 
positive side of a surface, 280 
positively oriented, 264 
power series, 107 
principal minors, 196 
product of forms, 299 
proper subset, 1 
Pythagoras, 169 
Pythagorean Theorem, 169 

q-chain, 315 
q-form, 294 
q-form of order n, 294 
q-surface, 293 
q-surface domain, 293 

R-cover, 223 
radius of convergence, 108 
range, 5, 173 
Ratio Test, 27 
real numbers, 11 
rectangle, 223 
refinement, 71 
regular, 259, 274 
relatively closed in, 122 
relatively open, 42, 122 
reparametrization, 222 
Reverse Triangle Inequality, 14, 117 
Riemann, Georg Friedrich Bernhard, 73 
Riemann integrable, 73, 225 
Riemann-Stieltjes integral, 97 
right-continuous, 99 
right-hand limit, 48 
right-hand orientation, 280 
Root Test, 27 

saddle point, 167 
same orientation, 312 
Sandwich Principle, 104 
Schmidt, Erhard, 170 
Schwarz, Hermann Amandus, 117 
second derivative, 63 
self-adjoint, 177 
separable, 124 
separately continuous, 133 
separates points, 150 
sequence, 16 
sequence converges, 16 
series, 24 
series converges, 24 
series diverges, 24 
sign of a permutation, 180 
sign of a real number, 181 
simple curve, 258 
simple discontinuity, 49 
simple mapping, 245 
singleton, 2 
smooth curve, 156 
smooth function, 63, 156 
smooth q-form, 294 
spectral decomposition, 186 
Spectral Theorem, 185 
spectrum, 184 
spherical coordinates, 249 
Squeeze Principle, 104 
squeezing principle, 51 
standard basis, 158 
standard representation, 298 
starting point, 258 
Stieltjes, Thomas Jan, 97 
Stokes, George Gabriel, 288 
Stokes's Theorem, 288 
Stone, Marshall, 150 
Stone-Weierstrass Theorem, 150 
strictly decreasing function, 49 
strictly decreasing sequence, 18 
strictly increasing function, 49 
strictly increasing sequence, 18 
strictly monotonic function, 49 
subcover, 133 
subsequence, 19, 120 
subset, 1, 2 
subspace, 117 
supremum, 7 
surface, 199, 269 
surface area, 275 
surface domain, 269, 293 
surface integral, 275 
surjective, 5, 173 
Swiss cheese, 232 
symmetric, 177 
symmetric group, 180 

tangent affine hyperplane, 200 
tangent plane to a surface, 273 
Taylor, Brook, 68 
Taylor's Theorem, 68 
topologist's sine curve, 144 
total variation, 94 
totally bounded, 135 
trace of a curve, 156 
trace of a q-chain, 313 
trace of a surface, 269, 293 
transpose, 177 
transposition, 180 
Triangle Inequality, 115 
Trichotomy Law, 11 
trigonometric polynomial, 153 
twice continuously differentiable, 63 
twice differentiable, 63 
Type I, 264, 284 
Type I cover, 265, 285 
Type II, 264, 284 
Type II cover, 265, 285 
Type III, 284 
Type III cover, 285 

uncountable set, 29 
uniform convergence, 103, 107 
uniformly Cauchy sequence, 106 
uniformly continuous, 41, 132 
union, 2, 121 
unit circle, 45 
unit normal, 277 
unit normal vector, 263 
unit simplex, 310 
unit tangent vector, 260 
upper bound, 7 
upper limit, 22 
upper sum, 71, 225 
Urysohn, Pavel Samuilovich, 131 
Urysohn's Lemma, 131 

volume, 223, 232 
volume zero, 226 

wedge, 294 
wedge product, 299 
Weierstrass, Karl, 19 
Weierstrass M-Test, 107 
Weierstrass Theorem, 151 

zero-form, 294  

 












Index of Symbols
, 115 
, 269, 293 
, 16 
, 16 
, 3 
, 3 
, 2 
, 2 
, 1 
, 177 
, 177 
, 122 
, 94 
, 63 
, 63 
, 310, 311 
, 63 
, 63 
, 63 
, 192 
, 163, 188 
, 314 
, 71 
, 225 
, 225 
, 263 
, 273 
, 95 
, 95 
, 260 
, 71 
, 225 
, 223 
, 232 
, 1 
, 30 
, 30 
, 16 
, 142 
, 2 
, 174 
, 162 
, 95 
, 155 
, 99 
, 121 
, 4 
, 121 
, 4 
, 170 
, 16 
, 5, 146 
, 123 
, 36 
, 46 
, 284 
, 180 
, 284 
, 178 
, 35, 126 
, 140 
, 36 
, 126 
, 128, 140 
, 82 
, 205 
, 158 
, 52 
, 259, 260 
, 156 
, 205 
, 271 
, 222 
, 184 
, 311 
, 312 
, 90 
, 275 
, 7 
, 97 
, 225 
, 225 
, 313 
, 260 
, 259 
, 73 
, 73 
, 259 
, 123 
, 276 
, 173 
, 220 
, 188 
, 117 
, 16 
, 48 
, 48 
, 47 
, 49 
, 22 
, 22 
, 81 
, 83 
, 163 
, 166 
, 1 
, 2 
, 6, 11 
, 13 
, 15, 22 
, 1 
, 96 
, 122 
, 309 
, 123 
, 317 
, 314 
, 315 
, 315 
, 281 
, 158 
, 159 
, 276 
, 173 
, 225 
, 73 
, 168 
, 293, 296 
, 275 
, 46 
, 24 
, 24 
, 7 
, 40 
, 296 
, 100 
, 313 
, 293 
, 156, 258 
, 16 
, 2 
, 16 
, 299 
, 298 
, 299 
, 294 
e, 82 
, 158 
, 52 
, 5 
, 48 
, 48 
, 47 
, 37 
, 4 
, 5 
, 37 
, 40 
, 40 
, 60 
, 146 
, 103 
fg, 37 
, 225 
, 181 
, 1 
, 1 
, 172, 208 
, 168 
, 272 
, 82 
, 22 
, 22 
, 277 
, 116 
, 95 
, 94 
, 7 
, 7 
, 180 
, 181 






