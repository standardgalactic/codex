




Contents

Cover
Front Matter
1. Basic Notions and Definitions
2. Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
3. Convex Functions and Generalized Convex Functions
4. Unconstrained Optimization Problems. Set-Constrained Optimization Problems. Classical Constrained Optimization Problems
5. Constrained Optimization Problems with Inequality Constraints
6. Constrained Optimization Problems with Mixed Constraints
7. Sensitivity Analysis
8. Convex Optimization: Saddle Points Characterization and Introduction to Duality
9. Linear Programming and Quadratic Programming
10. Introduction to Nonsmooth Optimization Problems
11. Introduction to Multiobjective Optimization
Back Matter



Landmarks

Cover
Table of Contents
Body Matter











Book cover of Basic Mathematical Programming Theory












Volume 344
International Series in Operations Research & Management Science

Series Editor

Camille C. Price

Department of Computer Science, Stephen F. Austin State University, Nacogdoches, TX, USA




Editorial Board

Emanuele Borgonovo

Department of Decision Sciences, Bocconi University, Milan, Italy

Barry L. Nelson

Department of Industrial Engineering & Management Sciences, Northwestern University, Evanston, IL, USA

Bruce W. Patty

Veritec Solutions, Mill Valley, CA, USA

Michael Pinedo

Stern School of Business, New York University, New York, NY, USA

Robert J. Vanderbei

Princeton University, Princeton, NJ, USA




Associate Editor

Joe Zhu

Foisie Business School, Worcester Polytechnic Institute, Worcester, MA, USA




Founding Editor

Frederick S. Hillier

Stanford University, Stanford, CA, USA




The book series International Series in Operations Research and Management Science encompasses the various areas of operations research and management science. Both theoretical and applied books are included. It describes current advances anywhere in the world that are at the cutting edge of the field. The series is aimed especially at researchers, advanced graduate students, and sophisticated practitioners.
The series features three types of books:
• Advanced expository books that extend and unify our understanding of particular areas.
• Research monographs that make substantial contributions to knowledge.
• Handbooks that define the new state of the art in particular areas. Each handbook will be edited by a leading authority in the area who will organize a team of experts on various aspects of the topic to write individual chapters. A handbook may emphasize expository surveys or completely new advances (either research or applications) or a combination of both.
The series emphasizes the following four areas:
 Mathematical Programming : Including linear programming, integer programming, nonlinear programming, interior point methods, game theory, network optimization models, combinatorics, equilibrium programming, complementarity theory, multiobjective optimization, dynamic programming, stochastic programming, complexity theory, etc.
 Applied Probability: Including queuing theory, simulation, renewal theory, Brownian motion and diffusion processes, decision analysis, Markov decision processes, reliability theory, forecasting, other stochastic processes motivated by applications, etc.
 Production and Operations Management: Including inventory theory, production scheduling, capacity planning, facility location, supply chain management, distribution systems, materials requirements planning, just-in-time systems, flexible manufacturing systems, design of production lines, logistical planning, strategic issues, etc.
 Applications of Operations Research and Management Science: Including telecommunications, health care, capital budgeting and finance, economics, marketing, public policy, military operations research, humanitarian relief and disaster mitigation, service operations, transportation systems, etc.
This book series is indexed in Scopus.





Giorgio Giorgi, 
Bienvenido Jiménez and 

Vicente Novo




Basic Mathematical Programming Theory



Logo of the publisher







Giorgio Giorgi

Department of Economics and Management, University of Pavia, Pavia, Italy



Bienvenido Jiménez

Department of Applied Mathematics, National University of Distance Education, Madrid, Spain



Vicente Novo

Department of Applied Mathematics, National University of Distance Education, Madrid, Spain





ISSN 0884-8289
e-ISSN 2214-7934

International Series in Operations Research & Management Science


				ISBN 978-3-031-30323-4
e-ISBN 978-3-031-30324-1


https://doi.org/10.1007/978-3-031-30324-1

© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, expressed or implied, with respect to the material contained herein or for any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland




For Elena, Elisa, Marcello and Lucia

Giorgio Giorgi

For my wife Elena and my children Roberto,

Cristina and Elena

Bienvenido Jiménez

For my grandchildren Leo, Vega, Eva and

Sara

Vicente Novo


Preface

It is quite superfluous to stress that mathematical optimization is a cornerstone of not only several scientific subjects, such as Economic Analysis, Operations Research, Management Sciences, Engineering, Chemistry, Physics, Statistics, Computer Science, but also Biology and other Social Sciences. The subject of (static) optimization, called also mathematical programming, is, besides its various applications, one of the most important and wide branches of modern mathematics, with deep and beautiful theoretical results. The present book is concerned with the main theoretical questions on optimality and duality theory of mathematical programming problems in the Euclidean space 

. Also in order of limiting the dimension of the book, we have decided to devote our efforts only to expose the basic mathematical tools and results concerning the most treated mathematical programming problems formulated in a finite-dimensional setting. We wish to make clear that it would be desirable that the student or the researcher interested in these questions would complete his knowledge by learning also the basic questions on the various algorithmic methods and on the most important particular applications of mathematical programming problems.
It is however our opinion that the student or researcher interested in learning the fundamental facts of mathematical programming, before being acquainted with the various algorithms and numerical questions, must possess the basic mathematical notions and the basic theoretical background used in analyzing optimization problems.
As it happens for any book, also the present one reflects the tastes of its authors. We have been compelled to make choices, as some subjects of Mathematical Programming have grown at an exponential rate (e.g., Linear Programming) and it would be impossible to cover in a single volume every aspect of mathematical programming theory. Consequently, we have left out certain important subjects, such as, for example, Complementarity Theory, Discrete Optimization, Stochastic Programming, Semi-infinite Programming, Bilevel Programming, and Fractional Programming. Also, set-valued optimization problems are not treated in the present book. However, the last chapter is concerned with an introduction to vector optimization problems, but only in finite dimensions (as done for the scalar case), that is the multiobjective case.
The text assumes no previous experience in optimization theory and the treatment of the various topics is largely self-contained. The prerequisites are the basic tools of differential calculus for functions of several variables, the basic notions of topology in 

 and of Linear Algebra. Some of these concepts are recalled in Chap. 1. We do not claim any originality on the structure of this book; however, we hope that the gradual and self-contained treatment of the subjects will reveal to be a "friendly" approach to the non-experienced reader. We have accompanied several theoretical results with examples and we have often made reference to papers and books, in order to give further information to the curious and willing reader. The list of works in the bibliographical references is quite long.
The book addresses not only to both undergraduate and postgraduate students interested in mathematical programming problems but also to those professionals who use in their jobs optimization methods and wish to learn more theoretical aspects of these questions. We hope that it can be useful in courses of optimization, operations research, economic analysis, and in other courses where optimization theory and methods are investigated. The book is organized into 11 chapters.
Chapter 1 includes background material on classical analysis and linear algebra, together with some basic definitions and properties concerning optimization problems. We present also the main types of optimization problems that will be studied in the next chapters.
Chapter 2 is concerned with the fundamental facts of convex analysis, a subject which is at the heart of optimization theory. We give particular attention to the theorems of the alternative for linear systems. One of the most used and known results of this type, from which all other theorems of the alternative for linear systems can be obtained, is the famous Theorem (or Lemma) of Farkas (or of Farkas-Minkowski). However, some excellent books on optimization theory present an unsatisfactory proof of this theorem, as it is given for granted that a polyhedral cone is a closed set. But this is, in a certain sense, just equivalent to the statement of Farkas' theorem. In the same chapter, we give also the main definitions and properties of some local cone approximations used in optimization theory.
Chapter 3 provides an overview of convex functions and generalized convex functions, with emphasis on their most important properties regarding optimality conditions. Generalized convexity and generalized monotonicity of functions have attracted several researchers, both in mathematics and in other professional disciplines: the Working Group of Generalized Convexity (WGGC) is a section of the Mathematical Programming Society (since 2010 named Mathematical Optimization Society). The chapter concludes with some theorems of the alternative for nonlinear systems.
Chapter 4 treats optimality conditions for an unconstrained optimization problem, denoted by (P1) for a constrained optimization problem with a set constraint (or abstract constraint), denoted by (P2), and for a "classical" constrained optimization problem, denoted by (P3); in other words, (P3) is an optimization problem with only equality constraints. These problems have been called "classical" constrained optimization problems, as they were studied for the first time by J. L. Lagrange in the second half of the 18th century.
Chapter 5 treats a "modern" constrained optimization problem, i.e., a constrained minimization problem with inequality constraints, problem denoted by (P4). The basic necessary and sufficient first-order and second-order optimality conditions are given (Fritz John conditions and Karush-Kuhn-Tucker conditions). A special attention is devoted to the question of constraint qualifications: various constraint qualifications are presented, together with their inclusion properties. Other formulations of (P4) are taken into consideration and several simple numerical examples are discussed.
Chapter 6 treats constrained optimization problems with mixed constraints, i.e., with both equality and inequality constraints, problems denoted by (P5). We have preferred to treat separately these types of problems, as the related optimality conditions have some particular features. Also for these problems, first-order conditions and second-order conditions are discussed with a certain wideness and the question of constraint qualifications is extensively treated, with various constraint qualifications proposed and analyzed. The chapter concludes with some insights on a constrained optimization problem with both equality and inequality constraints and with a set constraint, problem denoted by (P6), and on asymptotic optimality conditions for (P5).
Chapter 7 is concerned with sensitivity analysis for problem (P5) a subject usually not treated in textbooks on optimization theory, but important for its economic and financial applications and also for computational questions. We follow mainly the classical approach of Fiacco (1983).
Chapter 8 is concerned with optimality conditions for a convex programming problem of the type (P4) expressed in terms of saddle points conditions, and with Lagrangian duality. From a historical point of view, optimality conditions via saddle points are important, as one of the aims of the pioneering paper of Kuhn and Tucker (1951) was to extend to the nonlinear (convex) case the duality and saddle points results previously obtained for the linear case (Linear Programming). As for what concerns duality theory, we have chosen to give some basic insights on the so-called "Lagrangian duality", because this approach is equivalent (at least for convex programming) to Fenchel's approach which uses conjugate functions. We briefly treat also the general approach to duality which makes reference to the "minimax theory".
Chapter 9 is concerned with Linear Programming and Quadratic Programming. Linear programming problems are treated with reference to their fundamental formal properties, therefore with no mention to the famous "simplex method" of G. B. Dantzig, nor to other more modern algorithmic questions. For these last aspects, we have given in the bibliographical references some suggestions. The same holds true for quadratic programming problems, which are important for some applications in Finance, Econometrics and Statistics. A special attention has been devoted to duality theory, both for linear programming problems and for quadratic programming problems.
Chapter 10 is an introduction to nonsmooth optimization. The term "nonsmooth analysis" is due to the Canadian mathematician F. H. Clarke; the related theory begins with the necessity to treat, within convex optimization problems, non-necessarily differentiable functions. The basic contributions to this case are the works of Fenchel (1953), Moreau (1963), and the celebrated book Convex Analysis by Rockafellar (1970). Subsequently, Clarke (1983) extended the domain of nonsmooth analysis from convex to locally Lipschitz functions. The first and second sections of Chap. 10 are, respectively, concerned with nonsmooth convex optimization problems and with nonsmooth locally Lipschitz optimization problems. The third and last section is concerned with an axiomatic approach to nonsmooth analysis and nonsmooth optimization, due to Elster and Thierfelder (1985, 1988a, b, 1989).
The final Chap. 11 is an introduction to vector optimization problems, but only in finite dimensions, that is the multiobjective case. Necessary and sufficient optimality conditions are given, together with the so-called "weighted sum method".

Acknowledgements
This work, for the second and third authors, was partially supported by Ministerio de Ciencia e Innovación and Agencia Estatal de Investigación (Spain) under the project with reference PID2020-112491GB-I00/AEI/10.13039/501100011033.



Giorgio Giorgi


Bienvenido Jiménez


Vicente Novo


Pavia, Italy
Madrid, Spain

December 2022



Contents





1 Basic Notions and Definitions

1




1.​1 Introduction

1





1.​2 Basic Notions of Analysis and Linear Algebra

2





1.​3 Basic Definitions and Properties of Optimization Problems

9





References

22






2 Elements of Convex Analysis.​ Linear Theorems of the Alternative.​ Tangent Cones

23




2.​1 Elements of Convex Analysis

23





2.​2 Theorems of the Alternative for Linear Systems

41





2.​3 Tangent Cones

47





References

52






3 Convex Functions and Generalized Convex Functions

53




3.​1 Convex Functions

53





3.​2 Generalized Convex Functions

64





3.​3 Optimality Properties of Convex and Generalized Convex Functions.​ Nonlinear Theorems of the Alternative

74





References

81






4 Unconstrained Optimization Problems.​ Set-Constrained Optimization Problems.​ Classical Constrained Optimization Problems

83




4.​1 Unconstrained Optimization Problems

83





4.​2 Set-Constrained Optimization Problems

96





4.​3 Optimization Problems with Equality Constraints ("Classical Constrained Optimization Problems")

102





References

121






5 Constrained Optimization Problems with Inequality Constraints

123




5.​1 First-Order Conditions

123





5.​2 Constraint Qualifications

137





5.​3 Second-Order Conditions

141





5.​4 Other Formulations of the Problem.​ Some Examples

147





References

167






6 Constrained Optimization Problems with Mixed Constraints

169




6.​1 First-Order Conditions

169





6.​2 Constraint Qualifications

184





6.​3 Second-Order Conditions

201





6.​4 Problems with a Set Constraint.​ Asymptotic Optimality Conditions

215





References

222






7 Sensitivity Analysis

225




7.​1 General Results

225





7.​2 Sensitivity Results for Right-Hand Side Perturbations

236





References

242






8 Convex Optimization:​ Saddle Points Characterization​ and Introduction to Duality

243




8.​1 Convex Optimization:​ Saddle Points Characterization​

243





8.​2 Introduction to Duality

254





References

273






9 Linear Programming and Quadratic Programming

275




9.​1 Linear Programming

275





9.​2 Duality for Linear Programming

289





9.​3 Quadratic Programming

301





References

315






10 Introduction to Nonsmooth Optimization Problems

317




10.​1 The Convex Case

318





10.​2 The Lipschitz Case

337





10.​3 The Axiomatic Approach of K.​-H.​ Elster and J.​ Thierfelder to Nonsmooth Optimization

367





References

379






11 Introduction to Multiobjective Optimization

383




11.​1 Optimality Notions

384





11.​2 The Weighted Sum Method and Relations with Proper Efficiency

399





11.​3 Optimality Conditions

403





References

429





Index

431
















© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_1





1. Basic Notions and Definitions



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es







1.1 Introduction
It is well-known that the central problem of mathematical programming is that of minimizing or maximizing a given numerical function of several variables, where the variables are free to move over the whole domain of the function or (more usually) are constrained by a system of constraints.
Mathematical programming, called also nonlinear programming, can be viewed as that field of optimization theory  which treats static and finite-dimensional optimization problems. It seems that the term "mathematical programming" was first introduced by the American economist Robert Dorfman in 1949, as a generalization of the term "linear programming", introduced by the American mathematician George B. Dantzig a couple of years before. The term "nonlinear programming" appears for the first time in 1951 in the title of the famous pioneering paper of Kuhn and Tucker [1]. Mathematical programming problems are at the heart of many theoretic and applied sciences: indeed, these problems occur in different contexts, such as for example, economic analysis, operations research, management sciences, games theory, statistics, physics, engineerings, etc. Mathematical programming problems have attracted a wide interest also because of their applications in many practical questions arising in industry, commerce, government and military questions.
In the present text-book we shall be concerned with the basic aspects of optimality conditions and duality conditions related to a mathematical programming problem. We have preferred to point out the basic ideas on the mathematical structure of these problems, rather than on the various algorithmic techniques, available in many excellent books treating numerical optimization. 


1.2 Basic Notions of Analysis and Linear Algebra
In this section we recall some basic notions of Analysis and Linear Algebra, which will be useful to understand several notions developed in the next chapters. In order to deepen the concepts expounded here, the reader is referred to the texts quoted in the Bibliographical References.
General concepts of basic topology on R


Given a vector (point) in 



we denote by 

 its Euclidean norm:

A neighborhood 

 or also 

 of 

 is given by an open ball of a given radius 



When it is useful to specify the radius 

 we shall write 

 

 

 

 etc.
In any case we have

A point 

 is an interior point of a set 

 if 

 and there exists a neighborhood 

 contained in S.
The set 

 is open if all its points are interior points. The set 

 is closed if its complementary set is open (equivalently: if it contains all its boundary points or if it contains all its accumulation points). The boundary  of S,  denoted by 

 or 

 is the set of points x for which 

 contains a point in S and a point not in S,  for all 


The interior of a set 

 is given by all its interior points, i.e., if we denote the interior of S by 



The closure of S,  denoted by 

 or also by 

 is given by the intersection of all closed sets which contain S. It holds

In other words, 

 consists of S and all boundary points of S, i.e. 

.
The algebraic sum of two sets 

 of 

 is defined as

The multiplication of a set 

 by a real number or real scalar 

 is defined as

We have the following calculus rules:

Let be given a set 

 and an element 

 we shall write 

, instead of 

 Moreover, we shall write 

 to denote the operation 


Differentiability
Let be given a function 

. Then f is said to be (Fréchet) differentiable at 

 if there exists a vector 

 such that

for all 


The Landau symbol ("small o") o(t) means that

The vector 

 is the gradient of f at 

 its elements are given by the n partial derivatives of f,  evaluated at 



We observe that if, in the above definition, 

 with 

 then 


We accept the following definition of twice differentiability.  A function 

, differentiable at 

 is said to be twice differentiable at 

 if each component of 

 is differentiable at 

 Then, there exists a square matrix, denoted 

 or also 

 of order n,  such that

 for all 


The matrix 

 is the Hessian matrix of f evaluated at 

 its elements are given by the second-order partial derivatives of f,  evaluated at 



The function f is differentiable on the open set 

, respectively, twice differentiable on the open set 

 if it is differentiable, respectively, twice differentiable, at every point 

 If the first-order partial derivatives of f are also continuous, we say that f is continuously differentiable or also that f belongs to the 

-class and shall write 

 If 

 then f is differentiable (the vice-versa does not hold).
If all second-order partial derivatives of f are also continuous, we say that f is twice-continuously differentiable and shall write 

 If 

 then f is twice differentiable (the vice-versa does not hold). Obviously, twice continuous differentiability is more easy to check than twice differentiability, however several results on optimization theory hold under the assumption of twice differentiability. If a function f is twice differentiable (and, even more, if f is twice-continuously differentiable), then its Hessian matrix 

 is symmetric (Schwarz theorem), i. e.

for all 

 


A vector function 

 is  differentiable at 

 if each component 

, 

 is differentiable at 

 In this case we can build the matrix

of order (n, p),  called the Jacobian matrix of h at 

 We draw the reader's attention on the fact that many authors define the Jacobian matrix as a matrix whose rows are the gradients of the functions 

 


Now, let be given 

 and 

 both differentiable, and consider the composite function 

 defined by means of the composition operation 

 This function will be differentiable and it holds ("chain rule"):

We recall Taylor's formula for twice-continuously differentiable functions.
(a)
Let 

 be a 

-function on the open set 

 and let be 

 Then, for any 

 we have 

 for 

 
(Taylor's formula with remainder in Peano's form).
 (b)
Let 

 be a 

-function on the open set 

 and let be 

 Then, for any 

 we have 

 where 

 with 



(Taylor's formula with remainder in Lagrange's form).
Putting 

 Taylor's formula with remainder in Peano's form becomes 

 and putting 

 with 

 and 

 




 Systems of linear equations
Let be given a vector 

 

 and a scalar 

. The set

is a hyperplane in 

 The vector a is called the normal to the hyperplane 

 Note that a hyperplane is a level set of a non-identically zero linear function.
Let be given a (real) matrix A of order (m, n),  with 

 non-zero row vectors, and a vector 

 The solutions of the linear system

are given by the intersection of m hyperplanes. If the set of solutions is not empty, it will be a linear manifold (a linear subspace if 

), with dimension 

 where 

 denotes the rank of matrix A.
Let the row vectors of A be linearly independent, i.e. matrix A has full rank. It is then possible (maybe by reordering the rows of A) to decompose A into the form

with 

 square non-singular matrix of order m. Correspondingly, vector 

 will be partitioned as

where 

 is called vector of basic variables and 

 is the vector of non-basic variables.
Then, the original system 

 has now the form

from which

Systems of nonlinear equations and Implicit Function Theorem
In the general case, the vector equation 

 is not formed by linear equations. Nevertheless, if the Jacobian matrix of h has full rank at a point 

 which solves the equation 

 it is possible to get some important solvability results. These results are contained in the following classical version of the Implicit Function Theorem. In essence, this theorem gives sufficient conditions for the existence of a function that locally expresses a set of basic variables in terms of non basic variables, i.e. a nonlinear version of what previously seen for the linear case.
Implicit Function Theorem

Let 

 (

) be 

 on the open set X and let 

 be a solution of 

 Let 

 be of full rank, i.e. 

 decomposed as (after a possible reordering of the variables)

where 

 is a non-singular square matrix of order m. Then, there exists a neighborhood U of 

 where the system 

 defines "implicitly" a system of functions of the type 

 More precisely: (a)
There exists a unique function 

 defined in a neighborhood U of 

 of 

 class in this neighborhood.
 (b)
It holds 

 for all 

 in the said neighborhood U.
 (c)


 for all 

 in the said neighborhood U.
 (d)
It holds 



 

There are also weaker versions of this theorem; in particular, it is possible to consider differentiable functions, instead of 

 functions. See, e.g., Halkin [2].
Quadratic forms
Let be given a (real) symmetric matrix A of order n. The related quadratic form 

 is defined as

The above quadratic form (and its related matrix A) is classified as follows.
(a)
Q is positive (negative) definite if 

 (

), for all 

 


 (b)
Q is positive (negative) semidefinite if 

 (

), for all 


 (c)
Q is indefinite if there exist two vectors 

 such that 

 and 


 

Obviously the quadratic form 

 (i.e. the symmetric matrix A which characterized the said quadratic form) is positive (negative) definite (semidefinite) if and only if 

 is negative (positive) definite (semidefinite).
We have the following two criteria which establish the sign of a quadratic form.

Theorem 1.1
The quadratic form 

 (the real symmetric matrix A) is: (a)
Positive (negative) definite if and only if all eigenvalues of A (which are real, being A symmetric) are positive (negative).
 (b)
Positive (negative) semidefinite if and only if all eigenvalues of A are nonnegative (nonpositive) and at least one eigenvalue of A is zero.
 (c)
Indefinite if and only if A has at least one positive eigenvalue and least one negative eigenvalue.
 


In order to introduce the next criterion ("Sylvester criterion"), we recall that, given a matrix A,  of order (m, n),  we have the following definitions.
The minors of order k of A,  

 are all those determinants formed by k rows and k columns of A. It is shown that we have

minors of order k. We recall that

Now, let A be a square matrix of order n.
The principal minors of A of order k,  

 are all those determinants formed by k rows of A and the corresponding k columns. It is shown that we have

principal minors of order k.
The leading principal minors or North-West principal minors of A of order k,  

 are all those determinants formed by the first k rows and the first k columns of A. Obviously, we have n leading principal minors:




Theorem 1.2
(Sylvester criterion for quadratic forms) Let be given the quadratic form 

 Then Q(x) (i.e. the symmetric matrix A) is: (i)
Positive definite if and only if all leading principal minors of A are positive.
 (ii)
Negative definite if and only if all leading principal minors of A alternate in sign, beginning with 


 (iii)
Positive semidefinite if and only if all principal minors of A are nonnegative and 


 (iv)
Negative semidefinite if and only if all principal minors of A of odd order are nonpositive, of even order are nonnegative, and 


 (v)
Indefinite on the residual cases.
 


Note that if a symmetric matrix A is positive (negative) semidefinite and 

 then A is positive (negative) definite, since A cannot have in this case, a zero eigenvalue.
In many applications of real quadratic forms we are interested in determining the sign of a quadratic form Q(x) when 

 must belong to some subset of 

 In particular, an important case is when x must belong to the set of nonzero solutions of a homogeneous linear system of the form

where B is a matrix of order (m, n),  with 

 and 

 Let us consider the following "bordered matrix", square of order 






Theorem 1.3
Let be 

 and, without loss of generality, suppose that the first m columns of B are linearly independent. Then 

 is positive definite on the set of nonzero solutions of 

 if and only if the leading principal minors of M,  of order 

 have the sign of 

:

where 

 is the h-th leading principal minor of M.


 is negative definite on the same set if and only if the sign of 

 alternate, for 

 beginning with the sign of 



See, e.g., Debreu [3].

Corollary 1.4
If 

 i.e. we have one constraint of the type 

 with 

 the previous conditions become: (a)
Q(x) is positive definite on the set of nonzero solutions of 

 if and only if 



 (b)
Q(x) is negative definite on the same set of (a) if and only if 



 


We point out that the assumption in Theorem 1.3 stating that the first m columns of B give the rank of B (if necessary, renumber the variables) is essential to obtain necessary and sufficient conditions for checking the sign of a constrained quadratic form. In absence of the said assumption, we have only sufficient conditions. Consider, e.g., 

, 

,

which is positive definite on 

 (i.e. here 

). Yet we have





1.3 Basic Definitions and Properties of Optimization Problems
Any non-empty set S of real numbers that is bounded above has a least upper bound 

, i.e. 

 is an upper bound for S and 

 for every upper bound b of S;  

 is called the supremum of S and we write 

 If 

 then 

 is the maximum of S and we write 


Any non-empty set S of real numbers that is bounded below has a greatest lower bound 

 i.e. 

 is a lower bound for S and 

 for every lower bound a of S;  

 is called the infimum of S and we write 

 If 

 then 

 is the minimum  of S and we write 


If 

 is not bounded above, we write 

 and if S is not bounded below, we write 

 One usually defines 

 and 


Obviously, with 

 and 

, we have that the infimum value of f is

the minimum value of f is

the supremum value of f is

the maximum value of f is

In the following we will consider a minimization problem or a maximization problem of the form

where 

 is a real-valued function, called the objective function, and 

 is a subset of the domain of f,  

 The case 

 is not excluded. The set S is called also the feasible set or feasible region or opportunity set. When S is an open set (e.g. when 

) or, more generally, when for the optimal point 

 it holds 

 we speak of unconstrained mathematical programming problem. We suppose in any case that 


We recall some basic definitions.

Definition 1.5
A point 

 is called a global minimum point or global minimizer for problem (P) or for the function f on S (respectively: a global maximum point or global maximizer  for problem (P) or for the function f on S) if




We note the following facts.

Global minimizers (global maximizers) need not exist, as one can see by considering the following examples.
(a)
Minimize the function 

 over 


 (b)
Minimize the function 

 over 

.
 (c)
Minimize the function 

 over 


 


Global minimizers (global maximizers) need not be unique. One example is the function 

 with 

, which has two global minimizers: 

 A more extreme example is the function 

 

, for which every point 

 is a global minimizer and a global maximizer.


The value 

, with 

 a global minimizer (the value 

, with 

 a global maximizer) of f over S, is also said to be the global minimum (resp. the global maximum) of f over S. The set of global minimizers (global maximizers) is sometimes denoted by

It is easy but important to note that the minimizers of a function f on S coincide with the maximizers of 

 on S;  we simply write

whereas for the minimum value 

 and for the maximum value 

 we have the obvious relation

In order to avoid unnecessary and trivial repetitions, we shall be mainly concerned in the sequel with minimization problems, being the results related to maximization problems easily obtainable from the previous ones.

Definition 1.6
A point 

 is called a local minimizer or local minimum point for problem (P) or for the function f on S if there exists a neighborhood 

 of 

 such that 

 is a global minimizer of the problem




In other words, 

 is a local minimizer or a local minimum point for f on S,  if there exists 

 such that

for all 

 such that 


Slightly strengthening the above definitions, we obtain the following ones.

Definition 1.7
A point 

 is called a strict local minimizer for problem (P) or for the function f on S,  if




In other words, with respect to Definition 1.6, we replace the weak inequality 

 by the strict inequality < (and in this case we consider 



).

Definition 1.8
A point 

 is called a strict global minimizer for problem (P) or for the function f on S,  if





Remark 1.9
(a) If 

 is a global minimum point, then 

 is of course a local minimum point. If 

 is a strict local (or also global) minimum point, then 

 is of course also a local (or global) minimum point.
(b) The isolated points of S are both minimizers and maximizers, at least in the local sense, of 

.
(c) If there exists for (P) a strict global minimizer 

 then 

 is obviously the unique strict global minimizer. However, note that it may exist infinite global minimizers (not in a strict sense!). For example, the function 

 

, presents infinite global minimizers at 

 and infinite global maximizers at 

 None of these points is, respectively, a strict global minimizer (a strict global maximizer), as at all these points the value of the function is 

 (respectively: 1). On the other hand, everyone of the said points is, respectively, a strict local minimizer (a strict local  maximizer).
(d) It may also exist infinite strict local minimizers (which however are not global ones): for example, the function 



, has infinite strict local minimizers and infinite strict local maximizers, which are not global ones.


Definition 1.10
A point 

 is called an isolated local minimizer for (P) if there exists a neighborhood 

 of 

 such that 

 is the unique local minimizer for f(x) in the said neighborhood 

 or in 



Note that every isolated local minimizer is a strict local minimizer, but the converse does not hold in general. As an example, consider the (rather pathological) function

This function has a strict local minimizer at 

 (which is at the same time the unique global minimizer of f), but there exists a sequence of (isolated!) local minimizers converging to zero. Thus the minimizer 

 is not isolated.

Definition 1.11
A point 

 is a strict local minimizer (or a minimum point) of order 

 for (P),  if there are a neighborhood 

 and a constant 

 such that, it holds




If 

 the point 

 is more commonly called a strong local minimizer for (P) or also a sharp local minimizer. If 

 some authors speak of "quadratic growth condition". We observe that if 

 is a strict local minimizer of order p,  then it is also a strict local minimizer of order r for all 

 Moreover, it is clear that any strict local minimizer of order p is a strict local minimizer. However, not every strict local minimizer is a strict local minimizer of order p for some p.
For example, define 

 as follows

and let 

 Then 

 is a strict local minimizer that is not a strict local minimizer of order p for any 

.
Existence of Minimizers
First recall that the lower limit of a sequence of real numbers 

 is defined as

This is equivalent to defining 

 as the smallest possible limit of convergent subsequences of 

 Note that, in contrast to the usual notion of limit of a sequence, every sequence has a lower limit (the sequence 

 is increasing, and therefore its limit exists).
Similarly for the definition of the upper limit of a sequence of real numbers 



It can be proved that

and that a sequence 

 in 

 converges to a limit 

 if and only if

The above notions can be given directly with reference to a real-valued function 

. If 

, 

 is an accumulation point for X,  we have




Definition 1.12
A function 

 is said to be lower semi-continuous on X if for every 

 and every sequence 

 converging to x we have




A function 

 is said to be upper semi-continuous on X if (and only if) 

 is lower semi-continuous on X,  i.e. for every 

 and every sequence 

 converging to x we have

Thus, for a lower semi-continuous function, whenever we have a sequence 

 converging to x, the sequence of values 

 cannot have a limit smaller than f(x). Similarly for an upper semi-continuos function.
Definition 1.12 can be restated in the following terms: 

 is lower semi-continuous on X if for every 

 (

 accumulation point for X)

(Similarly for upper semi-continuous functions).
We point out that several authors do not take into consideration, in the above relation, a deleted neighborhood 

 but simply a neighborhood 

 Under this assumption, 

 is lower semi-continuous on X if for every 



A lower semi-continuous function (an upper semi-continuous function) need not be a continuous function; indeed, it holds the vice-versa, as stated by the following basic result.

Theorem 1.13
A function 

 is continuous on X if and only if it is both lower semi-continuous and upper semi-continuous on X.


Example 1.14
(a)
The function 

 defined by 

 is lower semi-continuous, but not continuous.
 (b)
The function 

 defined by 

 is lower semi-continuous, but not continuous.
 (c)
The function 

 defined by 

 is not lower semicontinuous (nor continuous).
 (d)
If 

, 

 is any family of continuous functions, then the function 

 is lower semi-continuous (note that it is not required that the family is finite!).
 



Remark 1.15
An alternative equivalent definition of lower semi-continuity is the following one.
(a)
A function 

 is lower semi-continuous on X if (and only if) its lower level set


 is relatively closed in X for every 

. In other words: whenever 

 and 

 is a sequence that converges to some 

 we have that 

 Because this characterization does not rely directly on sequences but rather on the notion of closedness, it can, in some situations, be less cumbersome to handle.
Other equivalent characterizations of lower semi-continuity of 

 are:
 (b)
The set 

 is relatively open in X for every 

.
 (c)
The epigraph of f :  

 is relatively closed in 

.
 


The importance of semi-continuous functions lies in a generalization of the well-known Weierstrass Theorem.

Definition 1.16
Assume that the set 

 of problem (P) is nonempty and let

A minimizing sequence for (P),  i.e. for the problem

is a sequence 

 satisfying




That is, a minimizing sequence is a sequence such that the function values of which converge to the minimal (infimal) value of f. A minimizing sequence always exists. Note that this does not say anything about the convergence of the sequence 

 itself. For example, the sequence

is a minimizing sequence for the function 



Theorem 1.17
(Generalized Weierstrass Theorem) Assume that 

 is nonempty, closed and bounded (i.e. compact) and let be 

.
(a)
If f is lower semi-continuous on S,  it admits at least one global minimizer 


 (b)
If f is upper semi-continuous on S,  it admits at least one global maximizer 


 



Proof
We prove only part (a). Since f is upper semi-continuous if and only if 

 is lower semi-continuous. Let 

 be a minimizing sequence for the optimization problem (P). Because S is closed and bounded, it follows that the sequence 

 admits a sub-sequence, say 

 converging to some point 

 (Heine-Borel Theorem). Thus the definitions of 

 

 and 

 and the lower semi-continuity of f imply that

which shows that 

 for every 

 In other words, 

 is a global minimizer of f on S.    




Corollary 1.18
(Weierstrass Theorem) Assume that 

 is closed and bounded and that 

 is continuous on S. Then, there exists 

 such that 

 

 and there exists 

 such that 

 



In order to obtain an existence result that is also applicable to an optimization problem where the feasible set 

 is not bounded, we have to introduce another definition.

Definition 1.19
A function 

 is called coercive, if every sequence 

 with 

 satisfies 




Theorem 1.20
Assume that in problem (P) the feasible set 

 is nonempty and closed, and that 

 is lower semi-continuous and coercive. Then problem (P) admits at least one global minimizer 




Proof
Let 

 be a minimizing sequence of the optimization problem. Then the sequence 

 does not diverge to 

 and therefore the coercivity of f implies that the sequence 

 is bounded. Thus it admits a sub-sequence 

 converging to some point 

 Because S is closed, it follows that, actually 

 Thus we have (as above) that

which shows that 

 is a global minimizer of f on S.    



In the sequel we shall be mainly concerned with the following mathematical programming problems (or optimization problems): 

 and 


(1)
Unconstrained minimization problems

 where 

 and S is an open set or, more generally, where for the optimal point 

 it holds 

 In other words, we are looking for those optimal points 

 of f(x) which are interior to S. We note that in this case the definition of local minimizer for 

 can be rewritten in the form 

 being obviously always possible to choose 

 such that 


 (2)
Constrained minimization problems with a set constraint (or abstract constraint)

 where 

 and S is not necessarily open or not necessarily the optimal point 

 is interior to S. We recall that the function f is called the objective function and the set 

 is called the feasible set or constraint set. We shall assume 

 however, many authors adopt the convention that if 

 then 


 (3)
"Classical" constrained minimization problems, i.e. minimization problems with only equality constraints

 where 

 is an open set contained in the domains of the functions involved in 

 f and each 

 

 are real-valued function defined on 

 The set 

 is the feasible set for 

 and f is the objective function. The restriction 

 is made in order to avoid that the feasible set shrinks to only isolated points or to the empty set.
This type of constrained minimization problem is called "classical", as its analysis and related solution go back to the work of J. L. Lagrange (1736-1813). For some related historical questions see, e.g., the book of Giorgi and Kjeldsen [4].
 (4)
Constrained minimization problems with only inequality constraints

 where 

 is an open set contained in the domains of the functions involved in 

 f and each 

 

 are real-valued function defined on 

 The set 

 is the feasible set for 

 and f is the objective function. In contraposition with 

 

 is a type of "modern" constrained minimization problem or nonlinear programming problem, as these problems have been systematically analyzed starting from the second half of the 20th century.
We note that our formulation is sufficiently general for our purposes: for example, a maximization problem can be transformed (as already remarked) into a minimization problem: 

 If we have a constraint of the type 

 we can equivalently write 

 and if we have a constraint of the type 

 we can equivalently write 

 where 

 Also the nonnegativity constraint on vector x could be transformed into: 

, even if this procedure is not too useful.
 (5)
Constrained minimization problems with mixed constraints or general nonlinear programming problems

 where 

 is an open set contained in the domains of the functions involved in 

 f, 

 

 and 

 

 are real-valued functions defined on 

 In this case the feasible set is given by 

 and f is the objective function for 


 

If in the above problems the objective function and the constraints are at least differentiable, we speak of differentiable or smooth mathematical programming problems, otherwise of nonsmooth  mathematical programming problems. If the objective function and the inequality constraints are convex functions, the equality constraints are affine functions and 

 is a convex set, then we speak of convex programming problems  (see Chap. 8). We shall be concerned also with some important particular cases of the above problems: (A)
The Linear Programming Problem, usually written, for a minimization problem, in the form 

 where 

 A is a (real) matrix of order (m, n) and 

 Here the inequality signs are meant to denote componenwise inequality. The constraint 

 is usually called "nonnegativity constraint". If the problem is a maximization one, it is usually written as 



 (B)
The Quadratic Programming Problem, under linear constraints, usually written, for a minimization problem, in the form 

 where Q is a symmetric matrix of order n,  

 

 A is a (real) matrix of order (m, n) and 


 

Problems (A) and (B) are quite important, above all for economic applications.
There are also other special and important types of mathematical programming problems we however shall not treat in the present book, e.g.:
The fractional programming problem, usually written, for a minimization problem, in the form 

 where a(x),  b(x) and every 

 are real-valued functions on 

 and 

, 

 
Also this type of mathematical programming problem has several interesting applications.

The semi-infinite programming problem, usually written, for a minimization problem, in the form 

 where f(x) and 

 are real-valued functions defined on 

 and I is an arbitrary index set. Also this type of mathematical programming problems has received a growing attention owing to its interesting applications.
Finally, we give here some hints on vector optimization problems, in finite dimensions, called also multiobjective optimization problems. For example 




In multiobjective optimization problems the objectives often conflict with each other and consequently the concepts of optimality seen for the scalar case are not directly suitable for the vector case, even if there are techniques of scalarization, in order to transform a vector problem into a scalar problem. These techniques, however, work under suitable assumptions.
Of course, if there exists a feasible point 

 which minimizes all the components of the vector objective function simultaneously, it provides a solution to the problem. Such a point is usually called an utopia solution or utopia point, but this kind of solution seldom exists and we are obliged to introduce other solution concepts. These new concepts of optimality for the vector case were introduced, within Economic Analysis, by the English economist Francis Ysidro Edgeworth (1845-1926) in 1881 and by the Italian economist and sociologist Vilfredo Pareto (1848-1923) in 1896.
First, we remark that if we have a scalar function 

, the definition of (global) minimum point 

 for f over 

 is, as previously seen,

This is equivalent to require that there exists no 

 such that

If we wish to extend the concept of optimal point to problem 

 the said equivalence is no longer valid, but this second way is the right way to introduce the concepts of optimal points for the vector case. More precisely, we have the following formal definitions.

Definition 1.21
A feasible point 

 is said to be an efficient solution (or Pareto optimal solution) for 

 if there exists no 

 such that

with at least one strict inequality.

If we denote by 

 the nonnegative orthant of 

 i.e. all vectors of 

 with nonnegative elements, and by 

 the nonpositive orthant of 

 i.e. all vectors of 

 with nonpositive elements, the previous definition can be rewritten as




Definition 1.22
A feasible point 

 is said to be a weak efficient solution (or a weakly efficient solution) for 

 if there exists no 

 such that

i. e., with 



i. e.




If the previous definitions are verified in 

 where 

 is a suitable neighbourhood of 

 then 

 is said, respectively, a local efficient solution and a local weak efficient solution. Note that in the scalar case (

), the above definitions collapse to the ordinary definitions of a global (or local) minimum point. Note, moreover, that (local) efficiency implies (local) weak efficiency.
Of course other ordering cones, not necessarily coincident with 

 or 

 can be considered. For example, if K is a convex cone in 

 containing the origin and pointed (i.e. 

 

), then 

 is said to be a K-efficient point or K-minimal point for 

 if there exists no 

 such that

a weak K-minimal point, if there exists no 

 such that

It can be proved that the order relation "induced" by the cone K verifies the reflexive, antisymmetric and transitive properties. For the definition of cone and convex cone, see Chap. 2. These subjects will be developed in Chap. 11.
We point out that in the present book we do not intend to discuss the important subjects concerning the various algorithms or numerical methods available to solve or to get an approximate solution of the various mathematical programming problems described above. We intend to express the basic optimality conditions referred to the said problems, conditions which are, beyond their intrinsic interest, a fundamental tool for developing the related numerical algorithms.

References1.H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability, ed. by J. Neyman (University of California Press, Berkeley, 1951), pp. 481-492. Reprinted in Giorgi and Kjeldsen (2014)2.H. Halkin, Implicit functions and optimization without continuous differentiability. SIAM J. Control Optim. 12, 229-236 (1974)3.G. Debreu, Definite and semidefinite quadratic forms. Econometrica 20, 285-300 (1952)4.G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (Birkhäuser, Basel and New York, 2014)












© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_2





2. Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es







2.1 Elements of Convex Analysis
Mathematical programming theory is strictly connected with Convex Analysis. We give in the present section the main concepts and definitions regarding convex sets and convex cones. Convex functions and generalized convex functions will be discussed in the next chapter.
Geometrically, a set 

 is convex if the line segment joining any two points in the set lies entirely in the set. We recall that the (closed) line segment joining the points 

 and 

 of S, denoted as 

 is given by

The open line segment is denoted as 

 and is given by

We have the following basic definitions.

Definition 2.1
A nonempty set 

 is convex if for any two points 

, we have 

 A set 

 is strictly convex if




Note that, unlike a convex set, the boundary of a strictly convex set cannot contain any segment. The empty set 

 is considered to be convex; any singleton (i.e. a set containing just one single point) is convex.
We recall now some basic definitions concerning various types of combinations of vectors of 


Let 

 be vectors of 

 A linear combination of the vectors 

 is any expression of the form

 (2.1)where each 

.
When 

 the linear combination (2.1) is called affine combination of the vectors 


When it holds that each 

 the linear combination (2.1) is called convex conic combination or nonnegative combination of the vectors 


When in (2.1) it holds that each 

 and 

 the expression (2.1) is called a convex combination of the vectors 



Definition 2.2
A set 

 is a cone with vertex at the origin if




Many authors, however, do include the vertex in the cone by letting 

 in the above definition. It may be useful to accept both definitions, in order to have more flexibility in the various cases and problems encountered in treating this topic. A cone 

 which is also convex is called...a convex cone! It is easy to prove that a cone 

 is convex if and only if

Indeed, if K is convex, we have 

 where 

 being K convex and 

 being K a cone. Conversely, if 

, then we have 

 

 since K is a cone, and therefore 

, i.e. K is a convex set.
Note that the definition of cone in 

 is an abstract and multi-dimensional generalization of the well-known ice-cream cone. A cone 

 may be open, closed or neither open nor closed. Examples of cones are:

Note that 

 and 

 are convex cones.
If 

 and 

 are convex cones, also 

 and 

 are convex cones. Every linear subspace of 

 is a closed convex cone.
Now, let S be a nonempty subset of 


The collection of all linear combinations of vectors of S is said to be the linear space generated by S or linear span of S or also linear hull of S and denoted by 




 It can be proved that 

 is the smallest linear space of 

 containing S.

The collection of all affine combinations of vectors of S is called affine hull of S and denoted by 

: 

 It can be proved that 

 is the smallest affine subspace of 

 containing S. If 

 where L is a linear subspace of 

 then the dimension of the affine hull of S is given by the dimension of L. The dimension of S is given by the dimension of its affine hull.

The collection of all convex conic combinations of vectors of S is called the convex conic hull of S or convex cone generated by S or convex cone spanned by S and denoted by 

: 

 Some authors (e.g. Bazaraa and Shetty [1]) require that the coefficients 

 

 are not all zero, i.e. 

 It can be proved that 

 is the smallest convex cone of 

 containing S (equivalently: it is the intersection of all convex cones in 

 containing S).

The collection of all convex combinations of vectors of S is called the convex hull of S and denoted by 

: 





It can be proved that 

 is the smallest convex set of 

 containing S;  equivalently: 

 is the intersection of all convex sets in 

 containing S (see the next Theorem 2.4).
We note that if S is a nonempty subset of 

 we have

Moreover: (a)


 is a linear subspace of 

 if and only if 


 (b)


 is an affine set of 

 if and only if 


 (c)


 is a convex set of 

 if and only if 


 (d)


 is a convex cone with vertex at 

 if and only if 


 

Let us prove (c). The proofs of the other properties are similar and left to the reader.

Theorem 2.3
A nonempty set 

 is convex if and only if every convex combination of elements of S lies in S.


Proof
The sufficiency of the condition is obvious from the definition. We prove the necessity by induction on the number of elements of S occurring in the convex combination. When 

 the condition follows from the definition. Assuming that every convex combination of k or fewer points of S yields a point of S,  we consider a combination of 

 points. Let 

 where 

 and 

 and 

 for all i. If 

 then 

 which belongs to S and there is nothing further to prove. Suppose that 

 In this case 

 and we have

By the induction hypothesis, the point

belongs to S. Thus, 

 is a convex combination of two points in S and so 

    



It is important to note that the intersection of any collection of convex sets is a convex set, while the union of two (or more) convex sets is not convex in general. The complement of a convex set need not be convex, For any two convex sets X and Y of 

 their sum 

 is convex.
For any 

 and a convex set 

 the set 

 is convex.
Now we prove that 

 is given by the intersection of all convex sets which contain S.

Theorem 2.4
For any set 

 we have that

is equal to the set 

 given by the intersection of all convex sets wich contain S.


Proof
Let 

 with 

 

 and 

 By Theorem 2.3 the point x obviously belongs to any convex set containing S and therefore also the set T,  i.e. 

 Conversely let 

 and 

, where 

 

 and 

 

 be two elements of 

 Then, for any 

 



is an element of 

 since each coefficient belongs to the interval 

 and

Then 

 is a convex set containing S and so 

 Therefore 

.    



A sharper result in 

 is the following Theorem of Carathedory:

Theorem 2.5
(Caratheodory) The convex hull of 

 is precisely the set of all convex combinations of at most 

 elements of S.

The notation "

" is widely used, however some authors use other notations: for example Jeter [2] uses the notation 

 whereas Dhara and Dutta [3]) use the notation 

 to denote the convex cone generated by S. We remark that 

 need not be a closed set, even if 

 is compact. However, it can be proved that 

 is closed in special cases, such as when S is finite. We speak in this case of finite cone or finitely generated cone, i.e. the closed convex cone generated by a finite set 

 of vectors of 



The vectors 

 of 

 are said to be the generators of 

 The proof that a finitely generated cone is closed is basic in proving the well-known Farkas Theorem (or Farkas Lemma); see the next section of the present chapter.
Another important convex cone is the following one:

where B is a matrix of order (m, n). This cone is called a polyhedral (convex) cone. The Minkowski-Weyl Theorem states that a cone is polyhedral if and only if it is finitely generated. See, e.g., Bertsekas [4], Bertsekas et al. [5], Florenzano and Le Van [6], Hiriart-Urruty and Lemaréchal [7], Rockafellar [8]).
In the literature it is often introduced the conic hull of 

 or radial hull of S,  as the smallest cone (not necessarily convex!) which contains S. Unfortunately this cone is almost always denote by 

 which can generate some confusions and misunderstandings. As this cone is given by the union of all rays starting form the origin and passing through the elements 

, we propose the notation 



Some authors require 

 and some authors use the notation 

 The basic relation between 

 and 

 is given by the following result.

Theorem 2.6
If 

 is a nonempty convex set, then





Proof
As 

 is a cone, it is sufficient to show that 

 is convex; then the result is at hand by the definitions of 

 and 

 Let 

 then there exist two points 

 and numbers 

 such that

For any 

 

 we put

 (2.2)and consider two cases.
(1)


 We put 

 and note that 

 

 

 It follows from (2.2) and convexity of S :  



 (2)


 It follows 

 and hence 

.
    



Moreover, it holds, with 

 


It is sometimes also useful to consider cones and convex cones generated by a set 

 with reference to a point 

 Let 

 with S a nonempty subset of 

 Then 

 is the smallest cone which contains 

 and 

 is the smallest convex cone which contains 

 i.e., with 






These cones are also called, respectively, the cone generated by S at 

 (or from 

) and the convex cone generated by S at 

 (or from 

). The cone 

 is called by Palata [9] the projection cone of S at 

 This cone may be viewed as a (very) rough approximation of the set S in a neighborhood of 

 In the next section we shall consider other more "refined" local cone approximations of the set S at 


We now recall some topological properties related to convex sets.

Theorem 2.7
(i) If 

 is a convex set, then 

 is convex.
(ii) If 

 is a convex set, then 

 is convex.


Proof
(i) For two points 

 consider two neighborhoods 

 and 

 that belong entirely to S. Let 

 being S convex we have

Obviously the relation appearing in the left-hand side of the last relation can be rewritten in the form




So, we have found a neighborhood of 

 which lies in S,  i.e. this point belongs to the interior of S. The set 

 is therefore convex.
(ii) The convexity of the closure of S follows at once from its definition:

being the neighborhood 

 a convex set.    




Theorem 2.8
If 

 is an open set, then 

 is open.


Proof
Since S is open, 

 But 

 so we must have 

 Furthermore, the previous theorem implies that 

 is convex, so 

 On the other hand, 

 so 

 and hence 

 is open.    



Note that the convex hull of a closed set need not be closed. However, contrary to what happens for 

 we have the following result.

Theorem 2.9
If 

 is a compact set, then 

 is compact.


Definition 2.10
The dimension of a convex set 

, denoted 

 is the dimension of the affine hull of S.


Definition 2.11
The convex hull of a finite set of points is called a polytope; if 

 and 

 then 

 is called k-dimensional simplex and the points 

 are called vertices of the simplex.

From Theorem 2.9 we have that a polytope is closed, bounded and convex. A zero-dimensional simplex is a point, a one-dimensional simplex is a line segment and a two-dimensional simplex is a triangle.
We point out that we can have convex sets in 

 with empty interior (we recall that the empty set 

 is convex by definition). For example, consider a line segment in 

 or a circular disk in 

 It is therefore useful to introduce the notion of relative interior of a convex set.

Definition 2.12
Let be given a set 

 The set

is the relative interior of S. A point 

 is called a relative interior point of S.

A set 

 is said to be relatively open  if 

 We note that if 

 has maximal dimension, i.e. if 

 then the sets 

 and 

 coincide. If S is a singleton, then 

 The notion of relative interior is particularly important when referred to convex sets. Furthermore, we have the following result.

Theorem 2.13
Let 

 be a nonempty convex set; then 




Proof
Consider a nonempty convex set 

 Without loss of generality assume that 

 Then 

 is a subspace containing S. Let us assume that 

 is a subspace of dimension m. If 

 then S and 

 contain only one point and the result holds. Hence we now consider 

 We can always find linearly independent vectors 

 in S such that 

 Indeed, if this would not be possible, then one would always be able to find linearly independent vectors 

 

 such that 

 This however contradicts the fact that 

 has dimension m. Now observe that the set 

 has a nonempty interior relative to 

 Thus we have that 

.    



The following result is known as line segment principle and gives further information on the closure and relative interior of a convex set.

Theorem 2.14
Let 

 be a nonempty convex set. Consider 

 and 

 Then any point of the form 

 for 




Proof
For simplicity let us consider S to be a full dimensional set, i.e. 

 Hence 

 we have to show that for any given 

 there exists 

 such that

Since 

 it is easy to see that for any 

 there exists 

 such that 

 Thus 

 for any 

 Therefore we have

This can be re-arranged to show that

Since 

 we have for sufficiently small 



Thus we have

This proves the result.    



Moreover, we have that, if 

 is a nonempty convex set, it holds: (a)



 (b)



 

We will now discuss separation theorems between convex sets, which play a central role in mathematical programming. We recall that a hyperplane in 

 is a set of the form

where 

 is a nonzero vector and 

. The vector a is called the normal to the hyperplane. The related (closed) half-spaces determined by the hyperplane H are given by




We accept the following definitions.

Definition 2.15
Two nonempty sets 

 and 

 of 

 are said to be: (a)
Separable or weakly separable, if there exists a hyperplane 

, 

, 

, such that 

 In other words, it must exist a hyperplane H,  such that 

 i.e. 

 is contained in one of the closed half-spaces determined by H and 

 lies in the opposite closed half-space. The hyperplane H is called separating hyperplane (between 

 and 


 (b)
Properly separable, if they are separable and there exists at least a point 

 such that 

 In other words, 

 and 

 are properly separable if they are separable and it holds 



 (c)
Strongly separable, if there exists a vector 

, and a real scalar 

 such that 



 


It appears that strong separations implies proper separation and proper separation implies (weak) separation. We point out that there are in the literature other kinds of separation and also other denominations (for example, strong separation is sometimes called stable separation or also perfect separation).
The following result will be useful to prove the basic separations theorems we will consider. We leave its proof to the reader.

Lemma 2.16
The two nonempty sets 

 are separable, respectively, properly separable, strongly separable if and only if the sets 

 and 

 are separable, respectively, properly separable, strongly separable.

First we formulate a result concerning strong separability.

Theorem 2.17
Let 

 and 

 be nonempty convex sets in 

 with 

 If 

 is compact (i.e. closed and bounded) and 

 is closed, then there exists a hyperplane that strongly separates 

 and 




Proof
On the grounds of the assumptions, the set 

 is closed and convex and it holds 

 We have to prove that 

 and 

 are strongly separable. Hence, we look for a point 

 such that

This point exists (and it is uniquely determined). Moreover, we have 

 Since for a given point 

 and for a given number 

 with 

 we have

it follows

and hence

As this inequality holds for all 

 we get

i.e.

In addition, we put 

 so we have

for all 

 i.e. the sets 

 and 

 are strongly separable and therefore also 

 and 

 are strongly separable.    



As an immediate corollary we have the following result.

Corollary 2.18
Let S be a closed convex set in 

 and let 

 be any point outside of S,  i.e. 

 Then there exists a hyperplane 

 which separates S and 

 strongly:




If 

 is any nonempty convex set (not necessarily closed) and if 

 is a boundary point of S,  it is natural to conjecture that y can be (weakly) separated from S by a hyperplane passing through y. This conjecture is correct and the related hyperplane is called a supporting hyperplane  to S at y. Indeed, we have the following result ("supporting hyperplane theorem").

Theorem 2.19
Let S be any nonempty convex set in 

 and let 

 be a boundary point of S. Then, there exists at least one supporting hyperplane to S at y,  i.e. there exists 

 

 such that





Proof
Let 

 be the closure of S. Then 

 is convex by Theorem 2.7. Since y is a boundary point for S and S is convex, y is also a boundary point for 

 Take any sequence 

 

 lying outside 

 and converging to y as 

 Since 

 and 

 is closed and convex, by Theorem 2.17 (more precisely by its corollary), there is a vector 

 such that 

 for all 

 Without loss of generality we might assume that 

 for each k,  so that 

 is a sequence moving in the unit sphere of 

 Since a unit sphere is compact, 

 has a convergent subsequence, we denote again by 

 such that

 (2.3)If we let the limit of 

 as 

 be the vector a,  we get, taking the limit in (2.3),

   



We are now ready to prove the (weak) separation theorem, essentially due to H. Minkowski.

Theorem 2.20
Let 

 and 

 be two nonempty convex sets in 

 If 

 and 

 are disjoint, then there exists a hyperplane that separates them, that is, there exist a vector 

 

 and a real scalar 

 such that





Proof
Let 

 Then X is convex and 

 The set 

 is also convex by Theorem 2.7. If 

 then 

 and 

 can be strongly separated according to Theorem 2.17 (Corollary 2.18). If 0 is a boundary point for X,  then 

 and 

 can be separated by Theorem 2.19 ("supporting hyperplane theorem"). In any case, there exists a vector 

 

 such that 

 

 Therefore we can assert that there exists 

 such that

   



More generally, the result of Theorem 2.20 holds under the assumption 


Now we are able to formulate a theorem on proper separation.

Theorem 2.21
(Proper separation theorem) Two nonempty convex sets 

 and 

 in 

 can be properly separated if and only if 




Proof
Define the convex set 

 It follows that 

 Thus 

 and 

 are equivalent statements. Consequently, we have to prove that the sets 

 and X are properly separable if and only if 


Suppose that the origin and X are properly separated by a hyperplane H such that 

 and 

 We claim that 

 If 

 then 

 so that 

 Otherwise, 

 and there exists a point 

 If we had 

 there would exist a point 

 such that 

 giving the contradiction 

 where

This proves the claim.
Conversely, suppose that 

 Write

where 

 

 are linearly independent vectors. If 

 then 

 

 are linearly independent and we can extend it to a basis 

 

 of 

 Then the hyperplane 

 does not contain the origin, so it properly separates 

 and X. If 

 we apply Theorem 2.20 within the vector space L to the sets 

 and 

 and obtain a hyperplane P in L separating 

 and X such that 

 We may assume that 

 otherwise the translation of P so that it passes through the origin also satisfies the same separation properties. Extending P to the hyperplane 

 it is evident that H properly separates 

 and X.    



As a consequence of the theorem on strong separability we have an interesting characterization of closed convex sets of 



Theorem 2.22
A closed convex set 

 is given by the intersection of all closed half-spaces that contain S.


Proof
The intersection D of all closed half-spaces that contain S is obviously a closed convex set and it holds 

 We now prove the opposite inclusion 

 by an indirect proof. Let be given a point 

 with 

 so the sets S and 

 are strongly separable, i.e. there exist a vector 

 and a number 

 such that

Therefore, it will exist a closed half-space

which surely contains the set S,  but not the point 

 i.e. 

 in contradiction with the assumptions.    



In order to get other applications of the separation theorems, we now present the notion of polar cone of a set 

 of bipolar cone, and point out their main properties.

Definition 2.23
Let 

 be any set; then the (negative) polar cone of S is given by

The bipolar cone of S is defined by




Some authors call dual cone of S the positive polar cone: 


However, there is not uniformity of definitions in the literature.
We accept the definition 

 Obviously, any polar cone (and hence any bipolar cone), being given by

is the intersection of closed half-spaces and therefore it is a closed and convex cone, with 


From the definition it follows at once that

If 

 is a linear subspace, the polar cone of L is given by the orthogonal complement of L,  i.e.

The following theorem gathers the main properties of polar cones.

Theorem 2.24
For any sets 

, 

 the following properties hold.
(a)



 (b)



 (c)



 (d)



 (e)


 if S is a nonempty closed convex cone. Therefore if L is a linear subspace of 

 we have 


 (f)


 (if 

) and therefore 


 (g)



 (h)


 if 

 and 

 are closed convex cones.
 



Proof
The first four properties are quite immediate consequences of the definitions of polar and bipolar cones. We prove property (e), called also "bipolar theorem": if 

 is a closed convex cone, then 

 From the definition of 

 we see that if 

 then 

 for all 

 this proves that 

 Suppose that the reverse inclusion 

 is not true, and pick a point 

 It follows from the strong separation theorem (Theorem 2.17) that there exists a nonzero vector 

 such that

 (2.4)On the one hand, setting 

 in (2.4) gives 

 on the other hand, if 

 is a fixed point, then 

 for all 

 and (2.4) gives 

 or 

 Letting 

 we obtain

which implies that 

 However, since 

 we must have 

 which contradicts the fact 

 proved above.
Property (f) follows from (e), being 


As 

 is a non-empty closed convex cone, we have from property (e), also 

 i.e. property (g).
Property (h) is obtained from properties (b), (e) and (f), being

The proof of the proposition

is left to the reader.    



We remark that it could be proved that property (e) of Theorem 2.24 holds if and only if S is a closed convex cone. Moreover, the same property can be given in the following weaker form (called sometimes "polar cone theorem"): for any nonempty cone 

 we have

Therefore

and hence

If 

 it holds

We now briefly recall again a special class of convex cones, called polyhedral cones. First we introduce the notion of  polyhedral sets. Polyhedral sets of 

 are formed by the intersection of a finite number of closed half-spaces. Thus a typical polyhedral set P can be represented as follows.

where 

 and 

. It turns out that polyhedral sets are closed convex sets and that alternatively they can be written in the form

where A is a matrix of order (m, n) and 


A polyhedral cone 

 is represented as

i.e. C is a polyhedral set where 

 Obviously, polyhedral cones are closed convex cones. For this type of cones the following properties hold.
If 

 are polyhedral cones, then: (a)



 (b)


 is a polyhedral cone.
 (c)


 and 

 are polyhedral cones.
 (d)



 (e)



 

Properties (d) and (e) are also called "modularity theorem".
In addition, we recall again the notion of finitely generated cone or finite cone. 

Definition 2.25
A convex cone 

 is said to be finitely generated if it is generated by a finite set of vectors of 

 i.e. if it has the form




The vectors 

 of 

 are said to be the generators of the cone C. We point out that if 

 are the columns of a matrix A,  of order (n, m) and 

 a finitely generated cone can be written as

 (2.5)We have two important results related to finitely generated cones, results previously mentioned.

Theorem 2.26
Let 

 be a finitely generated cone given by

with A matrix of order (n, m). Then C is a closed convex cone.


Proof
The facts that C is a cone with vertex at the origin 

 and that it is convex are obvious. Let us rewrite C as a nonnegative linear combination of the columns 

 of A : 

We will show that the cone C is closed by an induction argument based on the number of the columns 

 

 When 

 C is either the origin 

 or a half-line and is therefore closed. Now suppose that for 

 the cone generated by the vectors 

 is closed:

is closed. We have to show that the cone

is closed too. There are two cases.
(1)
First, suppose that 

 contains the vectors 

 Then 

 is a linear subspace of dimension not exceeding k,  so it is closed.
 (2)
Assume that at least one of the vectors 

 does not belong to 

 say 

 (renumber if necessary). Then, every 

 can be represented as 

 

 where 

 To show that 

 is closed, suppose that 

 is a limit point. Then, there exists a sequence 

 such that 

 as 

 where 

 has the form 

 If the sequence 

 is bounded, we can assume, without loss of generality, that the sequence converges to a limit 

 and consequently 

 where this last set is closed. Indeed, 

 since 

 is closed. We conclude that 

 Thus, if the sequence 

 is bounded, then the set 

 is closed. We now assume that 

 for 

 Then, since 

 converges, it is a bounded sequence. Hence 

 as 

 It follows that 

 as 

. Therefore 

. But since 

 is closed, this means that 

, which is a contradiction.
    




Theorem 2.27
(Minkowski-Weyl Theorem). A cone 

 is polyhedral if and only if it is a finitely generated cone.

Note that from the Minkowski-Weyl theorem we obtain at once that a finitely generated cone is closed. However, also the said theorem has not a trivial proof.
We now compute the polar of the finitely generated cone 

 given by (2.5):

i.e. the polar of a finitely generated cone is a polyhedral cone. Moreover, we can assert that the angles between the vectors 

 and the column vectors of A are not smaller than 

. For what concerns the bipolar cone of C we have

The equality between the cones C and 

 (according to Theorem 2.24(e) since C is a closed convex cone), together with what obtained above, mean that, given a matrix A and a vector b,  the condition

is equivalent to

This is the statement of the well-known Farkas' theorem or Farkas' lemma. This theorem is one of the most quoted and used theorem of the alternative for linear systems. The next section is concerned with several theorems of the alternative for linear systems.


2.2 Theorems of the Alternative for Linear Systems
The general structure of a theorem of the alternative is the following one. A theorem of the alternative is a result concerning the following proposition: between two given systems of linear (or also nonlinear) relatione, say a "primal" system S and a "dual" system 

 one and only one of them admits solutions. In other words: S admits solutions if and only if 

 does not admit solutions (equivalently: 

 admits solutions if and only if S does not admit solutions).
The theorem of the alternative of Farkas can therefore be expressed in the following form, which puts into evidence the "alternative" between two linear systems.

Theorem 2.28
Let be given a matrix A of order (m, n) and a vector 

 Then the system

admits solutions 

 if and only if the system

does not admit solutions 




Remark 2.29
Obviously system 

 in Theorem 2.28 can be equivalently written in the form

Moreover, 

 and 

 of Theorem 2.28 can be equivalently written as




Another equivalent formulation of Farkas' theorem (not in an "alternative form") is the following one, previously given at the end of the last section:
A necessary and sufficient condition for 

 to have solutions 

 is the validity of the implication

or, equivalently,

Finally, note that for 

 Farkas' theorem becomes trivial.

The following result is a simple formal variant of Farkas' theorem and generated a first list of theorems of the alternative for linear systems.

Theorem 2.30
Let be given the positive integers 

 the matrices 

 of order 

 

 

 the vectors 

 

 The system

 (2.6)admits solutions 

 if and only if the system

does not admit solutions 




Proof
The above result comes out at once from Farkas' theorem: we put 

 with 

 

 and then we transform inequalities into equalities by means of the "slack vectors" 

 

 System (2.6) can be therefore rewritten in the form

 (2.7)with 

 

 

 

 

 Applying to (2.7) Farkas' theorem we obtain the thesis.    



From Theorem 2.30 it is possible to obtain easily a first list of theorems of the alternative. In the following list we use the short convention

in order to specify that the "primal" system 

 admits solutions if and only if the "dual" system 

 does not admit solutions.
(1)


; 

. Note that this result gives necessary and sufficient conditions for the existence of solutions of a non-homogeneous system of linear equations: system 

 admits solutions if and only if it holds 

 for any vector y such that 

 This result is sometimes called the Fredholm theorem of the alternative.

 (2)
(Theorem of the alternative of Gale [10]). 

; 

 .
 (3)



 (4)
(Theorem of the alternative of Ky Fan). 

; 

.
 (5)


 ; 

.
 (6)


.
 (7)


.
 (8)


 .
 (9)


.
 (10)


 ; 


 (11)


.
 (12)


. (This result is nothing but Farkas' theorem, where the "primal" and the "dual" problems have been interchanged).
 (13)


.
 (14)


.
 (15)


; 

.
 

Another important theorem of the alternative for linear systems (important for its applications in obtaining optimality conditions for mathematical programming problems) is Motzkin's theorem of the alternative.

Theorem 2.31
(Motzkin) Let be given (real) matrices A,  B and H of appropriate dimensions. Then, exactly one of the following systems has a solution: (i)


;
 (ii)


.
 



Proof
It is easy to show that both (i) and (ii) cannot have a solution. Suppose 

 for some 

 

 

 w unrestricted in sign. Then, for every vector x we have 

 If 

 then 

 and if 

 then 

 Thus 

 Since 

 

 

 cannot hold.
Suppose now that (i) has no solution. Then the system

has no solution (the vector e is the summation vector, i.e. 

). This last system can be written in the form

From Farkas' theorem, there exists a vector 

 such that

This can be rewritten as

Letting 

 we have completed the proof of (ii).    



We remark that in Theorem 2.31 matrices B and H may be missing. If H in Theorem 2.31 is missing, we have the two "alternative systems": (1)




 (2)




 

Antosiewicz [11] proves that the previous statement is equivalent to the following one: either (a)


 has a solution, or
 (b)


 has a solution, but never both.
 

If in (1) and (2) B is missing, we obtain the theorem of the alternative of Gordan:

either 

 has a solution, or



 has a solution, but never both.


If in (a) and (b) B is missing, we obtain the theorem of the alternative of Stiemke:
either 

 has a solution, or


 has a solution, but never both.
Therefore, Gordan's theorem and Stiemke's theorem are equivalent statements. Obviously the first statement of Gordan's theorem can be equivalently restated as

This leads to the following geometric version of Gordan's theorem: let S be a subspace of 

 Then one and only one of the following assertions is true:


. S contains a positive vector.


. 

 contains a nonnegative nonzero vector (

 is the orthogonal complement of S).
From Stiemke's theorem, Nikaido [12] obtains the following result, due to A. W. Tucker, and called also "key theorem".

Theorem 2.32
For any given matrix A of order (m, n) the systems

possess solutions x and y such that




From this result, as shown by Mangasarian [13], it is possible to obtain several theorems of the alternative, among which the theorems of Gordan, Stiemke, Farkas, Motzkin and other ones, such as, for example the following ones.

The theorem of the alternative of Slater: let A, B, C and D be given matrices (C and D may be missing). Then either 

 has a solution x or 




 has a solution u, v, w, z,  but never both.

The theorem of the alternative of Tucker: let B, C and D be given matrices (C and D may be missing). Then either 

 has a solution x,  or 

 has a solution v, w, z,  but never both.

The theorem of the alternative of Ville: either the system 

 has a solution x,  or the system 

 has a solution y,  but never both. Note that system S can be equivalently written as 

 or also as 





It turns out that all the theorems of the alternative described in the present section (and many other ones) are in fact equivalent statements.
In addition, we point out another result, due to A. W. Tucker, which is useful in obtaining duality theorems for linear programming problems.

Theorem 2.33
Let be given a square skew-symmetric matrix L (i. e. 

). Then the system

admits a solution w such that





Proof
By Tucker's key theorem (Theorem 2.32), applied to matrix 

 where I has the same order of L,  there are solutions x and y of




 If we let 

 

 

 the above relations become




In view of 

 the third relation entails 

 Therefore, by letting 

 we have




This completes the proof.    





2.3 Tangent Cones
In mathematics the approximation of sets by means of other sets with a simpler structure plays an important role, especially in optimization theory. In connection with the development of Convex Analysis the interest focused on the approximation of a given set 

 around a given point 

 (or also 

) with cones or with convex cones. Since the vertex of the various approximating cones 

 is usually at the origin of 

 more precisely the approximating cone of a set S at 

 is given by the translation 


There are various notions of local approximating cone; here we shall mention only the following ones. We begin with a cone introduced by the French mathematician Bouligand at the beginning of the 30'ies of the XX century, cone usually called contingent cone or Bouligand tangent cone. 
For surveys of the various approximating cones introduced in the literature, see, e.g., Aubin and Frankowska [14], Bazaraa and Shetty [1], Giorgi et al. [15].

Definition 2.34
A sequence 

 with 

 is called tangentially convergent in the direction 

 to the point 

 if

and we write 



Obviously any convergent sequence 

 (with 

 for all k) contains at least a tangentially convergent subsequence. The set of all directions y for which there exists a feasible sequence 

 with 

 tangentially convergent to 

 form a cone which is a local cone approximation at 

 of the set S.

Definition 2.35
Let 

 and 

 the cone

is called Bouligand tangent cone or contingent cone to the set S at the point 

 If 

 is an isolated point of S,  we put 

.

Other equivalent characterizations of 

 are the following ones:










 The notation 

 means that 

 and 

 for all k.
Note that 

 is indeed a cone, closed but not necessarily convex, with 

 We note also that: (i)


 depends only on the structure of S in a neighborhood of 

 that is 

 where 

 is any neighborhood of 

 (the notion of "Bouligand tangent cone" is therefore an "infinitesimal notion"; this holds true also for the other approximating cones).
 (ii)
If 

 then 


 (iii)


 where 


 (iv)


 if 


 

The fact that 

 is not necessarily convex appears, e.g., from the following example.

Example 2.36
Consider the set

Take 

 Then 

 which is not a convex set.


Example 2.37
As 

 if 

 we see that the definition of Bouligand tangent cone is indeed meaningful when 

 is a point of the boundary of S. Also in this evenience, it may be that 

 does not contain the set S. For example, if 



then 

 and 

.


Example 2.38
If we have 

 functions 

 continuously differentiable on 

 let us consider the set

Let 

 be such that the gradients 

 are linearly independent; then 

 is the subspace

This can be proved with the help of the Implicit Function Theorem (see Theorem 4.​38).


Theorem 2.39
Let S be a nonempty set in 

 and let 

 Then





Proof
Note that the set 

 

 

 is what we have called "cone generated by 

": 

 Let us suppose that the point 

 is not an isolated point, otherwise the property would be trivial. For a given number 

 and a given convergent sequence 

 with 

 it holds obviously the relation

for sufficiently large 

. Let this sequence be in particular sequentially convergent, with 

 so vector y belongs (together with the related contingent cone 

) to the closure of all these cones and hence also to their intersection.
Conversely, let 

 (we can choose y such that 

), with y belonging to the said intersection, so this vector belongs also to the closure of every single cone. For every 

 with 

 sufficiently large, there exists therefore a vector 

 with 

 

 and 

 such that 

 The expression

converges therefore to y,  i.e. 

 and hence vector y belongs to 

.    




Corollary 2.40


 is a closed cone.


Theorem 2.41
Let 

 be a convex set and let 

 then

Under the said assumption 

 is therefore a closed convex cone.


Proof
First we shall show that 

 For this, let us consider 

 Then, there exists a sequence 

, 

 and 

 such that

Again observe that 

 This shows that 

 being S a convex set. In order to prove the desired result we now need to prove the opposite inclusion. In this part of the proof the assumption of the convexity of S will play its role. Let us consider a sequence of the following form

when 

 It is easy to see that 

 can also be represented as

Since S is a convex set, we see that 

 So we have

as 

 This shows that 

 Also, from the expression of 

 we can show that 

 Taking the limit as 

 we see that 

 Since 

 is a cone and 

 is the smallest cone containing 

 we have that 

 Since we know that 

 is closed, we conclude that 

 Being S convex, it holds 

 and we deduce that 

 is a closed and convex cone.    



Note that the inclusion 

 holds without the assumption that S is a convex set.

Definition 2.42
The normal cone 

 to a convex set 

 at 

 is defined as




In other words 

 is the polar cone of the convex set 

 


It turns out that the Bouligand tangent cone and the normal cone at 

 of the convex set 

 are polar cones of each other, i.e.




Other local cone approximations of a set 

 at 

 are the following ones.

Definition 2.43
Let 

 and 

 the cone

is called cone of attainable directions to S at 

 or Kuhn-Tucker tangent cone to S at 



This cone was used by Kuhn and Tucker [16] in their pioneering paper on nonlinear programming. It can be proved that 

 is a closed cone (see, e.g., Peterson [17]) and that

Other equivalent expressions of 

 are, for example, the following ones.







Definition 2.44
Let 

 and 

 the cone

is called cone of feasible directions to S at 

 or also radial cone to S at 




Remark 2.45
Note that 

 is a cone containing the origin but it is neither open nor closed. It need not be convex and it holds

If 

 is a convex set, then 

 

 and 

 are all convex cones and it holds

Therefore note that if S is convex, 

 consists of the vectors 

 with 

 and 


If S is a convex polyhedron, then

From a geometric point of view, we can say that if 

 is a feasible direction at 

 with respect to 

 then we can move starting from 

 along a straight line by a certain range of step to 

 The geometric meanings of attainable and tangent directions are that, besides a straight line, 

 can be approached by a continuous path and a sequence of points belonging to S,  respectively.


References1.M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economic and Mathematics Systems, vol. 122 (Springer, Berlin, 1976)2.M. Jeter, Mathematical Programming. An Introduction to Optimization (Marcel Dekker, New York, 1986)3.A. Dhara, J. Dutta, Optimality Conditions in Convex Optimization. A Finite-Dimensional View (CRC Press, Boca Raton, London, New York, 2012)4.D.P. Bertsekas, Nonlinear Programming, 2nd edn. (Athena Scientific, Belmont, Mass, 1999)5.D.P. Bertsekas, A. Nedic, A.E. Ozdaglar, Convex Analysis and Optimization (Athena Scientific, Belmont, Mass, 2003)6.M. Florenzano, C. Le Van, Finite Dimensional Convexity and Optimization (Springer, Berlin, 2001)7.J.-B. Hiriart-Urruty, C. Lemarechal, Convex Analysis and Minimization Algorithms, vol. I, II (Springer-Verlag, Berlin and New York, 1993)8.R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)9.J. Palata, A survey of conical approximations used in optimization. Optimization 20, 147-161 (1989)10.D. Gale, The Theory of Linear Economic Models (McGraw-Hill Book Company, New York, 1960)11.H.A. Antosiewicz, A theorem of the alternative for pair of matrices. Pac. J. Math. 5, 641-642 (1955)12.H. Nikaido, Convex Structures and Economic Theory (Academic, New York, 1968)13.O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)14.J.P. Aubin, H. Frankowska, Set-Valued Analysis (Birkhäuser, Boston, 1990)15.G. Giorgi, A. Guerraggio, J. Thierfelder, Mathematics of Optimization: Smooth and Nonsmooth Case (Elsevier, Amsterdam, 2004)16.H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability, ed. by J. Neyman (University of California Press, Berkeley, 1951), pp. 481-492. Reprinted in Giorgi and Kjeldsen (2014)17.D.W. Peterson, A review of constraint qualifications in finite-dimensional spaces. SIAM Rev. 15, 639-654 (1973)












© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_3





3. Convex Functions and Generalized Convex Functions



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es







3.1 Convex Functions
Similarly to convex sets, convex and concave functions play a central role in mathematical programming theory. Geometrically, a real-valued function defined on a convex set 

 is convex (concave) if the line segment connecting any two points on the surface generated by the function nowhere lies below (above) the surface itself. More formally, we have the following basic definition.

Definition 3.1
The function 

, X nonempty convex set, is said to be convex on X if, for any two points 

 it holds

for all scalars 

 

 with 

 i.e. for all 

 it holds

 (3.1)


Obviously it is equivalent to require that the inequality in (3.1) holds for all 

 The function f is called strictly convex on X when, for any two points 

 

 it holds

 (3.2)A function 

 (

 nonempty convex set) is said to be concave (resp. strictly concave) on X if and only if 

 is convex (resp. strictly convex) on X. In other words, the above inequalities (3.1) and (3.2) are reversed.
In what follows, in order to avoid useless repetitions, we shall refer in general only to convex functions. The reader will remark that the set 

 must be convex, in order that the left-hand side of (3.1) and (3.2) makes sense. Note that a real-valued function may be simultaneously convex and concave (e.g. any function of the type 

 

 

 see further), but a function cannot be simultaneously strictly convex and strictly concave. Examples of strictly convex functions on 

 are 

 and 

 the function 

 is a typical strictly concave function on 

 The function 

 is neither convex nor concave. The function 

 is alternatively convex and concave and, therefore, it is neither convex nor concave on 

. A more elaborated example of convex functions in 

 is one of the following examples.

Example 3.2
The quadratic function

where B is a symmetric matrix of order n and 

 (

), is convex on 

 if and only if the matrix B is positive semidefinite. Indeed, we have




and for all 

 we have

if and only if B is positive semidefinite. This and the definition of convex functions imply the assertion of the example.
It is obvious that for a quadratic function 

 to be strictly convex on 

 it is necessary and sufficient that the matrix B be positive definite.

Similarly to what was said for convex sets, we have the following result.

Theorem 3.3
A function 

 (X nonempty convex set) is convex on X if and only if, with 

 any collection of elements of X,  it holds

for all 

 with 



The above inequality is known as Jensen inequality for convex functions. Obviously, similar inequalities hold for strictly convex functions, for concave functions, and for strictly concave functions.
A class of convex functions that plays an important role in optimization is given by those functions called sublinear functions.

Definition 3.4
A function 

 is called a sublinear function if, for all 

(i)



 (ii)



 


Note that for 

 we have 

 It is possible to prove the following result.

Theorem 3.5
Let 

 be a convex function that is positively homogeneous. Then f is a sublinear function.

We first recall the basic properties of convex and concave functions of one variable, properties useful also for characterizing convex and concave functions of several variables. We have the following propositions.
Let 

 be a function defined on an open interval I.
(1)
Let 

 be differentiable on I;  then 

 is convex (concave) on I if and only if 

 is increasing (decreasing) on I.
 (2)
Let 

 be twice-differentiable on I;  then 

 is convex (concave) on I if and only if 

 (

) for all 


 (3)
If 

 is differentiable on I,  then 

 is strictly convex (strictly concave) on I if and only if 

 is strictly increasing (strictly decreasing) on I.
 (4)
If 

 is twice-differentiable on I,  then 

 is strictly convex (strictly concave) on I if 

 (

) for all 

 Note that here we have only a sufficient condition.
 

Now we describe several equivalent characterizations of convex functions of several variables.

Theorem 3.6
Let 

 be a nonempty convex set and let 

. The following properties are equivalent: (a)
The function f is convex on X.
 (b)
For every 

 and every 

, the function 

 is convex on the set 


 (c)
For every 

 the function 

 is convex on the interval 


 (d)
The set ("epigraph of f") 

 is convex.
 (e)
Let 

 be convex and open. For every 

 there exists 

 such that 



 



Proof


 It is easy to see that the set T(x, y) is convex (it is an interval!). Let 

 and 

 Being f convex, it holds

with 




 For every 

 and 

 it holds

From the convexity of 

 it results at once the convexity of 




 Let 

 

 and 

 From the convexity of 

 it holds

i.e.

which proves that



 Let be 

 and 

 As 

 and 

 are elements of 

 and this set is convex, it results that

is an element of 

. Therefore,



 Let be 

 It results that 

 belongs to the boundary of the convex set 

. From the supporting hyperplane theorem (see Theorem 2.​19), it results that there exists 

 such that

 (3.3)for every 

.
We can see that 

 if it would be 

 it would result 

 which implies 

 and hence 

 absurd. If 

 then by choosing z sufficiently large, we could obtain

in contradiction with inequality (3.3), previously proved. Now, from inequality (3.3), with 

 by choosing 

 and with 

 we obtain



 Let be 

 and 

 By multiplying the inequality

and the inequality

respectively, by 

 and 

 we obtain

By choosing 

 from the previous inequality it results that f is convex.    



It is useful to remark that vector 

 of characterization (e) is called a subgradient of f(x) at 

 (see, e.g. Rockafellar [1] and see Sect. 10.​1). The set of all subgradients of f(x) at 

 is called the subdifferential of f(x) at 

 and denoted by 


To motivate the geometric interpretation of these concepts we consider the convex function 

 

. Note that at the origin (point of non-differentiability) we may draw an infinite number of non-vertical tangent lines which are in fact non-vertical supporting hyperplanes to the epigraph of f(x). The slope of each of these lines is in fact a subgradient of f(x) at 

 Non-subdifferentiability can however occur on the boundary of the domain of a convex function, where a vertical supporting hyperplane to its epigraph may exist. Consider, e.g. the function 

 defined by 

 This function is clearly convex, however 

 We may, therefore, restate characterization (e) of Theorem 3.6 as:
Let f be a real-valued function on an open convex set 

 Then f is convex on X if and only if it has a subgradient at each point 




From the above characterization, we get that a real-valued convex function on an open convex subset X of 

 is subdifferentiable on X. See also Bazaraa and Shetty [2], p. 92 or Bazaraa, Sherali, and Shetty [3]. We shall revert on these questions in Chap. 10.

Theorem 3.7
(Equivalent characterizations of differentiable convex functions) Let 

 be an open convex set and 

 differentiable on X. The following statements are equivalent: (a)
f is convex on X.
 (b)
For every 

 and 

 the derivative 

 is increasing on T(x, y).
 (c)
For every 

 the derivative 

 is increasing on 


 (d)
For all 

 it holds 



 (e)
For all 

 it holds 



 (f)
For all 

 it holds 



 



Proof


 From the previous theorem it results that f is convex on X if and only if 

 is convex on T(x, y),  which is equivalent to the fact that the derivative 

 is increasing on T(x, y).


 Again from the previous theorem, it results that f is convex on X if and only if 

 is convex on 

 which is equivalent to the fact that the derivative 

 of 

 is increasing on 




 As 

 is increasing on 

 it results for every 



and, therefore,

From Taylor's formula (first-order expansion) we get

The result follows from the last two inequalities, with 




 For every 

 we can write

i.e.



 By summing the following two inequalities




we have the desired result.


 For any 

 and any 

 with 

 we can write

Let us denote 

 and 

 It results that 

 and that

Therefore,

and hence 

 is increasing on 

.    



We are now concerned with the characterization of twice-continuously differentiable convex functions, i.e. functions belonging to the 

 class.

Theorem 3.8
Let f be 

 on the open convex set 

 Then f is convex on X if and only if its Hessian matrix 

 is positive semidefinite for every 




Proof
(1)
Let 

 be positive semidefinite for all 

 By Taylor's formula (second-order expansion) we can write 

 with 

 

 Being 

 positive semidefinite for all 

 we have 



 (2)
Let f be convex on X. We have (Theorem 3.7) that 

 is increasing on 

 Being 

 also 

 is twice differentiable on T(x, y). It holds, therefore, that 

 for all 

 i.e. 

 for all 

 In particular, for 

 we get 

 for all 

 and for all x

 i.e. 

 is positive semidefinite for all 

.
    



The previous results can be easily transferred to the case of concave functions (of several variables).
For what concerns strictly convex functions we have the following results.

Theorem 3.9
Let be 

 with X nonempty convex set. The following statements are equivalent: (a)
f is strictly convex on X,  i.e. 



 (b)
For any 

 and 

 

 the function 

 is strictly convex on the interval 


 (c)
The function 

 is strictly convex on the interval 


 



Theorem 3.10
Let 

 be differentiable on the open convex set X. The following statements are equivalent: (a)
f is strictly convex on X.
 (b)


.
 (c)


.
 (d)


.
 



Theorem 3.11
Let 

 be 

 on the open convex set X. Then f is strictly convex on X if 

 is positive definite for all 



We note that Theorem 3.11 gives only sufficient conditions for 

 to be strictly convex. Indeed, if we consider, for example, the function 

 

, or also 

 

 we can see that these functions are strictly convex on 

 (on 

) but the second-order derivative evaluated at 

 (the Hessian matrix evaluated at 

) is zero (is the zero matrix). A weaker sufficient condition for the strict convexity of 

-functions is (see, e.g. Fenchel [4]).
The Hessian matrix 

 is positive semidefinite for all 

 and 

 on all segments contained in X.
However, note that for quadratic functions

the positive definiteness of the matrix B is necessary and sufficient for 

 to be strictly convex (see the last lines of Example 3.2).
We give now a necessary condition for the convexity of a function defined on a nonempty convex set 

 This condition will be useful in characterizing a class of generalized convex functions: the class of quasiconvex functions.

Theorem 3.12
Let 

 be a nonempty convex set and 

 be convex on X. Then the lower level set

is convex for all 

.


Proof
Let 

 and 

 As X is a convex set, it results 

 From the convexity of f we obtain

Being 

 this shows the convexity of 

 for every 

 (we recall that the empty set 

 is convex by definition).    



As we have remarked, the proposition of Theorem 3.12 is only a necessary condition for the convexity of 

 (

 convex set). Consider, for example, the function 

 

, 

 which is not convex (it is strictly concave!), but which satisfies the condition of Theorem 3.12. It is the same for 

, 

, for 

 

, etc.
A similar result holds obviously for concave functions: the upper level set


is convex for all 

.

Theorem 3.13
Let 

 be an open convex set. If 

 is convex on X,  then f is continuous on X.


Proof
We prove the theorem in three steps.
Step 1. If f is convex on X and 

 and 

 and 

 then (Jensen inequality)

Step 2. For each 

 there exists a 

 such that 

 for 

, where 

 is the unit vector. Call these vectors 

 Let be 

 Since x lies in the interior of the convex hull of 

 there exists 

 such that 

 also lies in the convex hull of 

 Then, for any y satisfying 

 it holds that 

 for some appropriate 

 and 

 and so

Step 3. Without loss of generality, we assume that 

 and we want to prove that f(x) is continuous at 

 For any 

 we must exhibit a 

 such that if 

 then 

 Let 

 and M be chosen so that 

 implies 

 (from Step 2). Now let be 

 Let y satisfy 

 Also, we can assume that 

 and write

Since 

 it follows that 

 Therefore,

We also have

and so

Therefore, 

 and so 

.    



From the previous theorem, it appears that if f is convex on 

 X convex but not necessarily open, and if f has discontinuity points, these points are on the boundary of X. Consider the following example:



 defined as

It results that f is convex on X,  with a discontinuity point at 


For what concerns the differentiability of convex functions, we report the following results (see, e.g. Fenchel [4]).

Theorem 3.14
If 

 is convex on the open convex set X, then f is differentiable with continuous partial derivatives (i.e. 

) everywhere on X,  except for a set of measure zero (in Lebesgue's sense).

Hence a convex function 

, X open convex set, may be non-differentiable at some points 

 Consider, e.g. the convex function 

 

, obviously non-differentiable at 



Theorem 3.15
Let 

 be a convex set and 

 be convex on X. Then (a)
f is bounded on every compact subset 


 (b)
f is bounded from below on every bounded subset 


 


An affine function is obviously both convex and concave (but not in the strict sense!) on a convex set 

 Also the vice-versa holds, as shown by the following (a bit less trivial) result.

Theorem 3.16
Let 

 be a convex set and let be 

. If f is both convex and concave on X,  then f is linear affine on X,  i.e.

for any 

 and any 

 such that 




Proof
Being f both convex and concave on X,  it results, for any 

 and for all 



Let now 

 such that 

 and let be 

 If we choose 

 sufficiently small such that the inequality 

 is verified, it results that 

 and hence

From here, we derive the desired property 

.    



We have seen that if 

 is convex on the convex set X,  then f is continuous on 

 We remark again that f may be non-differentiable on 

 however, convex functions possess some nice properties concerning directional derivatives. 
Let f be a real-valued function defined on an open set 

 The (one-sided) directional derivative of f at 

 in the direction of 

 denoted 

 or also 

 or 

 etc., is given by

if the limit exists (

 and 

 being allowed as limits).
Note that

If 

 then f is said to be a two-sided directional derivative at 

 in the direction of y,  i.e. the limit

exists (finite or not).
If f has a two-sided directional derivative in all directions at 

 then f is said to be Gâteaux differentiable at 

 We recall that if 

 is differentiable at 

 then f is Gâteaux differentiable at 

 with finite derivative, for all 

 Moreover,

We have the following basic results (see, e.g. Delfour [5], Rockafellar [1], Roberts and Varberg [6], Ruszczynski [7]).

Theorem 3.17
Let 

 be a convex function on the convex set X. Then, for every 

 and every 

, the directional derivative Df(x, y) exists (finite or infinite). If 

 then Df(x, y) is finite for all 

 Moreover, Df(x, y) is a positively homogeneous convex function of y, with




We can summarize in the following proposition what was previously asserted.

Let 

 be a convex function on the open convex set X;  then:
 (a)
f admits finite one-sided directional derivatives for all directions 

 at any point 

 Therefore, f admits left- and right-sided partial derivatives at any point 


 (b)
At all points 

 where there exists the gradient 

 then f is continuously differentiable.
 

We shall revert on these questions in Chap. 10.


3.2 Generalized Convex Functions
Several generalizations of the classical concept of a convex function have been introduced in the literature; under the name of "generalized convex functions" we mean functions that are not convex but that retains some of the nice properties and characteristics of convex functions. For good accounts of generalized convex functions one may consult the books quoted in the References, e.g. Bertsekas [8], Cambini and Martein [9], Hadjisavvas et al. [10].
We have seen in Theorem 3.12 that a necessary (but not sufficient) conditions for 

 to be convex on the convex set 

 is:
The lower level set 

 is convex for all 

.


This property becomes one of the characterizations of the class of quasiconvex functions.

Definition 3.18
Let be given 

 and defined on the convex set X. Then f is said to be quasiconvex on X if




Obviously, the above relation is equivalent to:

The function 

 is quasiconcave on the convex set X if and only if 

 is quasiconvex on X.

Theorem 3.19
Let 

 be a nonempty convex set and let 

. The following statements are equivalent: (a)
f is quasiconvex on X.
 (b)
For any 

 and any 

 the function 

 is quasiconvex on the interval 



 (c)
For any 

 the function 

 is quasiconvex on 


 (d)
For any 

 the lower level set

 is convex.
 



Proof


 The proof is similar to the one for the corresponding implications in Theorem 3.6.


 Let 

 and 

 From the quasiconvexity of 

 it results

i.e.

and, therefore, 

 i. e. 

 is a convex set. Recall that 

 is convex by definition.


 Let 

 and 

 and let 

 As 

, and 

 is a convex set, it results that 

 that is

i.e. f is quasiconvex on X.    



Now we characterize the class of differentiable quasiconvex functions.

Theorem 3.20
Let 

 be differentiable on the open convex set X. Then the following statements are equivalent: (a)
f is quasiconvex on X.
 (b)


 


 (c)


 


 (d)


 


 



Proof


 Let f be quasiconvex on X,  i.e. for any 

 the function

is quasiconvex on 

 Let be 

 It results

which shows that 

 has at 

 a global maximum point on 

 Being f differentiable on the open and convex set X,  it results that 

 is differentiable on 

 and, therefore, it must be

i.e.



 Let 

 with 

 It is sufficient to prove that 

 has at 

 a global maximum point on 

 Let us absurdly suppose that this property does not hold; it results then that the set

is nonempty. Moreover, as 

 is differentiable, it results that it is continuous and that A is open. It follows that 

 and hence 

 Now we show that 

 is constant on A. As 

 it results 

 and, therefore, 

 with 

 From the assumption we obtain

Similarly, as 

 we get

The last two inequalities can be written in the form

and

from which we get

which shows that 

 is constant on A. Therefore, it results

which is absurd, being 

 continuous at 




 Trivial.


 Property (d) follows immediately from (b). For the converse, see [11].
   



Another useful class of generalized convex functions, originally introduced by O. L. Mangasarian for differentiable functions, is the class of pseudoconvex functions.

Definition 3.21
Let 

 be an open set and let 

 be differentiable on X. Then f is pseudoconvex on X if

or equivalently,

The function 

 is pseudoconcave on X if and only if 

 is pseudoconvex on X.

In order to compare pseudoconvex functions with other classes of generalized convex functions, it is convenient to assume that 

 is open and convex.

Definition 3.22
Let be 

, with X nonempty convex set. Then f is said to be semistrictly quasiconvex on X if

for every 

 with 

 and for every 



It can be proved that Definition 3.22 is equivalent to: for every 

, one has

We have to point out that in the literature semistrictly quasiconvex functions are also called strictly quasiconvex functions and that also other denominations have been used.

Theorem 3.23
Let 

 be a nonempty convex set and 

 be semistrictly quasiconvex on X and lower semi-continuous on X. Then f is quasiconvex on X.


Proof
Let 

 and let us suppose that it holds 

 If 

 the thesis is immediate. If 

 we have to prove that

for every x of the segment 

 Let us absurdly suppose the opposite case. It results that the set

is nonempty. From the semistrict quasiconvexity of f,  it results, therefore, that for every x of the segment 

 and for every 

 we have 

 On the other hand, from the lower semi-continuity of f,  it results that A is open relatively to the segment 

 and, therefore, there exist 

 with 

 Hence it results 

 and 

 which is absurd.    




Remark 3.24
We note that in Theorem 3.23 if the assumption on lower semi-continuity is missing, the implication does not hold. For instance, the function

is semistrictly quasiconvex, but not quasiconvex. Obviously, there are functions which are quasiconvex, but not semistrictly quasiconvex (for example a monotone function on 

, which is constant on some open interval).

We now point out the relationships among the classes of convex and generalized convex functions previously introduced.

Theorem 3.25
Let 

 be a nonempty convex set and let be 

.
(i)
If f is strictly convex on X,  then f is convex on X.
 (ii)
If f is convex on X,  then f is semistrictly quasiconvex on X;  if f is semistrictly quasiconvex on X and it is also lower semi-continuous on X,  then f is quasiconvex on X.
 



Proof
Implication (i) and the first implication of (ii) follow directly from the definitions. The second implication of (ii) is the thesis of Theorem 3.23.    




Theorem 3.26
Let 

 be an open convex set and let 

 be differentiable on X.
(i)
If f is convex on X,  then f is pseudoconvex on X.
 (ii)
If f is pseudoconvex on X,  then f is semistrictly quasiconvex on X and hence also quasiconvex on X.
 



Proof
(i) Let 

 with 

 Being f convex (and differentiable) on X, by Theorem 3.7 we have

and hence

which proves that f is pseudoconvex.
(ii) Let us prove first that if f is pseudoconvex on X,  then f is semistrictly quasiconvex on X. Assume, on the contrary that f is not semistrictly quasiconvex. Then, there exist 

, 

, and 

 such that

 (3.4)By pseudoconvexity of f we have

 (3.5)As 

 one has 

 for some 

, and so

Also, 

, i.e. 

. Therefore,

From here, using (3.5), we obtain

As 

, there exists 

 such that 

 and 

, and so 

 by (3.4). Again by pseudoconvexity of f applied to the pairs 

 and 

, we have

 (3.6)From 

, reasoning as above, we get 

, but this equality is incompatible with (3.6). Thus f is semistrictly quasiconvex. Since a differentiable function is continuous, it follows, from Theorem 3.23, that f is also a quasiconvex function.    



The next result is due mainly to Crouzeix and Ferland [12].

Theorem 3.27
Let 

 be an open convex set and let 

 be differentiable and quasiconvex on X. Then f is pseudoconvex on X if and only if every stationary point 

 of f,  i.e. any point 

 with 

 is a global minimum point of f over X.


Corollary 3.28
Let 

 be an open convex set and let 

 be differentiable on X,  with 

 

 Then f is pseudoconvex on X if and only if f is quasiconvex on X.

The above inclusion relationships are all strict. For example,


 

, is convex, but not strictly convex.



 is pseudoconvex, but not convex. A more important example of a pseudoconcave function which is not concave is the probability density function of a standardized random variable with a normal (Gaussian) distribution: 






 

, is semistrictly quasiconvex (and also quasiconvex), but not pseudoconvex.



 is quasiconvex, but not semistrictly quasiconvex.


There are also conditions (necessary or sufficient, or both) for quasiconvexity and pseudoconvexity of 

-functions. We report only the following ones.

Theorem 3.29
The following equivalent conditions are necessary for the 

-function 

 to be quasiconvex on the open convex set X.
(a)



 (b)


 and the equation 

 of degree 

 in 

, has nonnegative roots.
 



Theorem 3.30
The following equivalent conditions are sufficient for the 

-function 

 to be pseudoconvex on the open convex set X.
(i)


.
 (ii)
The matrix 

 is positive definite for 

 sufficiently large, for all 

.
 


The following results give the necessary and sufficient conditions for the quasiconvexity and pseudoconvexity of a 

-function on the open convex set 



Theorem 3.31
Assume that 

 is a 

-function on the open convex set X. Then: (i)
f is pseudoconvex on X if and only if:       

, and       

.
 (ii)
f is quasiconvex on X if and only if:       

, and       

.
 


There are many other definitions of generalized convex functions, more or less useful and meaningful. We mention only the preinvex functions and the invex functions.

Definition 3.32
A function 

, X nonempty convex set, is said to be preinvex on X,  when there exists a vector-valued function 

, such that




It is immediate to note that convex functions are a particular case of preinvex functions, when we make the substitution 

 There are functions that are preinvex, but not convex. For example, consider the function 

 defined by 

 Then f is not convex, but is preinvex, with 

 given by

Preinvex functions keep some interesting properties of convex functions: for example, every local minimum point of a preinvex function is a global minimum point and nonnegative linear combinations of preinvex functions are preinvex (for this last property, referred to convex functions, see the next Theorem 3.34).

Definition 3.33
A function 

 differentiable on the open convex set X is said to be invex on X,  if there exists a vector-valued function 

 such that




Also here it is evident that differentiable convex functions are a particular case of invex functions. These functions have been introduced by Hanson [13] and called "invex" by Craven [14]. This term is a contraction of the terms "invariant" and "convex". Indeed, if we operate a certain transformation on a convex function, this transformation will destroy convexity, but the "transformed" function will be surely invex.
In the next chapter we shall see a nice characterization of the class of invex functions. It is easy to prove that if a differentiable function is preinvex on the open convex set 

 then it is invex on X. Indeed, if 

 is differentiable on X and 

 from the definition of preinvex functions it follows

Taking the limit for 

 we obtain

It will appear in the next chapter that pseudoconvex functions are invex, but there exist invex functions that are not pseudoconvex. Moreover, there exist invex functions that are not quasiconvex and there exist quasiconvex functions that are not invex. See, e.g. Mishra and Giorgi [15].
The criteria of positive definiteness and positive semidefiniteness of the Hessian matrix are "operative" criteria for establishing strict convexity and convexity of a function 

 of class 

 These criteria, however, sometimes may be noisy to apply. For example, the function

is convex on 

 by a simple application of the next theorem, but its Hessian is a mess. Fortunately, there are other ways than the use of the Hessian matrix to show that a function is convex. The following theorem shows that convex functions can be combinated in a variety of ways to produce other convex functions.

Theorem 3.34
(a)
If 

 are convex functions on a convex set 

 then 

 is convex on S. Moreover, if at least one 

 is strictly convex on S, then the sum f is strictly convex.
 (b)
If f is convex (resp. strictly convex) on a convex set 

 and 

 is a positive scalar, then 

 is convex (resp. strictly convex) on S. Therefore, the linear combination, with positive coefficients, of convex functions is a convex function.
 (c)
If f is a convex function (resp. a strictly convex function) defined on the convex set 

 and if g is an increasing (resp. a strictly increasing) convex function defined on the range of f, then the composite function 

 is convex (resp. strictly convex) on S.
 



Proof
(a) To show that any finite sum of convex functions on S is convex on S,  it suffices to show that the sum 

 of two convex functions on S is again convex on S. If 

 and 

 then

Hence, 

 is convex on S. Moreover, it is clear from this computation that if either 

 or 

 is strictly convex, then 

 is strictly convex.
(b) This result follows by an argument similar to the one used in (a).
(c) If 

 and 

 then

since f is convex on S. Consequently, since g is an increasing, convex function on the range of f(x),  it follows that

Thus, the composite function 

 is convex on S. If f is strictly convex and g is strictly increasing, the first inequality in the preceding computation is strict for 

 and 

 so 

 is strictly convex on S.    




Example 3.35
The function

is strictly convex on 

 (it follows from Theorem 3.34(c)).
The function

with 

 vectors of 

 and 

 is convex on 

 (it follows from Theorem 3.34(b)).
It must be noted that, contrary to convex functions, the sum of quasiconvex functions is not in general a quasiconvex function. For example, let be

which are both quasiconvex (and quasiconcave) functions, but their sum 

 is not quasiconvex (nor quasiconcave). The same holds true for the sum of pseudoconvex functions.

There are also results concerning the composition of generalized convex functions. We quote only the following one.

Theorem 3.36
Let f be a quasiconvex (resp. a semistrictly quasiconvex) function on the convex set 

 and let g be an increasing (resp. strictly increasing) function defined on the range of f. Then the composite function 

 is quasiconvex (resp. semistrictly quasiconvex) on S.



3.3 Optimality Properties of Convex and Generalized Convex Functions. Nonlinear Theorems of the Alternative
We postpone to the next chapter the optimality properties of convex and generalized convex functions in the differentiable case. Here we give some general optimality properties that hold also without differentiability assumptions. We denote by

the set of optimal (global) solutions of the problem 

 

 

.

Theorem 3.37
(a) Let 

 be convex on the convex set X. Then, if 

 is a local minimizer of f,  then 

 is a global minimizer of f.
(b) If 

 is strictly convex on the convex set X and if 

 is a local minimizer of f,  then 

 is the unique  (strict) global minimizer of f.


Proof
(a) Let y be any point of X. Consider 

 and sufficiently close to 1. Then we have that (

 is the local minimizer in question)

since X convex. Moreover, 

 and being 

 a local minimizer and using the convexity of f, we have

From here,

and as 

 we derive that

But y is any point of X : , therefore, 

 is a global minimizer for f on X.
(b) Absurdly, let us suppose that there exist two distinct (global) minimizers 

 and 

 Being f strictly convex, we would have

which is absurd, because 

 and by assumption 

 is a global minimizer for f on X.    




Theorem 3.38
If 

 is convex on the convex set X,  then the set 

 is a convex set. If f is strictly convex on X,  then 

 contains at most one point.


Proof
If 

 then 

 is convex by definition. Let be 

 and let be 

 two global minimizers for f on X : 

We have to show that it holds

Indeed, we have, for any 

 and for any 



The second assertion of the theorem is an assertion (b) of Theorem 3.37.    



Under suitable assumptions, the previous results hold also for some generalized convex functions.

Theorem 3.39
Let 

 be a convex set, let 

 and let 

 be a local minimum point of f on X. If f is semistrictly quasiconvex on X,  then 

 is a global minimum point of f on X.


Proof
As 

 is a local minimum point of f(x),  there exists 

 such that 

 

 Let us suppose that there exists 

 such that 

 From the semistrict quasiconvexity of f it follows

for all 

 for which 

 Now, if we choose 

 smaller than 

 it results easily that 

 which contradicts the assumption that 

 is a local minimum point of f on X. Therefore, it results that 

 

 i.e. 

 is a global minimum point of f on X.    



Obviously, the thesis of the above theorem holds also under the assumption that f is pseudoconvex on X. The thesis is no longer true under the assumption of quasiconvexity of f. For example, the function 

 defined by

is quasiconvex and has at 

 a local minimum point which is not global.
However, if a quasiconvex function 

, X convex set, has a strict local minimum point at 

 then the following result holds.

Theorem 3.40
Let 

 be quasiconvex on the convex set X. If 

 is a strict local minimum point of f on X,  then 

 is also a strict global minimum point of f on X.


Proof
Suppose that 

 is a strict local minimum point of f on X,  i.e. there exists 

 such that

 (3.7) If 

 is not a strict global minimum point of f,  then there exists 

 

 such that

By the quasiconvexity of f,  we have

But for sufficiently small 

 it follows that 

 contradicting (3.7).    



We may mention here that if a local minimum point 

 of a quasiconvex function f is not a global minimum point, then f is constant on the intersection of some neighborhood 

 and the line segment between 

 and any global minimum point. See Ponstein [11].

Theorem 3.41
Let 

 be a nonempty convex set and let 

 be quasiconvex on X. The set 

 is a convex set.


Proof
As we can write, with 

 any point of 

,

the result is evident from one of the characterizations of quasiconvex functions (see Theorem 3.19(d)).    



It is known that a necessary and sufficient condition for 

 to be a global minimum point of a function 

 over a set 

 is that 

 is a global ray minimum point of f over S. That is, for every vector 

 

 is a global minimum point on

Similarly, a necessary condition that 

 be a local minimum point of f over S is that 

 be a local ray minimum pointoverS,  i.e. for every vector 

 there exists 

 such that

whenever 

 and 


We may say that a local minimum point over S is a local ray minimum point over S. But a local ray minimum point need not be a local minimum point, as the following example, due to G. Peano, shows. Consider the function 

 defined by

The point 

 is a local ray minimum over the plane, but not a local minimum point for f. However, for quasiconvex functions on the convex set 

 the necessary conditions become sufficient.

Theorem 3.42
If 

 is quasiconvex on the convex set S,  then any local ray minimum point of f over S is a local minimum point of f over S.

See Thompson and Parke [16].
Nonlinear Theorems of the Alternative
Many theorems of the alternative for nonlinear systems are available in the mathematical literature. These theorems usually hold under various convexity or generalized convexity assumptions on the functions involved and some of them are formulated in an infinite-dimensional topological setting. We mention only the following theorems.

Theorem 3.43
Let 

 be a nonempty convex set, 

 a vector-valued convex function (i. e. each component 

 

 is a convex function on X) and 

 a linear affine vector-valued function. If the system

has no solution, then there exist vectors 

 and 

 with 

 such that





Proof
The set of 



is a convex set and 

 as it is easy to verify. From the separation theorem it results that there exist 

 and 

 with 

 such that

Moreover, it must be 

 indeed, if 

 for some index i,  then, by choosing 

 sufficiently large, we should contradict the above inequality. Therefore, for any 

 and any 

 we have 

 where 

 and hence

or

It results

Indeed, if 

 we get, by picking 

 such that 

 thet

which is a contradiction to the fact that 



 Hence

   



If we observe that for an m-dimensional vector function f,  defined on 

 we have

and

then, the following corollary is a direct consequence of Theorem 3.43.

Corollary 3.44
Let 

 be a nonempty convex set, let 

 

 

 be vector-valued convex functions on X and 

 a linear affine vector-valued function. If the system

has no solution, then there exist 

 

 

 and 

 such that




From the previous theorem, it is possible to obtain a generalization to the nonlinear case of Gordan's theorem of the alternative. The following result is due to Fan et al. [17].

Theorem 3.45
Let 

 be a nonempty convex set and let 

 be a vector-valued convex function. Then, either (a)


, or
 (b)


 but never both.
 



Proof
If the system described sub (a) has a solution, obviously (b) cannot hold. If (a) has no solution, then by Theorem 3.43 we have at once that (b) has a solution.    



Another useful theorem of the alternative for nonlinear systems is presented by Berge and Ghouila-Houri [18]. See also Stoer and Witzgall [19].

Theorem 3.46
Let be given the convex functions 

 defined on 

 and the linear affine functions 

 also defined on 

 If the system

admits no solution, but there exists 

 such that it holds ("Slater constraint qualification")

then there exist multipliers 

, such that




The theorem of Farkas is easily obtained from Theorem 3.46. It is immediate to see that the following systems

and

cannot admit both solutions. It remains to prove that if 

 does not admit solution, then 

 admits solution. Let us rewrite 

 by putting 

 and 

 From Theorem 3.46 there exists 

 such that 

 for every 

 and, therefore, we have 

 i.e. 

 admits solution.
Another general approach to nonlinear theorems of the alternative is due to Giannessi [20]. The following result is a particular case of a more general theorem, proved by the said author.

Theorem 3.47
Let be 

 and 

(i)
Assume that 

 and g be linear affine. Then the following system 

 is impossible if and only if there exist 

 and 

 such that 

 where the first inequality of 

 must be verified in a strict sense if 


 (ii)
Assume that 

 and g are concave, and that there exists 

 such that 

 Then 

 is impossible if there exists 

 such that 



 (iii)
Assume that 

 and g are concave. 

 is impossible if and only if there exist 

 and 

 such that 

 with 





 and 

 when 


 


Also from Theorem 3.47 it is possible to get easily Farkas' theorem. Let us rewrite Farkas' theorem in the form

and

 Set 

 and 

 Theorem 3.47 (point (i)) can be applied. At 

 

 becomes 

 

 

 which is obviously impossible. At 

 

 becomes 

 

 

 which holds if and only if 

 

 which is equivalent to 



References1.R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)2.M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economic and Mathematics Systems, vol. 122 (Springer, Berlin, 1976)3.M.S. Bazaraa, H.D. Sherali, C.M. Shetty, Nonlinear Programming. Theory and Algorithms, 3rd edn. (Wiley Interscience, New York, 2006)4.W. Fenchel, Convex Cones, Sets and Functions, Lecture Notes (Princeton University, Princeton, 1953)5.M. Delfour, Introduction to Optimization and Hadamard Semidifferential Calculus, 2nd edn. (SIAM, Philadelphia, 2020)6.A.W. Roberts, D.E. Varberg, Convex Functions (Academic, New York, 1973)7.A. Ruszczynski, Nonlinear Optimization (Princeton University Press, Princeton, 2006)8.D.P. Bertsekas, Convex Optimization Theory (Athena Scientific, Belmont, Mass, 2009)9.A. Cambini, L. Martein, Generalized Convexity and Optimization. Theory and Applications (Springer, Berlin, 2009)10.N. Hadjisavvas, S. Komlosi, S. Schaible (eds.), Handbook of Generalized Convexity and Generalized Monotonicity (Springer, New York, 2005)11.J. Ponstein, Seven kinds of convexity. SIAM Rev. 9, 115-119 (1967)12.J.P. Crouzeix, J.A. Ferland, Criteria for quasi-convexity and pseudo-convexity: Relationshipsand comparisons. Math. Program. 23, 193-205 (1982)13.M.A. Hanson, On sufficiency of the Kuhn-Tucker conditions. J. Math. Anal. Appl. 80, 545-550 (1981)14.B.D. Craven, Duality for generalized convex fractional programs, in Generalized Concavity in Optimization and Economics, eds. by S. Schaible, W.T. Ziemba (Academic, New York, 1981), pp. 473-48915.S.K. Mishra, G. Giorgi, Invexity and Optimization (Springer, Berlin, 2008)16.W.A. Thompson, D.W. Parke, Some properties of generalized concave functions. Oper. Res. 21, 305-313 (1973)17.K. Fan, I. Glicksberg, A.J. Hoffman, Systems of inequalities involving convex functions. Proc. Amer. Math. Soc. 8, 617-622 (1957)18.C. Berge, A. Ghouila-Houri, Programming, Games and Transportation Networks (Wiley, New York, 1965)19.J. Stoer, C. Witzgall, Convexity and Optimization in Finite Dimensions, I (Springer, New York, 1971)20.F. Giannessi, Constrained Optimization and Image Space Analysis. Vol. 1: Separation of Sets and Optimality Conditions (Springer, New York, 2005)












© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_4





4. Unconstrained Optimization Problems. Set-Constrained Optimization Problems. Classical Constrained Optimization Problems



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es







4.1 Unconstrained Optimization Problems
In this section we shall treat problem 

 i.e.

where 

 and S is an open set (for example, 

) or, more generally, where for the optimal point 

 it holds 

 In other words, we assume that the optimal points of 

 are interior to S. A first basic result is given by the following necessary optimality conditions.

Lemma 4.1
Let 

 be a local minimizer for 

 and let f admit its ith partial derivative evaluated at 

 then it holds





Proof
Being 

 a local minimizer for 

 it holds 

 

 Obviously, this inequality holds, a fortiori, with respect to the ith component of 

:

for each 

 where N(0) is a (uni-dimensional) neighborhood of 

 and 

 is the ith elementary vector of 

 i.e. 

 with 1 as its ith element. It follows that

By letting 

 the first member becomes 

 which exists by assumption, and, therefore, 

    



As an immediate consequence, we have the following celebrated result, due to P. Fermat.

Theorem 4.2
(Fermat Theorem) If 

 is a local solution for problem 

 and if f admits the gradient 

 then it holds





Remark 4.3
The points 

 such that 

 are usually called stationary points or critical points.  Obviously, Theorem 4.2 holds also if 

 is a local maximizer for the objective function f. Therefore, all those points, which are unconstrained local minimum points or maximum points, are stationary points (if all partial derivatives exist at these points).
This condition is only a necessary condition; consider, e.g. the function 

 

. It results 

 but the point 

 is not a minimizer, nor a maximizer for f;  as it is well-known, 

 is an inflection point.
We have, therefore, no information on the "nature" of stationary points; we have an information on all points which are not stationary, i.e. such that 

: they cannot be (local) unconstrained minimum nor maximum points for 



The previous remark demands the introduction of further assumptions in order to get some information on the nature of stationary points. We begin by introducing the following second-order necessary optimality conditions for 



Theorem 4.4
Let 

 be a local minimum point for 

 and let 

 be twice-continuously differentiable on 

 Then, 

 is a stationary point for f and moreover, 

 is positive semidefinite.


Proof
Being 

 a stationary point, we have for all vectors 

 and for all scalars 

 sufficiently small,

Because this last expression cannot be negative, it follows that the Hessian matrix 

 is positive semidefinite.    



Obviously, if 

 is an unconstrained local maximum point for 

 it will hold that 

 is negative semidefinite.
Again, if we consider the function 

 

, we see that 

 and 

 which confirms that the conditions of Theorem 4.4 are only necessary optimality conditions. We give now sufficient second-order optimality conditions for 



Theorem 4.5
Let 

 be a stationary point for f, let f be twice-continuously differentiable on 

 and let 

 be positive definite. Then 

 is a strict local minimum point of f for 




Proof
As in the proof of the previous theorem, we start from the relation




For all 

 and for all 

 sufficiently small, the first addendum of the last expression is positive. It follows that also 

 and hence 

 is a strict local minimum point of f over S.    



Obviously, if 

 and 

 is negative definite, 

 is a strict local maximum point of f over S. Note, moreover, that the conditions of Theorem 4.5 are only sufficient optimality conditions; indeed, consider, e.g. the function 

 

. Here 

 is a minimum point of f (it is the unique strict minimum point), but 

 The same is true for the function, defined on 

 

 with respect to the point 



Definition 4.6
Let 

 and let be 

 If, for every neighborhood 

 of 

 there exist points 

 such that 

 and points 

 such that 

 then 

 is called a saddle point of f on S. More generally, a stationary point 

 is a saddle point if it is neither a local minimum point for f on S,  nor a local maximum point.

On the grounds of what previously expounded, we have the following result.

Theorem 4.7
Let f be twice-continuously differentiable on 

 and let be 

 If 

 is indefinite, then 

 is a saddle point for f on S.

The origin of the name "saddle point" stems from the fact that in some cases the form of the surface generated (in 

) by a function 

 in a neighborhood of a saddle point, looks like a saddle for horses. It is the case, for example, of the function

Its unique stationary point is the origin of 

 Moreover,

If we consider the restriction 

 then 

 and we see that the origin of 

 is a minimizer for this last function; if we consider the restriction 

, then 

 and now we see that the origin of 

 is a maximizer for this function. Therefore,

Hence, (0, 0) is a saddle point for f.
However, Definition 4.6 contains also other cases for the occurrence of a saddle point. We may have a saddle point also if at a stationary point of 

 the Hessian matrix 

 is positive semidefinite (or negative semidefinite). Consider, e.g. the function 

 defined as

The origin of 

 is a stationary point for f and we have

which is positive semidefinite.
However, 

 has at 

 a minimum point, whereas 

 has at 

 a maximum point. Hence (0, 0) is a saddle point for f.
Let us consider the function 

 given by

The origin of 

 is a stationary point for f and we have

For every scalar 

, the function 

 has at 

 a minimum point, whereas the function 

 has at 

 an inflection point. Hence, (0, 0) is not a minimum point nor a maximum point: it is a saddle point.
Finally, we remark that this concept of saddle point must not be confused with the concept of saddle point of the Lagrangian Function that will be introduced in Chap. 8.

Remark 4.8
We have previously remarked, in Chap. 3, that if 

 is a stationary point for f and is a local ray minimum point with respect to any direction starting from 

 then 

 need not be a local minimum point for f. The following example, due to G. Peano, confirms the said assertion. The function

has a stationary point at (0, 0),  with 

 The origin is a local ray minimum point over the plane, but not a local minimum point, as on every neighborhood of (0, 0) there are points where f is positive and points where f is negative. Hence (0, 0) is a saddle point.

Summing up:
Let 

 be a stationary point for 

 and let f be twice-continuously differentiable on a neighborhood 


If 

 is positive (resp. negative) semidefinite, we cannot exclude that 

 is a local minimum point for 

 (resp. a local maximum for a maximization problem). The "semidefinite" case is, in a sense, an "indeterminate case" and further investigations are needed to try to specify the "nature" of the stationary point.

If 

 is positive definite (resp. negative definite) we can conclude that 

 is a local strict minimizer for 

 (resp. a local strict maximizer for a maximization problem).

If 

 is indefinite, we can exclude that 

 is a local minimizer or a local maximizer for f. In this case 

 is a saddle point.



Remark 4.9
Under the assumption of Theorem 4.5, it is possible to obtain a more precise and sharper result. See, e.g. Hestenes [1, 2]. Indeed, if at a point 

 we have

then there exists a neighborhood 

 of 

 and a positive number m such that

In other words, 

 is a strict local minimizer of order 2 for 

 See Sect. 1.​3. Furthermore, always under the assumptions of Theorem 4.5, it is possible to assert that 

 is an isolated strict local minimizer for 




Theorem 4.10
Let f be a 

-function and let 

 satisfy the relation 

 moreover, let 

 be positive definite. Then 

 is a locally unique critical point and thus an isolated strict local minimizer for 

.


Proof
Assume to the contrary that there is a sequence 

 

 of critical points 

 i.e. 

 Then by the Taylor expansion formula, we have

Dividing by 

 yields

The bounded sequence 

 has a convergent subsequence, we continue to denote by the same notation, such that

Taking the limit for 

 in the above equality, we have

and thus

contradicting the positive definiteness of 

    



The function, already considered in Chap. 1,

has a strict (global) minimizer at 

 which, however, is not isolated. Indeed, this function is not 

 at 

 and Theorem 4.5 is, therefore, not applied.
We anticipate that the usual second-order sufficient conditions for constrained problems do not guarantee in general that the optimal point is isolated. See Example 6.​45 and Theorem 6.​46.

Example 4.11
Specify the type to which belong the stationary points of the function

We have

So, we have the system

which generates four stationary points:

Then we have





(1)


 This matrix is negative definite, hence, the point A is an unconstrained strict local maximizer for f.
 (2)


 This matrix is indefinite; therefore, the point B is a saddle point for f.
 (3)


 We have the same conclusions of the previous point 2): C is a saddle point for f.
 (4)


 This matrix is positive definite; the point D is, therefore, an unconstrained strict local minimizer for f.
 



Example 4.12
Let be

The system 

 is given by

For 

 the unique solution is the origin of 

 which is, therefore, the unique stationary point. Then we have

This matrix is positive definite if 

 i.e. if 

 positive semidefinite if 

 indefinite if 


If 

 the function becomes

which obviously has infinite (global) minimizers on the straight line 


If 

 the function becomes

which obviously has infinite (global) minimizers on the straight line 


Moreover:
If 

 the function has a strict minimizer at (0, 0). In fact, this point is the unique global minimizer, as in this case the function is strictly convex.
If 

 the point (0, 0) is a saddle point.


Example 4.13
Let us consider the function 

 defined by

We note that the domain of f is an open subset of 

: 

. Then we have

Hence

By substituting this relation into 

 we get

and, therefore, 

 for 


Then, for 

 we have 

 and so 

 for 

 i.e. for 

 Therefore, 

 for 


We have only one stationary point 

 as 

 does not belong to 


Then we have




Being 

 we conclude that 

 is a saddle point for f.


Example 4.14
(a)
Find the unconstrained minimizers, maximizers, and saddle point (if any) of 

 We have 

 Hence all stationary points are all those points on the straight line 











 

The Hessian matrix 

 is, therefore, positive semidefinite for 

 negative semidefinite for 

 and both positive and negative semidefinite for 

 (in this last case 

 the zero matrix).
We compute the difference between the values of the function and the values of the function on its stationary points:

Therefore, (1)
For 

 all stationary points are local minimizers.
 (2)
For 

 all stationary points are local maximizers.
 (3)
At 

 there is a saddle point.
 (b) Find the unconstrained minimizers, maximizers, and saddle point (if any) of

We have

In consequence, the following are stationary points:

The Hessian matrix is

Hence

Therefore, A and B are local minimum points. For the point C we have

This matrix is semidefinite. We have

The sign of this difference depends, therefore, from the sign of 

 As 

 represents a circumference centered at P(1, 0) and with radius 

 we conclude:
C(k, 0),  for 

 are all minimum points;
C(k, 0),  for 

 are all maximum points;
C(k, 0),  for 

 are all minimum points;
C(0, 0) is a saddle point;
C(2, 0) is a saddle point.

The results of Theorem 4.5 give sufficient conditions for (unconstrained) local optimality related to problem 

 If we wish to obtain global solutions for 

 we have to make reference to some convexity (or generalized convexity) assumptions on f. If 

 is convex on the convex set 

 we have seen in the previous chapter that:
Every local minimizer of f (if existing) is also a global minimizer (Theorem 3.​37).

The set of all minimizers of f (necessarily global minimizers) form a convex set (Theorem 3.​38).


We now add a differentiability assumption on f. The following result is an immediate consequence of definitions and properties seen in the previous chapter.

Theorem 4.15
Let f in 

 be differentiable on the open convex set 

(i)
Let f be convex on S;  then the point 

 is a global minimum point for 

 if and only if 


 (ii)
Let f be strictly convex on S;  the point 

 is the unique strict global minimum point for 

 if and only if 


 (iii)
Let f be pseudoconvex on S;  the point 

 is a global minimum point for 

 if and only if 


 



Example 4.16
Let us consider the function

We have

The stationary points of f are all points that belong to the straight line 

 Then we have




The elements of the Hessian matrix are constant quantities, hence 

 is positive semidefinite on the whole 

 This means that f is a convex function on 

: all its stationary points 

 are global minimizers for f.
Let us observe that 

, where 

 is linear and 

 has a global minimizer at 

.


Example 4.17
Let us consider the function

It results that the unique stationary point is the zero vector 

 The Hessian matrix is

Also here 

 is made of numbers, i.e. of constant quantities. Its leading principal minors are

Therefore, 

 is negative definite on 

 This means that f is a strictly concave function. Therefore, 

 is the unique strict global maximizer for f.


Example 4.18
Let us consider the quadratic function

with A square symmetric matrix of order n. We have that stationary points are given by the solutions (if they exist) of the linear system


(1)
If A is non-singular, there is a unique stationary point given by 

 Being 

 we conclude that:
If A is positive definite, then 

 is the unique strict global minimizer for F.

If A is negative definite, then 

 is the unique strict global maximizer for F.

If A is indefinite, then 

 is a saddle point for F.


 (2)
If A is singular, then F admits stationary points if and only if 

 Let us suppose that this condition is verified. Then, we can conclude that:
If A is indefinite, all stationary points are saddle points.

If A is positive semidefinite, then F is a convex function and hence all its stationary points are global minimizers.

If A is negative semidefinite, then F is a concave function and hence all its stationary points are global maximizers.


 



Example 4.19
(The least-squares method) Let be given n pairs of data 

 

 where 

 and 

 are mutually interconnected (for example, 

 is the price of the ith good and 

 is the related demand, in a competitive market). The problem is to find a curve ("curve fitting problem"), for example a straight line of equation 

 which fits "at best" the distribution of the points 

, 

 in the plane. When a straight line is chosen, we speak of "linear least-squares problem" ; this problem is a widely used statistical tool: the method is used to fit data to a function that is linear in the model parameters to be estimated.
In our problem we have to find the coefficients a and b of the equation 

 in such a way that the corresponding line is "as much as possible close" to the given n pairs. In the least-squares method it is chosen as a measure of the said distance the smallest possible sum of squares of deviations of the observed data 

 from the value y of the said equation, in correspondence with 

:

In other words, we are looking for those values of a, b which minimize the function

We have

We have that 

 when it holds

The determinant of the coefficient matrix of the last system is

i.e.

i.e.

where M(X) is the mean value of the random variable X,  which assumes the distinct values 

 all with the same probability 

 

 is the square of the said random variable and 

 is the variance of X.
If the values 

 are not all the same, it will be 

 Then, the above system admits one solution:

Being

it results that 

 is everywhere positive definite, hence 

 is the global strict minimizer of F(a, b).

We have introduced in Chap. 3 the notion of invex functions (see Definition 3.​33). A differentiable function 

 is invex if there exists a vector function 

 such that

 (4.1)Clearly, differentiable convex functions satisfy (4.1), with 

 It may exist more than one 

 which satisfies (4.1) for a given function f. The class of invex functions has a nice characterization, given in the following result (see, e.g. Ben-Israel and Mond [3], and Craven and Glover [4]).

Theorem 4.20
The differentiable function 

 is invex if and only if every stationary point is a global minimum point.


Proof
Clearly, if f is invex, then 

 implies 

 


Assume now that

If 

 take 

 If 

 take

   



As a consequence, if f has no stationary points, then f is invex. Although pseudoconvex functions are invex, this is not the case for quasiconvex functions. The class of invex functions and the class of (differentiable) quasiconvex functions have only a partial overlapping. For example, 

 

, is quasiconvex but not invex, since its stationary point 

 is not a global minimum point for f. The function

is invex, since it has no stationary points, but it is not quasiconvex. Take 

 

 

 we have 

 but 

 so f is not quasiconvex.


4.2 Set-Constrained Optimization Problems
In this section we take into consideration problem 

 i.e.

where 

 and S is not necessarily open (for example, S is a closed set) or, more generally, the optimal point 

 is not necessarily interior to S. The set S is also called a set constraint for 

 or an abstract constraint.  The function f is the objective function of 

 This problem may, therefore, be considered a first type of constrained optimization problem and hence the optimality results of the previous section are no longer valid for the present case. A first easy necessary optimality condition for 

 is given in the following result.

Theorem 4.21
Let 

 be differentiable on an open set 

 containing the set S and let 

 be a local minimum point of f on S (i.e. for problem 

). Then

 (4.2)where 

 is the cone of feasible directions of S at 

 (see Definition 2.​44). If 

 is a local maximum point of f over S,  then





Proof
Being y a feasible direction, there will exist 

 such that 

 

 Since f is differentiable on A,  it will hold

If, absurdly, we have 

 for 

 and sufficiently small, it would hold

and hence 

 contrary to the assumptions.    



Relation (4.2) can be rewritten in the form

Moreover, note that if 

 Theorem 4.21 recovers the Fermat theorem (Theorem 4.2), since in this case any direction 

 is feasible (i.e. 

) and hence, for all 

 we have

which implies that 



Example 4.22
Let us consider the function 

 given by

and let be 

 i.e. 


The minimum point of f on S is 

 Hence 

 Let us note that

Therefore, 

 which shows that the Fermat rule is not valid in the present case. The cone of feasible directions of S at 

 is given by the vector 

 

, 

 We have




There exist also second-order necessary optimality conditions related to Theorem 4.21.

Theorem 4.23
Let 

 be 

 on the open set 

 containing the set S and let 

 be a local minimum point for 

 Then, for all 

 it holds: (i)



 (ii)
If 

 then 


 



Proof
Relation (i) is nothing but Theorem 4.21. Being f a 

-function, we have

If 

 it will hold

If 

 for 

 sufficiently small it will hold

and hence also 

 contrary to the assumptions.
The last part of the theorem is obvious.    



If we consider again Example 4.22, we see that

and

Therefore,

The difficulty related to Theorem 4.21 is that its necessary condition may be vacuous because there may be no feasible directions, other than zero, and hence Theorem 4.21 has in this case no content. Consider, e.g. the set

Then, the only feasible direction at any point of S is just the zero vector. Hence, regardless of the objective function f and the point 

 we have that (4.2) is satisfied. It is, therefore, convenient to introduce a necessary optimality condition for 

 sharper than the one of Theorem 4.21.

Theorem 4.24
Let 

 be differentiable on the open set 

 containing the set S and let 

 be a local minimum point of f on S. Then it holds

 (4.3)where 

 is the Bouligand tangent cone to S at  

 (see Definition 2.​35).


Proof
Let be 

 any direction of 

 and without loss of generality, let us suppose 

 There will exist, therefore, a feasible sequence 

 with 

 As the quotients

for k sufficiently large, are nonnegative, being 

 a local minimum point for 

 and converge to 

 the thesis is proved.    



We note that (4.3) can be rewritten in the form

Guignard [5] obtained the relation

where 

 However, this condition is equivalent to (4.3), as, for any cone 

 we have 


If 

 in problem 

 is a convex set, then it holds

where 

 is the normal cone to S at 

 (see Definition 2.​42) and hence we can write

relation that some authors write as

or also as

 (4.4)Now, if f is pseudoconvex on the convex set S (i.e. x,  

 

), then (4.4) is a necessary and sufficient condition for 

 to be a global minimum point for f on S.
We have also first-order sufficient local optimality conditions for 



Theorem 4.25
Let us consider a point 

 in problem 

 If

 (4.5)then 

 is a strict local minimum point for 




Proof
We suppose absurdly that 

 is not a strict local minimizer of f on S. Then there exists for every index 

 a point 

 with 

 and 

 The feasible sequence 

 converges to 

 and contains a tangentially convergent subsequence (see Definition 2.​34). Without loss of generality we can denote by 

 this last subsequence for which we have 

 We have, therefore, 

 but the quotients

converge to 

 contrary to the assumptions.    



We note that for the validity of relation (4.5), the cone 

 must contain no straight line, i.e. it must be a so-called "pointed cone".
Moreover (see Hestenes [1, 2]), it can be proved that (4.5) gives a stronger result: if (4.5) is satisfied, then there exist a neighborhood 

 and a positive number m such that

In other words, 

 is a strong local minimizer or sharp local minimizer for 


There are also second-order optimality conditions for 

 related to Theorems 4.24 and 4.25.

Theorem 4.26
Let in 

 the objective function f be twice-continuously differentiable on an open set 

 containing S and let 

 be a local minimum point for f on S. If 

 then





Proof
Let be 

 any vector of 

 Without loss of generality we assume 

 There will exist a feasible sequence 

 with 

 On the grounds of the assumptions the quotients

for sufficiently large 

 are nonnegative and converge to 

    




Theorem 4.27
Let be given problem 

 with f twice-continuously differentiable on the open set 

 containing S. If, for 

 it holds 

 and

then 

 is a strict local minimum point for f on S.


Proof
The proof is indirect; let us assume that 

 is not a strict local minimum for f on S. Then there will exist for each index 

 a point 

 with 

 and 

 The feasible sequence 

 converges to 

 and contains a tangentially convergent subsequence, we shall denote again by 

 It holds 

 but the quotients

converge to 

 contrary to the assumptions.    




Remark 4.28
Following Hestenes [2], the thesis of Theorem 4.27 can be reformulated in the following way: there exists a neighborhood 

 and a constant 

 such that

Moreover, if the set S is a polyhedral convex set, then Theorems 4.26 and 4.27 can be reformulated in the following more general results: (1)
(Necessity). If 

 is a local minimum point for 

 then 

 for all 

 and 

 for all 

 such that 


 (2)
(Sufficiency). If 

 is such that 

 for all 

 and 

 for all 

 such that 

 then there exist 

 and 

 such that 



 


We point out finally that Hestenes [2] has further generalized Theorems 11 and 12 by means of the lower supporting functions for f at 

 as follows.
A function 

 having the same differentiability properties of f at 

 and satisfying the relations

is called a lower support function for f at 

. Hestenes [2] proves the following result.

Let 

 and suppose that there exists 

 

 such that 

 (4.6) Suppose further that for each vector 

 

 satisfying relation (4.6), there is a lower support function F such that 

 Then there are a neighborhood 

 and a constant 

 such that 





Note that in the previous result it is not required that F to be the same for every 

 

 satisfying relation (4.6).


4.3 Optimization Problems with Equality Constraints ("Classical Constrained Optimization Problems")
In the present section we shall treat the so-called "classical" constrained optimization problems, i.e. optimization problems with only equality constraints. We consider, therefore, problem 

:

where 

 is an open set contained in the domains of the functions involved in 

 

 is differentiable on X and every 

, 

 is continuously differentiable on X. The feasible set of 

 is denoted by

where 

 

 are the constraints or constraint functions of the problem (f is the objective function).
The restriction 

 is imposed in order to avoid that the feasible set shrinks to only isolated points or to the empty set. We have called 

 a "classical" constrained optimization problem, as it was treated by J. L. Lagrange since 1759 (J. L. Lagrange: "Recherches sur la méthode de maximis et minimis", Miscellanea Taurinensia, 1759, t. 1, 18-32. Reprinted in Giorgi and Kjeldsen [6]). Subsequently Lagrange reconsidered his method (within a more general class of problems, called Calculus of Variations) in his famous book "Mécanique Analytique" (Paris, 1788. Complete Edition, joining the notes of the 3rd Edition, revised, corrected, and annotated by Joseph Bertrand, and those of the 4th Edition published under the direction of Gaston Darboux, Albert Blanchard, Paris, 1965). This method, now called Lagrange Multipliers Rule, is one of the main cornerstones of optimization theory and is the basis of the modern developments of mathematical programming theory.
In rough words, the method of Lagrange converts the constrained problem 

 into an unconstrained one, by means of a suitable function, called "Lagrangian function" and then it uses the rules of unconstrained optimization problems to compute the solutions of problem 

 For some historical considerations see, e.g. Prekopa [9], Bussotti [7], and Giorgi and Kjeldsen [6].
When in 

 we have 

 and 

 (one constraint and two variables) it can be sometimes useful the so-called "explicitation method", i.e. to express one variable as a function of the other one, in the constraint, and then to make the substitution into the objective function. The problem becomes, therefore, an unconstrained optimization problem. It must be paid attention to the fact that the domain of the new objective function may change, owing to the "introduction" of the constraint functions. We illustrate it with a couple of examples.

Example 4.29
Find the extremum values of

on the feasible set

We have, from the constraint,

Therefore, the objective function becomes

We have 

 from which we deduce that 

 is the global maximizer of g and hence, being 

 we have 

 Therefore, 

 is the global maximum point of f on 




Example 4.30
Find the extremum values of

on the feasible set

From the first constraint we have 

, from which 

. From the second constraint we have 

 Then f takes the form

with 

 


We have, therefore, four points to consider:

Hence 

 is the constrained global maximum point, 

 and 

 are the constrained global minimum points and 

 is a local constrained maximum point.

Always for the case 

 

 it may be useful also the geometrical method which is based on the level sets or level lines of the objective function:

where 

. Next we illustrate the method with an example.

Example 4.31
Find the extremum values of

on the feasible set

The feasible set is drawn in Fig. 4.1, it is a circle of radius 2 centered at (5, 3).

Fig. 4.1
Example 4.31. Feasible set, level lines, minimum (a) and maximum (b)


The level curves are of the form

They are parallel lines to the line 

 and f increases in the direction (3, 4). So the minimum is achieved at the point A and the maximum at the point B, where the parallel lines are tangents to the circumference 

. At a point of tangency, the tangent line is perpendicular to the radius at the point of contact. So, if we consider the perpendicular line to 

 through the center of the circumference, that is the line 

, the points A and B are the solutions of the system

Solving this system we obtain 

 and 

.
A second possibility to obtain the points A and B is as follows:

Let us observe that 

 is a unit vector in the direction (3, 4) and 2 is the radius of the circumference.
A third possibility to find A and B is based on algebraic considerations. For each c the line 

 from the family of level lines cuts the circumference at two points, at only one (A or B) or at none. Therefore, the values of c to obtain A and B are those for which the system 

 has only one solution. Changing to the variables 

, 

, the system becomes 

 where 

. From the second equation 

, and substituting in the first equation, it results 

. This equation in u has only one solution if its discriminant is zero, that is, 

. This gives 

, and so 

, 

, 

, 

 and 

, and with this values we obtain the same points A and B as above.

The reader is invited to solve the problem of Example 4.29 with the geometrical method. We recall that the relation 

 

, 

 generates a family of equilateral hyperbolas. Other examples where the geometrical method is useful are Examples 4.35, 5.​30, and 5.​33 and the problems at the end of Chap. 5.
The above methods are in general no longer useful when 

 has more than two variables and more than one constraint. In the general case, it is the Lagrange Multipliers Rule that must be adopted. For the reader's convenience we begin to treat problem 

 again under the assumption of 

 

 Subsequently we shall treat the general case.

Theorem 4.32
Let be in problem 

 

 and 

 i.e. 

 and 

, with X open set of 

 Let f be differentiable on X and h be continuously differentiable on X. Let 

 be a local minimum point of f on 

 and let be 

 Then, there exists a unique scalar 

, called "Lagrange multiplier", such that

 (4.7)



Proof
Consider, without loss of generality, the case 

 Owing to the Implicit Function Theorem (Chap. 1, p. 6), there exists a neighborhood 

, where h(x, y) defines implicitly a function 

 such that

In this neighborhood we have also 


It must hence hold

But, owing to the "chain rule" on differentiability of composite functions, we have also

Hence

Therefore, at the point 

 it will hold

On the other hand we have the following obvious identity:

If we put

we have the final result.    



A geometric interpretation of this theorem is given in Fig. 4.2.

Fig. 4.2
Geometric interpretation of Theorem 4.32. f decreases in the direction 

 and 

 is a local minimum of f, one has 

 with 

 (in this case 

)



Remark 4.33
(i) Obviously it is equivalent to write the thesis of Theorem 4.32 in the form

as no sign restriction is made on the multiplier 


(ii) The necessary optimality conditions of Theorem 4.32 are obviously the same also for a constrained maximization problem

In other words the necessary optimality conditions expressed by means of the Lagrange Multipliers Rule makes no distinction between minimization problems and maximization problems.
(iii) The function

(or, equivalently, 

) is called Lagrangian function or shortly, Lagrangian. We note that the thesis of Theorem 4.32 leads to find the stationary points of the Lagrangian function. In this sense, the constrained optimization problem in question is treated by means of an unconstrained one, where the function involved is the Lagrangian function.

Under the assumptions of Theorem 4.32, if 

 the vectors 

 and 

 are, therefore, proportional. The thesis of Theorem 4.32 can be rewritten as

whereas the relation

is equivalent to the feasibility of the pair 

 i.e. 


We wish to stress that Theorem 4.32 gives only necessary optimality conditions and that the "nature" of the constrained optimal points is not conserved by the Lagrangian function 

 What can be said is that, if the assumptions of Theorem 4.32 are satisfied and 

 is a constrained optimal point for 

 then this point is a stationary point of the Lagrangian. For example, 

 is the minimum point of 

 under the constraint 

 (and also the maximum point, as in this rather "pathological" case the feasible set intersects with the objective function at one point) with multiplier 

 but 

 is not a minimum point of 

 on 

.
Always for the case 

 and 

 we now give the second-order sufficient optimality conditions. These conditions will be proved next, for the general case.

Theorem 4.34
Let f(x, y) and h(x, y) be twice-continuously differentiable on the open set 

 Let 

 with

and let 

 satisfy relation (4.7). If the quadratic form

is positive definite 

 for all 

 

 such that

 (4.8)then 

 is a strict local minimum point of f on 

 [resp. a strict local maximum point of f on 

.

We recall that on the grounds of Corollary 1.​4, the above quadratic form is positive definite 

 on the constraint (4.8) if, for the following bordered matrix

it holds 





Example 4.35
Find, by the method of Lagrange multipliers, the minimizers and/or maximizers, if any, of the function

on the feasible set 


We write the Lagrangian function in the form

The conditions of Theorem 4.32 and the feasibility conditions are:

From the first two equations we have

From the third equation we have

We have, therefore, the two triplets

Then we have

Now we consider the bordered matrix

i.e.

At 

 we have

As 

 the point (2, 1) is a constrained strict local maximum point.
At 

 we have

As 

 the point 

 is a constrained strict local minimum point.
Moreover, as the feasible set is closed and bounded and the objective function is continuous on 

 really the points founded are constrained global extremum points. This example is illustrated in Fig. 4.3.



Fig. 4.3
Example 4.35



Example 4.36
Find, by the method of Lagrange multipliers, the minimizers and/or maximizers, if any, of

on the feasible set

First of all, it must be 

 We write the Lagrangian function in the form

The conditions of Theorem 4.32 and the feasibility conditions are:

From the second equation we have 

 or 

(1)
Let be 

 From the first equation we have 

 from which 

 or 

 or 

(a)


 We have, therefore, two "candidate points": 



 (b)



 (c)


 We have two other "candidate points": 



 

 (2)
Let be 

 (and 

 any). From the third equation we have 

 from the first equation we find again 

 and, therefore, we find again the points C and D.
 


We note that also in the present example the feasible set is closed and bounded. Therefore, we have no necessity to use the second-order sufficient conditions. We have

Therefore, we have that C and D are constrained global maximizers (not strict global maximizers!) and A and B are constrained global minimizers.
We are now ready to state the results for a general problem 



where 

 is an open set contained in the domains of the functions involved in 

 

 is differentiable on X and every 

, 

 is continuously differentiable on X. We recall that the set

is the feasible set of 



Definition 4.37
Let be 

 the cone

is called the linearizing cone of 

 at 



Obviously, as 

 is the solution set of a homogeneous linear the system, is a linear space, therefore, a closed and convex set.

Theorem 4.38
Let 

 it holds

If the Jacobian matrix 

 of order (n, p),  has full rank (i.e. 

), then





Proof
Let us consider a direction 

 

 and without loss of generality let us suppose 

 Then there exists a feasible sequence 

 with 

 The quotients

then converge to 

 Therefore, 


To prove the second part of the theorem, let us assume that the Jacobian matrix 

 has full rank. From the Implicit Function Theorem (Chap. 1, p. 6), it is possible to express the system 

 in a neighborhood of the point 

, by means of p basic variables, i.e. with the notation used in the said theorem, to write

The derivatives at the point 

 of the vector-valued function 

 have the following representation:

For a given vector

the relation

is, therefore, equivalent to

Let us suppose 

 (otherwise we have also 

 and the result would be trivial). Without loss of generality, suppose 

 Then, there exists a sequence 

 of non-basic variables which converges tangentially in the direction 

 to the point 

 Therefore, also the corresponding sequence of basic variables 

 with 

 converges to 

 The sequence

is, therefore, feasible and tangentially convergent in the direction 

 to the point 

 being

and

Therefore, it holds 

    



The previous result is a modern version of a classical result: the Theorem of Lyusternik (see, e.g. Ioffe and Tikhomirov [8]).
We are now in a position to prove the general version of Theorem 4.32, i. e. the "Lagrange Multipliers Rule"  for problem 



Theorem 4.39
Let 

 be a local minimum point of 

 and let the gradients 

 be linearly independent. Then, there exists a unique vector of multipliers 

 such that

 (4.9)



Proof
As the gradients 

 

 are linearly independent, the Jacobian matrix 

 has full rank and hence, on the grounds of the previous theorem, it holds 

 From Theorem 4.24 we have, therefore,

As 

 is a linear subspace of 

 the previous relation holds as an equality, i.e.

This means (recall also the theorem of the alternative of Motzkin, Theorem 2.​31) that the vector 

 is given by the linear combination of the column vectors 

 of the Jacobian matrix 

 This is just the thesis of the theorem.    



As already said, the scalars 

, 

 are called "Lagrange multipliers" and the function

is called "Lagrangian function". Obviously relation (4.9) holds also if 

 is a local maximum point of 

 The conditions

are, therefore, first-order necessary conditions for 

 to be a local minimizer (or local maximizer) for 


A point 

 for which 

 has full rank is called a regular point for 

 which, in this case it is also called a "regular problem". We point out that when the constraints 

 

 are all linear affine, there is no need to assume the linear independence of the gradients at 

 See the section on constraint qualifications in Chap. 6.
If 

 is not a regular point, it is possible to obtain the following first-order necessary optimality conditions for 

 conditions attributed to C. Caratheodory (1935) and which anticipate, for classical constrained optimization problems, the Fritz John Theorem for problems 

 and 

 See Chaps. 5 and 6.

Theorem 4.40
(Caratheodory) Let 

 be a local minimum point for 

 Then, there exist multipliers 

, not all zero, such that





Proof
If 

 has full rank, i.e. 

 is regular, i.e. 

 then Theorem 4.39 applies with 

 If 

 i.e. the vectors 

 are linearly dependent, there will exist multipliers, not all zero, 

 such that

It is, therefore, sufficient to choose 

    




Remark 4.41
In the above result the situation 

 points out the "non regularity" of the problem, whereas a non zero multiplier 

 can be present in both regular problems and non-regular problems. In other words, we have the implications




Indeed, if we write the Lagrangian function at 

 in the form

we have that relation (4.9) is (

 is the Jacobian matrix, of order (n, p)):

From a well-known theorem on systems of linear equations, this system has a solution 

 if and only if (Theorem of Rouché-Capelli)

It is possible that the two ranks coincide even if 

 (for example, if 

), and regardless of the fact that 

 is or not an optimal point for 




Example 4.42
Consider the problem

By using, e.g. the level sets method, it is seen that the solution is at the point (1, 0). This point is not regular, as 

 The Lagrange conditions (4.7) are not verified at 

. However, we have, with 



with 

, 

 relation which satisfies the thesis of Theorem 4.40.

We now give the second-order optimality conditions for optimization problems with equality constraints.

Theorem 4.43
Let 

 and every 

, 

 be twice-continuously differentiable on the open set 

(i)
Let 

 be a local minimizer 

 of f on 

 and let 

 be a regular point. Then, besides relation (4.9), it holds 

 for all 

 such that 



 (ii)
Let 

 If relation (4.9) is satisfied by the pair 

 and if 

 for all 

, 

 such that 

 (4.10) then 

 is a strict local minimizer 

 for f on 


 



Proof
(i) This result is a direct consequence of Theorem 4.26. Being 

 a regular point it will hold

Moreover, 

 is a local minimizer 

 in 

 of 

 Therefore, we have

for all 

 But, thanks to Theorem 4.38, 

 and the thesis follows.
(ii) This result is a direct consequence of Theorem 4.27. Being (4.9) satisfied and being, for all 



if

for all 

 then 

 

 

 

 This is equivalent to state that 

 is a strict local minimum point (resp. local maximum point) of f on 

 Being 

 we can substitute in the above inequality 

 with 

 See also the end lines of Remark 4.44.    




Remark 4.44
Following Hestenes [2], it is possible to assert that conditions (ii) of the previous theorem guarantee that 

 is a strict local minimizer 

 of order 2 for 


We recall (see Chap. 1) that in order to check the second-order sufficient optimality conditions (ii) of the previous theorem, we can consider the bordered matrix, of order 



If the leading principal minors of 

 of order 

 have the sign of 

 then the quadratic form 

 is positive definite on the set (4.10). If the leading principal minors of 

 of order 

 alternate in sign, beginning with the sign of 

 then the quadratic form 

 is negative definite on the set (4.10). Note that if the above conditions on 

 are satisfied, then the gradients 

 are linearly independent and hence 



We have also sufficient conditions for global optimality.

Theorem 4.45
Let 

 and let the pair 

 satisfy relation (4.9). If 

 is pseudoconvex, with respect to x,  on the open convex set 

 then 

 is a global minimizer of f on 

 If 

 is pseudoconcave in x, then 

 is a global maximizer of f on 




Proof
If 

 is pseudoconvex, with respect to x,  we have, for all 



But being (4.9) satisfied, we have, 



i.e. , 



   



We recall that if f is convex and the Lagrangian function is given in the form 

 then 

 is convex (with respect to x) if every 

 is a convex function and all multipliers are positive. If all constraints are linear affine (i.e. 

 

) and the objective function is convex 

, then the Lagrangian function is convex 

 regardless of the sign of the multipliers. We can, therefore, give the following result.

Theorem 4.46
Suppose f be convex 

 on the convex set 

 and suppose 

 be linear affine. Then 

 such that the pair 

 satisfy relation (4.9), is a global minimizer 

 of f on 




Example 4.47
Find the minimizers and/or the maximizers, if any, of

on the feasible set

We write the Lagrangian function in the form

The system 

 is

We have: 

 

 

 

 The first equation becomes then

i.e.

We have, therefore,

Therefore, the two vectors

The bordered matrix M(x, v) is

Being 

 and 

 we have to compute only the leading principal minors of M of order 

 i.e. 

 For A we have 

 and for B we have 

 As 

 has the sign of 

 it results that the constrained quadratic form is positive definite and hence 

 is a constrained strict local minimizer. As 

 has the sign of 

 it results that the constrained quadratic form is negative definite and hence 

 is a constrained strict local maximizer.


Example 4.48
Factorize the integer number 8 into three positive (not necessarily integer) factors, such that the sum of the inverses of the said factors is minimal.
In other words, we have the problem

subject to: 


We use the Lagrangian multipliers method. The Lagrangian function is

and the related first-order conditions are

Obviously 

 we obtain the equation

We find the solution 

 with the related multiplier 

 We have

For 

 and 

 we have

This matrix is positive definite everywhere (and not only on the set 

). Therefore, the point 

 is a constrained global minimum point, as f is a strictly convex function on 




Example 4.49
Find the minimizers and/or maximizers, if any, of

subject to: 

 


We write the Lagrangian function in the form

We write the system

We obtain from the first two equations 

 

 By inserting these expressions in the third equation we get 

 This expression, together with the two linear constraints, determines a linear system of three equations in three unknowns. We obtain the (unique) solution

We observe that the objective function 

 is a strictly convex function (it is the sum of strictly convex functions). Since the constraints are both linear affine, the Lagrangian function is, therefore, (strictly) convex. Hence the point 

 is the unique constrained strict global minimizer of the objective function.


Example 4.50
(Variational characterization of the eigenvalues of a symmetric matrix A of order n) Let us consider the Rayleigh quotient

where 

 and A is a symmetric matrix of order n. This function is homogeneous of zero degree: it holds, for 

 



Therefore, in order to compute the minimum and the maximum of R(x) for 

 if they exist, it is sufficient to compute the minimum and the maximum of R(x) on the unit sphere

Note that we have a continuous function 

 on a compact set and, therefore, the Weierstrass theorem applies. Let us denote

Let us order the eigenvalues of A (which are all real!) in the following way:

We want to prove the following proposition.

If A is a symmetric matrix, of order n,  with eigenvalues 

 then 

 We use the Lagrangian multipliers theorem, where the objective function is 

 and 

 can be expressed as 

 We write the Lagrangian function 

 in the form 

 The gradient of 

 with respect to x is 

 Therefore, the condition 

 becomes 

 The maximum and minimum points of 

 on U (points which surely exist) are to be looked for among the n orthonormal eigenvectors 

 of the matrix A,  eigenvectors corresponding to the eigenvalues 

 Let us compute the value which 

 assumes in correspondence of an eigenvector 



 as 

 We conclude that 

 reaches its maximum value for 

 and its minimum value for 

 We find, as a corollary, the well-known criterion (see Chap. 1) for stating the sign of a (real) quadratic form 

 where the eigenvalues of A have been ordered in the following way: 



Q(x) is positive definite if and only if 



Q(x) is positive semidefinite if and only if 



Q(x) is negative definite if and only if 



Q(x) is negative semidefinite if and only if 



Q(x) is indefinite if and only if 






References1.M.R. Hestenes, Calculus of Variations and Optimal Control Theory (Wiley, New York, 1966)2.M.R. Hestenes, Optimization Theory. The Finite Dimensional Case (Wiley, New York, 1975)3.A. Ben-Israel, B. Mond, What is invexity? J. Austral. Math. Soc. Ser. B 28, 1-9 (1986)4.B.D. Craven, B.M. Glover, Invex functions and duality. J. Aust. Math. Soc. Ser. A 39, 1-20 (1985)5.M. Guignard, Generalized Kuhn-Tucker conditions for mathematical programming problems in a Banach space. SIAM J. Control 7, 232-241 (1969)6.G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (Birkhäuser, Basel and New York, 2014)7.P. Bussotti, On the genesis of the Lagrange multipliers. J. Optim. Theory Appl. 117, 453-459 (2003)8.A.D. Ioffe, V.M. Tichomirov, Theory of Extremal Problems (North Holland, Amsterdam, 1979)9.A. Prekopa, On the development of optimization theory. Amer. Math. Mon. 87, 527-542 (1980)












© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_5





5. Constrained Optimization Problems with Inequality Constraints



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es







5.1 First-Order Conditions
In the present chapter, we are concerned with constrained optimization problems with inequality constraints, i.e. with problem 



where X is an open set contained in the domains of the functions involved in 

 f and each 

 

 are real-valued functions defined on 

 The function f is the objective function of 

 

 

 are the constraints and the set

is the feasible set of 


In the last century, just before the Second World War, it became apparent that there are many optimization problems which involve constraints in the form of inequalities, instead of in the form of equalities, or involve constraints in the form of both inequalities and equalities. The transition from "classical" constrained optimization problems to "modern" constrained optimization problems (i.e. with constraints expressed by inequalities) requested almost 180 years! This, above all due to the fact that, whereas the constrained classical optimization problems are substantially treated by means of a standard result of Mathematical Analysis, i.e. the Implicit Function Theorem, the modern constrained optimization problems require results from Convex Analysis and Linear Algebra, topics developed mainly during the 20th century.
It was during the Second World War, in the USA, and a few years before its beginning, in the Soviet Union, that a new chapter in the theory of constrained optimization was developed: the Linear Programming theory by the American mathematician G. B. Dantzig and by the Russian mathematician L. V. Kantorovich (Nobel prize in Economic Science in 1975, together with T. C. Koopmans). In 1951, in the USA, mathematicians H. W. Kuhn and A. W. Tucker developed the Lagrange multipliers rule with reference to convex and nonconvex (nonlinear) programming problems with inequality constraints. Some years before [3], the mathematician Fritz John had published a paper on the same subject (perhaps the first published paper on these problems), obtaining some weaker optimality conditions with respect to the ones of Kuhn and Tucker. But, prior to F. John and Kuhn and Tucker, in 1939 W. Karush in his Master's Thesis at the University of Chicago, had obtained optimality conditions for 

 similar to the ones of Kuhn and Tucker. Thus, these conditions are now known as Karush-Kuhn-Tucker conditions.  The thesis of Karush was neglected for several years and has been entirely published only in 2014. See Giorgi and Kjeldsen [4].
For our purposes, the formulation of 

 is sufficiently general. We recall that the maximization problem 

 

 is equivalent to 

 

 Obviously, it holds

Moreover, if we have some inequalities of the type 

 obviously, these ones are equivalent to 

 If we have some constraints of the type 

 it is possible to write them as 

 with 

 Also the constraints 

 (i.e. 

 

) may be rewritten in the form

even if this procedure is often not convenient.
Given 

 the constraints 

 for which it holds 

 are called active constraints (or binding constraints or effective constraints) at 

 Those constraints for which at 

 we have 

 are called non-active constraints (or non-binding constraints or non-effective constraints) at 

 For 

 the set

is the set of indices of those constraints which are active at 

 It is also called set of the active constraints at 



The active constraints have a special meaning: they restrict feasible corrections around a feasible point. If a constraint 

 is non-active at a feasible point 

 (i.e. 

) it is possible to move from 

 a bit in any direction without violating this constraint. So, in a sense, at least locally, non-active constraints are not important with respect to optimality criteria for 

.

Example 5.1
Let be, with 



At 

, we have 

 at 

, we have 

 at 

, we have 


So, if 

, problem 

 becomes an unconstrained optimization problem and this case is therefore not relevant to what treated in the present chapter.

Let us now make the assumption that all the functions involved in 

 are (at least) differentiable on the open set 



Definition 5.2
Let be 

 the set (polyhedral cone)

is called linearizing cone of 

 at 

 (or also cone of locally constrained directions of 

 at 

).
The set

is called cone of interior locally constrained directions of 

 at 

 or cone of descent directions of 

 at 



Obviously, 

 because 

 Actually, 

 is a polyhedral cone and thus it is closed and convex. On the other hand, 

 is an open convex cone, being 

 Therefore, 

 if and only if 

. Geometrically, each vector 

 has a negative projection on the gradients of active inequality constraints. This implies that moving from 

 along y within a certain range of steps will not violate the constraint. Hence, y is a feasible direction, i.e. 

. 

 and 

 provide analytic representations of the local approximation of 

 at x



Theorem 5.3
Let 

 then it holds

where 

 

 and 

 are, respectively, the cone of feasible directions to 

 at 

 the cone of attainable directions to 

 at 

 and the cone of tangent directions or Bouligand tangent cone or contingent cone to 

 at 

.


Proof
If 

, then 

 and it holds trivially 

 Let us suppose therefore that 

 Let be 

 and without loss of generality, let be 

 First we prove that 

 We need to show that there exists 

 such that 

 

 When 

 we have, thanks to the continuity of 



when 

 is sufficiently small. When 

 for 

 and sufficiently small, we have

Consequently, 

 for 

 sufficiently small. Therefore, 

 and 

 From the definitions of 

 

 and 

 it is easy to check that 

 (see Remark 2.​45). Finally, we prove that 

 Let be 

 with 

 and, without loss of generality, with 

 There will exist therefore a feasible sequence 

 with 

 Then, for every 

, the quotients

converge to 

 Then 

.    



Theorem 5.3 shows that 

 can be slightly larger (if not equal to) 

 

 and 

 We note, moreover, that it holds (see Theorem 2.​24, properties of polar cones):




Corollary 5.4
If 

 then it holds





Proof
Let be 

 i.e.

Now we choose a vector 

 i.e. a vector 

 such that

For all 

, we have therefore

Hence, 

 Consequently, it holds 

 and therefore we obtain the inclusion 

 from which we obtain the thesis, on the grounds of the previous theorem and taking into account the fact that both cones 

 and 

 are closed.    



We shall see that the condition 

 is known as "Cottle Constraint Qualification", a condition that really is due to Arrow, Hurwicz, and Uzawa [1].
We can now obtain the first important result concerning necessary optimality conditions for 

 i.e. the Fritz John conditions. Perhaps this result is the first published theorem [3] regarding optimality conditions for a mathematical programming problem with inequality constraints. Though this result is usually treated without many comments and with little emphasis in several books on optimization theory, recent works by Bertsekas [5] and Bertsekas and Ozdaglar [6] bring a new light on the Fritz John Theorem. These authors speak of "enhanced Fritz John conditions", as their conditions are useful also in view of theoretic and algorithmic developments. We shall revert to the main results of Bertsekas and Ozdaglar in the next chapter. We now give the classical version of the Fritz John theorem.

Theorem 5.5
(Fritz John Theorem) Let 

 be a local minimum point for 

 Then there exist multipliers 

 not all zero, such that








Proof
Let 

 be a local minimum point for 

 Then we have (Theorem 4.​24):

We have also 

 for all vectors y such that 

 

 In other words, the system of linear inequalities

does not  admit solutions 

 Thanks to Gordan's theorem of the alternative (see Chap. 2, p. 44), it results that there exist multipliers 

 

 nonnegative and not all zero, such that

By choosing 

 

 we obtain the thesis.    



The conditions 

 

 are called complementary slackness conditions. Note that if 

 we have the result 

 i.e. 

 is a stationary point for f. Note that only the multipliers 

 

 

 are required to be not all zero. If 

 the necessary optimality conditions expressed by Theorem 5.5 become useless, as in this case, the role played by the objective function vanishes. It is therefore important to have conditions which assure 

 i.e. without loss of generality, 

 The conditions which assure, in Theorem 5.5, 

 are called "constraint qualifications"  and have for 

 the role that the "regularity conditions" have for the "classical" constrained optimization problem 


The result, contained in the proof of Theorem 5.5: Let 

 be a local minimum point for 

 then the system

has no solution 

 is also known as Abadie linearization lemma (Abadie [7]). Its geometric meaning is clear: if 

 is a local solution of 

 there does not exist a direction 

 along which it is possible to remain in the feasible set and at the same time to decrease the objective function.
The complementary slackness conditions emphasize that both 

 and 

 cannot hold with a strict inequality at the same time. Hence,

If, for all 

 we have 

 we say that the strict complementary slackness conditions  hold at 

 i.e.

These conditions are important for some questions regarding second-order optimality conditions and for some questions of sensitivity analysis (see Chap. 7).

Example 5.6
Let us consider the problem

It is easy to see (by geometric considerations) that the solution of the problem is the point 

 The Fritz John conditions for this problem are:









 

 

 not all zero.
At 

, we have

i.e.

from which it results that 

 (and 

 that can be chosen 

).

In their pioneering paper of 1951 Kuhn and Tucker [8] introduced a condition, called "constraint qualification" (indeed, it was already introduced by Karush in 1939 in his Master Thesis) in order to avoid that, in the Fritz John conditions, we have (as in Example 2) 

 There are many constraint qualifications, ranking from simple ones, easy to check, to sophisticated ones, more general but less easy to check. A problem 

 where a constraint qualification holds, is therefore called "qualified". Constraint qualifications usually are conditions regarding only the constraints and not also the objective function. We consider for problem 

 a very general constraint qualification, due to Guignard [9] and Gould and Tolle [10]. We shall see in the next chapter that this constraint qualification is, in a certain sense, the weakest among the other constraint qualifications proposed for 

 or for 


Let 

 We say that the Guignard-Gould-Tolle constraint qualification holds if

 (5.1)which can be equivalently expressed as

or also as

In order to obtain the celebrated Kuhn-Tucker conditions or, better, Karush-Kuhn-Tucker conditions, we need a simple previous result. Following Gould and Tolle [10, 11], we introduce for 

 the cone of gradients:

Note that the cone of gradients is a finitely generated cone and hence it is closed and convex (see Theorem 2.​26). It is easy to show that 

 and 

 are polar cones of each other.

Lemma 5.7
Let 

 Then it holds

and





Proof
Obviously, we prove only the first equality. The inclusion 

 is obvious: consider any 

 and thus 

 

 Thus, for 

 

 we have 

 This shows that 

 The opposite inclusion is a direct consequence of Farkas' theorem (see Theorem 2.​28).    



We are now able to prove, under assumption (5.1), the celebrated Karush-Kuhn-Tucker conditions for 

 perhaps the most important theorem for this kind of mathematical programming problems.

Theorem 5.8
(Karush-Kuhn-Tucker) Let 

 be a local solution of 

 and let (5.1) be verified, i.e. let be verified the Guignard-Gould-Tolle constraint qualification. Then, there exist multipliers ("Karush-Kuhn-Tucker multipliers") 

 such that

 (5.2)


 (5.3)


 (5.4)



Proof
We have proved in Theorem 4.​24, that if 

 is a local solution of 

 then

But if (5.1) holds, then we can write the above relation as

and, on the grounds of Lemma 5.7,

Consequently, there exist multipliers 

 

 such that

 (5.5)Now, taking 

 for all 

 the thesis of the theorem is proved.    



By using the Lagrangian function (here perhaps it is better to speak of Lagrange-Kuhn-Tucker function)

the conditions (5.2)-(5.3)-(5.4) of Theorem 5.8 can be rewritten in the form

Note that for 

 the Karush-Kuhn-Tucker conditions collapse to the stationarity condition 

 If 

 relation (5.5) says that the steepest descent direction (i.e. negative gradient) of the objective function, 

 is a conic combination of the gradients of the active constraint functions (see Fig. 5.1). This means that in general the active constraints could be violated if we move 

 along a descent direction of f at 

.

Fig. 5.1
Geometric interpretation of the Karush-Kuhn-Tucker conditions: 

 with 

, 

 is not active at 

. f decreases in the direction 

 and f attains a local minimum at 




We insist on the fact that the Karush-Kuhn-Tucker theorem (and also the Fritz John theorem) gives necessary optimality conditions, but not sufficient ones.

Example 5.9
Consider the problem

The point 

 verifies the Karush-Kuhn-Tucker conditions with 

 but 

 is not a local optimum for the problem.

We now give for 

 some sufficient first-order optimality conditions, based on the Karush-Kuhn-Tucker conditions.

Theorem 5.10
Let 

 let f be pseudoconvex on the open convex set 

 and let every constraint 

 

 be quasiconvex on X. Let 

 verify the Karush-Kuhn-Tucker conditions (5.2)-(5.3)-(5.4). Then 

 is a solution of 




Proof
Being 

 

 a quasiconvex function on 

 we have, for every 

 and for every 



Being the multiplier 

 

 it will hold, for every 



As 

 

 it holds




From relation (5.2) of the Karush-Kuhn-Tucker conditions, we obtain

i.e.

Hence, it will hold, as 

 



But, being f pseudoconvex on X,  we have

   



We note that the quasiconvexity of the objective function f,  together with the quasiconvexity of every constraint 

 

 does not imply that the Karush-Kuhn-Tucker conditions are sufficient for 

 to be a global minimum point for 

 Consider, e.g. the problem

The objective function is quasiconvex (and quasiconcave), the point 

 satisfies the Karush-Kuhn-tucker conditions with 

 

 but the minimum occurs at 

.
A more general sufficient optimality condition for 

 under the assumptions on 

 the objective function f and every constraint 

 

 contained in Theorem 5.10, is:

 (5.6)


Condition (5.6) is called by Mangasarian [12] "minimum principle" optimality condition. The above assertion is quite obvious, on the grounds of the proof of Theorem 5.10. The same is true if we assume, instead of the pseudoconvexity of f and the quasiconvexity of 

 

 that the Lagrangian function 

 is pseudoconvex, with respect to x,  on the open convex set 

 This condition is neither stronger nor weaker than the previous ones, as we recall that the sum of pseudoconvex or quasiconvex functions is not necessarily a pseudoconvex nor a quasiconvex function.
It is also possible to obtain sufficient optimality conditions for 

 starting from the Fritz John conditions, but under rather strong assumptions.

Theorem 5.11
Let 

; let f be convex and every 

 

 be strictly convex on the open convex set 

 If 

 satisfies the Fritz John conditions of Theorem 5.5, then 

 is a solution of 




Proof
Since we have

with 

 

 

 not all zero, it follows from Gordan's theorem of the alternative that the system

 (5.7)has no solution 

 Consequently, the system

 (5.8)has no solution 

 for it did have a solution 

 then 

 and

by convexity of f, and

by strict convexity of every 

 

. This contradicts (5.7) if we set 

 Recalling that 

 

 we have from (5.8) that

has no solution 

 Since 

 

 is in 

 and hence 

 solves 

.    



A similar result will be given for 

 in the next chapter, but with weaker assumptions (see Theorem 6.​10).
It is also possible to get first-order sufficient optimality conditions for 

 in absence of convexity or generalized convexity assumptions on the functions involved in the problem. We obtain however only local optimality conditions and under rather strong assumptions. The following result is due to John [3]; see Stoer and Witzgall [13].

Theorem 5.12
Let 

 verify the Fritz John conditions of Theorem 5.5, with multipliers 

 

 

 If

then 

 is a local minimum point for 



We shall give the proof of this result in the next chapter, with reference to problem 


Another first-order sufficient optimality condition for 

 is obtained by means of invex functions (Definition 3.​33).

Theorem 5.13
Let 

 and let the objective function f and the constraints 

 

 be invex functions, with respect to a same vector-valued function 

 on the open set 

 If 

 satisfies the Karush-Kuhn-Tucker conditions (5.2)-(5.3)-(5.4) of Theorem 5.8, then 

 is a solution of 




Proof
For any 

, we have

by the Karush-Kuhn-Tucker conditions. Then we have

being 

 

 and being every 

 invex with respect to a common function 

 The right-hand side of the last expression, thanks to the complementary slackness conditions, is given by

being 

 

 and 

 

 So, we have, for every 



i.e. 

 is a solution of 

.    



It is interesting to know when a finite collection of functions is made of invex functions, with respect to a common vector-valued function 

 The answer is contained in a result of Martínez-Legaz [14], we report for the reader's convenience.

Theorem 5.14
Let 

 be differentiable functions defined on an open subset X of 

 The following statements are equivalent: (i)
The functions 

 are invex with respect to the same 


 (ii)
The functions 

 

 are invex with respect to the same 


 (iii)
The functions 

 

 are invex.
 (iv)
For every 

 every stationary point of 

 is a global minimum point.
 



Proof
We first recall a theorem of the alternative due to Gale (Gale [30]; see also Chap. 2, p. 43): For a given matrix A of order (m, n) and a given vector 

 either the system

has a solution 

 or the system

has a solution 

 but never both. In other words, if a system of the type 

 has no solution 

 then there exists 

 such that

where 

 is the ith row of A.
Now we prove the theorem. Implications (i) 

 (ii) 

 (iii) 

 (iv) are obvious, so we have to prove only the implication (iv) 

 (i). Assume, by contradiction, that there is no vector-valued function 

 such that

In other words, there exist 

 such that the system

in the unknown vector 

 has no solution. Hence, by the theorem of the alternative of Gale above recalled, there is 

 such that 

 and 

 Therefore, 

 has a stationary point which is not a global minimum, since

This contradicts (iv).    



Therefore, not always invex functions are a useful tool in obtaining sufficient optimality conditions for 

 as f and each 

 can be individually invex, but only with respect to different 

 Ben-Israel and Mond [15] consider the following example.

Example 5.15
Consider the problem

If we take 

 

 the Karush-Kuhn-Tucker conditions are satisfied. Here f is convex (and therefore invex) and g is pseudoconvex (and therefore invex), but for 

 the Lagrangian function 

 is not invex, i.e. f and g are invex with respect to different 

 so the sufficiency result of Theorem 5.13 is not applicable, although, of course, 

 is a global minimum point, by Theorem 5.10.



5.2 Constraint Qualifications
In the previous section, we obtained the Karush-Kuhn-Tucker conditions under the constraint qualification (5.1). In other words, this condition assures that in Theorem 5.5 of Fritz John it holds 

 We wish to stress that the question of constraint qualifications (for 

 or for the more general problem 

 or also for other more general mathematical programming problems) is not always related to the geometric structure of the feasible set around the optimal point 

 such as the presence of a cusp, as suggested, e.g. by Mangasarian [12]. Constraint qualifications are indeed related to the functional form of the constraints. If we reconsider the problem of Example 5.6, we see that the feasible set present a cusp at the optimal point 

 We have seen that the Fritz John conditions for the said problem are verified at 

 only by 

 As a matter of fact, at 

 no constraint qualification is satisfied by the constraints of the problem. However, the presence of a cusp is neither necessary nor sufficient to cause the Karush-Kuhn-Tucker conditions to fail at an optimal solution. Let us add to the problem of Example 5.6 a new constraint:

Clearly, the feasible set remains the same (the new constraint is therefore redundant), but now the problem is qualified, i.e. the Fritz John conditions are satisfied at 

 with 

 hence the Karush-Kuhn-Tucker conditions hold at 


We now give an overview of the main (but not all!) constraint qualifications proposed in the literature, with reference to 

 Let 


1. Guignard-Gould-Tolle constraint qualification. It is just condition (5.1):

which can be equivalently expressed as

or also as

See Guignard [9], Gould and Tolle [10, 11]. Gould and Tolle [10] proved that this condition is necessary and sufficient for the Karush-Kuhn-Tucker conditions to be verified by any (differentiable) objective function of which 

 is a local optimal solution on 

 In this sense the Guignard-Gould-Tolle constraint qualification is the weakest possible among constraint qualifications. See also the next chapter.
2. Abadie constraint qualification. It is expressed as

Therefore, the Abadie constraint qualification requires that 

 be a convex cone. Obviously, the Abadie constraint qualification implies the Guignard-Gould-Tolle constraint qualification. A point 

 satisfying the Abadie constraint qualification is called by Hestenes [16] a "regular point", whereas 

 satisfying the Guignard-Gould-Tolle constraint qualification is called, by the same author, a "quasiregular point".
3. Kuhn-Tucker constraint qualification or, better, Karush-Kuhn-Tucker constraint qualification.  It is expressed as

Obviously, from the definitions of the related cones, the Karush-Kuhn-Tucker constraint qualification implies the Abadie constraint qualification.
4. Zangwill constraint qualification (see Zangwill [17]). It is expressed as

For what previously seen, we have that the Zangwill constraint qualification implies the Karush-Kuhn-Tucker constraint qualification.
We note that all the above implications are strict.
5. Cottle constraint qualification or Arrow-Hurwicz-Uzawa constraint qualification. It is expressed as

or, equivalently, as

This qualification is considered, as a particular case of a more general constraint qualification, by Arrow et al. [1], who are, therefore, the first authors to have introduced this constraint qualification. In its original form the Cottle constraint qualification requires that the system

has the zero sulution only, i.e. the vectors 

 

 have to be positively linearly independent. Indeed, by applying Gordan's theorem of the alternative (see p. 44), we see that the two formulations are equivalent.
We have seen, in Theorem 5.3 and in Corollary 5.4, that the Cottle constraint qualification implies the Zangwill constraint qualification.
The Cottle constraint qualification has been "refined" by Abadie [7] and by Arrow et al. [1]. In order to describe these constraint qualifications, we introduce two variants of the linearized cone 

 considered, respectively by Abadie and by Arrow, Hurwicz and Uzawa.




6. Abadie constraint qualification II. It is expressed as

or, equivalently, as

7. Arrow-Hurwicz-Uzawa constraint qualification II. It is expressed as

or, equivalently, as

We have to note at once that if all functions 

 

 are pseuconcave or even concave, then the Arrow-Hurwicz-Uzawa constraint qualification II is automatically satisfied. Arrow et al. [1] call this case Reverse constraint qualification. If all functions 

 

 are linear (or even linear affine), the Abadie constraint qualification II and the Arrow-Hurwicz-Uzawa constraint qualification II are automatically satisfied. Hence, for a Linear Programming Problem (see Chap. 9) no constraint qualification is required.

Theorem 5.16
Let be 

 Then





Proof
We prove only the inclusions not previously already proved. It is easy to see that 

 We now prove that 

 Let 

 we claim that 

 with 

 being sufficiently small for all 

 such that 

 is pseudoconcave. Otherwise 

 and then 

 by the pseudoconcavity, which is a contradiction. For 

 

 is not pseudoconcave, the considerations are similar. In any case 

 and hence 

.    



Hence, we have the following implications:
Cottle c. q. 

 Abadie c. q. II 

 Arrow-Hurwicz-Uzawa c. q. II


 Zangwill c. q. 

 Karush-Kuhn-Tucker c. q. 

 Abadie c. q.


 Guignard-Gould-Tolle c. q.
8. Slater constraint qualification. It is expressed as: every constraint 

 

 is pseudoconvex and there exists 

 such that 

 



Theorem 5.17
The Slater constraint qualification implies the Cottle constraint qualification.


Proof
Suppose that the Slater constraint qualification is satisfied. For 

, we have 

 Therefore, 

 because 

 is pseudoconvex. Let be 

 then 

 This means 

 and hence the Cottle constraint qualification holds.    



The original Slater constraint qualification was given under convexity assumptions on the constraints 

 

 Note that, under this assumption, the Slater constraint qualification and the Cottle constraint qualification are equivalent assertions. The "relaxed" Slater constraint qualification here presented, is due to Mangasarian [12].
9. Linear independence constraint qualification. It is expressed as: the gradients

are linearly independent.
It is immediate to see that

Indeed, if the gradients of the active constraints at 

 are linearly independent, they are also positively linearly independent, i.e. the Cottle constraint qualification holds. Note, moreover, that the Linear independence constraint qualification assures the uniqueness of the Karush-Kuhn-Tucker multipliers 

 

 in relations (5.2)-(5.3)-(5.4) of Theorem 5.8. We shall show in the next chapter, with reference to problem 

 a necessary and sufficient condition for the uniqueness of the Karush-Kuhn-Tucker multipliers.
Here, we have considered constraint qualifications for differentiable functions, some of these qualifications have been extended for directionally differentiable functions in Giorgi et al. [18].


5.3 Second-Order Conditions
We have already considered both second-order necessary and second-order sufficient optimality conditions in unconstrained optimization problems and in "classical" constrained optimization problems. In absence of convexity or some kind of generalized convexity of the functions involved in an optimization problem, the second-order sufficient conditions are an important tool to determinate whether a "candidate" to be a (local) optimal point is indeed a local solution of the problem. In this section we give the basic second-order necessary optimality conditions and the basic second-order sufficient optimality conditions for 

 We shall reconsider these questions, with further insights, in the next chapter, with reference to problem 


We make the assumptions that all functions involved in 

 are twice-continuously differentiable on the open set 


Let be 

 and let the pair 

 verify the Karush-Kuhn-Tucker conditions







We define the set of strictly active constraints at 



We introduce the set

Now we introduce two "regularity conditions" :


 The Bouligand tangent cone 

 is equal to the following "modified" linearizing cone or critical cone or cone of critical directions

i.e.



 The vectors 

 

 are linearly independent and there exists 

 such that

Note that this last condition is a restricted version of the Cottle constraint qualification. With reference to 

 this condition has been introduced by Kyparisis [19]. It is not difficult to prove that 

 satisfies 

 if and only if the system

admits the zero solution only. In other words, the vectors 

 

 are positively linearly independent. We shall give the proof in the next chapter, for problem 


We can easily prove the following result on necessary second-order optimality conditions for 



Theorem 5.18
Let 

 be a local solution of problem 

 and let the pair 

 verify the Karush-Kuhn-Tucker conditions. Then it holds

If, moreover, condition 

 holds, then we have

 (5.9)



Proof
Given the Lagrangian function 

 we have obviously, thanks to the complementary slackness conditions,

As 

 is a local solution of 

 this point is also a local solution of

But the conditions of Karush-Kuhn-Tucker at 

 give 

 Applying Theorem 4.​26, we have

If 

 i.e. 

 holds, then obviously, we have relation (5.9).    



Now we prove that 

 is sufficient for the validity of 

 We follow closely Elster and others [20].

Theorem 5.19
Let be 

 Then





Proof
Let be 

 Being the vectors 

 

 linearly independent, there exists a matrix A,  of order 

 such that

 (5.10)(For brevity we denote 

 by 

).
Now let us consider a vector 

 

 which verifies 

 as well as the system, in 

 and t : 

 (5.11)The system (5.11) admits the solution 

 By (5.10), there exist, owing to the Implicit Function Theorem, in a neighborhood 

 of 

 the functions 

 

 with




 (5.12)By differentiating (5.12) with respect to t at 

 we get

From 

 

 it follows

By (5.10) we obtain 

 and therefore

 (5.13)Now we prove that there exists 

 such that 

 so that the curve

lies entirely in G. To this purpose, let us develop the functions 

 

 at 

 with respect to 

 keeping in mind that 

 It follows

From (5.13) we obtain

and

As y satisfies condition 

 we have 



 There exists therefore 

 such that, for 

, we have

Taking into account also relation (5.12), it follows the existence of 

 such that the curve x(t),  

 lies entirely in G. It is then possible to build a sequence 

 

 with 

 with the property 

 We have 

 and for 

 taking relation (5.13) into account,

i.e. for 

 we have the conclusion of the theorem. For 

 condition 

 is the Cottle constraint qualification, and also in this case, the theorem holds.    



We point out that if the gradients 

 

 are linearly independent, then surely 

 is satisfied. We obtain therefore, as a corollary, the following classical result on second-order necessary optimality conditions for 



Corollary 5.20
Let 

 be a local solution of 

 and let the gradients 

 

 be linearly independent. Then, there exists a unique vector of Karush-Kuhn-Tucker multipliers 

 such that the Karush-Kuhn-Tucker conditions are verified at 

 Moreover, it holds




We note that, in absence of constraints, i.e. with reference to unconstrained optimization problems, we have then the following classical result: if 

 is a local minimum point, then 

 is positive semidefinite.
Theorem 5.18 and Corollary 5.20 do not give a sufficient optimality condition.

Example 5.21
Consider the problem



 The point 

 is the unique solution of the Karush-Kuhn-Tucker conditions, with multiplier 

 The linear constraint is active at 

 and 

 The Hessian matrix of the Lagrangian function at 

 is the zero matrix, but 

 is not a local optimum because 

 for all 




Theorem 5.22
Let 

 and let the Karush-Kuhn-Tucker conditions be satisfied by the pair 

 If

 (5.14)then 

 is a strict local minimum point for 




Proof
We perform the proof in an indirect way. We suppose that f has no strict local minimizer at 

 Then, there exists a sequence 

 with 

 and 

 with 

 It follows

and, being 

 

 



Therefore, we obtain

From 

 it follows

By assumption 

 For 

 we have therefore a contradiction with relation (5.14). If 

 let us suppose that for an index 

 it holds 

 Multiplying 

 by y and taking into account that 

 and 

 

, we have

and hence a contradiction. Therefore, we have 

 

 and we get the thesis of the Theorem.    



As it holds always 

 we can write the thesis of the previous theorem in a stronger form, which is the usual form of the second-order optimality conditions for 



where 

 is the critical cone previously introduced

This last formulation is essentially due to McCormick [21]. We may remark that if 

 i.e. the strict complementary slackness conditions hold at 

 we have

with

It is therefore possible to use, in this case, the criteria which assure that the quadratic form

is positive definite on the set of nonzero solutions of the system described by 

 See Chap. 1 and see, e.g. Chabrillac and Crouzeix [2] and Debreu [22].

Example 5.23
Consider the problem

where 

 is a parameter.
The point 

 satisfies the Karush-Kuhn-Tucker conditions, with multipliers 

. Indeed, at this point the problem is qualified (why?). But only for 

 and 

 the sufficient optimality conditions of Theorem 5.22 are satisfied. Then, for 

 the objective function has at 

 a strict local minimum over the feasible set. For 

 it holds 

 and therefore, on the grounds of Theorem 5.22, we cannot draw any conclusion.



5.4 Other Formulations of the Problem. Some Examples
On the grounds of what previously said, it is not difficult to obtain the Karush-Kuhn-Tucker conditions (or the Fritz John conditions) for other formulations of 

 Let us consider, for example, the following problem:

in which there are, besides the functional constraints, non-negativity constraints on the variables, i.e. 

 that is, in vector notation, 

 This formulation appears in all mathematical programming problems arising from economic and financial environments. Let us rewrite the above problem in the form

where

Let us suppose that the functional constraints 

 

 are qualified at the solution point of the problem. The constraints 

 

 are surely qualified, since they are linear functions. On the other hand, the Jacobian matrix of 

 is 

 a nonsingular matrix. The Karush-Kuhn-Tucker conditions at the solution point 

 for the last problem are therefore

These conditions may be rewritten in the form







In other words, we have










We rewrite these last relations in a more usual way:










These are the Karush-Kuhn-Tucker conditions for the problem considered.
For example, if we consider the problem

and 

 is a local solution of this problem, the related Karush-Kuhn-Tucker conditions are

We have seen in Chap. 4 that if f is differentiable and 

 is a local minimum point of f over the closed convex set 

 then

Being the nonnegative orthant of 

, 

 surely a closed convex set, the previous relation becomes

i.e.

 (5.15)We will now use the following technical result:


 for all 

 if and only if 

 and 

 (

).
Using this simple result it follows that (5.15) holds if and only if

 (5.16)Since 

 and 

 we can conclude that (5.16) holds if and only if

i.e. if and only if the Karush-Kuhn-Tucker conditions hold for the above problem.
Now we consider a maximization problem of the type

We recall that 

 If 

 is a local solution of the said maximization problem and the constraints 

 

 are qualified, we have therefore that the following Karush-Kuhn-Tucker conditions hold:










i.e.










For example, the problem

presents at the local optimal solution 

 the following Karush-Kuhn-Tucker conditions:

For the reader's convenience we write in Table 5.1 the Karush-Kuhn-Tucker conditions related to various reformulations of problem 

Table 5.1
Karush-Kuhn-Tucker conditions for several reformulations of problem 


 
   Problem

   K.K.T. conditions

(a)

   







(b)

   







(c)

   







(d)

   











   











   











   











   








If we have a Linear Programming Problem (see Chap. 9) of the type

where 

 

 

 and A is a matrix of order (m, n),  then 

 is a solution of the problem if and only if there exists a multipliers vector 

 such that




We now consider some "linearization properties" related to a nonlinear programming problem of the type 

 We continue to assume that the functions involved in 

 are differentiable on the open set 



Theorem 5.24
(a) Let 

 be a solution of 

 and let the constraints of 

 be qualified at 

 Then 

 is also a solution of the linearized problem

(b) Let f be pseudoconvex on the open convex set 

 and let every 

 

 be quasiconvex on X. If 

 is a solution of 

 then 

 is also solution of 




Proof
(a) Let be

i.e. 

 is the feasible set for 


Obviously, if 

 then 

 If 

 is a solution of 

 and some constraint qualification holds at 

 the usual Karush-Kuhn-Tucker conditions will be satisfied:







We have therefore 

 and, from the complementary slackness conditions, we have 

 

 


Therefore,

and

We have therefore that for every 

:

which shows that 

 is solution of 


(b) We remark that 

 as if 

 we have, for every 



being the functions 

 

 quasiconvex on the open convex set 

 If 

 is a solution of 

 we have

But, being f pseudoconvex on X and being 

 we have

   



We note that 

 is a linear programming problem and therefore, if the assumptions of Theorem 5.24 are verified, the same theorem may be a "solution test" for 


Some authors have observed that 

 is equivalent to the following problem

where 

 is a vector of "auxiliary variables" or "slack variables". This device is also known as the "squared slack variables technique" for nonlinear programming problems. See, e.g. the paper of Taylor [23]. We do not treat this question, but simply remark that it is true that the above transformation reduces a nonlinear programming problem with inequality constraints into a problem with only equality constraints ("classical constrained optimization problem"), but it is also true that the number of variables increases considerably. Moreover, the transformed problem may lose some important properties of the original problem, such as the linearity of the constraints, etc. This transformation, even if it is useful for some cases and considerations, does not get rid of treating in a specific way the case of inequality constraints. See also Bertsekas [5] for more formal considerations.
Finally, we make some considerations for the case when, in 

 besides the functional constraints 

 

 there is also an abstract constraint or set constraint,  given by a closed set 

 In other words, we have a problem of the type (we continue to assume differentiability of the functions involved in the problem)

In this case the usual Fritz John conditions of Theorem 5.5 are no longer valid and also several constraint qualifications have to be suitably modified, in order to obtain the Karush-Kuhn-Tucker conditions. The following result is proved by Barbu and Precupanu [24], Giorgi and Guerraggio [25], Nagahisa and Sakawa [26].

Theorem 5.25
Let 

 be a local solution of 

 Then, there exist multipliers 

 

 not all zero, such that

 (5.17)


where 

 is any convex subcone of 

 with vertex at 

 The case 

 is not excluded.

We remark that if it is possible to choose the largest convex subcone 

 of 

, in case 

 is not a convex cone, Theorem 5.25 will be sharper. Treiman [27] has shown that there are infinite convex subcones of the Bouligand tangent cone. In Nonsmooth Analysis one of the most used of these convex subcones is the Clarke tangent cone. See Clarke [28]. Given 

 and 

 the cone

is called Clarke tangent cone to S at 

 See also Chap. 10. This cone is closed and convex and it holds

However, in some (perhaps pathological) cases, 

 is a too small approximating cone of S at 

 The polar cone of 

 is called Clarke normal cone to S at 

 and denoted by 

 With this choice, relation (5.17) can be therefore written as

 When S is a convex set, then 

 coincides with the usual normal cone of Convex Analysis.
It follows also that if C is a closed convex set, then (5.17) becomes

where 

 is the normal cone to C at 

 (see Definition 2.​42). The same relation can be rewritten in the form

or also in the form

 (5.18)


Remark 5.26
In order to get 

 (i.e. 

) in Theorem 5.25, we have to impose some constraint qualification.
If 

 is convex and for some 

 it holds

then relation (5.17) holds with 


If 

 is (closed) and convex  and there exists 

 such that

(generalization of the Cottle constraint qualification), then relation (5.18) holds with 



For what concerns sufficient optimality conditions for problem 

 we can prove the following result.

Theorem 5.27
Let in 

 the functions 

 and each 

, 

 be differentiable convex functions on the open convex set 

 and let 

 be a closed convex set. Let 

 be feasible for 

 and assume that there exist multipliers 

 

 such that (i)


;
 (ii)


. Then 

 is a solution of 

.
 



Proof
From the condition (i) it is clear that there exists 

 such that

 (5.19)Using the fact that f and each 

 are convex (see Theorem 2.​6(d)) and also using the complementary slackness conditions (ii) and relation (5.19), along with the definition of normal cone to a convex set, we have

for all x feasible in 


Now for any feasible x, we have 

 since 

 

 This clearly shows that 

 for all feasible points x.    



Following Gould and Tolle [11], it is possible to obtain for 

 a sort of "modified Karush-Kuhn-Tucker conditions", in absence of assumptions about constraint qualifications.
Let us define the set 


The set

continues to denote the linearizing cone at 


We recall that it holds 

 i.e. 

 As 

 is a convex cone, from

we obtain

i.e.

where 

 is the cone of gradients (previously already defined):

We have therefore the following result.

Theorem 5.28
If 

 is a local solution of 

 then there exist multipliers 

 

 such that

 (5.20)





On the previous theorem the following remarks can be useful. If it holds

 (5.21)obviously relation (5.20) becomes

i.e. we obtain one of the classical Karush-Kuhn-Tucker conditions. The reader will have noted that (5.21) is the Guignard-Gould-Tolle constraint qualification referred to 

. From a "practical" point of view it is rather unlikely that this constraint qualification is satisfied in most cases (see also Bazaraa and Shetty [29]). A more convenient constraint qualification involving the Bouligand tangent cones is contained in the following result, due to Gould and Tolle [11] and Guignard [9].

Theorem 5.29
Let 

 be a local solution of 

 and let the following condition

be verified. Then, there exist multipliers 

 

 such that







The Karush-Kuhn-Tucker conditions are basic tools in the construction of many numerical algorithms for the determination of the solution or the approximate solution of a nonlinear programming problem. However, the direct application, with only "paper and pen", of these conditions may result rather complicate, even for simple problems. We present few examples, just for giving an idea of what previously expounded.

Example 5.30
Consider the problem

The problem is qualified, as the constraints are convex functions and the point 

 satisfies the Slater constraint qualification. The Karush-Kuhn-Tucker conditions (Theorem 5.8) are


(1)
First case: 

 We have (first equation): 

 (second equation): 

 Hence, we get 

 

 However 


 (2)
Second case: 

 

 We have 

 i.e. 

 From the second equation it results 

 We have two points: 

 and 

 However, from the first equation, we have 

 i.e. 

 not acceptable.
 (3)
Third case: 

 

 We have from the third condition (complementary slackness condition): 

 i.e. 

 From the first equation we get 

 From the second equation, we have 

 i.e. 

 We substitute this value in the first equation: 

 i.e. 

 from which 

 Therefore, from 

 we get 

 We have 

 with 

 and 


 (4)
Fourth case: 

 

 From the complementary slackness conditions, we have 

 from which 

 If 

 we have 

 and, from the first equation, we have 

 not acceptable. If 

 we have 

 and, from the second equation, we have 

 not acceptable. So, the unique acceptable point is 

 (see Fig. 5.2). Since the objective function and the constraints are convex, by Theorem 5.10, we have that 

 is a solution of the problem. Moreover, as the objective function is a strictly convex function, from Theorem 3.​37(b) it follows that 

 is the unique (strict) solution of the problem.
 




Fig. 5.2
Example 5.30. Feasible set and level curve for f



Example 5.31
Consider the problem

The constraints are linear and hence the problem is qualified. The Karush-Kuhn-Tucker conditions at the feasible point 

 are (see 

 in Table 5.1, p. 151):







Therefore, we have













From 

, we have 


Then, from 

, we have either 

 or 

(1)
If 

 then, from 

, we have 

 since 

. Hence, from the condition 

, we have 

 i.e. 

 not acceptable, as 


 (2)
If 

 from 

 it follows that 

 or 

.
Both equations have the solution 

, and hence from 

, we have 

 i.e. 

 
Hence, we have only a feasible point 

 that satisfies the Karush-Kuhn-Tucker conditions with 

 
As the feasible set S is compact and f is continuous on S, by the Weierstrass Theorem, the maximum is attained. Then the Karush-Kuhn-Tucker conditions are satisfied at this maximum, and as 

 is the only point satisfying these conditions, we derive that 

 solves the problem.
 



Example 5.32
Consider the problem

We remark that the feasible set (see Fig. 5.3) is closed and bounded (and so it is compact) and that the objective function is continuous.

Fig. 5.3
Example 5.32. Feasible set


The Karush-Kuhn-Tucker conditions, including the feasibility conditions, are (see 

 in Table 5.1, p. 151):





(1)
Case 

 The above conditions become 




 From these conditions we obtain the points 

 It holds 

 

 We exclude however the point 

 which is interior to the feasible set, but where 

 is indefinite.
 (2)
Case 

 

 We have the system 




 From the third condition, we have 

 From the fourth condition, we have 

 The condition 

 eliminates the zero solutions. Moreover, we have 

 and from 

 we get 

 from which we have 

 i.e. 

 The reader can verify that these values satisfy the remaining relations of the system. We have therefore the point 

 and it holds 


 (3)
Case 

 

 We have the system 

 From the third and fourth conditions we get 

 The zero solutions are not acceptable. We have 

 from which 

 Also this solution is not acceptable, as it is not feasible: 

 Therefore, the case under examination does not produce new candidates.
 (4)
Case 

 

 We have the system 

 From the fifth and sixth conditions, we have 



 

By substituting 

 in the third and fourth condition we find 

 

 Therefore, 

 is not acceptable. By substituting the point 

 we find again 

 

 Also 

 is not acceptable.
By comparison of the values assumed by f on the feasible points we have found, 

 and 

, we can conclude that the solution of the problem is

with associated multipliers 

 




Example 5.33
Consider the problem

The feasible set of this problem is drawn in Fig. 5.4.

Fig. 5.4
Example 5.33. Feasible set


We consider the Lagrangian function

We have

For 

, we have 

 and therefore we have no solution of the above relations.
The case 

 gives, with 

 

 and we have the solutions




Also the case 

 gives, with 

 

 and we have no solution of the Kuhn-Tucker conditions.
Finally, for 

 from the nonlinear equations 

 

 we get the solutions

Now, let us consider the Hessian matrix

For

we have

which is positive definite on the cone

Therefore, by Theorem 5.22, this point is a strict local minimum point of the problem.
The points

both give the matrix

This matrix is not positive semidefinite on the cone

and hence, by Theorem 5.18, these points are not local minimizers of the problem proposed.
Finally, we consider the points

As in this case, the critical cone is 

 

, These points are trivially local minimum points for the problem proposed.
By computing the values of the objective function and making the comparisons, we have that 

 is the global minimum point for the problem considered.

We propose the following problems. The reader is invited to use, when possible, the Karush-Kuhn-Tucker conditions.

Problem 5.34


(The point (0, 1) is the solution, which can be found by a geometric method. At this point the Karush-Kuhn-Tucker conditions are satisfied, with multipliers 

 

 

).


Problem 5.35


(Verify that the point 

 satisfies the Karush-Kuhn-Tucker conditions, with multipliers 

. Being the objective function convex, the above point is a global solution of the problem).


Problem 5.36
Consider the problem

and check whether the Karush-Kuhn-Tucker conditions are verified at the point (0, 1, 1).
(The above point does not verify the Karush-Kuhn-Tucker conditions and hence it cannot be a solution of the problem).


Problem 5.37
Consider the problem

Solve the problem by means of the Karush-Kuhn-Tucker conditions.
(The point (2, 1) is the solution of the problem).


Problem 5.38
Solve the problem

(The infinite points of the segment of end points (0, 0) and (6, 0) are solutions of the problem).


Problem 5.39
Use the first- and second-order conditions to solve the problem

(The points 

 and 

 are the two solutions).


Problem 5.40
Use the first- and second-order conditions to solve the problem

(The point 

 is the unique global solution).


Problem 5.41
Use the first- and second-order conditions to solve the problem

(The point (1, 1) is the unique solution).


References1.K.J. Arrow, L. Hurwicz, H. Uzawa, Constraint qualifications in maximization problems. Naval Res. Logist. 8, 175-191 (1961). Reprinted in Giorgi and Kjeldsen (2014)2.Y. Chabrillac, J.-P. Crouzeix, Definiteness and semi-definiteness of quadratic forms revisited. Linear Algebra Appl. 63, 283-292 (1984)3.F. John, Extremum problems with inequalities as subsidiary conditions, in Studies and Essays: Courant Anniversary Volume, eds. by K.O. Friedrichs, O.E. Neugebauer, J.J. Stoker (Interscience Publishers, New York), pp. 187-204. Reprinted in Giorgi and Kjeldsen (2014)4.G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (Birkhäuser, Basel and New York, 2014)5.D.P. Bertsekas, Nonlinear Programming, 2nd edn. (Athena Scientific, Belmont, Mass, 1999)6.D.P. Bertsekas, A.E. Ozdaglar, Pseudonormality and Lagrange multiplier theory for constrained optimization. J. Optim. Theory Appl. 114, 287-343 (2002)7.J.M. Abadie, On the Kuhn-Tucker theorem, in Nonlinear Programming. ed. by J.M. Abadie (North Holland, Amsterdam, 1967), pp. 21-368.H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability, ed. by J. Neyman (Univ. of California Press, Berkeley, 1951), pp. 481-492. Reprinted in Giorgi and Kjeldsen (2014)9.M. Guignard, Generalized Kuhn-Tucker conditions for mathematical programming problems in a Banach space. SIAM J. Control 7, 232-241 (1969)10.F.J. Gould, J.W. Tolle, A necessary and sufficient qualification for constrained optimization. SIAM J. Appl. Math. 20, 164-172 (1971)11.F.J. Gould, J.W. Tolle, Geometry of optimality conditions and constraint qualifications. Math. Program. 2, 1-18 (1972)12.O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)13.J. Stoer, C. Witzgall, Convexity and Optimization in Finite Dimensions, I (Springer, New York, 1971)14.J.E. Martinez-Legaz, What is invexity with respect to the same 

. Taiwanese J. Math. 13, 753-755 (2009)15.A. Ben-Israel, B. Mond, What is invexity? J. Austral. Math. Soc. Ser. B 28, 1-9 (1986)16.M.R. Hestenes, Optimization Theory. The Finite Dimensional Case (Wiley, New York, 1975)17.W.I. Zangwill, Nonlinear Programming: A Unified Approach (Prentice-Hall, Englewood Cliffs, N.J., 1969)18.G. Giorgi, B. Jiménez, V. Novo, On constraint qualifications in directionally differentiable multiobjective optimization problems. RAIRO Oper. Res. 38(3), 255-274 (2004)19.J. Kyparisis, On uniqueness of Kuhn-Tucker multipliers in nonlinear programming. Math. Program. 32, 242-246 (1985)20.K.-H. Elster, R. Reinhardt, M. Schäuble, G. Donath, Einführung in die nichtlineare Optimierung (Teubner Verlagsgesellschaft, Leipzig, BSB B. G, 1977)21.G.P. Mccormick, Second order conditions for constrained minima. SIAM J. Appl. Math. 15, 641-652 (1967). Reprinted in Giorgi and Kjeldsen (2014)22.G. Debreu, Definite and semidefinite quadratic forms. Econometrica 20, 285-300 (1952)23.J.G. Taylor, A squared-variable transformation approach to nonlinear programming. Naval Res. Logist. Quart. 20, 25-39 (1973)24.V. Barbu, T. Precupanu, Convexity and Optimization in Banach Spaces, 4th edn. (Springer, Berlin, 2012)25.G. Giorgi, A. Guerraggio, First order generalized optimality conditions for programming problems with a set constraint, in Generalized Convexity. Proceedings of the IV International Workshop on Generalized Convexity, eds. by S. Komlosi, T. Rapcsak, S. Schaible (Pecs, Hungary, Springer, Berlin, 1992), pp. 171-18526.Y. Nagahisa, Y. Sakawa, Nonlinear programming in Banach spaces. J. Optim. Theory Appl. 4, 182-190 (1969)27.J.S. Treiman, An infinite class of convex tangent cones. J. Optim. Theory Appl. 68, 563-581 (1991)28.F.H. Clarke, Optimization and Nonsmooth Analysis (Wiley, New York, 1983)29.M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economics and Mathematics Systems, vol. 122. (Springer, Berlin, 1976)30.D. Gale, The Theory of Linear Economic Models (McGraw-Hill Book Company, New York, 1960)












© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_6





6. Constrained Optimization Problems with Mixed Constraints



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es







6.1 First-Order Conditions
In this chapter, we shall be concerned with problem 

 i.e. with a constrained minimization problem with mixed constraints, i.e. with both inequality and equality constraints.

where 

 is an open set contained in the domains of the functions involved in 

 f,  

 

 and 

 

 are real-valued functions defined on 

.
We make the assumptions that f and every 

 

 are (at least) differentiable on X and that every 

 

 is (at least) continuously differentiable on X (weaker differentiability assumptions are possible).
It is quite evident that 

 subsumes the properties of 

 and 

 however, it deserves a specific treatment. For example, if we rewrite the equalities 

 

 appearing in 

 as 

 and 

 the first relation of the Fritz John conditions for this equivalent problem (see Theorem 5.​5) becomes

with multipliers not all zero and nonnegative. Unfortunately, this condition is satisfied by any feasible point of 

 by 

 

 and by 

 

 nonnegative and not all zero. The above reduction of 

 to the form of 

 is in this case of no utility, being the necessary Fritz John conditions always verified by any feasible point, and therefore meaningless.
The feasible set or set of feasible points of 

 is given by

and f is the objective function of 


The set of active constraints or effective constraints or binding constraints at 

 is

If 

 the linearizing cone of 

 at 

 (or cone of locally constrained directions of 

 at 

 is given by

Obviously, this cone is a convex polyhedral cone and hence it is closed and convex.
The cone

is called cone of relative interior locally constrained directions of 

 at 

 (or also strictly inward cone or cone of descent directions of 

 at 

).
We note that 

 is a relatively open convex cone, with respect to the subspace 

 Obviously, if 

, both 

 and 

 coincide with the said subspace. We note also that the forms of 

 

 and 

 remain quite similar to the ones defined for problem 

 howeve,r the cone of feasible directions 

 is very likely given by the singleton 

 unless the constraints 

 

 are linear affine. So, in the present chapter, we will not take 

 into consideration.

Theorem 6.1
Let 

 It holds

If the Jacobian matrix 

 has full rank (i.e. the gradients 

 

 are linearly independent), then it holds

If, moreover, 

 then





Proof
The first inclusion is proved in a similar way of what proved in Theorem 4.​38 and in Theorem 5.​3. We repeat the proof. Let be given 

 with 

 Therefore, there exist a feasible sequence 

 with 

 Hence, for all 

, the quotients

converge to 


For all 

, the quotients

converge to 


It follows that 


For the second inclusion let us assume 

 otherwise it would be 

 and the thesis is immediate from Theorem 4.​38. Then we have 

 with 

 so this vector belongs (on the grounds of the assumptions), thanks to Theorem 4.​38, to the Bouligand tangent cone to the set 

 with only equality constraints, i.e. there exists a sequence 

 belonging to this set which converges tangentially to 

 in the direction y.
As, for each active constraint, the quotients

converge to 

 we have that 

 for 

 sufficiently large. For non-active constraints at 

 the said inequality holds, thanks to continuity. The sequence 

 is therefore a feasible sequence. Hence, 


The proof of the third statement of the theorem is performed in a similar way of the proof of Corollary 5.​4.    




Remark 6.2
It is possible to prove a more complete version of Theorem 6.1, i.e. with 

, it holds: (a)


.
(This is obvious, as we have always 

).
 (b)
If 

 

 are linearly independent, then it holds 

 and if 

 then 

 This is useful in order to compare (see the next section) the Kuhn-Tucker constraint qualification and the Abadie constraint qualification for 

.
 


We are now ready to prove the Fritz John necessary optimality conditions for problem 



Theorem 6.3
(Fritz John Theorem) Let 

 be a local minimum point for 

 Then there exist multipliers ("Fritz John multipliers") 

 not all zero, such that (i)


;
 (ii)


;
 (iii)


.
 



Proof
If the vectors 

 are linearly dependent, the thesis of the theorem is trivial. Assume therefore that these vectors are linearly independent, i.e. the Jacobian matrix 

 is of full rank.
As 

 is a local minimum point for 

 it follows from Theorem 4.​24 and taking into account the second result of the previous theorem,

It holds also 

 for all those y such that 

 

 and such that 

 

 In other words, the inequality system

 (6.1)admits no solution 

 By Motzkin's theorem of the alternative (Chap. 2), there exist therefore numbers 

 

 not all zero, and 

, 

 such that

In any case, by choosing 

 for all indices 

 we obtain the thesis.    



Conditions (i), (ii) and (iii) in Theorem 6.3 are called Fritz John conditions.
It appears from the proof of the previous theorem that if the gradients 

 

 are linearly independent, then we can obtain that the multipliers 

 are not all zero. If 

 is a local solution of 

 and the gradients 

 

 are linearly independent, from the proof of the previous theorem it appears that the system (6.1) admits no solution 

 This is the Abadie linearization lemma for 

 It may be considered a (first-order) "primal necessary optimality condition" for 

 whereas the Fritz John theorem may be considered a "dual necessary optimality condition" for 


We give now another type of proof of the Fritz John necessary conditions for 

 i.e. a proof based on a "penalization technique" on the original problem. This type of proof is originally due to Mc Shane [1] and subsequently has been reconsidered and ameliorated by Bertsekas [2] and Bertsekas and Ozdaglar [3], who obtained what they call "enhanced Fritz John optimality conditions" (see Sect. 6.4).
We make the assumption that all functions involved in 

 are continuously differentiable on the open set 



Proof
of Theorem 6.3 by a penalization technique For every 

, 

 we define the function

where 


Let us consider a closed neighborhood (a closed ball) 

 centered at 

 and of radius 

 such that 

 and

The function 

 is continuous on X and 

 is a compact set contained in X. Therefore, there exists a point 

 which minimizes 

 over 

 It holds in particular

i.e.

 (6.2)The expression between parentheses on the right-hand side of (6.2) is bounded (with respect to k) and hence, taking the limit for 

 we get

The sequence 

 is in the compact set 

 hence we can consider a subsequence 

 converging to 

 We have that 

 and, by the continuity of the functions 

 and 

 we get 

 

 and 

 

 Therefore, 


But, being 

 for every index 

 (this comes from relation (6.2) since the left hand side of (6.2) is 

), taking the limit we have

It holds 

 as 

 is a minimizer of f over 

 hence 

 and so 


This reasoning holds for every convergent subsequence of 

 hence, we deduce that the sequence 

 converges to 

 when 


By starting from a certain value of k,  we have that 

 lies in the interior of 

 and therefore, by the stationary condition,

Let us denote




The vector 

 and is of Euclidean norm equal to 1 (by construction!). Moreover,

By considering a subsequence, we take the limit of the above expression:




as 

 

 and the applications 

 

 and 

 are continuous.
It is clear that 

 being the limits of nonnegative quantities are nonnegative. Finally, if 

 i. e. 

 we have 

 starting from a certain index k,  and hence 

 for 

 from which the complementary slackness conditions.    



As previously remarked for problem 

 in order to avoid that in the Fritz John conditions it holds 

 we have to impose some constraint qualification. We introduce for 

 the Guignard-Gould-Tolle constraint qualification. 
Let 

 We say that the Guignard-Gould-Tolle constraint qualification holds if

 (6.3)equality equivalent to the expression given by Guignard [4]:

We introduce also the cone of gradients for 

:

Obviously, 

 is a finite cone, i.e. a convex polyhedral cone; hence it is a closed convex set and with the same proof of Lemma 4.​1, we see that

and

We are now ready to obtain for 

 the Karush-Kuhn-Tucker optimality conditions.

Theorem 6.4
(Karush-Kuhn-Tucker) Let 

 be a local solution of 

 and let the Guignard-Gould-Tolle constraint qualification (6.3) be satisfied. Then there exist multipliers ("Karush-Kuhn-Tucker multipliers" ) 

 and 

 such that (i)


;
 (ii)


;
 (iii)


.
 



Proof
The proof is the same of the one for 

 From Theorem 4.​24, we know that 

 for every 

 whence 

 We use now the constraint qualification (6.3), i. e. the relation 

 to deduce that 


But, being 

 we get 

 Consequently, there exist 

 

 

, 

 such that

If we choose 

 for all 

 the thesis follows.    



Gould and Tolle [5] showed that (6.3) is not only a sufficient condition for the existence of Karush-Kuhn-Tucker multipliers for 

 but also necessary, in a certain sense. More precisely, the pair (g, h) is said to be Lagrange regular at 

 if for every differentiable objective function f that has a local constrained minimum at 

 there exist vectors 

 and 

 such that (i), (ii), and (iii) of Theorem 6.3 hold. It is shown by Gould and Tolle [5] that (g, h) is Lagrange regular at 

 if and only if condition (6.3) holds. See the next section. It must be observed that this question has been previously treated, for a problem of the type 

 but assuming that the feasible set 

 is a convex set, by Arrow et al. [6].
Some authors (e.g. Avriel [7] and Forst and Hoffmann [8]) follow a slightly different approach in obtaining Theorem 6.4 by assuming the Guignard-Gould-Tolle constraint qualification. We report their "steps" for the reader's convenience.

Let 

 the cone 

 is called the cone of descent directions of f at 

.

For 

, it holds 

 if and only if (i), (ii), and (iii) of Theorem 6.4 hold.
Indeed, by definition of 

 and 

, it holds that 




 By Farkas's Theorem of the Alternative (Chap. 2), we have the following equivalence: 

 if and only if there exist 

 

 and 

 

 

 such that 

 If we set 

 for 

 and 

 for 

 we obtain that 

 if and only if there exist 

 

 and 

, 

 such that (i), (ii) and (iii) of Theorem 6.4 hold.

We recall Theorem 4.​24: if 

 is a local minimizer for 

 then 




Assume the Guignard-Gould-Tolle constraint qualification (6.3). Then, if 

 is a local minimizer for 

 then the thesis of Theorem 6.4 holds. Indeed, from 

, we have, by (6.3), 

 Now 

 Indeed: 





But 

 is just equivalent to the thesis of Theorem 6.4. 


By introducing for 

, the related Lagrangian function


we can rewrite the Karush-Kuhn-Tucker conditions of Theorem 6.4 in the following form, which takes into account also the feasibility of the point 

:







Remark 6.5
(a) Let us consider the following generalization of problem 

 when some of the variables are nonnegative:

where f,  

 

 

 

 are real-valued functions defined on the open set 

 f and every 

 are differentiable on X and every 

 is continuously differentiable on X.
Let 

 be a local minimum point for the said problem and let some constraint qualification be verified at 

 Then there exist multipliers 

 and 

 such that, with

we have










(b) Consider now a minimization problem

with linear affine constraints of the type

with 

 

 and 

 matrix of order 

 

 Let 

 be differentiable on an open set 

 and let 

 be a constrained local minimum point for the above problem (as we shall see in the next section, the constraint qualifications are automatically verified in the case of linear affine constraints). Then there exist multipliers 

 

 such that
















The classical (first-order) sufficient conditions for global optimality for problem 

 are due to Mangasarian [9].

Theorem 6.6
Let 

 be a point such that, for 

 and 

 it holds







In other words, 

 u and v satisfy the Karush-Kuhn-Tucker conditions of Theorem 6.4. Let f be pseudoconvex on the open convex set 

, let every 

 

 be quasiconvex on X and let every 

 

 be quasiconvex and quasiconcave on X. Then 

 is a solution of 




Proof
It is the same proof as the one given in Theorem 5.​10, by observing that the equality constraints 

 

 can be written as 

 and 

 

 and that the negative of a quasiconvex function is a quasiconcave function (and vice-versa).    




Remark 6.7
(a) In particular, if 

, u and v satisfy the Karush-Kuhn-Tucker conditions in Theorem 6.4, f and every 

, 

 are convex on X and every 

, 

 is linear affine, then 

 is a solution of 

. Indeed, by Theorem 3.​26(i) one has that f is pseudoconvex and by Theorem 3.​26(i)-(ii), each 

, 

, is quasiconvex.
(b) Instead of the first relation of the Karush-Kuhn-Tucker conditions, in the previous theorem, we can impose the more general condition ("mimimum principle-type condition"):

(c) One of the first works concerning functions that are both quasiconvex and quasiconcave (it is used also the term "quasilinear") is the pioneering paper of Arrow et al. [6]. These authors prove the following characterization of quasilinear functions. Let 

 be defined on the convex set X. Its level set

is called maximal (resp. minimal) level set if it is the set on which f(x) attains its maximum (resp. its minimum). A set 

 will be said to be bounded by two noncrossing hyperplanes in X if there exist linear functions 

 

 not identically constant in X such that

and

Then f is both quasiconvex and quasiconcave (i.e. quasilinear) on the convex set X if and only if every level set is not minimal nor maximal is bounded by two noncrossing hyperplanes in X. See also Martos [10].
Obviously, if every 

 

 is linear affine the assumptions of Theorem 6.6 are verified. It can be proved that if 

 is differentiable on the open convex set X,  then f is quasilinear on X if and only if

Every monotone function 

 is quasilinear.

If we make use, in Theorem 6.6, of "modified" Karush-Kuhn-Tucker conditions, for what regards the multipliers 

 

 we can relax the quasilinearity assumption on equality constraints 

 

 The proof of the following result is obvious.

Theorem 6.8
Let 

 be a point such that there exist multipliers 

 and 

 such that (i)



 (ii)





 (iii)


 

 

 

 
Suppose that f is pseudoconvex on the open convex set 

 and that every 

 

 and every 

 

 is quasiconvex on X. Then 

 is a solution of 


 


If, in Theorem 6.6, we suppose that the constraint 

 with a positive multiplier 

 is quasiconvex and the constraint 

 with a negative multiplier 

 is quasiconcave (the constraint 

 with a zero multiplier obviously can be any), again we obtain that 

 solves 

 if the Karush-Kuhn-Tucker conditions hold at 


It is also possible to obtain first-order global sufficient optimality conditions for 

 by means of Fritz John conditions (instead of Karush-Kuhn-Tucker conditions). We need the following definition.

Definition 6.9
The function 

 defined on the open convex set X is said to be strictly pseudoconvex on X if, for every 

 with 

:

i.e.




This class of generalized convex functions does not contain the class of differentiable convex functions, but does contain the class of (differentiable) strictly convex functions. Obviously, the class of strictly pseudoconvex functions is contained in the class of pseudoconvex functions.

Theorem 6.10
Let in 

 the objective function f be pseudoconvex on the open convex set 

 let every 

 

 and every 

 

 be strictly pseudoconvex on X;  let 

 satisfy the following modified Fritz John conditions: (a)



 (b)





 (c)


 

 
Then 

 solves 


 



Proof
Owing to the complementary slackness conditions, relation (a) of the theorem can be rewritten as

Applying Gordan's theorem of the alternative (Chap. 2, p. 44) we have that there does not exist any 

 such that

 (6.4)Therefore, the system

 (6.5)has no solution 

 Indeed, if there did exist a solution 

 (

) then, thanks to the assumptions,

(by pseudoconvexity of f);




(by strict pseudoconvexity of g and h).
But this violates (6.4), which has no solution 

 Recalling that 

 

 we have from (6.5) that

has no solution 

 Hence, 

 is an optimal solution of problem 

 being 

.    




Remark 6.11
It is worthwhile to make the following considerations. Let be given the problems







Let 

 be the feasible set of 

 

 Let 

 be a sufficient condition for 

 to be a solution of 

 

 Clearly

 (6.6)Then it follows trivially from (6.6) that

 (6.7)is a sufficient condition for 

 to be an optimal solution of 

 If 

 in (6.7) is well known, then the sufficient condition (6.7) requires no further investigation and proof.

We give now a local first-order sufficient optimality condition, due to Fritz John, for 

 which works in absence of generalized convexity assumptions and also for the "degenerate case" of 

 (see the similar conditions for 

 in Theorem 5.​12).

Theorem 6.12
Let 

 be a point satisfying the Fritz John conditions:









 not all zero.
If the vectors

span 

, i.e. the matrix formed by the above vectors has rank n,  then 

 is a local minimizer of 




Proof
Suppose that 

 is not a local minimizer of 

 Then, there exists a feasible sequence of points 

 satisfying 

 Writing 

 with 

 

 we have







Since 

 we can assume, by taking a subsequence if necessary, that 

, 

 Dividing both sides of all equalities and inequalities above by 

 and letting 

 gives 

 

 

 and 

 


Since

we have







By virtue of our assumption on the gradient vectors, the vector y is orthogonal to every vector in 

 This implies 

 contradicting 

.    



Another first-order sufficient condition for the local optimality of 

 is given in the following "primal" condition given by Still and Streng [11].

Theorem 6.13
Let 

 and suppose that there is no nonzero solution 

 to the system

then 

 is a strict local minimizer of order one for problem 

 i.e. there exist 

 and a number 

 such that




A first-order sufficient condition for local optimality of 

 in terms of "dual" conditions is given by Hestenes [12], Theorem 7.2. See also Giorgi, Jiménez and Novo [13].

Theorem 6.14
Let 

 and suppose that 

 satisfies the Karush-Kuhn-Tucker conditions of Theorem 6.4. Suppose further that there is no vector 

 

 such that 

 Then 

 is a strict local minimizer of order one for problem 




Proof
We have previously proved that the inequality

holds for every 

 if and only if 

 satisfies the Karush-Kuhn-Tucker conditions (it is a direct consequence of Farkas' theorem). In virtue of this assertion, our hypotheses imply

for every 

 

 But being 

 we have therefore

By Theorem 4.​25, this states that 

 is a strict local minimizer for 

 more exactly (Hestenes [12]), 

 is a strict local minimizer of order one for 

.    





6.2 Constraint Qualifications
In this section, we review the most used constraint qualifications for problem 

 The Guignard-Gould-Tolle c. q., the Abadie c. q. and the Kuhn-Tucker c. q. seen in the previous chapter are simply generalized to problem 

 Let 


(1) Guignard-Gould-Tolle constraint qualification. It is expressed as

or, equivalently,

(2) Abadie constraint qualification. It is expressed as

We shall see in the present section that the Guignard-Gould-Tolle c. q. is, in a certain sense, the weakest constraint qualification for 

 The following example shows that the Guignard-Gould-Tolle c. q. may be strictly weaker than the Abadie c. q.

Example 6.15
Consider the problem

The global minimizer is 



Hence, the Abadie c. q. is violated at 

 On the other hand, we have

and hence the Guignard-Gould-Tolle c. q. is satisfied at 

 Note, however, that the Abadie c. q. (and hence the Guignard-Gould-Tolle c. q.) is satisfied at any other feasible point of the problem.

(3) Kuhn-Tucker constraint qualification or Karush-Kuhn-Tucker constraint qualification. It is expressed as

For what said about the cones 

 and 

 we have obviously

(4) Mangasarian-Fromovitz constraint qualification (MF c. q.). It is expressed as: (i)
The gradients 

 

 are linearly independent.
 (ii)
It holds 

 i.e. the system 

 has a solution 


 

This constraint qualification can be also expressed in the following equivalent form: The gradients 

 

 are linearly independent and 


The Mangasarian-Fromovitz c. q. has also a "dual" representation, given in the following result.

Theorem 6.16
Let 

 then the Mangasarian-Fromovitz constraint qualification is equivalent to the positive linear independence of the vectors

That is, the only solution of the linear system

is the zero vector.


Proof
Let us suppose that the Mangasarian-Fromovitz c. q. is satisfied. If the system of Theorem 6.16 admits a solution with 

 for some 

 by using the theorem of the alternative of Motzkin (Theorem 2.​31) we obtain at once a contradiction with the Mangasarian-Fromovitz c. q. Let us suppose that the linear system in question admits a solution with 

 for all 

 but 

 for some 

 In this case, the gradients 

 

 are linearly dependent, and again we obtain a contradiction with the Mangasarian-Fromovitz c. q.
Vice versa, let us suppose that the linear system of the theorem admits only the zero solution. In particular, the system has no solution 

 for some 

 Again by using the theorem of Motzkin, we obtain that there exists 

 that satisfies the Mangasarian-Fromovitz c. q. Indeed, the vectors

are linearly independent, as, if not, there would exist some 

 such that 

 against the assumption that the linear system of the theorem has the zero solution only (by choosing 

 

).    



The Mangasarian-Fromovitz c. q. is also called No Nonzero Abnormal Multiplier Constraint Qualification or also Basic Constraint Qualification. Note that in absence of equality constraints, the Mangasarian-Fromovitz c. q. is equivalent to the Cottle c. q. or Arrow-Hurwicz-Uzawa c. q., seen for 

 The Mangasarian-Fromovitz constraint qualification is a stable constraint qualification, in the following sense. If this qualification holds at 

 then there exists a neighborhood 

 such that the same constraint qualification holds at each 


We shall see in the sequel another important property of the Mangasarian-Fromovitz c. q. For what previously said in Theorem 6.1 and in Remark 6.2, we have the following implications:




For a more detailed proof of the above implications, the reader can see the paper of Still and Streng [11].
Similarly to what done in Chap. 5 for problem 

 we can relax the Mangasarian-Fromovitz c. q. by introducing the second Abadie c. q. and the second Arrow-Hurwicz-Uzawa c. q.
(5) Abadie constraint qualification II. It is expressed as: the vectors 

 

 are linearly independent and 

 where

(6) Arrow-Hurwicz-Uzawa constraint qualification II (AHU c. q. II). It is expressed as: the vectors 

 

 are linearly independent and 

 where, with 

 open convex set,

Obviously, if all functions 

 

 are linear (affine), and the gradients 

 

 are linearly independent, then the Abadie constraint qualification II holds automatically and if all functions 

 

 are pseudoconcave and the gradients 

 

 are linearly independent, then the Arrow-Hurwicz-Uzawa constraint qualification II holds automatically.
We have the following implications.

(7) Slater constraint qualification. 
In its extended form it is expressed as: every 

 

 is pseudoconvex and every 

 

 is quasilinear (i.e. quasiconvex and quasiconcave) on the open convex set 

 the gradients 

 

 are linearly independent and there exists 

 such that 

 

 and 

 



Theorem 6.17
The Slater c. q. implies the Mangasarian-Fromovitz c. q.


Proof
Let 

 We only need to prove that it holds 

 for all 

 For each 

 and all 

 we have

because 

 is quasiconvex. Note that 

 is also quasiconcave, hence

Consequently, 

 By the Taylor's expansion of 

 at 

 we have

as 

 Similarly to the proof of Theorem 5.​17, we can prove that 

 

 Therefore, 

 and so 

 The Mangasarian-Fromovitz c. q. is therefore satisfied.    



Note that if in 

 the constraints 

 

 are linear affine, with the gradients 

 linearly dependent, we can always choose a linearly independent subset of this set, say 

 such that

Moreover, keeping only the constraints 

 in the formulation of 

 does not change its feasible set. That's why some authors (e.g. Bazaraa and Shetty [14]) formulate the extended Slater c. q. for 

 by assuming that the functions 

 

 are linear affine, without mentioning the linear independence of their gradients. Therefore, we can assert that if in 

 all functions 

 

 and all functions 

 

 are linear affine, the problem is automatically qualified. Again, for a Linear Programming Problem, with both inequality and equality constraints, no constraint qualification is needed.
(8) Linear Independence constraint qualification (LI c. q.). It is expressed as: the gradients

are linearly independent.
Owing to the "dual" characterization of the Mangasarian-Fromovitz c. q. (Theorem 6.16), we have the following implication:

(9) Constant Rank constraint qualification (CR c.q.). It was introduced by Janin [15] and is expressed as follows: there exists a neighborhood 

 of 

 such that for every pair of subsets 

 and 

 the set of gradients

has the same rank for all 


It appears that the rank in question depends on the choice of 

 and 

 but not on the point 

 Clearly, the Linear Independence c. q. implies the Constant Rank c. q. Linearity of all constraints of 

 also implies the Constant Rank c. q. The constant Rank c. q. is indeed a constraint qualification: Janin [15] proved that this constraint qualification implies the Abadie c. q. However, the Constant Rank c. q. is neither weaker nor stronger than the Mangasarian-Fromovitz c. q.
Note also that, unlike the Mangasarian-Fromovitz c. q., if the Constant Rank c. q. holds at 

 it will continue to hold if any of the equality constraints 

 were to be replaced by the two inequalities 

 and 


(10) Constant Positive Linear Dependence constraint qualification (CPLD c. q.).  It was introduced by Qi and Wei [16] and is expressed as follows: there exists a neighborhood 

 of 

 such that whenever for some index set 

 and 

 the system

has a nonzero solution, the set

is linearly dependent for all 


Comparing the dual form (Theorem 6.16) of the Mangasarian-Fromovitz c. q. with the above constraint qualification, it is immediate that

It can be proved that the Constant Positive Linear Dependence c. q. is indeed a constraint qualification, as it implies the Abadie c. q. (Andreani et al. [17]). It can be also proved that CPLD c. q. is weaker than the Constant Rank c. q. Hence,

and

The Mangasarian-Fromovitz constraint qualification is a necessary and sufficient condition in order that the set of Karush-Kuhn-Tucker multipliers for 

 at 

 is a closed and bounded set. This result is due to Gauvin [18]. Let us denote by 

 the set of Karush-Kuhn-Tucker multipliers for 

:

We have the following result.

Theorem 6.18
Let 

 and let 

 Then 

 is closed and bounded (more precisely: a compact convex polyhedron, i.e. a polytope) if and only if the Mangasarian-Fromovitz c. q. holds at 




Proof
Let us first suppose that the Mangasarian-Fromovitz c. q. is satisfied at 

 As the set of multipliers is a polyhedron, it is closed and convex. It remains to prove that 

 is bounded. Let us suppose absurdly that 

 is not bounded, i.e. there exists a sequence 

 such that 

 for 

 and that for every k

By choosing, if necessary, a subsequence, we can assume that

If we divide both members of the last equality by 

 and take the limit for 

 we get

But this relation contradicts the dual characterization of the Mangasarian-Fromovitz constraint qualification (Theorem 6.16).
Now, suppose that 

 is bounded. If the Mangasarian-Fromovitz c. q. is not satisfied, thanks to Theorem 6.16, there will exist a nonzero vector 

 

 such that

Let 

. In particular, it will hold

For every 

, we have 

 and

In other words, the multipliers vector 

 is a Karush-Kuhn-Tucker multipliers vector. Being 

 if we choose 

 and arbitrarily large, we get that 

 is not bounded, in contradiction with our assumption.    



Another question related to a "modified" Mangasarian-Fromovitz c. q. is the uniqueness of Karush-Kuhn-Tucker multipliers for an optimal solution 

 In other words: when 

 is a singleton? The question has been solved by Kyparisis [19] who introduced what he calls the Strict Mangasarian-Fromovitz c. q.
The Strict Mangasarian-Fromovitz constraint qualification (Strict MF c. q.) holds at 

 if, denoting by 

 the set of strictly active inequality constraints at 

 i.e.

it holds: (i)
The gradients 

 are linearly independent.
 (ii)
The system 

 has a solution 


 

Obviously, we have

We note however that the Strict Mangasarian-Fromovitz c. q. is not properly a constraint qualification, as it involves the sign of the multipliers in its definition. Usually, these multipliers depend also on the objective function and not only on the constraints. Perhaps a better name would be "Strict Mangasarian-Fromovitz regularity condition".
Similarly to what holds for the Mangasarian-Fromovitz c. q., we have the following "dual" characterization of the Strict Mangasarian-Fromovitz c. q. For brevity, in the summation symbols, we denote 

 by 

 and 

 by 



Theorem 6.19
The Strict Mangasarian-Fromovitz c. q. holds at 

 if and only if there exist no vector 

 

 

 

 such that

 (6.8)



Proof
We rewrite as follows the Strict Mangasarian-Fromovitz c. q.: (a)
The gradients 

 are linearly independent.
 (b)
(By Motzkin's theorem) there is no vector (s, t, v),  

 

 such that 



 

We now show the equivalence between (6.8) and (a) and (b). Assume absurdly that there exists a multipliers vector 

 with 

 such that (6.8) holds. We have two cases: (i)


 but this is in contradiction with (b).
 (ii)


 then it holds 

 but this is in contradiction with (a).
 

Conversely, let us absurdly suppose that

are linearly dependent, i.e. there exist multipliers vectors 

 such that

If we set 

 then there exists 

 such that

But this contradicts the assumptions on relation (6.8).    




Theorem 6.20
The set 

 of Karush-Kuhn-Tucker multipliers associated to the optimal point 

 is a singleton if and only if the Strict Mangasarian-Fromovitz c. q. is satisfied at 




Proof
Let us suppose that the Strict Mangasarian-Fromovitz c. q. is satisfied. Let 

 be a pair of Karush-Kuhn-Tucker multipliers vectors, and let, as usual,




If there exists another pair 

 with 

 then

with 

 and 

 for 

 But this contradicts the validity of the Strict Mangasarian-Fromovitz c. q., on the grounds of Theorem 6.19.
Conversely, if 

 is the unique pair in 

 it is easy to verify that there does not exist a nonzero solution of relation (6.8), which is equivalent to say that the Strict Mangasarian-Fromovitz c. q. is satisfied.    



Another question related to the set 

 of Karush-Kuhn-Tucker multipliers is the following one: obviously 

 depends a priori on the point 

 When 

 is independent of the choice of 

? If 

 is a convex problem, in the sense specified by the next definition, then the set 

 does not depend on the minimum point 



Definition 6.21
Problem 

 is a convex problem if 

 and every 

, 

 are convex functions on the open convex set 

 and every 

, 

 is a linear affine function.


Theorem 6.22
Let 

 be a convex problem. The set 

 is the same for all minimum points of f on 




Proof
Clearly 

 is a convex set. Let 

 be two minimum points of f on 

 and let 

 and 

 be the two related sets of Karush-Kuhn-Tucker multipliers. Let us verify that 

 According to the fact that these points are global minimum points (f is convex) one has 

 Let 

 Then

with 

 

 for every 

 The convex Lagrangian function 

 is minimized at 

 on X,  therefore 

 which implies

Taking into account the signs of the multipliers 

 and of 

 we have that 

 for every 

 From

we get that 

 is a minimum point for the convex function 

 on X. Hence,

We have that 

 The inclusion 

 is therefore proved. The converse inclusion follows by exchanging 

 and 

 in the above proof.    



We have previously asserted that if the Guignard-Gould-Tolle constraint qualification holds, i.e.

 (6.9)then, any differentiable objective function f having a local minimum over 

 at 

 satisfies the Karush-Kuhn-Tucker conditions at 

:

 (6.10)We have also, more than one time, asserted that (6.9) is, in a certain sense, the weakest constraint qualification that guarantees that the above Karush-Kuhn-Tucker conditions will hold at a minimizer 

 In order to be more precise, we introduce the following definition, due to Gould and Tolle [5], but anticipated for problem 

 by Arrow et al. [6].

Definition 6.23
The pair (g, h) of problem 

 is said to be Lagrange regular at 

 if and only if for every objective function f,  with a constrained local minimum at 

 the Karush-Kuhn-Tucker conditions hold at 



Gould and Tolle [5] show that the pair (g, h) is Lagrange regular at 

 if and only if the Guignard-Gould. Tolle c. q. (6.9) holds. In other words, for any given objective function f(x) with a local minimum over 

 at 

 if the Karush-Kuhn-Tucker conditions (6.10) hold, we can claim that (6.9) holds.

Theorem 6.24
Let 

 Then the constraint qualification 

 is equivalent to the fact that the pair (g, h) is Lagrange regular at 




Proof
To prove the above theorem we only need to show that 

, since the converse inclusion is always true. We will show that for each 

 there corresponds an objective function f which is differentiable at 

 and has a local minimum over 

 at 

 with the property that 

 But from the Karush-Kuhn-Tucker conditions we have

where 

 

 Hence, 


We follow closely the proof of Haeser and Ramos [20] who amend some minor inaccuracies of the original proof of Gould and Tolle. Another proof is given by Bazaraa and Shetty [14].
Then, let 

 

 The Lagrange regularity assumption implies 

 Let us define 

 

 a cone of nonzero directions which form with y an angle between 0 and 

 Then, for every 

 there exists 

 such that 

 Indeed, if there would exist k such that 

 

 then

Taking the limit in 

 for a subsequence, we would have 

 with 

 which contradicts the fact that 


Let us define 

 and 

, 

 Let us assume, without loss of generality, that 

 and 

 moreover, let us define 

 in a subspace orthogonal to y,  in the following way:

We remark that P is piecewise linear and continuous. Moreover, for 

, we have

This fact is a geometric property of affine and increasing functions which have a negative value at the origin. It shows that P is differentiable at the origin, with 

 Let now be 

 defined by 

 where 

 and let us prove that f has a local minimum over 

 at 


Let be 

, with 

 As 

 and 

 it is sufficient to show that 

 If 

 in case 

 we would have that d is a positive multiple of 

 which contradicts the fact that 

 Hence, 

 being 

 there exists 

 such that 

 Therefore, 

 Note that 

 is equivalent to say that 

 Being 

 we have 

 Assuming 

 as in the opposite case the result is trivially verified, we have

Hence, 

. Being 

, we have 

. It follows that 

 Being 

 and 

 for 

 sufficiently small, it follows from the assumptions that 

 satisfies the Karush-Kuhn-Tucker conditions, i.e. 

.    



We wish to stress that the Lagrange regularity of (g, h) of problem 

 is intended with regard to all differentiable objective functions having at 

 a local minimum point. It is therefore possible to find examples where the Guignard-Gould-Tolle constraint qualification does not hold, yet the Karush-Kuhn-Tucker conditions hold at an optimal point 

 of f over 



Example 6.25
Let us consider the problem

The point 

 is a global minimum point of f over the feasible set, the Guignard-Gould-Tolle c. q. is not satisfied at 

 but at 

 the Karush-Kuhn-Tucker conditions hold.

Following Forst and Hoffmann [8], further insights on the Karush-Kuhn-Tucker conditions and on the Guignard-Gould-Tolle c. q. can be obtained by "linearizing" problem 

 Let us consider the following linearized version of 



The feasible set of 

 will be denoted by 

 If a local minimizer 

 of 

 also solves 

 then the Karush-Kuhn-Tucker conditions for 

 are met and hence also for 

 since the gradients that occur are the same in both problems. The following example, due to Forst and Hoffmann, shows that the converse of the above assertion is not true.

Example 6.26
Let us consider the problem, with 

:

It is seen that 

 yields the global minimum for the problem. The related linearized problem is

with feasible set 

 The linearized objective function 

 is not even bounded from below on 



We can rewrite problem 

 by removing the value 

 and by using only the set of the active inequalities at 

 i.e.

being of course 

 



Lemma 6.27
Let 

 then 

 is a solution of 

 if and only if 

 is a solution of 




Proof
Let us denote by 

 the feasible set of 

 If 

 is a solution of 

 then 

 holds for 

 Since 

 

 is also a solution of 


If conversely 

 is a minimizer of 

 then 

 hence 

 holds for 

 Let 

 we consider the vector

with 

 It holds that

and for 



 For 

 we have 

 and thus for t sufficiently small

 Hence, for such t the vector u(t) is in 

 consequently

and thus

hence 

 Since we have chosen 

 arbitrary, 

 yields a solution to 

    



With the transformation 

 we obtain the following formulation of problem 

:




Lemma 6.28
Let 

 then 

 is a solution of 

 if and only if 

 is a solution of 




Proof
Obviously, on the grounds of Lemma 6.27.    



We remark that the feasible set of 

 is the linearizing cone 

 of 

 at 


The following proposition clarifies the role of the various linearized problems with respect to the Karush-Kuhn-Tucker conditions for 

 Let 

 we recall that the cone

is the cone of descent directions of f at 

 already considered in the present section when we discussed how to obtain the Karush-Kuhn-Tucker conditions from the Guignard-Gould-Tolle constraint qualification.

Theorem 6.29
Let 

 then the following assertions are equivalent: (a)


 is a solution of 


 (b)


 is a solution of 


 (c)


 is a solution of 


 (d)



 (e)



 (f)
The Karush-Kuhn-Tucker conditions hold at 


 


The equivalence of the previous assertions has already been proved in the present section.
We recall once more that if 

 is a local solution of 

 then

being, moreover, 

 i.e. 

 Therefore, if it holds

i.e. the Guignard-Gould-Tolle c. q. holds at 

 then the Karush-Kuhn-Tucker conditions hold at 

 (points (d) and (f) of the previous theorem).
We conclude this section with a couple of examples.

Example 6.30
Consider the problem







The feasible set is given by the segment with end points A and B,  with respective coordinates

It is seen that, in all interior points of the said segment, only the equality constraint is active and it holds 

. At the end points of the segment, A and B,  both constraints are active and the independence constraint qualification is satisfied. We have

The Karush-Kuhn-Tucker conditions are

and the feasibility conditions are




The case 

 is excluded, as it leads to the relation 

 which contradicts the inequality constraint. Let therefore be 

 We obtain the two solutions

with multipliers

The multiplier 

 is negative and therefore must be rejected. Therefore, we have the solutions

which give the unique constrained global minimum point, whose existence is assured by the Weierstrass theorem (the objective function is continuous and the feasible set is compact). Obviously, in this case, the use of the Karush-Kuhn-Tucker conditions could be avoided.


Example 6.31
Consider the problem

It is quite easy to check that the feasible set is closed and bounded and that the constraints are qualified. The Karush-Kuhn-Tucker conditions are

and the feasibility conditions are




We obtain that the point 

 with multipliers 

 

 is the global minimizer of the problem; the point 

, with multipliers 

 

, is a constrained local minimizer.



6.3 Second-Order Conditions
We give in this section second-order necessary and second-order sufficient optimality conditions for problem 

 i.e. for the problem of the form

where X is an open set and the functions involved in 

 are twice-continuously differentiable on X.
First, we introduce three polyhedral cones, related to second-order optimality conditions for 

 We recall the following index sets previously defined:







We define, with 









Being 

 we have

If the Strict Complementary Slackness Conditions hold at 

 i.e. in the Karush-Kuhn-Tucker conditions 



 then obviously

The cone 

 is often called critical cone or cone of critical directions at 


In the literature another description of the cone 

 often appears; it is the cone (again called "critical cone"):

Indeed, it can be proved that, under the validity of the Karush-Kuhn-Tucker conditions at 

 the two cones 

 and 

 coincide.

Theorem 6.32
Let 

 verify the Karush-Kuhn-Tucker conditions. Then





Proof
We first show that 

 Let 

 clearly, we only need to show that, for 

 we have 

 By the Karush-Kuhn-Tucker conditions, we have that

Because 

 

 and 

 for 

 we have

Because 

, and every 

 for all 

 we have

Now we prove that 

 Let y be any point in 

 It suffices to show that 

 As before, we have

Clearly, 

 because all other terms are zero.    



Another critical cone is introduced in the analysis of second-order optimality conditions and usually when second-order necessary conditions of the Fritz John-type are considered. It is the cone defined as follows (

):

 (6.11)Obviously, 

 We may call 

 the extended critical cone at 

 We point out the following result.

Theorem 6.33
Let 

 be a local minimum point for 

 Then the Fritz John conditions are satisfied at 

 with 

 if and only if 




Proof
If 

 there will exist 

 such that

 (6.12)We write the first basic Fritz John relation:

Multiplying this relation by y,  we have that 

 On the other hand, if 

 we conclude that system (6.12) has no solution 

 From Farkas' theorem (Theorem 2.​28), we deduce the existence of multipliers 

 

 

, 

 such that

   



We recall that if 

 is a local solution of 

 and a constraint qualification is satisfied, then there exist multipliers 

 

 and 

, 

 with 

 

 such that

We recall again the definition of the index set 

:

Let us introduce the set

If we consider the usual Lagrangian function for 



we have, due to the complementary slackness conditions,

As 

 is a local solution of 

 this point is also a local solution of the problem

But, thanks to the Karush-Kuhn-Tucker conditions, we have 

 and therefore Theorem 4.​26 applies. We obtain the following second-order necessary optimality conditions for 



Theorem 6.34
Let 

 be a local minimum point of 

 and let some constraint qualification be verified; then there exists a triplet 

 which satisfies the Karush-Kuhn-Tucker conditions and moreover we have

 (6.13)


Now, if the Abadie constraint qualification, referred to the set Q,  holds, i.e. if

 (6.14)(note that 

 is the linearizing cone of Q at 

), then obviously (6.13) can be written as

 (6.15)which is one of the classical second-order necessary optimality conditions for 


When is equality (6.14) satisfied? The following result gives sufficient conditions for the validity of (6.14).

Theorem 6.35
If at 

 the Linear Independence constraint qualification is satisfied or even the more general Strict Mangasarian-Fromovitz constraint qualification is satisfied (and hence 

 is a singleton), then (6.14) holds and therefore (6.13) can be substituted by (6.15).

The proof follows, mutatis mutandis, from the proof of Theorem 5.​19 and will not be repeated here.
Note that the Linear Independence c. q. and the Strict Mangasarian-Fromovitz c. q. are not only first-order constraint qualifications, but also second-order constraint qualifications which permit to obtain relation (6.15). This is not the case, as we shall see next, for the Mangasarian-Fromovitz constraint qualification.
Being 

 obviously a second-order necessary optimality condition weaker than (6.15) is

This condition appears in the paper of McCormick [21] and in Fiacco and McCormick [22]. It has the advantage to be tested by means of the results on the sign of a quadratic form constrained by a linear homogeneous equations system (see Chap. 1, Chabrillac and Crouzeix [23], Debreu [24]).
A second-order constraint qualification for 

 is considered in the pioneering paper of McCormick [21] and also in McCormick [25, 26].

McCormick Second-Order Constraint Qualification.


This constraint qualification holds at 

 if for all 

 y is the tangent of a twice differentiable arc 

 where for some 

:

and 

 


McCormick proves that if a first-order constraint qualification and the above second-order constraint qualification hold at the local optimal point 

 then, besides the Karush-Kuhn-Tucker conditions, also condition (6.15) holds.
McCormick shows, by numerical examples, that his second-order c. q. does not assure the validity of the Karush-Kuhn-Tucker conditions, i.e. the McCormick second-order c. q. is not a first-order c. q. On the other hand, the Linear Independence c. q. and the Strict Mangasarian-Fromovitz c. q. assure the validity of the McCormick second-order c. q., but this is not the case, for example, of the Mangasarian-Fromovitz c. q. or of the Kuhn-Tucker c. q. (for this last case McCormick [21] gives a numerical example).
Fiacco and McCormick in an unpublished paper of 1968 (A. V. Fiacco and G. P. McCormick, Asymptotic conditions for constrained minimization, RAC-TP-340, 1968, Research Analysis Corporation, McLean, Virginia) and subsequently McCormick [26] give for 

 also a second-order necessary optimality conditions of the Fritz John-type.

Theorem 6.36
Let 

 be a local minimum point of 

 Then, at 

 besides the (first-order) Fritz John conditions with multipliers 

 it will hold the following second-order necessary conditions:

 (6.16)where 




Proof
It is enough to prove (6.16) for 

 with 

. Then there exists a sequence 

 such that 

 (see Definition 2.​34), i.e. 

. Observe that 

 for all 

 Then, for k sufficiently large we have 

 Hence, for k sufficiently large 

 is feasible for 

 For k sufficiently large

Therefore,

 (6.17)Note that, for every 

, we have 

 Therefore, for each 

, we have

 (6.18)Again we have 

 for all 

 Therefore, for all j, one has

 (6.19)Using (6.17), (6.18), (6.19) and the Fritz John conditions, one can easily establish that

 (6.20)Dividing the expression (6.20) throughout by 

 and proceeding to the limit as 

 we have, since 

 for all 



i.e. the thesis of the theorem.    



Obviously, if 

 we can express (6.16) with reference to the critical cone 

 It is not difficult to prove that if the Second-Order McCormick c. q. holds at 

 then 

 in relation (6.16). See McCormick [26].
It is also possible to obtain second-order necessary optimality conditions of the Fritz John-type which make reference to the extended critical cone 

 However, in this case, the Fritz John multipliers which appear in 

 are not necessarily fixed. The following result (Theorem 6.39) is due to Ben-Tal [27], previously we need a lemma and we do a comment.

Lemma 6.37
Let 

 and 

. Suppose that the gradients 

, 

, are linearly independent. Then if 

 satisfies

 (6.21)where 

, then there exist a positive number 

 and a curve 

 such that

 (6.22)


Its proof, which is based on the inverse function theorem, can be seen in Still and Streng [11], Lemma 2.1.

Remark 6.38
If the gradients 

, 

, are linearly independent and condition (6.21) holds for some 

, it is said that the second-order Mangasarian-Fromovitz c. q. is satisfied at 

. This condition is implied by the (first-order) Mangasarian-Fromovitz c. q. Indeed, as 

, 

, are linearly independent, for a given 

, there exists 

 such that

Then, for a vector z satisfying the first-order Mangasarian-Fromovitz c. q., i.e. 

, 

 and 

, 

, putting 

, we find that

for 

 large enough, i.e. 

 is a vector satisfying (6.21).


Theorem 6.39
Let 

 be a local minimizer for problem 

 Then, for any 

 (see (6.11)), there are multipliers 

 not all zero, 

 such that the Fritz John conditions (see Theorem 6.3) are satisfied at 

 and, moreover,

 (6.23)


The reader is invited to remark the structure of the previous theorem and its different form with respect to the previous ones. An example of an optimization problem where, at a minimizer 

 different multipliers are really necessary to get (6.23), can be found in Ben-Tal [27], Example 2.1. The proofs of Theorem 6.39 given by Ben-Tal [27] and by Still and Streng [11] are based on several lemmas. We follow the soundproof of Bonnans and Shapiro [28].

Proof
of Theorem 6.39 (Bonnans and Shapiro) Let 

 If the gradients 

 

 are linearly dependent, then there exists 

 such that 

 Hence, 

 or 

 are Fritz John multipliers which satisfy the (first-order) Fritz John conditions. If (6.23) is satisfied with 

 there is nothing else to prove. Otherwise, since 

 is another Fritz John multipliers vector, and

we have that (6.23) is satisfied by 

. Therefore, for any 

 we can choose one of the two possibilities, so that (6.23) is satisfied.
We now assume that the gradients 

 

 are linearly independent. Consider the following linear programming problem in the variables 

:

 (6.24)where 

. The optimal value of this problem is nonnegative. Indeed, otherwise, there exists z which satisfies

 (6.25)By Lemma 6.37, there exists a path 

 satisfying conditions (6.22). Then, by a second-order Taylor expansion, we have for 

 small enough that

due to the first condition in (6.24) and the fact that 

. Therefore, for 

 small enough, 

 is feasible and 

, which contradicts the local minimality of 

. This proves that (6.24) has a nonnegative optimal value.
Since 

 

 are linearly independent, the equality constraints of (6.24) have a feasible solution because 

 and so 

, and thus there exists 

 such that 

 for all 

, and hence, since 

 can be made arbitrarily large, problem (6.24) is consistent. Therefore, (6.24) has a finite nonnegative optimal value. Since (6.24) is a linear programming problem, it follows, by the Strong Duality Theorem of Linear Programming (see Remark 9.​19), that its dual, in the variables 

 with 

 for 

, has the same optimal value. The dual of (6.24) is

subject to:







Since an optimal solution of this dual problem is a Fritz John multipliers vector associated to 

 by choosing 

 for 

 we get the thesis.    



The drawback of the previous theorem is that it may be 

 The Mangasarian-Fromovitz c. q., if verified, assures that this case cannot occur. However, even under the validity of the Mangasarian-Fromovitz c. q., we are not able to obtain the second-order necessary conditions with fixed  multipliers.

Theorem 6.40
Let 

 be a local optimal solution of problem 

 and let 

 verify the Mangasarian-Fromovitz c. q.; then, for every 

 there exist Karush-Kuhn-Tucker multipliers vectors (u, v),  

 

 

 

 such that the Karush-Kuhn-Tucker conditions are satisfied at 

 and, moreover,





Proof
It is sufficient to take into account that 

, to apply the previous theorem and to remark that the Mangasarian-Fromovitz c. q. assures 

 and hence 

 in the Fritz John conditions.    



A counterexample showing that the Mangasarian-Fromovitz c. q. is not able to assure the usual second-order necessary optimality conditions for 

 has been constructed by Arutyunov [29] and subsequently another counterexample was found by Anitescu [30]. Being 

 a convex and compact set (see Theorem 6.18), under the validity of the Mangasarian-Fromovitz c. q., it is then possible to write the thesis of Theorem 6.40 in the form

We may call "usual" second-order necessary conditions the second-order conditions with fixed multipliers and "weak" second-order necessary conditions the second-order conditions with non-fixed multipliers. The denominations are not standard!
It must be observed that if the Strict Mangasarian-Fromovitz c. q. holds at 

 then 

 is a singleton and therefore the weak second-order necessary conditions of Theorem 6.40 become the usual second-order necessary conditions previously described in Theorem 6.35. This confirms once more that the Strict Mangasarian-Fromovitz c. q. is not only a first-order constraint qualification, but also a second-order constraint qualification.
Besides the Linear Independence c. q. and the Strict Mangasarian-Fromovitz c. q., other first-order constraint qualifications have been recognized to assure the validity of the "usual" second-order necessary conditions (i.e. with fixed multipliers) for 

 Andreani, Echagüe and Schuverdt [31] have proved that under the Constant Rank Constraint Qualification, the following condition is valid (

 local solution of 

):

Also, the following result has been established by Andreani, Echagüe and Schuverdt [31]. We first introduce the notion of Weak Constant Rank Condition:
Let 

 then the weak constant rank condition holds if there is a neighborhood 

 such that the set 

 has the same rank for all 





Theorem 6.41
If 

 is a local minimizer for 

 satisfying the Karush-Kuhn-Tucker conditions (i.e. 

) and the weak constant rank condition holds, then

 (6.26)Therefore, any constraint qualification that ensures 

 in combination with the weak constant rank condition, guarantees that (6.26) holds at a local minimizer 

 for 




Remark 6.42
It is convenient to remark that the following conjectures are false.
Conjecture 1. If 

 is a local minimizer of problem 

 then the Hessian matrix 

 is positive semidefinite.
Example.




The optimal point is 

 but 

 is not positive semidefinite.
Conjecture 2. If 

 is a local minimizer of problem 

 then the Hessian matrix of the Lagrangian function 

 is positive semidefinite.
Example.

The optimal point is 

 but 

 is not positive semidefinite. Note that any feasible direction y satisfying 

 also satisfies 



Now we turn to second-order sufficient optimality conditions for 

 Taking into consideration Theorem 5.​22 we have the following second-order sufficient conditions for 



Theorem 6.43
Let 

 and let the Karush-Kuhn-Tucker conditions be satisfied by the triplet 

 If




then 

 is a strict local minimum point for 



As 

 it is possible to rewrite the previous conclusion in the more usual form

For the reader's convenience, we give a direct proof of this last result.

Theorem 6.44
Let 

 and let the Karush-Kuhn-Tucker conditions be satisfied by the triplet 

 If

 (6.27)then 

 is a strict local solution of 




Proof
The proof is indirect; let us assume that 

 is not a strict local minimum point for 

 Then there will exist a tangentially convergent sequence 

 

 with 

 and 

 for all 

 Hence, 

 and the quotients







where 

 and 

 converge to, respectively, 

, 

 and 

.
By the Karush-Kuhn-Tucker conditions (

 for all 

), we have

and each summation term is equal to zero. Then we have

Hence, 

 By considering




with 

 the quotients

converge to 

 in contradiction with the hypothesis.    



Following Hestenes [12] it is possible to reformulate the thesis of Theorem 6.44 in the following way:


 If (6.27) holds, together with the Karush-Kuhn-Tucker conditions, then the feasible point 

 is a strict local minimizer of order two for 

 i.e. there is a constant 

 and a neighborhood 

 such that

We recall the definition of the linear subspace 

:

Being 

 then we can replace in Theorem 6.44 relation (6.27) with the stronger condition

 (6.28)Indeed, this last condition is known as the strong second-order sufficient optimality condition for 

 See Robinson [32]. Note that when strict complementarity holds, the strong second-order sufficient condition and the usual second-order sufficient condition of Theorem 6.44 are equivalent. The advantage of (6.28) is that it permits the use of the results of testing the sign of a quadratic form subject to a system of homogeneous linear equations (see Chabrillac and Crouzeix [23], Debreu [24] and Chap. 1). McCormick [26] remarks that (6.28) can be expressed also in the following way. Let V be the matrix whose columns are a base of the linear space 

 Then (6.28) holds if and only if

is a positive definite matrix. See also Kelly and Kupferschmid [33].
We have to note that, contrary to what asserted in Fiacco and McCormick [22] and in McCormick [26], the conditions given in Theorem 6.44 do not assure that 

 is an isolated (i.e. locally unique) solution of problem 

 Robinson [34] provides the following counterexample in 

. See also Fiacco [35].

Example 6.45
Consider the problem

subject to: 

 


One can easily verify that the assumptions of Theorem 6.44 are verified at 

 However, every point in the set

is an isolated feasible point and therefore also a local minimum. However, 

 is not an isolated local minimum for the problem considered.

Conditions sufficient for 

 to be an isolated local minimum for 

 are obtained by Robinson [34] by strengthening the assumptions of Theorem 6.44 in two ways.

Theorem 6.46
(Robinson) Suppose that the Karush-Kuhn-Tucker conditions hold at 

 for 

 with some multipliers u and v and that the Mangasarian-Fromovitz constraint qualification holds at 

 Moreover, assume that the following General Second-Order Sufficient Conditions hold at 

:
The Second-Order Sufficient Conditions of Theorem 6.44 hold at 

 with (u, v) for every 




Then 

 is an isolated local minimum point for 

 i.e. there exists a neighborhood 

 of 

 such that 

 is the unique local minimum point for 

 in 



Note that if the Linear Independence c. q. or the more general Strict Mangasarian-Fromovitz c. q. is substituted for the Mangasarian-Fromovitz c. q. in Theorem 6.46, then the General Second-Order Sufficient Conditions of Theorem 6.46 coincide with the usual Second-Order Sufficient Conditions of Theorem 6.44, since 

 is then a singleton. Thus, under the Linear Independence c. q. or the Strict Mangasarian-Fromovitz c. q., Theorem 6.44 assures that 

 is an isolated local minimum point of 



Example 6.47
Consider the problem




There are four Karush-Kuhn-Tucker points: 

 

 

 and 

 The second-order sufficient conditions show that 

 and 

 are strict local minimizers. The second-order necessary conditions show that 

 and 

 are not local minimizers.

We have also second-order sufficient optimality conditions of the Fritz John-type (and also for the case of non-fixed multipliers; see Ben-Tal [27], Bonnans and Shapiro [28], Still and Streng [11]. In this case, the extended cone of critical directions 

 is used). The following result is given in the book of McCormick [26].

Theorem 6.48
Let 

 and suppose that 

 satisfies the Fritz John conditions for 

 with a Lagrangian function

If

then 

 is a strict local minimizer for 

 more precisely, 

 is a strict local minimizer of order two.

For what concerns second-order sufficient optimality conditions for 

 with non-fixed multipliers, we have the following results.

If 

 and for each 

 there exists 

 which together with 

, satisfy the Fritz John conditions for 

 and moreover 

 then 

 is a strict local minimizer of 

 of order two.

If 

 the set 

 of Karush-Kuhn-Tucker multipliers is nonempty and for each 

 there exists 

 such that 

 then 

 is a strict local minimizer of 

 of order two. These conditions can be also written in the equivalent form 

 where the above supremum can be 

 If the Mangasarian-Fromovitz c. q. holds at 

 (and hence 

 is compact), "sup" can be substituted by "max".


Finally, we report an interesting result of Ward [36], in which it is shown that the Strict Mangasarian-Fromovitz c. q. "closes the gap" between the (usual) second-order necessary optimality conditions and the (usual) second-order sufficient optimality conditions.

Theorem 6.49
Let 

 and suppose that the Strict Mangasarian-Fromovitz c. q. is satisfied at 

 with multipliers (u, v) such that 

 with 

 

 

 Then 

 is a strict local minimizer of order two for 

 if and only if






6.4 Problems with a Set Constraint. Asymptotic Optimality Conditions
When in problem 

 besides the functional constraints it appears also a set constraint or abstract constraint, represented by a closed set 

 the usual necessary Fritz John conditions, described in Theorem 6.3, and several constraint qualifications seen for 

 are no longer valid. Consider the following example.

Example 6.50





The point 

 is a solution of the problem, but there is no vector 

 such that

We define a new problem, 

 which contains also a set constraint 

:

where C is a closed set and the functions involved in 

 satisfy the same assumptions made for 

 The feasible set of 

 is denoted by 



One of the first papers which provides a general analysis of problem 

 is the one of Bazaraa and Goode [37]. These authors use the cone of interior directions to a set 

 at 

:

It appears that 

 is an open cone and that 

 Moreover, if 

 then 

 and if 

 is a convex set, with 

 then

The main result of Bazaraa and Goode [37] is the following one.

Theorem 6.51
Suppose that 

 is a local solution of 

 and suppose that 

 is a convex cone. Then, there exist multipliers 

 not all zero, such that (i)


;
 (ii)


;
 (iii)


.
 


Bazaraa and Shetty [14] give an example where it is shown that it is not possible to replace in (i) of Theorem 6.51 the cone 

 with the larger cone 

 in order to obtain a sharper necessary optimality condition.
The above result has been slightly improved by Giorgi and Guerraggio [38] who use an open cone larger than 

 i.e. the cone of quasi-interior directions to C at 

:

We note that when C is convex, with 

 relation (i) of Theorem 6.51 can be reformulated as

 (6.29)where 

 is the normal cone to C at 


Giorgi, Jiménez and Novo [39] have observed that (6.29) is valid even if no assumption on the convex set C is made (besides convexity). Also the approach of Gould and Tolle [40], previously reported for 

 in Chap. 5, Theorem 6.29, can be immediately fitted to 

 We continue to denote by 

 the linearizing cone for 

 at 

 We have the following result.

Theorem 6.52
Let 

 be a local solution of 

 Then there exist multipliers (u, v),  

 such that




More recently, a fruitful approach to get necessary optimality conditions for 

 has been presented by Bertsekas [2] and Bertsekas and Ozdaglar [3]. These two last authors consider, for a closed set 

 and a point 

 the Mordukhovich normal cone (see. e.g. Aubin and Frankowska [41], Rockafellar and Wets [42], Borwein and Lewis [43]; for the case of 

 closed, the definitions of these authors coincide with the following definition):

Equivalently, the graph of 

 viewed as a point-to-set mapping, 

 is the closure of the graph of 

 In general we have

The Mordukhovich normal cone is closed, however it may not be equal to 

 and in fact it may not even be a convex set. In the case where

we say that C is regular at 

 Two important properties of the regularity are: (i)
If C is convex, then it is regular at each 


 (ii)
If C is regular at some 

 then T(C, x) is convex.
 

The Mordukhovich normal cone is also called the limiting or basic normal cone (to C at 

). In this context the polar of the Bouligand tangent cone is called the Fréchet normal cone or also the regular normal cone (to C at 

) and denoted by 

 It can be shown that

We have seen that, in general, it is not possible to obtain necessary Fritz John-type necessary conditions for 

 by using the polar of the Bouligand tangent cone (i.e. the Fréchet normal cone). It is however possible to use the Mordukhovich normal cone.
We now assume that all functions involved in 

 are continuously differentiable on the open set 

 One of the basic results of Bertsekas and Ozdaglar [3] is the following one. For further considerations, see also Ozdaglar and Bertsekas [44].

Theorem 6.53
Let 

 be a local solution of 

 Then, there exist scalars 

 

 and 

 satisfying the following conditions: (i)


;
 (ii)


;
 (iii)



 (iv)
If the index set 

, where 

 and 

 is nonempty, there exists a sequence 

 that converges to 

 and is such that, for all k,  







 where 






 


Note that if C is regular at 

 i.e. 

 condition (i) of Theorem 6.53 becomes

or, equivalently,

and if C is convex (and hence regular at each its point), the previous relation becomes

It must be noted that conditions (iv) are stronger than the usual complementary slackness conditions, i.e. they imply these last ones. If 

 then according to condition (iv),  the corresponding i-th inequality constraint must be violated arbitrarily close to 

 implying that 

 Bertsekas and Ozdaglar [3] call conditions (iv) complementary violation conditions, as these further conditions state that the constraints for which the multipliers are zero are also violated but their "degree of violation" is arbitrarily small. Moreover, the value of the objective function at such nearby points is also strictly less than 

 This fact has important consequences for the use of numerical methods, such as "penalty techniques". See also Bector et al. [45] who reformulate Theorem 6.53 in a nonsmooth setting.
For what concerns conditions which assure that in Theorem 6.53 it holds 

 i.e. 

 one of them is the following one (see, e.g. Ruszczynsky [46]:
C is a closed convex set and there exists a point 

 such that, with 



 and the gradients 

 

 are linearly independent. Another one is a generalization of the Slater constraint qualification:

C is a closed convex set, the functions 

 

 are convex on C,  the functions 

 

 are linear affine, and there exists a feasible point 

 such that 

 and 

 




We conclude the present section with some considerations on asymptotic optimality conditionsfor

 The characterization of a local solution of a constrained optimization problem has traditionally be given, as in the present section and in the previous sections, in terms of the functions involved in the problem, put together to form an associated Lagrangian function, whose gradient is evaluated at the solution point for a corresponding set of finite multipliers (Lagrange multipliers, Fritz John multipliers, Karush-Kuhn-Tucker multipliers). Besides this classical approach, other treatments of constrained optimality conditions give a characterization of optimality in terms of appropriate sequences of points and multipliers. In this case, we can speak of "asymptotic optimality conditions" or "approximate optimality conditions" or also "sequential optimality conditions". There are some quite recent papers on this second approach in studying optimality conditions for a problem of the type of 

 We quote only Andreani, Martínez and Svaiter [47] and Haeser and Schuverdt [48]. We have to say that, prior to these contributions, the question was considered in an unpublished paper of Fiacco and McCormick, already quoted in the previous section (A. V. Fiacco and G. P. McCormick, Asymptotic conditions for constrained Minimization, RAC-PTP-340, Research Analysis Corporation, McLean, Virginia).
We give a short account of the asymptotic optimality conditions for 

 given by Haeser and Schuverdt [48]. Following these authors, we assume that all functions involved in 

 are continuously differentiable on the open set 



Definition 6.54
We say that the Asymptotic or Approximate Karush-Kuhn-Tucker Condition (AKKT) is satisfied at 

 if, and only if, there exist sequences 

 

 and 

 such that 



 (6.30)and

 (6.31)


It must be noted that (AKKT) implies the usual Karush-Kuhn-Tucker conditions for 

 under the Constant Positive Linear Dependence c. q. (CPLD) (see Sect. 6.2, p. 189):
(CPLD) holds at 

 if there exists a neighborhood 

 of 

 such that for 

 and 

 whenever the gradients 

 are positive-linearly dependent, then 

 are linearly dependent for every 

 (CPLD) is a constraint qualification weaker than the Mangasarian-Fromovitz c. q.; moreover, (CPLD) is also implied by the Constant Rank Constraint Qualification at 




Note, moreover, that if 

 is a local minimum point for 

 and any constraint qualification holds at 

 then (AKKT) holds at 

 for constant sequences 

 

 

 being 

 and 


Haeser and Schuverdt [48] prove the following basic result, which is a special case of a more general result of Andreani et al. [49].

Theorem 6.55
If 

 is a local minimum point for 

 then 

 satisfies the (AKKT) conditions (6.30)-(6.31).

The same authors prove that a stronger version of the (AKKT) conditions is sufficient for optimality in the case 

 is a convex problem.

Definition 6.56
A point 

 satisfies the strong (AKKT) condition (SAKKT) if there exist sequences 

 

 and 

 such that (6.30) holds and




We note that every local minimizer of 

 satisfies also (SAKKT).

Theorem 6.57
Let in 

 f and every 

, 

 be convex functions on the open convex set 

 and let every 

, 

 be linear affine. If 

 satisfies (SAKKT) and if the sequences 

 

 are such that 

 for every 

 and every 

 then 

 is a solution of 



Remark
In this chapter and in the previous ones, we have used local "first-order" cone approximations in obtaining first-order and second-order optimality conditions. However, it is possible to use (local) second-order tangent sets and (local) second-order tangent cones in order to obtain more accurate second-order optimality conditions. The literature on these questions is by now rather abundant; we quote only the works of Bonnans, Cominetti, and Shapiro [50], Bonnans and Shapiro [28], Cambini et al. [51], Cominetti [52], Giorgi et al. [53], Hachimi and Aghezzaf [54], Jiménez and Novo [55, 56], Haeser and Ramos [57], Penot [58], Ruszczynski [46]. In the said works, there are obviously many bibliographical references useful to deepen the questions. Here, we give only few hints.

The set 

 is called second-order tangent set to 

 at 

 and 

.

The cone 

 is called asymptotic second-order tangent cone to 

 at 

 and 

.
It must be observed that 

 and 

 are closed sets and that 

 is indeed a cone. Furthermore, if 

, then 

 we have also 

 In general, the second-order tangent set 

 is not a cone and it may not be convex even for a convex set 

 However, if 

 is convex and 

 then 

 and 

 See Jiménez and Novo [56].
By means of 

 and 

 it is possible to obtain second-order optimality conditions for scalar and for vector optimization problems. For example, we have the following results (see, e.g. Jiménez and Novo [56], Penot [58], Ruszczynski [46]).

Consider problem 

 i.e. 

 with 

 twice-continuously differentiable. Assume that 

 is a local optimal solution of 

 Then, for every 

 such that 

 we have the following optimality conditions: (a)


 


 (b)


 


 


Let 

 be twice-continuously differentiable, let 

 If for every 

 such that 

, one of the following conditions holds: (a)


 


 (b)


 


  where 

 denotes the orthogonal subspace to v,  then 

 is a strict local minimum point for 

 more precisely, it is a strict local minimum point of order 2 (see Jiménez and Novo [56]).



References1.E.J. McShane, The Lagrange multiplier rule. Am. Math. Mon. 80, 922-925 (1973)2.D.P. Bertsekas, Nonlinear Programming, 2nd edn. (Athena Scientific, Belmont, Mass, 1999)3.D.P. Bertsekas, A.E. Ozdaglar, Pseudonormality and Lagrange multiplier theory for constrained optimization. J. Optim. Theory Appl. 114, 287-343 (2002)4.M. Guignard, Generalized Kuhn-Tucker conditions for mathematical programming problems in a Banach space. SIAM J. Control 7, 232-241 (1969)5.F.J. Gould, J.W. Tolle, A necessary and sufficient qualification for constrained optimization. SIAM J. Appl. Math. 20, 164-172 (1971)6.K.J. Arrow, L. Hurwicz, H. Uzawa, Constraint qualifications in maximization problems. Naval Res. Logist. 8, 175-191 (1961). Reprinted in Giorgi and Kjeldsen (2014)7.M. Avriel, Nonlinear Programming. Analysis and Methods (Prentice-Hall, Englewood Cliffs, N.J., 1976)8.W. Forst, D. Hoffmann, Optimization. Theory and Practice (Springer, New York, 2010)9.O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)10.B. Martos, Nonlinear Programming. Theory and Methods (North Holland, Amsterdam, 1975)11.G. Still, M. Streng, Optimality conditions in smooth nonlinear programming. J. Optim. Theory Appl. 90, 483-515 (1996)12.M.R. Hestenes, Optimization Theory. The Finite Dimensional Case (Wiley, New York, 1975)13.G. Giorgi, B. Jiménez, V. Novo, A note on first-order conditions for Pareto problems. Numer. Funct. Anal. Optim. 29, 1108-1113 (2008)14.M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economic and Mathematics Systems, vol. 122 (Springer, Berlin, 1976)15.R. Janin, Directional derivative of the marginal function in nonlinear programming. Sensitivity, stability and parametric analysis. Math. Program. Study 21, 110-126 (A.V. Fiacco Ed.) (1984)16.L. Qi, Z. Wei, On the constant positive linear dependence condition and its application to SQP methods. SIAM J. Optim. 10, 963-981 (2000)17.R. Andreani, J.M. Martinez, M.L. Schuverdt, On the relation between constant positive linear dependence condition and quasinormality constraint qualifications. J. Optim. Theory Appl. 125, 473-483 (2005)18.J. Gauvin, A necessary and sufficient regularity condition to have bounded multipliers in nonconvex programming. Math. Program. 12, 136-138 (1977)19.J. Kyparisis, On uniqueness of Kuhn-Tucker multipliers in nonlinear programming. Math. Program. 32, 242-246 (1985)20.G. Haeser, A. Ramos, Condições de Otimalidade e Algoritmos em Optimização não Linear (Sociedade Brasileira de Matematica Aplicada e Computational, São Carlos, Brasil (available on the web, 2016)21.G.P. Mccormick, Second order conditions for constrained minima. SIAM J. Appl. Math. 15, 641-652 (1967). Reprinted in Giorgi and Kjeldsen (2014)22.A.V. Fiacco, G.P. Mccormick, Nonlinear Programming: Sequential Unconstrained Minimization Techniques (Wiley, New York, 1968)23.Y. Chabrillac, J.-P. Crouzeix, Definiteness and semi-definiteness of quadratic forms revisited. Linear Algebra Appl. 63, 283-292 (1984)24.G. Debreu, Definite and semidefinite quadratic forms. Econometrica 20, 285-300 (1952)25.G.P. McCormick, Optimality criteria in nonlinear programming, in Nonlinear Programming, eds. by R.W. Cottle, C.E. Lemke. SIAM-AMS Proceedings, vol. IX (American Mathematical Society, Providence, RI, 1976), pp. 27-3826.G.P. McCormick, Nonlinear Programming. Theory, Algoritms and Applications (Wiley, New York, 1983)27.A. Ben-Tal, Second-order and related extremality conditions in nonlinear programming. J. Optim. Theory Appl. 31, 143-165 (1980)28.J.F. Bonnans, A. Shapiro, Perturbation Analysis of Optimization Problems (Springer, New York, 2000)29.A.V. Arutyunov, Perturbations of extremum problems with constraints and necessary optimality conditions. J. Sov. Math. 54, 1342-1400 (1991)30.M. Anitescu, Degenerate nonlinear programming with a quadratic growth condition. SIAM J. Optim. 10, 1116-1135 (2000)Crossref31.R. Andreani, L.E. Echagüe, ML. Schuverdt, Constant-rank condition and second-order constraint qualification. J. Optim. Theory Appl. 146, 255-266 (2010)32.S.M. Robinson, Strongly regular generalized equations. Math. Oper. Res. 5, 43-62 (1980)33.T.K. Kelly, M. Kupferschmid, Numerical verification of second-order sufficiency conditions for nonlinear programming, SIAM Rev. 40, 310-314 (1998)34.S.M. Robinson, Generalized equations and their solutions, Part II: Applications to nonlinear programming. Math. Program. Study 19, 200-221 (1982)35.A.V. Fiacco, Introduction to Sensitivity and Stability Analysis in Nonlinear Programming (Academic, New York, 1983)36.D.E. Ward, Characterizations of strict local minima and necessary conditions for weak sharp minima. J. Optim. Theory Appl. 80, 551-571 (1994)37.M.S. Bazaraa, J.J. Goode, Necessary optimality criteria in mathematical programming in the presence of differentiability. J. Math. Anal. Appl. 40, 609-621 (1972)38.G. Giorgi, A. Guerraggio, First order generalized optimality conditions for programming problems with a set constraint, in Generalized Convexity. Proceedings of the IV International Workshop on Generalized Convexity, eds. by S. Komlosi, T. Rapcsak, S. Schaible (P écs, Hungary, Springer, Berlin, 1994), pp. 171-18539.G. Giorgi, B. Jiménez, V. Novo, Minimum principle-type optimality conditions for Pareto problems. Int. J. Pure Appl. Math. 10, 51-68 (2004)40.F.J. Gould, J.W. Tolle, Geometry of optimality conditions and constraint qualifications. Math. Program. 2, 1-18 (1972)41.J.P. Aubin, H. Frankowska, Set-Valued Analysis (Birkhäuser, Boston, 1990)42.R.T. Rockafellar, R.J.-B. Wets, Variational Analysis (Springer, Berlin, 2009)43.J.M. Borwein, A.S. Lewis, Convex Analysis and Nonlinear Optimization (Springer, New York, 2000)44.A.E. Ozdaglar, D.P. Bertsekas, The relation between pseudonormality and quasiregularity in constrained optimization. Optim. Methods Soft. 19, 493-506 (2004)45.C.R. Bector, S. Chandra, J. Dutta, Principles of Optimization Theory (Alpha Science International Ltd., Harrow, U. K., 2005)46.A. Ruszczynski, Nonlinear Optimization (Princeton University Press, Princeton, 2006)47.R. Andreani, J.M. Martinez, B.F. Svaiter, A new sequential optimality condition for constrained optimization and algorithmic consequences. SIAM J. Optim., 20, 3533-3554 (2010)48.G. Haeser, M.L. Schuverdt, On approximate KKT condition and its extension to continuous variational inequalities. J. Optim. Theory Appl. 149, 528-539 (2011)49.R. Andreani, G. Haeser, J.M. Martinez, On sequential optimality conditions for smooth constrained optimization. Optimization 60, 627-641 (2011)50.J.F. Bonnans, R. Cominetti, A. Shapiro, Second-order optimality conditions based on parabolic second-order tangent sets. SIAM J. Optim. 9, 466-492 (1999)51.A. Cambini, L. Martein, M. Vlach, Second-order tangent sets and optimality conditions. Math. Japonica 49, 451-461 (1999)52.R. Cominetti, Metric regularity, tangent sets and second-order optimality conditions. Appl. Math. Optim. 21, 265-287 (1990)53.G. Giorgi, B. Jiménez, V. Novo, An overview of second order tangent sets and their application to vector optimization. Bol. Soc. Esp. Mat. Apl. 52, 73-96 (2010)54.M. Hachimi, B. Aghezzaf, New results on second-order optimality conditions in vector optimization problems. J. Optim. Theory Appl. 135, 117-133 (2007)55.B. Jiménez, V. Novo, Second order necessary conditions in set constrained differentiable vector optimization. Math. Meth. Oper. Res. 58, 299-317 (2003)56.B. Jiménez, V. Novo, Optimality conditions in differentiable vector optimization via second-order tangent sets. Appl. Math. Optim. 49, 124-144 (2004)57.G. Haeser, A. Ramos, New constraint qualifications with second-order properties in nonlinear optimization. J. Optim. Theory Appl. 184, 494-506 (2020)58.J.-P. Penot, Second order conditions for optimization problems with constraints. SIAM J. Control Optim. 37, 303-318 (1998)












© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_7





7. Sensitivity Analysis



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es







7.1 General Results
An important area of applications of optimality conditions is concerned with questions arising from sensitivity analysis of nonlinear programming problems. In many applications, the objective function f,  as well as the constraints 

 

 and 

 

 may depend also on certain number of parameters. For some of these applications the optimal solution 

 of the unperturbed problem (i.e. with fixed values of the parameters) may be of less interest than its sensitivity with respect to changes in the parameters. In other words, one may ask: how does the solution of the problem change as a function of the changes in the values of the parameters?
In mathematical programming the term "sensitivity analysis" is usually referred to all those investigations concerned in what happens to a solution of a mathematical programming problem, containing a certain number of parameters, when there are changes in the problem data. If we start from the usual formulation of 

 i. e.

with f,  

 

 

 

 real-valued functions defined on an open set 

 the parametric version of 

 is the following problem, where we explicitly introduce a vector 

 that represents the parameters subject to modifications:

When 

 is fixed, the parametric problem 

 becomes a standard nonlinear programming problem, only formally different from 


We are interested in the analysis of the solutions 

 of 

 in the analysis of the optimal value function (called also the marginal function or the perturbation function) 

 and in other questions on 


We follow mainly the classical approach of [1] and his collaborators. For other more recent and more sophisticated approaches to sensitivity analysis in optimization, one can consult the book of [3].
Throughout the present chapter we make the assumption that all functions involved in 

 are twice jointly continuously differentiable with respect to 

 over 

 It will be clear when this assumption is not necessary.
In the present chapter we adopt the conventions and notations of [1]:
The vectors of 

 are again considered column vectors, but the gradient of a function 

 is considered a row vector of 

 Consequently the Jacobian matrix 

 of a function 

 is a (m, n) order matrix whose rows are the gradients of the components of f.



 is an (n, k) matrix: 






 is an 

 matrix representing the Jacobian of the Karush-Kuhn-Tucker triplet 

 taken with respect to the parameter vector: 






 is the Hessian matrix of order n,  of the Lagrangian function 

, with respect to x.



 is the Hessian matrix, of order k,  of 

 with respect to 





 is the Jacobian matrix of order 

 of the Karush-Kuhn-Tucker conditions, with respect to (x, u, v).



 is the Jacobian matrix of order 

 of the Karush-Kuhn-Tucker conditions, with respect to 





 is the matrix of order (n, k) given by 






 is the matrix of order (k, n),  whose (i, j) element is given by 

, for 

 and 

 Hence 




First, we spend some words for the unconstrained case. Let us consider an unconstrained parametric problem of the type

with 

 X open set, 

 f twice jointly continuously differentiable with respect to 

 on 

 We have the following basic results. Let 

 a fixed vector and let 



Theorem 7.1
If 

 and 

 is positive definite (Second-Order Sufficient Optimality Conditions), then 

 is a strict and locally isolated minimizer of 



This last one is a well-known result (see Theorems 4.​10 and 6.​46) and the related sensitivity results follow without additional assumptions.

Theorem 7.2
Assume that the Second-Order Sufficient Optimality Conditions (SOSOC) of Theorem 7.1 hold at 

 Then, for 

 near 

 there exists a unique once continuously differentiable vector function 

 such that 

 and the (SOSOC) continue to hold at 

 and hence 

 is a locally unique (i.e. isolated) local minimizer of 

 Furthermore, the optimal value function 

 is twice continuously differentiable.

The previous result which follows directly from the classical implicit function theorem, guarantees that the assumptions made at 

 will persist near 

 at 

 hence also the conclusions. It is possible, without any new assumptions respect to the ones made in the previous theorem, to obtain sensitivity formulas for the optimal value function.

Theorem 7.3
Assuming as in Theorem 7.1 and with 

 as in Theorem 7.2, it hold the following relations at 

 near 

(i)
From the chain rule for differentiation we have 

 since 

 where 

 means to evaluate F at 

 With this understanding, we get 

 (7.1)

 (ii)
Differentiating this last result again by 

, we find that 



 


The result in (7.1) is called in Economic Analysis "envelope theorem" (similarly for a constrained optimization problem) and has some interesting applications in utility theory, production theory, etc. See, e.g., [2, 4-7]. The term "envelope theorem" derives from the fact (see, e.g. [8], p. 342) that, given a one-dimensional parametrized family of curves, 

, where 

 runs over some interval, a curve 

 is the envelope of the family if each point on the curve h is tangent to one of the curves 

 and each curve 

 is tangent to h. That is, for each 

 there is some t and also for each t,  there is some 

 satisfying 

 and 

 We may state informally the envelope theorem by saying that under appropriate conditions the graph of the optimal value function is the envelope of the family of graphs of 


We now consider the parametric problem 

 and we give for this problem some basic sensitivity results, taken from the book of [1]. The reader must be aware that there are many other results concerning sensitivity and stability for mathematical programming problems (see, besides [1, 9]) and the more advanced book of [3]). Especially for Linear Programming Problems, where sensitivity and stability analysis is often referred to as postoptimal analysis, there is a huge literature, concerning also algorithmic questions.
We denote by 

 the feasible set of 

 and we assume that the functions defining 

 are twice jointly continuously differentiable in 


For the reader's convenience we recall the two basic second-order optimality conditions for the non-parametric problem 

, previously given in Chap. 6, i.e. the second-order necessary optimality conditions and the second-order sufficient optimality conditions that will be used in the present section.

Theorem 7.4
(Second-order necessary optimality conditions) Suppose that 

 is a local minimum point of 

 i.e. of 

 and that the Linear Independence Constraint Qualification holds at 

 i.e. the gradients

are linearly independent. Then the Karush-Kuhn-Tucker conditions hold at 

 with associated unique Karush-Kuhn-Tucker multipliers u and v,  and the additional (usual) second-order necessary conditions hold at 

 with multipliers (u, v) : 

where 

 is the critical cone (see also page 201) given by




We recall that 

 denotes the set of strictly active constraints at 

 i.e.

By strengthening the previous conditions one obtains the following standard second-order sufficient conditions for local strict optimality of 



Theorem 7.5
(Second-order sufficient optimality conditions). Suppose that the Karush-Kuhn-Tucker conditions hold at 

 with associated multipliers u and v,  and that the following second-order sufficient conditions hold at 



Then 

 is a strict local minimum point of 



The following result was originally proved for a specific class of parametric nonlinear programming problems in [10] and subsequently, with reference to 

 in [1, 11].

Theorem 7.6
Suppose that: (i)
The functions involved in 

 are jointly twice continuously differentiable on 


 (ii)
The second-order sufficient conditions of Theorem 7.5 for 

 hold at the feasible point 

 with associated Karush-Kuhn-Tucker multipliers u and v.
 (iii)
The gradients 

 

 and 

 all j,  are linearly independent (i.e. the Linear Independence c. q. holds at 

 for 


 (iv)


 when 

 i.e. strict complementary slackness holds.
 

Then: (a)


 is a local isolated minimum point of problem 

 and the associated Karush-Kuhn-Tucker multipliers u and v are unique.
 (b)
For 

 in a neighborhood of 0,  there exists a unique, once continuously differentiable vector function 

 satisfying the second-order sufficient conditions for a local minimum of problem 

 such that 

 and hence 

 is a locally unique local minimizer of problem 

 with associated unique Karush-Kuhn-Tucker multipliers 

 and 


 (c)
For 

 near 0,  the set of active inequalities is unchanged, strict complementary slackness holds, and the active constraint gradients are linearly independent at 


 



Proof
(Fiacco) Part (a) follows if (b) is true. It is stated separately because it is of intrinsic interest. That 

 is a strict local minimum point of 

 follows from assumption (ii), which also implies 

 The uniqueness of u and v follows from this and assumption (ii).
The proof of (b) follows from a straightforward application of the Implicit Function Theorem to the first-order necessary optimality conditions of 

 as follows.
Assumption (ii) implies the satisfaction of the Karush-Kuhn-Tucker conditions

 (7.2)at 

 Assumption (i) implies that the system of equations (7.2) is once continuously differentiable in all the arguments; so, in particular, the Jacobian matrix of (7.2) with respect to (x, u, v) is well defined. It follows that assumptions (ii), (iii) and (iv) imply the existence of the inverse of this matrix at 

 (see [12] and the next Theorem 7.7). The assumptions of the Implicit Function Theorem with respect to the Eq. (7.2) and the particular solution 

 are satisfied and we can conclude that in a neighborhood of 

 for 

 in a neighborhood of 0,  there exists a unique once continuously differentiable function 

 satisfying (7.2) with 

 The satisfaction of (7.2) means that for 

 near 0,  

 is a first-order Karush-Kuhn-Tucker point of problem 

 with associated Karush-Kuhn-Tucker multipliers 

 and 


To prove (c),  we first note that the active constraint set at x(0) remains the same for 

 near 0. This is seen immediately for the equalities 

 since 

 satisfies (7.2) near 

 For the inequalities, we have from (7.2) that 

 

 near 

 If 

 for some i,  then 

 (by strict complementary slackness), hence 

 near 

 by continuity of 

 and we conclude that 

 If 

 for some i,  then 

 near 

 by continuity. Therefore, defining,

we have concluded that 

 for 

 near 0. The argument also shows that strict complementary slackness is preserved for 

 near 0,  proving the first part of (c).
We now show that the second-order sufficient optimality conditions hold at 

 for any 

 near 0. We must show that there exists 

 such that for any 

 such that 

, it follows 

 for any vector 

 such that 

 for all 

 and 

 for all j. This may be proved as follows. Suppose the assumption is false. Then there must exist 

 and 

 such that 

 

 for all 

 

 for all j and 

 for 


Without loss of generality, assume 

 for all k. Select a convergent subsequence of 

 relabel the subsequence 

 for convenience and call the limit 

 Taking limits as 

 and recalling assumption (i) yields the conclusion that 

 for some 

 such that 

 

 for all 

 and 

 for all j. But this is a contradiction of assumption (ii) and the proof of the assertion is complete. Since it was established that 

 uniquely solves (7.2) for 

 near 0,  it follows that 

 is a locally unique local minimizer of 

 with associated unique Karush-Kuhn-Tucker multipliers 

 and 

 completing the proof of part (b).
The preservation of strict complementary slackness was proved above. The preservation of the linear independence of the (say) 

 active constraint gradients at 

 for 

 near 0 follows directly from the fact that an 

 by 

 Jacobian of the system of equations defined by the constraints that are active at x(0) must be nonsingular, along with the assumed continuity of the first derivatives. The proof is complete.    



References [1, 11] also show that the parameter derivatives of

can be calculated: indeed (7.2) is identically satisfied by this function for 

 near 0 (under the assumptions of Theorem 7.6) and can be differentiated with respect to 

 to yield explicit expression for the first partial derivatives of the vector function 

 Since the assumptions of Theorem 7.6 imply that the Jacobian matrix of (7.2), 

 with respect to (x, u, v),  is nonsingular, one obtains

from which

 (7.3)where

and

Thus (7.3) provides a formula for the parameter derivatives of all components of 

 for 

 near 0. It also follows that 

 is continuous near 0,  so 

 as 


The previous theorem and its consequences obviously are valid, mutatis mutandis, if instead of the unperturbed problem 

 we consider the unperturbed problem 

 with a fixed 


The next theorem, due to [12], shows that the conditions imposed in Theorem 7.6 are also essentially necessary (under appropriate regularity assumptions) for the invertibility of the Jacobian matrix 



Theorem 7.7
(i) Suppose that 

 satisfies the second-order necessary optimality conditions of Theorem 7.4 for a local minimum point of 

, with associated Karush-Kuhn-Tucker multipliers (u, v),  and suppose that 

 has an inverse. Then, the second-order sufficient optimality conditions of Theorem 7.5 hold, the strict complementary slackness conditions hold and the linear independence condition holds.
(ii) If the second-order sufficient optimality conditions of Theorem 7.5 hold for 

 with associated Karush-Kuhn-Tucker multipliers (u, v),  the strict complementary slackness conditions hold and the linear independence condition holds, then 

 has an inverse.

We can also calculate parameter derivatives of first- and second-order of the local optimal value 

 of 

 again by repeated use of the chain rule. Always under the assumptions of Theorem 7.6 (KKT) conditions for 

 Second-Order Sufficient Optimality Conditions, Strict Complementary Slackness and Linear Independence), then in a neighborhood of 

 the optimal value function 

 is twice continuously differentiable. The "optimal value Lagrangian" is defined as

We have the following results (for the proof see [1]): (a)
In a neighborhood of 

 it holds 



 (b)
Since 

 and since it can be shown that 

 it follows that 

 where, as usual, the vertical bar denotes evaluation at the specified point.
 (c)


 We give now some insights on the convexity and other properties of the optimal value function of 

 defined as 



 

For further developments see [1, 13, 14].
If in problem 

 the objective function f and every 

 

 are convex in x and every 

 

 is linear affine, for any 

 the problem 

 is said to be convex in x. If these function properties hold jointly in 

 and T is a convex set, then 

 is said to be jointly convex.
For simplicity, for the present considerations, continuous differentiability and continuity are assumed. The solution set 

 of 

 is defined as

We recall (see, e.g., [15]) that if F is a point-to-set mapping of 

 into 

, then it is said that F is uniformly compact near 

 if there exists a neighborhood 

 of 

 such that the closure of the set 

 is compact.
If problem 

 is convex, then any local solution is global and the solution set is convex; moreover, if the (KKT) conditions hold at the feasible point 

 then 

 is a global solution. We say that the Generalized Slater Constraint Qualification,  denoted by (GS(

)), holds for the convex problem 

 if there exists a feasible point 

 such that 

 for all i and such that the gradients 

 are linearly independent. For 

 convex, the (MFCQ) and (GS) are equivalent conditions.
The following propositions can be proved (see the references to Fiacco and Kyparisis quoted above).

Proposition 7.8
For the once differentiable problem 

 with nonempty uniformly compact feasible set 

 for 

 near 

 the optimal value function 

 is continuous at 

 if the (MFCQ) holds for some 




Proposition 7.9
The optimal value function 

 is convex on T if 

 is jointly convex in 

 as defined. Assuming solution attainment, this further implies that 

 is continuous and directionally differentiable in the interior of T.

We recall that the directional derivative of 

 at 

 in the direction 

 is




Proposition 7.10
If 

 does not vary with 

 and f is concave in 

 and T is convex, then 

 is concave on T. Again, assuming the solution is attained, this means that 

 is continuous and directionally differentiable in the interior of T.


Proposition 7.11
Suppose 

 is nonempty and compact and that it does not change with 

 and assume f and 

 are continuous in 

 Then, at any 

 it follows that 

 and compact and the directional derivative 

 exists for any direction z and is given by





Proposition 7.12
Assume that the problem 

 is convex in x for each 

 and the problem functions are once continuously differentiable in 

 Then, if 

 and the set of points 

 satisfying (KKT) is nonempty and bounded, then in a neighborhood 

 of 

 it holds 

 and 

 is convex for each 

 and 

 is uniformly compact in 

 Furthermore, 

 is continuous and directionally differentiable in 

 in any direction z and

where 

 is the set of multipliers (u, v) that satisfy the (KKT) conditions.

As previously remarked, if 

 is convex, the assumption (GS) is equivalent to (MFCQ), or to assuming that 

 and closed and bounded at a global solution. Dispensing with convexity, but assuming that the gradients 

 i such that 

 and 

 

 are linearly independent at every 

 we have that 

 exists for each 

 and

where 

 is the unique optimal Karush-Kuhn-Tucker multipliers vector associated with 


References [16, 17] extend the results of Theorem 7.6 by relaxing the Strict Complementary Slackness Conditions and strengthening the standard second-order sufficient optimality conditions of Theorem 7.5.

Theorem 7.13
Suppose that the Karush-Kuhn.Tucker conditions hold at 

 with some multipliers vectors u and v, that the following additional Strong Second-Order Sufficient Conditions hold at 

 for 

 i.e.

for all 

 such that

and that the Linear Independence Constraint Qualification holds at 


Then: (a)


 is an isolated local minimum point of 

 and the associated Karush-Kuhn-Tucker multipliers vectors u and v are unique.
 (b)
For 

 in a neighborhood of 

 there exists a unique continuous vector function 

 satisfying the Karush-Kuhn-Tucker conditions and the Strong Second-Order Sufficient Conditions for a local minimum of 

 such that 

 and, hence, 

 is a locally unique local minimum point of 

 with associated unique Karush-Kuhn-Tucker multipliers vectors 

 and 


 (c)
The Linear Independence Constraint Qualification holds at 

 for 

 near 


 (d)
There exist 

 and 

 such that for all 

 with 

 it follows that 



 


Note that the differentiability of 

 and 

 is no longer assured by the above theorem, however [16] proves that these functions admit at 

 one-sided directional derivatives. For what concerns the optimal value function 

 under the assumptions of Theorem 7.13 it is possible to obtain the following results [1, 16].

Theorem 7.14
If the assumptions of Theorem 7.13 are satisfied at 

 then for 

 near 

 the local optimal value function 

 is once continuously differentiable and (a)


,
 (b)


.
 


It is also possible to get some interesting sensitivity results for 

 by substituting the Linear Independence Constraint Qualification with the weaker Mangasarian-Fromovitz Constraint Qualification, but strengthening further the Strong Second-Order Sufficient Conditions for (local) strict optimality. This has been done in [18].

Theorem 7.15
(Kojima) Suppose that the Karush-Kuhn-Tucker conditions hold at 

, with some multipliers vectors u and v. Suppose that the following General Strong Second-Order Sufficient Conditions (GSSOSC) hold at 

 for 


GSSOSC: the Strong Second-Order Sufficient Conditions hold at 

 for 

 with multipliers (u, v) for every 

 being 





Suppose further that the Mangasarian-Fromovitz constraint qualification holds at 

 for 


Then: (a)


 is an isolated local minimum point of 

 and the set 

 is compact and convex.
 (b)
There are neighborhoods 

 of 

 and 

 of 

 such that for 

 in 

 there exists a unique continuous vector function 

 in 

 satisfying the Karush-Kuhn-Tucker conditions for some 

 and the General Strong Second-Order Sufficient Conditions such that 

 and, hence, 

 is the locally unique local minimum point of 

 in 


 (c)
The Mangasarian-Fromovitz constraint qualification holds at 

 for 

 in 


 




7.2 Sensitivity Results for Right-Hand Side Perturbations
In the present section we give some insights on sensitivity analysis for nonlinear programming problems subject to right-hand side perturbations, i. e. on problems of the type

with 

 open set, 

, 

 and 

 Obviously 

 

 and 

 with 

 We continue to assume that the functions of 

 are twice-continuously differentiable on the open set 

 It is quite obvious that the general results for 

 of the previous section can be specialized and adapted to problem 

 but, curiously, also the vice-versa holds, in the sense that any problem of the form 

 may be reformulated as an equivalent right-hand side parametric problem. It is sufficient to redefine 

 in 

 to be a variable and to introduce a new parameter 

 such that 

 This results in the problem

which is clearly equivalent to 

 and of the form of 

 See [1, 19].
Since the formulation of 

 is often considered in several applications (above all economic applications), we restate the specialized results of sensitivity analysis for 



Theorem 7.16
If (i)
The functions defining 

 are twice-continuously differentiable (in x) on the open set 


 (ii)
The second-order sufficient optimality conditions for a strict local minimum hold at the feasible point 

 of R(0),  with associated Karush-Kuhn-Tucker multipliers u and v.
 (iii)
The gradients 

 

 and 

 

 are linearly independent.
 (iv)
The Strict Complementary Slackness Conditions hold: 

 when 


 

Then: (a)


 is a local isolated minimizing point of R(0) and the associated Karush-Kuhn-Tucker multipliers vectors u and v are unique.
 (b)
For 

 in a neighborhood of 0, there exists a unique once-continuously differentiable vector function 

 satisfying the second-order suffcient conditions for a strict local minimum of problem 

 such that 

 and hence, 

 is a locally unique minimum point of 

 with associated Karush-Kuhn-Tucker multipliers 

 and 


 (c)
For 

 in a neighborhood of 0 we have 

 where 



 (d)
Strict complementary slackness conditions and linear independence of the active constraint gradients hold at 

 for 

 near 0.
 (e)
For 

 in a neighborhood of 0,  the gradient of the optimal value function is 



 (f)
For 

 in a neighborhood of 0,  the Hessian matrix of the optimal value function is 



 


The above results are easily obtained from the previous general results on 

 by letting 

 

 

 and 

 


For the reader's convenience we give an autonomous proof of a reduced version of the above theorem, i.e. we consider a parametric programming problem with right-hand side parameters and with only equality constraints, i.e. of the type 

 Therefore we consider the following problem

and let 

 and every 

, 

 be twice-continuously differentiable on the open set 

 For problem 

 we write the Lagrangian function in the form



 is the feasible set of 

 and the optimal value function of 

 is denoted, as before, by 

 The autonomous proof for the sensitivity results concerning the problem 

 can be performed, mutatis mutandis, following the steps of the proof given below for the parametric problem 



Theorem 7.17
Suppose that for 

 there is a local solution 

 of 

 and that the gradients 

 are linearly independent. Suppose that the associated Lagrange multiplier vector v (unique) satisfies the Lagrangian conditions

and the second-order sufficient conditions for strict optimality

for all 

 such that 


Then, there exists a neighborhood N(0) of 

 and a function x(c) continuously differentiable on N(0),  such that 

 and, for very 

 x(c) is a strict local minimizer of f on 

 Furthermore,





Proof
Consider the system of equations

 (7.4)


 (7.5)By the assumptions, there is a solution 

 to this system when 

 The Jacobian matrix of the system at this solution is

Because by assumption 

 is a regular point and 

 is positive definite on the linear subspace 

 an immediate consequence of a criterion on positive definiteness of quadratic forms on the nonzero solutions of an homogeneous linear system, is that M is nonsingular (see Chap. 1 and [20]). Otherwise, directly: indeed, the unique solution 

 of 

 is 

 and hence M is nonsingular. To prove this, let us consider 

 and decompose 

 into

It results

whence

 (7.6)But the only possibility for 

 to verify (7.6), owing to the second-order sufficient optimality conditions for 

 is 

 Hence 

 but being 

 of full rank, it holds also 


Being M nonsingular, it is possible to apply the Implicit Function Theorem: for all c in some open neighborhood N(0),  there exist x(c) and v(c) such that 

 

 the functions 

 and 

 are continuously differentiable, and

For c sufficiently close to 0 the vectors x(c) and v(c) satisfy the second-order sufficient optimality conditions for the problem in question, since they satisfy them by assunption for 

 This is straightforward to verify by using the continuity assumptions: if it were not true, there would exist a sequence 

 with 

 and a sequence 

 with 

 and 

 for all k,  such that

By taking the limit along a convergent subsequence of 

 we would obtain a contradiction with the second-order sufficient conditions at 

 Hence, x(c) is a strict local minimizer for problem (P(c)),  with associated Lagrange multiplier v(c).
Finally, being x(c) continuously differentiable, also the composite function 

 is continuously differentiable. By the chain rule we have

and

In view of (7.5) the second of these relations is equal to the identity matrix I of order p,  while this, in view of (7.4), implies that the first relation can be written as




   



Thus, the rate of change of 

 with respect to changes in the constraint values is captured entirely by the optimal Lagrange multipliers. In economic applications these multipliers are referred to as shadow prices (i.e. imputed prices) of resource levels. See, e. g., [6, 7, 21].

Remark 7.18
Let us consider again problem 



with 

 open set, 

, 

 and 

 We make the assumption that 

 is a convex problem,  i.e. that f and every 

 

 are convex on the open convex set X and that every 

 

 is linear affine. We make also the assumption that f and every 

 is differentiable on X (obviously every 

 is differentiable on 

 Without having recourse to second-order optimality conditions, it is possible, under the said assumptions, to obtain interesting results for 

 See, e.g., [13, 22].

Let us denote by 

 the optimal value function of 



Theorem 7.19
Let 

 be a convex problem; then: (i)
The function 

 is convex.
 (ii)
If 

 are such that 

 

 then 


 



Proof
(i) Let be

One can easily check that for 

 we have the inclusion

where 

 and 

 Consequently, if 

 



 then

Hence

(ii) Since 

 

 

 one has

   



Now we suppose that for the convex problem 

 the  Slater constraint qualification is satisfied at 

 and that R(0, 0) admits a solution. With 

 the Slater constraint qualification for our problem can be expressed as:
The vectors 

 are linearly independent, 

 There exists 

 such that 

 

 and 

 




We recall that under this constraint qualification the set 

 of the Karush-Kuhn-Tucker multipliers of R(0, 0) is a convex and compact set (nonempty). Under the said assumptions, it is not possible to obtain the differentiability of the optimal value function 

, however it is possible to obtain its directional differentiability.

Theorem 7.20
Let in 

 the above conditions be fulfilled and let 

 be a solution of R(0, 0) with multipliers u, v. Then the directional derivative 

 of the optimal value function at (0, 0) in the direction 

 exists and it holds




We have to note that in the case 

 is a singleton, then 

 is differentiable at (0, 0) and we get the usual formula




References1.A.V. Fiacco, Introduction to Sensitivity and Stability Analysis in Nonlinear Programming (Academic, New York, 1983)2.S.N. Afriat, Theory of maxima and the method of Lagrange. SIAM J. Appl. Math. 20, 43-357 (1971)3.J.F. Bonnans, A. Shapiro, Perturbation Analysis of Optimization Problems (Springer, New York, 2000)4.B. Beavis, I. Dobbs, Optimization and Stability Theory for Economic Analysis (Cambridge University Press, Cambrdidge, U.K., 1990)5.E. Silberberg, W. Suen, The Structure of Economics: A Mathematical Analysis, 3rd edn. (McGraw-Hill Publishing Company, New York, 2001)6.A. Takayama, Sensitivity Analysis in Economic Theory (1977)7.A. Takayama, Mathematical Economics, 2nd edn. (Cambridge University Press, Cambridge, 1985)8.T.M. Apostol, Calculus, 2nd edn. (Blaisdell, Waltham, Mass, 1967)9.B. Bank, J. Guddat, D. Klatte, B. Kummer, K. Tammer, Non-Linear Parametric Optimization (Birkhäuser, Basel, 1983)10.A.V. Fiacco, G.P. Mccormick, Nonlinear Programming: Sequential Unconstrained Minimization Techniques (Wiley, New York, 1968)11.A.V. Fiacco, Sensitivity analysis for nonlinear programming using penalty methods. Math. Program. 10, 287-311 (1976)12.G.P. McCormick, Optimality criteria, in nonlinear Programming, in Nonlinear Programming, eds. by R.W. Cottle, C.E. Lemke, S.I.A.M.-A.M.S. Proceedings, vol. IX (American Mathematical Society, Providence, RI, 1976), pp. 27-3813.A.V. Fiacco, J. Kyparisis, Convexity and concavity properties of the optimal value function in parametric programming. J. Optim. Theory Appl. 48, 95-126 (1986)14.J. Kyparisis, A.V. Fiacco, Generalized convexity and concavity of the optimal value function in nonlinear programming. Math. Program. 39, 285-304 (1987)15.J. Gauvin, A necessary and sufficient regularity condition to have bounded multipliers in nonconvex programming Math. Program. 12, 136-138 (1977)16.K. Jittorntrum, Solution point differentiability without strict complementarity in nonlinear programming. Math. Program. Study 21, 127-138. (A. V. Fiacco Ed.) (1984)17.S.M. Robinson, Strongly regular generalized equations. Math. Oper. Res. 5, 43-62 (1980)18.M. Kojima, Strongly stable stationary solutions in nonlinear programs, in Analysis and Computation of Fixed Points, ed. by S.M. Robinson (Academic, New York, 1980), pp. 93-13819.R.T. Rockafellar, Lagrange multipliers and subderivatives of the optimal value functions in nonlinear programming. Math. Program. Study 17, 28-66 (1982)20.G. Debreu, Definite and semidefinite quadratic forms. Econometrica 20, 285-300 (1952)21.J. Gauvin, Shadow prices in nonconvex mathematical programming. Math. Program. 19, 300-312 (1980)22.W. Hogan, Directional derivatives of extremal-value functions with applications to the completely convex case. Oper. Res. 21, 188-209 (1973)












© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_8





8. Convex Optimization: Saddle Points Characterization and Introduction to Duality



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es







8.1 Convex Optimization: Saddle Points Characterization
In the last 50 years or more, the words "nonsmooth optimization" generally refer to nonlinear programming problems (or also to problems of calculus of variations or optimal control) where the functions involved are not differentiable (in the sense of Fré chet), but satisfy weaker assumptions concerning various kinds of limits in various kinds of differential quotients, in order to obtain generalized gradients or generalized directional derivatives.
Some insights on these approaches to nonsmooth optimization problems will be presented in Chap. 10. But, from a historic point of view, the first approach used to treat a nonlinear convex programming problem, in the absence of differentiability assumptions on the functions involved in the problem, was the saddle points characterization of the Lagrangian function associated with the problem. This classical approach, which has some importance also with reference to dual problems and minimax theory (see the next section of the present chapter) will be summarized in what follows.
For simplicity, let us consider a nonlinear programming problem with only inequality constraints, i.e. a problem of the type 



where 

 is a nonempty set, 

 and every 

, 

 Note that we do not assume (at least for the moment) any differentiability property on the functions involved in 

 With regard to 

, we introduce the usual Lagrangian function

or, in vector notation




Definition 8.1
A pair 

 is called a Lagrangian saddle point or simply a saddle point for 

 if

 (8.1)


Intuitively, in 

 this could produce a picture like a horse saddle; however, there is a common misconception that a saddle point always looks similar to a saddle (in 

). See [1].
Clearly, a saddle point may never exist and even if it exists, it is not necessarily unique.

Remark 8.2
Definition 8.1 makes reference to 

 i.e. to a minimization problem. If we consider a maximization problem of the type

the saddle point characterization for this problem is

 (8.2)where




Some authors (really few) call (8.1) "negative saddle point condition" and (8.2) "positive saddle point condition". We shall always make reference to minimization problems.
Now we give a characterization of saddle points for the Lagrangian function of problem 



Theorem 8.3
The pair 

 

 

 is a saddle point for the Lagrangian function of problem 

 if and only if the following conditions hold: (i)


 


 (ii)


 


 (iii)





 



Proof
Let us suppose that 

 is a saddle point for the Lagrangian function 

 By Definition 8.1 we have

 (8.3)We rewrite the first inequality:

 (8.4)Clearly, this implies that we must have 

 

 or else (8.4) can be violated by making a component of u sufficiently large. Hence, (i) is proved. Now, taking 

 in (8.4) we obtain 

 but being 

 

 and 

 we have 

 and hence 

 Hence, (ii) is proved.
From (ii) and from (8.3) we have (iii). Conversely, suppose that we are given 

 with 

 and 

 such that (i),  (ii) and (iii) of the theorem hold. Then 

 

 by properties (ii) and (iii). Furthermore,

since (property (i)) 

 

 Hence, 

 is a saddle point for 

.    



The next result, which is a quite immediate corollary of the previous theorem, puts into relationship the existence of a saddle point for 

 and the existence of optimal solutions of 



Theorem 8.4
If the pair 

 

 

 is a saddle point for 

 

 

 then: (a)


 is a global solution of 


 (b)
The complementary slackness conditions hold: 



 



Proof
Relation (b) has been already proved in Theorem 8.3. From the same theorem we have that 

 is feasible for 

 

 

 From (iii) of Theorem 8.3 we have

For all feasible points x for 

 it will hold 

 and hence, for all feasible points x for 

 we have 

.    



We remark that the previous result (quite strong) yields a sufficient condition for a point 

 to be a global solution for 

 with no differentiability assumptions, nor convexity (or generalized convexity) assumptions on the functions involved in 

 The condition expressed by Theorem 8.4 is only sufficient. The next example exhibits a minimization problem having a global optimal solution, but no saddle point for the Lagrangian function.

Example 8.5
Consider the problem

with 

 This problem has a unique global minimizer at 

. This point is the only feasible solution (

). The associated Lagrangian function is

Note that 

 for all u. If the Lagrangian function has a saddle point 

, we would have

Let 

 If 

 is positive and sufficiently small, we get 

 whereas for 

 to be a saddle point, we must have 

 which is a contradiction.

To obtain necessary optimality conditions for 

 in terms of a saddle point characterization, we normally need to make some sort of regularity and convexity assumption on the functions involved in 

 Therefore, we consider a convex programming problem, i.e. in 

 the nonempty set 

 is a convex set  and the functions f and every 

 

 are convex on X.
We recall, from the previous chapters, mostly Chap. 3, the main properties of a convex programming problem:(1)
The set of feasible solutions is convex.
 (2)
A local minimum point is a global minimum point.
 (3)
If the functions involved in the problem are differentiable, then a solution of the Karush-Kuhn-Tucker conditions is a solution of the problem.
 (4)
A satisfactory duality theory can be established. See the next section.
 (5)
If the objective function is strictly convex, the minimum point (if there exists) is unique (and hence strict).
 

Some of these properties are still valid if the objective function and the constraints are convenient generalized convex functions (see Chap. 3).
The following result is essentially due to [2] and in part to [3].

Theorem 8.6
(Kuhn-Tucker-Uzawa) Consider the convex problem 

 and let 

 be a (global) minimum point for 

 Then, there exist 

 multipliers 

 

 not all zero, such that

 (8.5)Furthermore, we get the complementary slackness conditions, i. e. 

 




Proof
Being 

 a global minimum point for 

 the system

has no solution 

 Hence, a fortiori, the system

has no solution 

 Being f and every 

 

 convex on the convex set 

 the function 

 given by

is convex on X and by the Theorem of Fan-Glicksberg-Hoffman (Theorem 3.​45), there exist 

 nonnegative multipliers, not all zero, 

 such that

Thus, relation (8.5) holds. Being 

 

 and 

 

 we have 

 But if we substitute 

 into relation (8.5) we obtain 

 Hence, we have 

 or equivalently, 

 

.    



We note that in Theorem 8.6 it may occur 

 (as in the Theorem of Fritz John for the differentiable case). It is therefore essential to impose some conditions, i.e. some constraint qualification, which ensures that in relation (8.5) it holds 

 i.e. without loss of generality, 

 We take into consideration the following constraint qualifications, which require no differentiability assumptions. We recall that 

 is a convex set, and that 

 and every 

, 

 are convex functions.
(a)
Slater constraint qualification: There exists 

 such that 


 (b)
Karlin constraint qualification (see [4]): There exists no 

 such that 

 


 (c)
Strict constraint qualification: There exist 

 with 

 such that g is strictly convex at 

 with respect to 

 i. e. for all 

 it holds 



 


Theorem 8.7
It holds: 

 .


Proof
The equivalence 

 is an immediate consequence of the theorem of Fan-Glicksberg-Hoffman (Theorem 3.​45). From the fact that g is strictly convex at 

 (with respect to 

), it results, with 

 as 



and this shows that the point 

 verifies the Slater c. q.    




Theorem 8.8
Let 

 be a (global) solution of the convex problem 

 and let the Slater constraint qualification be satisfied. Then in (8.5) it holds 

 and the pair 

 is a saddle point for the Lagrangian function 

 Furthermore, 

 




Proof
If, absurdly, it would result 

 relation (8.5) then becomes

which is absurd, as 

 

 not all equal to zero, and 

 Then we have the relations





 by the complementary slackness conditions;



By relation (8.5), being 

 we have

Moreover, it holds, being 



Therefore, 

 is a saddle point for the Lagrangian function and the complementary slackness conditions hold (from Theorem 8.7 and from the characterization of saddle points).    



The following example shows that the Slater constraint qualification (or another suitable constraint qualification) cannot be skipped in the above theorem.

Example 8.9
Consider the problem

The only feasible point is 

 with value 

 So, 

 is the unique global solution of our problem. The Lagrangian function is

There is no 

 such that 

 is a saddle point of 



We can therefore formulate the following scheme.




The above notions have been generalized towards various directions. We wish to mention some results due to [5] who take into consideration the class of pre-invex functions (see Chap. 3). Again let us consider problem 



where 

 and 

.

Theorem 8.10
Let 

 be a nonempty set and let 

 be a pre-invex function on X,  with respect to 

 (i.e. each of its component is pre-invex on X with respect to the same 

). Then, either

has a solution 

 or





Proof
See [5].    



The problem 

 will be said to satisfy the generalized Slater constraint qualification if g is pre-invex (with respect to 

 ) and there exists 

 such that 


The following result can be proved in the same manner as in the case of convex functions.

Theorem 8.11
Assume that in 

 the objective function f is pre-invex on X,  with respect to the vector function 

 and that the vector-valued function g is pre-invex on X,  with respect to the same function 

. Assume that the generalized Slater constraint qualification holds. If 

 is a solution of 

 then there exists 

 such that 

 is a saddle point of the Lagrangian function of 



 (8.6)Conversely, if (8.6) is satisfied for some 

 then 

 is a solution for 



We now assume that in 

 the functions f and every 

 

 are differentiable on the open set 

 and will put into evidence the relationships between saddle point conditions for 

 and Karush-Kuhn-Tucker conditions for 

 these last ones called by [6], "quasi-saddle point conditions". These relationships are in fact the central topic of the pioneering paper of [3].

Theorem 8.12
Let in 

 the functions f and every 

 

 be differentiable on the open set 

 If the Lagrangian function of 

 has a saddle point 

 then the following Karush-Kuhn-Tucker conditions hold: (i)



 (ii)





 (iii)



 



Proof
The points (ii) and (iii) are parts of the characterization of a saddle point 

 see Theorem 8.3. We recall the definition of saddle point for 



From the second inequality it results that 

 is a minimum point for 

 over X. By Fermat's theorem we have (X is open):

Therefore, also (i) is proved.    



Now, let us consider the convex problem 

 under differentiability assumptions. We obtain the following converse result of the previous theorem.

Theorem 8.13
Let in 

 the functions f and every 

 

 be differentiable and convex on the open convex set 

 Let 

 verify the Karush-Kuhn-Tucker conditions, with a multipliers vector 

 Then the pair 

 is a saddle point of the Lagrangian function 




Proof
Being f and every 

 

 convex functions, the Lagrangian function 

 

 is a convex function. The first Karush-Kuhn-Tucker condition is

Being 

 convex, 

 the previous stationary condition means that 

 has a global minimum at 

 over X, hence

From the complementary slackness conditions and from the fact that 

 we have

and hence

This inequality, together with the previous one, gives the thesis.    



We present a scheme which summarizes the main results previously obtained. The reference problem is 

 i.e.
















Remark 8.14
From the previous scheme it appears that if 

 is a linear programming problem (see Chap. 9), i.e. the functions involved in the said problem are all linear (affine), i.e. differentiable and both convex and concave, the constraints are automatically qualified, and therefore the Karush-Kuhn-Tucker conditions hold at the optimal point 

 From this fact it follows that also the saddle point conditions are verified, without any constraint qualification. That is, for a linear programming problem (L. P.) the necessary conditions, expressed by the saddle point characterization, need no constraint qualification. This result is originally due to Goldman and Tucker (see [7]), with a nontrivial proof. This shows that sometimes, the progress of the mathematical machinery can drastically simplify the proofs of previous results.

We take again into consideration the convex problem 

 in order to make two further observations. First we show that the solutions of a convex problem (of the type 

) do not change if we take into considerations only the active constraints, referred to that solution 



Theorem 8.15
Let 

 be a solution of the convex problem 

 Then 

 is also an optimal solution of the "reduced" problem

where 

 is a nonempty convex set.


Proof
Let us suppose tnat 

 is not an optimal solution of 

 It follows that there exists 

 such that 

 

 and

 (8.7)Since X is a convex set, we have that 

 for any 

 Since all 

 are convex functions, it results that

 (8.8)for 


From (8.8) it follows that 

 for all 

 Since 

 for all 

 from (8.8) we have that 

 for every 

 and for 

 sufficiently small. Thus, 

 for a small 

 From (8.7) it follows that

 (8.9)for all 

 Since 

 relation (8.9) contradicts the optimality of 

 for 

.    



Now we consider again the convex problem 

 and add the differentiability assumption: all functions involved in 

 are differentiable on an open set containing the convex set 

 Then, if we know a solution 

 of this problem, it is possible to characterize the solution set of the same problem, i.e. the set

The following result has been obtained by [8], with the unnecessary assumption that the functions involved in the problem are 



Theorem 8.16
Let us consider the problem

where f and every 

 

 are convex on the convex set 

 and f and every 

 are continuously differentiable on some open set containing X. If 

 is a solution of 

 then a necessary and sufficient condition such that 

 is a solution of the same problem, is that:

 (8.10)


 (8.11)



Proof
In other words, the theorem asserts that if 

 then

We have to prove that, under the assumption that 

 is a solution of 

 then conditions (8.10)-(8.11) are equivalent to 

 The sufficiency is immediate. From convexity of f, we get

and, by (8.10)-(8.11) it holds 

 and hence 

 is a solution.
Conversely, let us suppose that 

 with 

 From convexity of S, we have

i.e.

From this relation and from convexity of f (Theorem 3.​7), we have

 (8.12)i.e. relation (8.11) holds. Indeed, we have 

 and if 

 then for 

 sufficiently small we have

against relation (8.12).
It remains to prove relation (8.10). Let us consider the convex function

Obviously, 

 by relation (8.11), previously proved. Moreover, 

 and 

 i.e. 

 is an unconstrained global minimum point of the convex function 

 From 

 it results therefore that x is an unconstrained global minimum point of 

 i.e. 

 i.e. relation (8.10) holds.    





8.2 Introduction to Duality
Duality plays a fundamental role in theory and methods of Linear Programming (see Chap. 9), where this topic was born and where the pioneering results go back to the classical minimax theorem of von Neumann for Games Theory (see [9]). Duality theory for linear programming problems essentially consists in the possibility, given a linear programming problem said "primal problem", to formulate an associated linear programming problem, said "dual problem" , with the basic property that if one of the two problems admits solution, then also the other problem admits solution and the two optimal values are equal (see Chap. 9).
Extensions of duality theory to the nonlinear case started immediately afterwards the basic paper of Kuhn and Tucker [3] and the said extensions remain one of the most investigated areas of mathematical programming, with great importance not only from a theoretical point of view but also (similarly to what happened for linear programming problems) for algorithmic developments.
The literature on duality theory in nonlinear programming is therefore abundant, just as the literature on duality of linear programming problems. We shall give only some basic results which are simple to prove and which open the path for the duality results of Linear Programming presented in the next chapter.
There are various approaches to duality for nonlinear programming problems, among which the Lagrangian approach, based on the Lagrangian function, and the conjugate functions approach, based on conjugate functions, introduced by Fenchel and subsequently studied in a great detail by Moreau and Rockfellar (see [10, 11]). As [12] has shown that both approaches are equivalent, we shall not consider the conjugate duality theory.
Let now consider 

 and 

 and let be given 

 and 

. We can consider the following pair of mathematical programming problems: a "primal" problem (P),  of the type

and a "dual" problem (D),  of the type

We say that between (P) and (D) there are duality relations, or that (P) and (D) is a pair of dual problems, when at least the first of the following properties is satisfied.


 

.
We accept the convention that 

 if 

 and that 

 if 

 Furthermore, the two objective functions of (P) and (D) may not reach the respective optimal values, therefore 

 may be rewritten in the more general form

This property is usually called "weak duality" .
A more satisfactory duality theory holds between (P) and (D) if also the following property is satisfied.


 If one of the two problems (P) or (D) admits solution, then also the other problem admits solution and it holds

This property is usually called "strong duality" .
From 

, we get also the following other duality properties:


 If 

 and 

 then the equality 

 assures that 

 and 

 are solutions, respectively, of (P) and (D).


 If one of the two problems (P) or (D) admits unbounded extremum, i.e.

then the other problem does not admit a finite solution.
In the literature we find also the following terminology, with reference to the connections between a primal and a dual problem.

Direct dual existence theorem: if the primal problem has an optimal solution, then also the dual problem has an optimal solution.

Converse dual existence theorem: if the dual problem has an optimal solution, then also the primal problem has an optimal solution.

Strict direct duality theorem: if 

 solves the primal problem (P),  then some 

 solves the dual and 



Strict converse duality theorem: if 

 solves the dual problem, then some 

 solves the primal problem and 




Moreover, if for a dual problem (D),  it happens that its dual is the primal problem (P),  we say that (P) and (D) is a pair of "symmetric" dual problems or that for (P) and (D) the "involution property" holds.
We give now some basic notions on Lagrangian duality. For simplicity we consider a constrained minimization problem with only inequality constraints, i.e. of the type 

 that in the present context we call the primal problem (P).

where 

 and 

 , 

 X nonempty subset of 


Given (P),  the corresponding Lagrangian function is defined in the usual way:

We remark that problem (P) can be equivalently reformulated as

being

In this context, the multipliers 

 

 are also called "dual variables" .
The Lagrangian dual problem (D) is the following one.

where

is called the Lagrangian dual function.
Note that the Lagrangian dual function 

 may assume the value 

 for some vector u. Moreover, the objective function of the dual may not reach the respective optimal value, so it is more convenient to substitute 

 instead of 

 in the primal problem, and 

 instead of 

 in the dual problem.
We now give a fundamental example which shows that the Lagrangian dual, as defined above, is equivalent to the dual problem for Linear Programming, in the form this last one is usually formulated.

Example 8.17
Consider a linear programming problem of the form

where 

 

 A is a matrix of order (m, n) and 

 Choosing 

 the Lagrangian dual problem is

where

This reduces to

Assuming there are nonnegative values of u such that 

 these would be the only feasible choices for the maximization of 

 and therefore (D) takes the familiar form of the dual problem for the linear programming (P) : 

See Chap. 9.


Example 8.18
(Differentiable convex programming problem) Let us consider the problem

where 

 is an open convex set, f and every 

 

 are differentiable convex functions on X. The Lagrangian function is 



 and it is further assumed that 

 for all 

 With these assumptions the Lagrangian function is convex in x and has a minimum where its gradient is zero. That is, the requirement 

 is the same as requiring 

 Thus, the dual problem may be written as

This is the Wolfe dual problem for (P),  one of the first nonlinear duals, proposed in [13]. See further, in the present section.

In the general case, the dual problem may not have a solution, even if the primal problem has a solution. Conversely, the primal problem may not have a solution, even if the dual problem has a solution. With reference to the Lagrangian duality, we have the following first basic result.

Theorem 8.19
(Weak duality theorem) Let x be feasible for problem (P),  that is 

 

 let u be feasible for problem (D),  that is 

 Then it holds





Proof
By definition of 

 and since 

 we have

since 

 

 This completes the proof.    




Corollary 8.20
It holds





Corollary 8.21
If 

 where 

 and 

 then 

 and 

 solve the primal and dual problems, respectively.


Corollary 8.22
If

then 

, for every 




Corollary 8.23
If

then the primal problem has no feasible solution.

If we set

and

from Corollary 8.20 it appears that

If in the above relation strict inequality holds true, then a  duality gap is said to exist. Contrary to Linear Programming Problems, for the nonlinear case, without further assumptions on the functions involved in (P) and (D),  there may exist a duality gap. Consider, e.g. the following example.

Example 8.24
Let be 

 

 

 Then 

 

 

 

. We get

and hence 



The next theorem shows that under suitable convexity assumption and under a constraint qualification, we have no duality gap.

Theorem 8.25
(Strong duality theorem) Let us consider the primal problem (P), where 

 is a nonempty convex set, 

 and every 

, 

 are convex on X. Suppose that the Slater constraint qualification is verified, i.e. there exists 

 such that 

 Then

 (8.13)Furthermore, if the 

 is finite, then 

 is achieved at some 

 with 

 If the 

 is achieved at 

 then 




Proof
Let 

 By assumption 

 If 

 then, by Corollary 8.22, 

 and therefore relation (8.13) holds true. Hence, suppose that 

 is finite, and consider the following system

By definition of 

 this system has no solution and a fortiori the following system has no solution.

By the Theorem of Fan-Glicksberg-Hoffman (Theorem 3.​45), there exists a nonzero vector 

 with 

 such that

 (8.14)We first show that 

 By contradiction, suppose that 

 By assumption, there exists 

 such that 

 Substituting in (8.14), it follows that 

 Since 

 and 

 the inequality 

 is possible only if 

 But this is excluded from the Theorem of Fan-Glicksberg-Hoffman. Hence, 

 Dividing (8.14) by 

 and denoting 

 by 

 we get

 (8.15)This shows that 

 In view of Theorem 8.19, it is clear that 

 and that 

 solves the dual problem.
To complete the proof, suppose that 

 is an optimal solution of the primal problem, that is 

 

 and 

 From (8.15), letting 

 we get 

 Since 

 and 

 we get 

 and the proof is complete.    



The Lagrangian dual function 

 is a is always a concave function on its domain, as, for fixed x,  

 is linear in u and thus 

 is the infimum of a (possibly infinite) collection of functions linear in u. It follows that 

 admits a directional derivative at every point of its domain. However, the Lagrangian dual function 

 may be not differentiable. Furthermore, we have to note that Theorem 8.25 provides only sufficient conditions for the existence of strong duality: strong duality can hold also for nonconvex problems. Consider, e.g. the following example.

Example 8.26
Consider the problem

We have 

 The Lagrangian function is 



Hence, 

 is the dual optimum and 



We consider again a primal problem of the type 

 but now we add a differentiability assumption on the functions involved in the said problem, in order to treat the Wolfe dual, already introduced in Example 8.18. Let us therefore consider the following primal problem (P),  i.e.

where the functions 

 and every 

, 

 are differentiable on the open set 

 The Wolfe dual (see [13]) is defined as follows (

 is the usual Lagrangian function of 

 

).

Note that the constraints of 

 are part of the Karush-Kuhn-Tucker conditions for the primal problem (P).

Theorem 8.27
(Weak duality theorem) Let 

 be an open convex set and let the functions 

 and every 

 be differentiable convex functions on X. If x is feasible for (P) and 

 is feasible for 

 we have





Proof
As f is differentiable and convex on X,  it holds

As 

 is feasible for 

 it holds

Being the functions 

 

 differentiable and convex on X,  it results

From the last three relations, we get immediately

Finally, as x is feasible for (P),  it results 

 and hence 

 From the last inequality proved above, we get therefore

   




Theorem 8.28
(Strict direct duality theorem) Let 

 be an open convex set and let the functions 

 and every 

 be differentiable and convex on X. If 

 is a solution of (P) and if the constraints of (P) verify a constraint qualification (i. e. (P) is "qualified" ), then there exists some 

 such that the pair 

 is a solution of 

 Moreover, it holds





Proof
Being the primal problem (P) qualified, the optimal point 

 verifies the Karush-Kuhn-Tucker conditions with a multipliers vector 



and

Therefore, the pair 

 is feasible for 

 Now

 (8.16)But, being f and g convex on X,  by Theorem 8.27 we have

Hence, 

 solves 

 and relation (8.16) puts into evidence that the optimal values of the two problems are equal.    




Theorem 8.29
(Strict converse duality theorem) Assume  that 

 is an open set and that 

 and 

, 

 are given. Let 

 be a solution of 

 and let f and every 

 

 be twice-continuously differentiable on X. If: (a)


 is pseudoconvex on X,  with respect to x,  and
 (b)
the Hessian matrix 

 is nonsingular,
then 

 is a solution of the primal problem (P) and, moreover, 



 



Proof
Being 

 a solution of 

 it results that the system

admits a solution. The assumptions of the theorem permit the application of the Implicit Function Theorem: there exists an open neighborhood 

 of 

 and a function 

 such that 

 and

Now we observe that, as 

 is a solution of the dual problem 

 it results that 

 is a solution of the following nonlinear programming problem

It results that the following conditions are satisfied:

Now, being

it results

The conditions written above become

i.e.

 (8.17)As 

 from (8.17) it results that 

 is also feasible for (P). As 

 it results

Being 

 pseudoconvex on X,  with respect to X,  it results that 

 is a global minimum point of 

 on the feasible set of (P). In other words, for every feasible x for (P),  we have

i.e.

Finally, as 

 for each feasible x (for (P) ), it results, for all feasible x

The fact that the optimal values of the two problems coincide, is an immediate consequence of the complementary slackness conditions established in (8.17).    




Remark 8.30
In Theorem 8.29, instead of assuming that the Lagrangian function 

 is pseudoconvex on X,  with respect to x,  it is possible to assume that f is pseudoconvex and that every 

 

 is quasiconvex on the open convex set 

 The proof is quite similar. The theorem still holds if 

 is not a global, but only a local maximum point of 

 on 



As we have just asserted, Theorem 8.29 holds with suitable generalized convexity assumptions on the functions f and every 

 

 involved in (P) and 

 whereas Theorems 8.27 and 8.28 require convexity assumptions. Indeed, for these last two theorems, a generalized convexity assumption on the functions involved in (P) and 

 does not assure their validity, not even for linear constraints. The following example is due to Mangasarian [14].

Example 8.31
Consider the following primal problem

Its Wolfe dual is

which can also be written in the equivalent form

The solution of the primal problem is obviously 

 the objective function of (P) is pseudoconvex and all other assumptions of Theorem 8.29 are verified. Nevertheless, the problem 

 has no optimal solution, as the equation 

 has no real root. It has a greatest upper value at 0, which is not attained, and even the weak duality theorem is not satisfied.

A more simple counterexample is the following one.

Example 8.32
Consider the primal problem

The optimal point is at 

 whereas the value of the Wolfe dual

is unbounded.

We have to note that if we impose (as in Theorem 8.29) pseudoconvexity on the Lagrangian function, the weak and strong Wolfe duality do hold. We give the simple proof for weak duality:

Therefore,

Now we give some other properties on the Wolfe dual problem. For convenience we denote by K(P) the feasible set of the primal problem and by 

 the feasible set of the Wolfe dual problem.

Theorem 8.33
Let 

 be an open set and let in (P) the objective function 

 and the constraints 

, 

 be differentiable on X.
(a)
If there exists a pair 

 such that the linear system 

 (8.18) has no solution 

 then the Wolfe dual problem has an unbounded objective function on 

 i.e. 

.
 (b)
If, furthermore, g is convex on the open convex set 

 then 


 



Proof
By Farkas' theorem of the alternative, if system (8.18) admits no solution 

 then there exists 

 such that

 (8.19)Let us put 

 

 it is clear that 

 and

for every 

 In other words, 

 for every 

 Moreover, as

it results

by the last inequality of (8.19). From the last written relation, we get

i.e. the thesis of part (a).
(b) Let us suppose 

 and let be 

 As g is convex on the open convex set 

 it results

As 

 from the last relation we have that system (8.18) has a solution 

 which is in contradiction with the assumptions.    




Theorem 8.34
If 

 g is linear (affine), 

 and 

 then the Wolfe dual problem has an unbounded objective function on 

 i.e.





Proof
Let be 

 with 

 and A matrix of order (n, m). It is sufficient to prove that the linear system (8.18) has no solution 

 Indeed, if this system has a solution 

 it results

i.e.

In other words, 

 which contradicts the assumption that 

.    




Theorem 8.35
Let 

 be an open convex set and let 

 and every 

, 

 be differentiable on X. If 

 and 

 and the functions f and every 

 

 are concave on X,  then f admits no local minimizer on K(P).


Proof
Let 

 as 

 and 

 it results that the linear system

admits no solution 

 By Farkas' theorem of the alternative, it results that there exists 

 such that

On the grounds of the previous relations, from the concavity assumptions on f and g on X,  for every 

, we obtain

and

Moreover, by choosing 

 small enough, we have 

 From what proved above, it results that for 

 small enough we have 

 and 

 which shows that 

 cannot be a local solution of the primal problem (P).    



As previously pointed out in Remark 8.30, when dealing with the Wolfe dual (DW),  weak and strong duality require convexity requirements on the objective and constraint functions, whereas the converse duality theorem can be stated under generalized convexity assumptions. In order to lessen the convexity requirements on the weak and strong duality results (under differentiability assumptions), in [15] it is proposed the following dual of (P).

The advantage of (MWD) over (WD) is that the objective function of the dual is the same as that of the primal, and, more importantly, the convexity requirements for weak and strong duality relations can be furthermore relaxed.

Theorem 8.36
(Weak duality) If for all feasible vectors x of (P) and all feasible vectors (y, u) of 

 the objective function f(x) is pseudoconvex and the function 

 is quasiconvex, then





Proof
Let x be feasible for (P) and (y, u) be feasible for 

 Since 

 and 

 by using Theorem 3.​20 since 

 is quasiconvex, we have

Therefore, by the constraints of 

, one has

and using the pseudoconvexity of f, we derive that 

.    




Theorem 8.37
(Strong duality) If 

 is a local or a global optimum point of (P) at which a constraint qualification is satisfied, then there exists 

 such that 

 is feasible for 

 and the corresponding values of (P) and 

 are equal. If, also, for all feasible (x, y, u),  f is pseudoconvex and 

 is quasiconvex, then 

 and 

 are global optima for (P) and 

 respectively.


Proof
Assuming that a constraint qualification is satisfied at 

 then by the Karush-Kuhn-Tucker conditions, there exists 

 such that

Thus, 

 is feasible for 

 Equality follows, given the pseudoconvexity of f and the quasiconvexity of 

 from weak duality.    




Example 8.38
We consider again the primal problem of Example 8.32:

The Mond-Weir dual is now

The optimum is attained at 

 



Now we wish to give a generalization of the Lagrangian saddle point (Definition 8.1) and to give further insights on the properties of saddle points, as these properties will allow to point out the relationships between saddle point theory, min-max theory and duality theory.
In general, saddle points are closely related to the Theory of Games, in which two players with conflicting interests oppose each other. For a given "pay off" function 

, one player is minimizing 

 with respect to x,  while the other player is maximizing 

 with respect to y. This is called a min-max of 

 The mathematical foundations of the theory of games and its applications to economics were laid down by J. von Neumann in the twenties of the last century and subsequently described in the classical work of [9].

Definition 8.39
Let 

 be a real function of two real vectors 

 and 

 Thus, the domain of 

 is 

 A point 

 with 

 and 

 is said to be a saddle point of 

 if

 (8.20)


The value 

 is called the value of the saddle point. It is clear that (8.20) is equivalent to

We have the following general property.

Theorem 8.40
For all saddle points 

 the value 

 is constant. If 

 and 

 are saddle points, then 

 and 

 are saddle points as well.


Proof
The following relations hold:




If, in the first one, we take 

 and 

 and in the second one we put 

 and 

 we get

Moreover, we can write for every 



whence 

 is a saddle point. For 

 the proof is similar.    



Now, let be 

 

 

 and let us consider the following two "min-max" problems, i.e. the "primal" problem (P)

and the "dual" problem (D)

where

and

We note that it always holds ("weak duality theorem" ):

 (8.21)The following fundamental theorem gives a characterization of saddle points in terms of a min-max property and therefore it establishes links between saddle points characterizations, min-max properties and duality properties for (P) and (D). In a certain sense, it may be regarded as a strong duality result without no convexity and no regularity assumptions on the functions involved.

Theorem 8.41
Let be 

, with 

 and 

 and let be 

 The following conditions are equivalent:
(a) The pair 

 is a saddle point of 

 on 


(b) 

 is a solution of (P),  

 is a solution of (D), and the two optimal values are equal, i.e.

 (8.22)Furthermore, if either (a) or (b) is satisfied, the common optimal value of (P) and (D) must be 




Proof
Suppose that (a) holds. We have

where the middle equalities follow directly from the definition of saddle point, and the first and last equalities are trivial. Then,

where the last inequality follows from the weak duality theorem (see (8.21)).
Since the first and the last terms of the above inequalities are the same, we must have equalities throughout. This proves (b),  and the fact that the common optimal value of (P) and (D) equals 


Conversely, suppose that (b) holds. Then (8.22) gives

which in turn implies

that is proposition (a).    



From the previous result, it appears that an existence theorem on saddle points for 

 can be considered an existence theorem on duality between (P) and (D) and vice-versa. Note that, since now, we have not imposed on X and Y any particular structure, nor we have required some particular property on the function 

 Now we recall the main results available in the literature, on the existence of a saddle point for 

.
(i) (von Neumann). Let be



 with A matrix of order (m, n). Then 

 admits a saddle point 

 on 


(ii) (Kakutani). Let X and Y be convex and compact sets in 

 and 

 respectively. Let 

 be continuous on 

 convex with respect to x on X (

) and concave with respect to y on Y (

). Then 

 admits a saddle a saddle point 

 on 


(iii) (Sion). Let X and Y be convex and compact sets in 

 and 

 respectively. Let 

 be lower semi-continuous and quasiconvex with respect to x on X and upper semi-continuous with respect to y on Y. Then 

 admits a saddle point 

 on 


See [16, 17].
We quote also a result, due to [18], which relates min-max theorems to duality theorems. For other results of this type, the reader is referred to [19-22].

Theorem 8.42
Let X and Y be convex and closed sets in 

 and 

 respectively; let 

 be continuous on 

 convex with respect to x on X and concave with respect to y on Y. For the programs




we have the following duality properties.
(i) If (D) admits a solution 

 i.e.

and if the set

is bounded, then there exists 

 such that 

 is a solution of both (P) and (D) and 


(ii) If (P) admits a solution 

 i.e.

and if the set

is bounded, then there exists 

 such that 

 is a solution of both (P) and (D) and 



Now let us reconsider the primal and dual problems (P) and (D) described at the beginning of the present section.

i.e.

being 

 

 and

and

where

On the grounds of what was previously asserted, we have the following result.

Theorem 8.43
The following statements are equivalent: (i)
The Lagrangian function 

 admits a saddle point at 


 (ii)


 is a solution of (P),  

 is a solution of (D) and the optimal values of (P) and (D) are equal: 



 


For the reader's convenience, we give an "autonomous proof" of this theorem.

Proof
(i) Suppose that 

 is a saddle point of the Lagrangian function; it will be 

 (Theorem 8.3), hence 

 is feasible for (P). Since 

, we have also that 

 is feasible for (D). Moreover, (Theorem 8.3), 

 By Corollary 8.21, 

 and 

 solve (P) and (D),  respectively, with no duality gap.
(ii) Suppose that 

 and 

 are optimal solutions to problem (P) and (D),  respectively, with 

 Hence, we have 

 

 and 

 Moreover, we have by primal-dual feasibility that

But 

 by hypothesis. Hence, equality holds throughout above. In particular, 

 and so,

Hence, all properties of Theorem 8.3 hold, in addition to 

 and 

 and so the pair 

 is a saddle point of the Lagrangian function.    




References1.A. Takayama, Mathematical Economics, 2nd edn. (Cambridge University Press, Cambridge, 1985)2.H. Uzawa, The Kuhn-Tucker theorem in concave programming, in eds. by K.J. Arrow, L. Hurwicz, H. Uzawa, pp. 32-37 (1958). Reprinted in Giorgi and Kjeldsen (2014)3.H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability, ed. by J. Neyman (University of California Press, Berkeley, 1951), pp. 481-492. Reprinted in Giorgi and Kjeldsen (2014)4.S. Karlin, Mathematical Methods and Theory in Games, Programming and Economics, vol. I, II (Addison-Wesley, Reading, Mass, 1959)5.T. Weir, B. Mond, Pre-invex functions in multiple objective optimization. J. Math. Anal. Appl. 136, 29-38 (1988)6.K.J. Arrow, L. Hurwicz, H. Uzawa, Constraint qualifications in maximization problems. Naval Res. Logist. 8, 175-191 (1961). Reprinted in Giorgi and Kjeldsen (2014)7.H.W. Kuhn, A.W. Tucker (Eds.), Linear Inequalities and Related Systems, Annals of Mathematics Studies N. 38 (Princeton University Press, Princeton, N.J., 1956)8.O.L. Mangasarian, A simple characterization of solution sets of convex programming. Oper. Res. Lett. 7, 21-26 (1988)9.J. Von Neumann, O. Morgenstern, Theory of Games and Economic Behavior, 2nd edn. (Princeton University Press, Princeton, 1947)10.R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)11.R.T. Rockafellar, Conjugate Duality and Optimization. (Society for Industrial and Applied Mathematics, Philadelphia, 1974)12.T.L. Magnanti, Fenchel and Lagrange duality are equivalent. Math. Program. 7, 253-258 (1974)13.P. Wolfe, A duality theorem for non-linear programming. Quart. Appl. Math. 19, 239-244 (1961)14.O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)15.B. Mond, T. Weir, Generalized concavity and duality, in Generalized Concavity in Optimization and Economics, eds. by S. Schaible, W.T. Ziemba (Academic, New York, 1981), pp.263-28016.M. Sion, On general minimax theorems. Pac. J. Math. 8, 171-176 (1958)17.C. Berge, A. Ghouila-Houri, Programming, Games and Transportation Networks (Wiley, New York, 1965)18.J. Stoer, Duality in nonlinear programming and the minimax theorem. Numer. Math. 5, 371-379 (1963)19.S. Karamardian, Strictly quasi-convex (concave) functions and duality in mathematical programming. J. Math. Anal. Appl. 20, 344-358 (1967)20.O.L. Mangasarian, J. Ponstein, Minmax and duality in nonlinear programming. J. Math. Anal. Appl. 11, 504-518 (1965)21.J. Stoer, C. Witzgall, Convexity and Optimization in Finite Dimensions, I (Springer, New York, 1971)22.W. Vogel, Duale optimierungsaufgaben und sattelpunktsä. Unternehmensforschung 13, 1-28 (1969)












© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_9





9. Linear Programming and Quadratic Programming



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es







9.1 Linear Programming
As said in the previous pages, a Linear Programming problem (L. P. for friends) is characterized by a linear (or a linear affine) objective function and by linear (or linear affine) constraints. Usually, the variables are also required to be nonnegative. As L. P. is a particular case of nonlinear programming (the involved functions are both convex and concave and differentiable on 

), all theorems seen for the general case of nonlinear programming hold also for L. P. and almost always in a simplified form.
The subject of L. P. was considered before the Second World War. The French mathematician Joseph Fourier (1768-1830) was one of the first researchers to investigate this subject and to point out its importance for mechanics and probability theory. In a certain sense, he may be considered a precursor of the modern theory on theorems of the alternative for linear systems and for the celebrated "simplex algorithm" for L. P., devised by the American mathematician Dantzig (1947). In the Soviet Union, the mathematician L. V. Kantorovich, in 1939, had already proposed an algorithm to solve a special linear programming problem arising from a transportation problem of products from various industries dislocated in different territorial points. Subsequently, it appeared that the two algorithms (of Dantzing and Kantorovich) are in fact equivalent (see, e.g. [1]).
Kantorovich (but not Dantzig) was awarded in 1975 (together with T. C. Koopmans) the Nobel Prize in Economic Sciences for the development of L. P.. For some other historical notions the reader may see the book edited by Giorgi and Kjeldsen [2]. For a description of various mathematical techniques to deal with a linear programming problem, it is useful to the paper of [3] and the works on L. P. quoted in the References. See also, for example: [4-19].
In the present book we shall not be concerned with the algorithms proposed to solve a linear programming problem, but only with the basic facts on optimality and duality theory. In L. P. the objective function f is usually expressed in the form

c,  

 

 and the constraints as inequalities of the type

or, in a matrix form

where A is a (real) matrix of order (m, n) and 

 Furthermore, almost always there is also a "sign restriction" on the variables, in the sense that they are required to be nonnegative:

Usually, in case of a maximization problem, a linear programming problem is written in the form, said "canonical form",

In case of a minimization problem, usually we have the form (again called "canonical form")

We remark once more that linear programming problems are differentiable optimization problems, both convex and concave. These problems can be represented as problems with functional constraints expressed by only equalities (this is possible also for nonlinear programming problems, but in the case of L. P. the procedure is more important, mostly for algorithmic considerations), by means of the introduction of nonnegative auxiliary variables, said "slack variables". More precisely, if the functional constraints are of the type

they are transformed into the equivalent equality system

with 


If the functional constraints are expressed as

they are transformed into the equivalent equality system

with 


A linear programming problem in the form

is said to be in "standard form". Some classical books on L. P. adopt an opposite denomination: they call a "canonical form" what we have called a "standard form" and vice-versa.
The applications of L. P. are numberless, in the most varied sectors; we limit ourselves to give only some typical examples, arising from management and financial models (one of the first books on economic applications of L. P. is the one of [11]).
(a)
Diet Problem. A diet problem (in the sense of linear programming) is one of finding the least expensive way to meet a given set of daily untrivial goals using a particular set of foods.
 (b)
Activity Analysis Problem. We have to use a given set of activities (production processes) and a given set of resources in order to maximize profit associated with the production processes subject to limitations on the resources. When the objective and constraints are expressed by linear (affine) functions we have a L. P. problem. The classical book on these questions (containing also the original paper of G. B. Dantzig on the "simplex algorithm") is the one edited by [20].
 (c)
Transportation and Assignment Problems. 
The first analysis of these types of problems is usually attributed to L. V. Kantorovich in 1939 and to F. L. Hitchcock in 1941: a single commodity is to be "shipped" from m sources to n destinations. At each source i there is a known supply 

 of the commodity. At each destination j there is a known demand 

 for the commodity. To ship a single unit of the commodity form source i to destination j costs 

 the known unit shipping cost. In such a problem we let the variable 

 denote the amount of the commodity shipped from i to j. The objective is to minimize the total shipping cost, taking into account the constraints: 



 

The set 

 or 

 or 

 is the feasible set for a canonical or standard L. P. problem. In the literature on L. P. the set K is also called "set of feasible solutions", whereas the optimal point 

 is also called "optimal feasible solution" (sic!).
Now, let 

 be a convex set. A point 

 is called an extreme point of S if there do not exist points 

 and 

 (

) in S such that

Note that strict inequalities are imposed on 

 The definition stipulates that an extreme point cannot be "between" any other two points of the set. Clearly, an extreme point is a boundary point of the set, but the vice-versa is not obviously true. If a convex set contains only a single point, this point will be considered an extreme point. There exist also convex sets without extreme points: for example in 

 the open set given by all interior points of a circle.
We have the following basic result on extreme points for convex sets. See, e.g. [21, 22]. We first need the following definition.

Definition 9.1
The set 

 is bounded from below if there exists a vector 

 such that

The set 

 is bounded from above ,if there exists a vector 

 such that




Obviously, a bounded set 

, is both bounded from below and bounded from above. We recall again the concept of supporting hyperplane for a convex set 

 (see also Theorem 2.​19): given a boundary point 

 then 

 

 

, is called a supporting hyperplane at 

 if 

 and if all other points of S lie in one of the closed half-spaces produced by the hyperplane, that is 

 for all 

 or 

, for all 

 (If 

 is a boundary point of a closed convex set, there is at least one supporting hyperplane at 

).

Theorem 9.2
Let 

 be a closed convex set, bounded from below (or bounded from above). Then every supporting hyperplane for S contains at least an extreme point of S.


Definition 9.3
A set in 

 which can be expressed as the intersection of a finite number of closed half-spaces is called a polyhedral set or a polyhedron. A bounded polyhedron is also called a polytope.

We have to point out that in the literature there is not uniformity on the above definitions. Several authors call "polytope" what we have called "polyhedron" and vice-versa. It can be shown that a polytope is given by the convex hull of a finite number of points (see Theorem 9.4 below).
The intersection of a finite number of polyhedra is a polyhedron and if there is a polytope among them, then the intersection is a polytope. A closed half-space is a polyhedron; a hyperplane is a polyhedron; the empty set is considered a polytope; the whole 

 is a polyhedron. It turns out that a polyhedron is a closed convex set. A polyhedral set can be represented by

or

where A is a matrix of order (m, n),  

 and 

 If 

 we have the representation of (convex) polyhedral cones (see Chap. 2).
Any nonempty (unbounded) polyhedron 

 can be expressed as the sum of a polytope and a polyhedral cone (Representation Theorem for polyhedra). This means that for every 

 there exist points 

 where 

 is a polytope, and 

 where 

 is a polyedral cone, such that 

 Accordingly, we write

An extreme point of a polyhedron is called also a vertex of the polyhedron. A polyhedron that has at least a vertex is also called a pointed polyhedron.

Theorem 9.4
A nonempty polytope is given by the convex hull of its vertices.

(This theorem is a particular case of a more general theorem, known as Theorem of Krein-Milman).
Let 

 and 

 be distinct extreme points of the convex set 

 The line segment joining them is called an edge of the convex set if it is the intersection of S with a supporting hyperplane. If 

 is an extreme point of S,  and if there exists another point 

 such that 

 

 and if, in addition the set 

 is the intersection of S with a supporting hyperplane, then the set L is said to be an edge of S which extends to infinity.
Two distinct extreme points 

 of the convex set 

 are called adjacent if the line segment joining them is an edge of the convex set. These concepts are particularly useful when S is a convex polyhedron: the extreme points 

 and 

 of the polyhedron K are adjacent if every point on the line segment joining 

 and 

 cannot be expressed as a convex combination of any pair of points in the convex polyhedron that are not on this line segment. The line segment joining a pair of adjacent extreme points of a convex polyhdron is an edge of the convex polyhedron.
From what previously said, we deduce that the feasible set of a linear programming problem, if non-empty, of the type 

 

 or 

 

 or 

 

 is a convex polyhedron (hence a closed and convex set). This polyhedron is, therefore, generated by the hyperplanes of equations

where 

 denotes the i-th row of A,  

 and by the hyperplanes 

 


If we denote by K the feasible set of an L. P. problem, then K can be: (i)
Empty, as the constraints are inconsistent.
 (ii)
Unbounded, i.e. some variables can assume arbitrary large values.
 (iii)
Bounded (and nonempty), i.e. a polytope. This is surely the most interesting case, at least for practical problems.
 

We can now state the first fundamental result on L. P.

Theorem 9.5
(First fundamental theorem on L. P.) A linear programming problem which admits a solution, admits a global solution; furthermore, the optimal points are not interior points of the feasible set. The optimal point, if unique, is at a vertex of the feasible set; if the optimal point is not unique, there are infinite optimal points corresponding to two or more vertices of the feasible set and to all points of the edge which contains these vertices.


Proof
We first remark that if the feasible set K is not bounded, the related P. L. problem may have no solution (we are not saying that the problem has no solution!). If K is bounded (i.e. it is a polytope), being also closed (and convex) and being the objective function a continuous function, the theorem of Weierstrass assures the existence of a solution. Being the objective function a linear (affine) function, it is both convex and concave and hence the optimal points, if any, are global optimal points. In any case, the optimal points cannot be interior to K: indeed, in this case we would have (Fermat's theorem) 

 i.e. 

 which is excluded by the assumption 

 Therefore, the optimal points, if any, are on the boundary of K. Let us consider, for example, the maximum point 

 i.e. we have

Clearly, the relation 

 characterizes one of the two half-spaces associated to the hyperplane 

 this half-space contains the whole K and the associated hyperplane contains also the point 

 The said hyperplane is, therefore, a supporting hyperplane for K,  which is a closed and convex set. But K,  in our assumptions, is also (at least) a lower bounded set (i.e. bounded from below), being 

 

 Therefore, Theorem 9.2 assures that every supporting hyperplane for K (and hence also the hyperplane 

) contains at least an extreme point of K. This fact allows to say that at least an extreme point (or vertex) of K is a maximum point. Let us prove that if the objective function attains its maximum value at more than one vertex, then it attains the same value at every point of the convex combination of the said maximum points. For example, let us assume that f has a maximum value at the vertices 

 i.e.

If 

 is any convex combination of the said vertices, i.e. if

being 

 

 

 by the linearity of f we have

so, 

 represents a (global) maximum point for the objective function. We can, therefore, conclude that if the optimal point is not unique and, say, 

 and 

 are two adjacent vertices which generate the solution of the problem, also all the infinite points (which form an edge) of the segment joining 

 and 

 are solutions, Obviously, for the case of minimum points the reasoning is similar and similar considerations hold for the case of problems expressed in standard form.    




Remark 9.6
Obviously, there are L. P. problems which admit no solution, for example, because the constraints are inconsistent (i.e. 

) or because, with 

 the feasible set is not bounded (from below or from above or both) and also the related objective function is not bounded over K. For example, consider the simple problem





Remark 9.7
Theorem 9.5 may generate the idea that an L. P. problem is, after all, a trivial problem: it is sufficient to compute the objective function on all vertices of K and then to draw the related conclusions. Unfortunately, in almost all practical problems, the number of vertices of a convex polyhedron, generated, e.g. by

with A matrix of order (m, n),  

 

 is a prohibitive number, also for a powerful computer. Indeed, this number is less or equal than

If, for example, 

 and 

 the said number is about equal to 

 The "efficiency" of the "simplex method" essentially consists of a drastic reduction of the number of vertices to inspect, in order to arrive to the solution (if there exists!) through a tractable number of iterations. Sometimes the "run" is not so rosy, however the algorithm is able to point out the obstacles that may exist. The reader is referred to the works quoted in the References.

The reader is invited to develop, by using geometric considerations (i. e. the level lines) the following simple problems in 

 in order to grasp the meaning of the main propositions of Theorem 9.5.

Example 9.8
Consider the following L. P. problem

The feasible set K is a bounded polyhedron (in 

 perhaps it is better to say "polygon"), whose vertices are (0, 0),  (2, 0),  (0, 3), 

 (see Fig. 9.1).

Fig. 9.1
Example 9.8. Feasible set and maximum


The solution is the point 

 with 




Example 9.9
Consider the following L. P. problem

The feasible set K is not bounded from above (see Fig. 9.2) and 

.

Fig. 9.2
Example 9.9. Feasible set


If, instead of a maximization problem we consider a minimization problem (over the same feasible set), the solution is 




Example 9.10
Consider the following L. P. problem

Note that the feasible set K is the same as Example 9.9. However, with this objective function we have that the two adjacent vertices of K:

are solutions of the problem, with 

 Hence, all points of the segment (edge) joining A and B are also solutions. Indeed, consider the (infinite) points

Let us compute 






We repeat that in the present book, we will not treat the computational questions related to the "simplex algorithm", however, we present some "algebraic" results that, in a sense, are basic for the theoretical foundations of the said algorithm and that allow us to obtain the second fundamental theorem for L. P.
Let us consider a linear programming problem in its standard form:

 (9.1)where A is a matrix of order (m, n),  x,  

 

 and 

 Without loss of generality, let us assume that:

This condition is not restrictive: indeed, if 

 (and 

), the system admits a unique solution 

 and this solution is feasible if 

 If 

 and if the system 

 admits solutions, then 

 constraints are linear combinations of the remaining constraints. Therefore, these 

 constraints can be eliminated. As 

 it is always possible to choose m linearly independent columns of A. Without loss of generality we assume that the first m columns of A are linearly independent (permute the columns, if necessary). We obtain the partitioned matrix

where B is square, non-singular, of order m and N is of order 


The matrix B is called a "basis matrix" of A,  as its lines are a basis for 

 In correspondence, the vector 

 is decomposed as follows

with 

 and 

 The variables of 

 are said "basic variables" and the variables of 

 are said "non-basic variables". We have

from which, being B non-singular,

and hence

 (9.2)is a solution of 

 for all 

.

Definition 9.11
The solution obtained by (9.2) putting in it 

 i.e.

is said a basic solution. If, moreover, it holds 

 this solution is said a feasible basic solution.



Definition 9.12
A basic solution with more than 

 zero components is said a degenerate basic solution. If, moreover, this solution is nonnegative, we speak of a feasible degenerate basic solution. The matrix B is also called, in this case, degenerate basis matrix.


Example 9.13
Let us suppose that the system 

 is the following one:

The first three columns of A are linearly independent, hence

The solution is 

 which is a basic solution, but not feasible, as 


Note that also the sub-matrix is formed by the fourth, second, and third column:

is non-singular; hence, another basic solution is given by

Hence the solution 

 is a basic solution and a feasible basic solution.

The notion of a basic solution is important as the search for optimal solutions (of an L. P. problem) is performed among the basic solutions.

Theorem 9.14
(Second fundamental theorem on L. P.) Let be given a linear programming problem in the standard form (9.1), with 

 and 

 If this problem admits a nonempty feasible set, then there exists a feasible basic solution. If there exists a solution to the problem, then there exists an optimal basic (feasible) solution.


Proof
Let us suppose that 

 i.e.

i.e. with 

 denoting the i-th column of A, 

Let us suppose that x has p non-zero components (

) and, without loss of generality, let us suppose that these components are the first p components. The last relation becomes then

 (9.3)We can have two cases: (1)
The columns 

 are linearly independent, hence 

 If 

 we have a basic solution, if 

 we have a degenerate basic solution and it is possible to choose 

 columns among 

 which, together with the first p columns form a basis.
 (2)
The columns 

 are linearly dependent, i.e. there exist multipliers 

 not all zero, such that 

 (9.4) From (9.3) and (9.4), by subtracting and multiplying (9.4) by a generic scalar 

 we obtain 



 

We now define 

 and so we obtain 

 hence 

 satisfies the system, but it may be not feasible, i.e. not nonnegative. It is, however, possible to choose 

 in such a way that at least one component of 

 is equal to zero (i.e. that component is feasible).
Now, let us consider every component of 

 with 

:

If we choose 

 where 

 is the index such that

then 

 is a solution with at most 

 non zero components, being equal to zero the component corresponding to 


By iterating this process, it is possible to get a solution corresponding to linearly independent columns. In order to prove that if there exists a feasible optimal solution, then there exists also a feasible basic optimal solution, we can follow the same lines of the previous proof. Again we consider two cases.
(i)
The columns 

 are linearly independent. In this case, the solution considered, obtained by adding the zero components, is a basic solution.
 (ii)
The columns 

 are linearly dependent. By modifying the vector x as in the first part of the present proof, we remark that 

 becomes 

 We know that 

 is feasible for every 

 If 

 we would have 

 against the assumption that x is optimal. If 

 we would have 

 against the assumption that x is optimal. Hence 

 and the optimality of the solution is kept, by passing from x to 

 a solution with at most 

 non zero components.
    



The previous theorem is important, as it allows to reduce the computations of the objective function over the set of the basic feasible solutions, whose number is less or equal than

Moreover, it is also possible to put into relation the vertices of a convex polyhedron, generated by a linear programming problem in its standard form, and the basic feasible solutions of the same problem.

Theorem 9.15
Let us consider a linear programming problem in its standard form (9.1), with A of full rank and let P be the convex polyhedron generated by the constraints of the said problem. Then the following statements are equivalent.
(a)
x is a vertex of P.
 (b)
x is a basic feasible solution of the feasible set K.
 



Proof
Let x be a basic feasible solution of a linear programming problem in its standard form; we have, therefore,

 (9.5)with 

 and 

 In order to prove that x is a vertex of P we have to show that there do not exist two vectors 

, 

 such that

 (9.6)Absurdly let us suppose that there exist two vectors 

 and 

 which verify (9.6) and given by

 (9.7)with 

 

 and 

 

 By substituting relation (9.5) into relations (9.6) and (9.7) and making equal the last 

 components, we obtain

 (9.8)with 

 

 

 

 Therefore, (9.8) holds only for 

 Remembering that 

 and 

 are feasible, we have

From 

 being B non-singular, it follows 

 and hence 

 against the assumptions, so x is a vertex of P.
Vice-versa, let us suppose that x is a vertex of P and that x has its first k components different from zero. It will hold

with 

 

 In order to show that x is a basic feasible solution, we have to prove that 

 are linearly independent. If, absurdly, these vectors are linearly dependent, there would exist a linear combination

with 

 not all zero. Then, putting 

 one has 

 for all 

. Remembering that 

 

 it will be possible to choose 

 such that

Putting 

 this vector is given by the convex combination of two distinct vectors of P,  which is absurd, as x is a vertex of P. Hence 

 are linearly independent and x is a basic feasible solution.    



We conclude the present section by remarking that the solution of a linear programming problem, in its standard form, is unique if 

 (then B is unique), i.e. for a non-degenerate basic solution; B can be non unique if some component of 

 is equal to zero, i.e. for a degenerate basic solution.


9.2 Duality for Linear Programming
Duality theory was born within linear models and mostly within L. P. models. We have already given in the previous chapter an example of dual problem for a "primal" L. P. problem. It seems that it was the father of G. B. Dantzig, Tobias Dantzing, himself a mathematician, who suggested the name of "primal problem", in contraposition to "dual problem". Duality theory for L. P. problems is important, not only from a theoretical point of view, but also from a computational point of view: there exists also a "dual simplex algorithm", which can be used, together with the simplex algorithm, to ameliorate the procedure of determining the solution of an L. P. problem.

If we consider a primal linear programming problem in its canonical form, of the type 

 its dual is the problem 




If we consider a primal linear programming problem in its canonical form, of the type 

 its dual is the problem 




If we consider a primal linear programming problem in its standard form, of the type 

 its dual is the problem 




If we consider a primal linear programming problem in its standard form, of the type 

 its dual is the problem 





On the grounds of what previously asserted, it is worth remarking what follows.
(a)
The dual (D) of the primal problem (P) is unique and is itself a linear programming problem.
 (b)
The dual of the dual is the primal problem ("involution property"). We speak also of a "pair" of primal-dual problems.
 (c)
If (P) is a maximization problem, (D) is a minimization problem (and vice-versa). If (P) is a minimization problem, (D) is a maximization problem (and vice-versa).
 (d)
The coefficients of the objective function of (D) are the right-hand side coefficients of the functional constraints of (P) and the right-hand side coefficients of the functional constraints of (D) are the coefficients of the objective function of (P).
 (e)
If (P) is in its canonical form, also (D) is in a canonical form, but with the constraints "reversed", with respect to the constraints of the primal problem.
 (f)
If (P) is in its standard form, (D) is in a canonical form, but without sign restrictions on the variables.
 (g)
If (P) is in a canonical form, but without sign restrictions on the variables, then (D) is in a standard form.
 

For cases (f) and (g) we speak also of "asymmetric" primal and dual problems. We can resume the above correspondences between primal and dual in the following scheme, where I, J, M and N are sets of indices.

Let us verify property (b). We consider the primal problem in the form

Its dual

can be rewritten in the form

i.e.

If we dualize the last formulation we obtain

i.e.

which is just the primal problem we have considered at the beginning.
Let us verify property (f). We consider the following primal problem in its standard form:

which we rewrite in the form

i.e.

Now we dualize the last formulation:

If we put 

 we obtain

with y unrestricted in sign, as 

 with 

 and 

 (obviously the difference may be a vector with components unrestricted in sign).

Example 9.16
By using the dualizing rules of a maximization problem in its canonical form, deduce the dual of

We transform the primal problem into a maximization problem:

Then we have:

i.e.

If we have the following general L. P. primal problem

its dual is

The relations between the two problems, primal and dual, are strict and interesting, not only from a formal point of view, and give rise to several results, useful also for computational and interpretative aspects. First of all we make some considerations on the Lagrangian functions of the primal and dual problems. We consider, e.g. the primal problem

and its dual

We write the respective Lagrangian functions, denoted, respectively, by 

 and 






Putting in 

 

 and putting in 

 the two Lagrangian functions become equal:

This shows that the vector of the variables of a problem is the vector of the multipliers of the other problem. We now write the Karush-Kuhn-Tucker conditions for the two said problems. We recall that being the constraints linear affine, the problems are qualified. Moreover, being also the objective functions linear functions (i.e. both convex and concave), the Karush-Kuhn-Tucker conditions are necessary and sufficient for the optimality of a feasible point that verifies the said conditions. Hence, 

 is a solution of (P) if and only if there exists a vector 

 such that

Similarly, 

 is a solution of (D) if and only if there exists a vector 

 such that

The Karush-Kuhn-Tucker conditions are, therefore, the same for the two problems: if 

 is a solution of (P),  then there exists 

 which satisfies the KKT conditions. Vice-versa, if 

 is a solution of (D),  then there exists 

 which satisfies the same conditions.

Other relations between the primal problem (P) and its dual problem (D) are put forward by various theorems and properties. We begin with two fundamental "existence theorems" on the primal and dual. We follow [23]. We continue to consider (P) as a maximization problem in its canonical form and (D) as its dual problem. We denote by K the feasible set of (P),  i.e.

and by Y the feasible set of (D),  i.e.




Theorem 9.17
(First fundamental existence theorem) Assume that 

 and 

 Then: (i)


 for any 

 for any 


 (ii)


 for some 

 


 



Proof
(i) Since 

 for 

 pre-multiplying 

 (being 

) by 

 yields 

 Similarly, as 

 for 

, we have 

 for all 

. Whence

(ii) A method to prove (ii) is to use Farkas' theorem of the alternative (see Theorem 2.​28). In view of (i),  it suffices to see that 

 for some 

 and 

 Thus we have only to show the existence of a solution, consisting of an m-dimensional vector y and an n-dimensional vector x,  of the system

 (9.9)


 (9.10)This system can be converted, by introducing an 

-dimensional slack vector w, to the system of equations

 (9.11)


 (9.12)where I is the identity matrix of order 


Then, in the light of Farkas' theorem, the system of equations (9.11)-(9.12) has a solution if

 (9.13)for any solution 

 of

 (9.14)where the dimension of the vectors 

 

 

 are m,  n,  1,  respectively.
Let us see that this sufficient condition is fulfilled in effect whenever 

 

 To this end, it is convenient to decompose (9.14) into the equivalent relations

 (9.15)


 (9.16)We divide the subsequent discussion into cases (a) and (b), depending on the positivity of 

(a)
Case 

 Dividing (9.15), (9.16) by 

 we obtain 

 

 

 

 so that 

 

 Whence by part (i), 

 which, multiplied by 

 implies (9.13).
 (b)
Case 

 Equations (9.15) and (9.16) become 

 

 

 

 Choose some arbitrary x from K and y from Y. Then 

 

 Hence 

 which implies (9.13).
 

Therefore, (9.14) implies (9.13) in both cases (a) and (b),  so that the system of equations (9.11)-(9.12) has a solution, or equivalently, the system of inequalities (9.9)-(9.10) has a solution. This completes the proof.    



The duality situation established above can be expressed in a slightly different way in the following second fundamental "existence theorem". We continue to make reference to the maximization problem (P) in its canonical form and to its related dual problem (D),  with K and Y feasible sets of, respectively, (P) and (D).

Theorem 9.18
(Second fundamental existence theorem) (i)
If 

, then (P) admits a solution if and only if 


 (ii)
If 

 then (D) admits a solution if and only if 


 



Proof
If 

 then the assumptions of Theorem 6 are met, so that the common value of 

 and 

 in Theorem 9.17(ii) is a finite maximum (i.e. a solution) of (P),  as well as a finite minimum (i.e. a solution) of (D).
Conversely, let us prove that if 

 the function 

 is unbounded from above on the set K,  or, more symbolically, 

. If we use a slack vector u of dimension n,  we find that the emptiness of Y is equivalent to the non-existence of a nonnegative solution 

 of

where I is the identity matrix of order n. By Farkas' theorem (see Theorem 2.​28) there is some n-dimensional vector 

 such that

If the substitution 

 is done, these results become 

 

 

 Choose now an arbitrary x from K;  then 

 for all 

 and 

 as 

, as was to be shown. The proof of (ii) is exactly similar.    




Remark 9.19
The result (i) of Theorem 9.17 is also known as the weak duality theorem for L. P., whereas the result (ii) of Theorem 9.17, together with Theorem 9.18, i.e. if 

 is feasible for (P) and 

 is feasible for (D),  then the equality 

 is a necessary and sufficient condition for 

 to be a solution of (P) and 

 to be a solution of (D),  is also known as the strong duality theorem for L. P.

We can summarize what previously said as follows (K and Y are, as usual, the feasible sets of, respectively, the primal problem (P) and its associated dual (D)).
1.


There exists a solution of (P) and (D).
 2.


 It holds 

 or it holds 

, but in this case the objective function of (D) is unbounded over Y.
 3.


 It holds 

 or it holds 

, but in this case the objective function of (P) is unbounded over K.
 


Example 9.20
Consider the problem

It is seen without difficulty that the objective function is unbounded on the feasible set K. Hence the problem admits no solution. Its dual is

Its feasible set, by Theorem 9.18(i), is empty: 



We have other theorems which relate the primal problem (P) to its dual problem (D). Again we assume that (P) is of the form

with dual




Theorem 9.21
(Equilibrium theorem or complementary slackness theorem) Let 

 and 

 Then, 

 and 

 are solutions, respectively, of (P) and (D) if and only if the following complementary slackness conditions hold:





Proof
The two above conditions are necessary, as they are part of the Karush-Kuhn-Tucker conditions for (P) and (D). As for what concerns the sufficiency, we note that if 

 and 

 satisfy the said slackness complementary conditions, we have

Therefore, we have 

 and so it holds (strong duality) that 

 solves (P) and 

 solves (D).    




Remark 9.22
The complementary slackness conditions of Theorem 9.21 can be rewritten in the form (

 is the i-th row of A,  whereas 

 is the j-th column of A): (a)


;
 (b)


;
 (c)


;
 (d)


.
 


It is possible to give economic interpretations of these implications; see, e.g. [23].
The following result, due originally to Goldman and Tucker (see [24]), puts into relation the primal and dual problems with the saddle point of the related Lagrangian function. For the usual maximization problem (P),  the Lagrangian function is defined as

For the said maximization problem (P) a pair 

 is a saddle point of 

 if

 (9.17)We recall that no constraint qualification is needed (for the necessary conditions), as the constraints are linear affine functions.

Theorem 9.23
(Saddle point and duality) The primal problem (P) admits a solution 

 and the dual problem (D) admits a solution 

 if and only if the pair 

 is a saddle point for the Lagrangian function 

 i.e. if and only if (9.17) is satisfied.


Proof
(i) Necessity. If 

 is a pair of optimal solutions of, respectively, (P) and (D),  we have







Whence




proving the necessity.
(ii) Sufficiency. If 

 is a saddle point of the Lagrangian function, (9.17) entails




giving rise to

Hence 

 

 On the other hand, (9.17) for 

 

 implies

which proves the optimality of 

 

 Therefore, 

 solves (P) and 

 solves (D).    



On the grounds of what previously expounded we can assert that the following propositions are equivalent: 1.
The Lagrangian function 

 has a saddle point 

 over 

.
 2.
The primal problem has an optimal solution 


 3.
The dual problem has an optimal solution 


 4.
Both the primal and the dual have a nonempty feasible set.
 5.


 is feasible for the primal and 

 is feasible for the dual and 


 

Finally, we give some insights on sensitivity for L. P. problems. The literature on sensitivity, stability and in general postoptimal analysis for L. P. problems is quite abundant (see, e.g. [25-27] and the works on L. P. quoted in the References of the present book). We remark once more that the vector of the solutions of the dual problem 

 is nothing but the vector of the multipliers of the Lagrangian function 

 Let us consider, as before, the primal problem

and its dual problem

Let us consider the optimal value function v(b) of the primal problem, as a function of the right-hand side vector b (while A is kept constant).
We write K(b) to put into evidence the dependence of the feasible set of (P) from b. Let us denote




Theorem 9.24
The optimal value function v(b) is concave on B.


Proof
Let 

 and 

 be two solutions of (P) corresponding, respectively, to 

 

 with c fixed. Then it can be easily verified that 

 for any 

 

 

 Hence

proving the desired concavity.    




Corrolary 9.25
The optimal value function v(b) is continuous on 

 It is possible to prove that v(b) is continuous on B.


Corrolary 9.26
The optimal value function v(b) has right-hand side and left-hand side partial derivatives on 




Theorem 9.27
If 

 

 is the i-th component of any optimal solution 

 of (D),  then we have, with 



Furthermore, if the dual problem (D) has a unique solution 

 then the optimal value function v(b) is differentiable at the corresponding point b and it holds




The economic interpretation of the last result is the same as the one given in Chap. 7: in economic analysis the dual solutions 

 are called "shadow prices" or "marginal costs" relative to the resource 


If (D) does not admit a unique solution, things are more complicate. However, it is possible to prove that if the set of dual solutions is compact, then the left-hand sided and the right-hand sided partial derivatives of the optimal value function v(b) are computable in the way expressed by the following result.

Theorem 9.28
Let the set U(b) of the optimal solutions of the dual problem (D) be nonempty and compact. Then it holds

where 

 denotes the i-th component of 



For a discussion on uniqueness of the solutions in an L. P. problem see, e.g. [28].


9.3 Quadratic Programming
In the present section we give some insights on an important type of nonlinear programming problems: the quadratic programming problems.  All such problems have a quadratic objective function and linear affine constraints. A quadratic function is one of the form

(the presence of the factor 

 is useful when the gradient and Hessian of 

 are computed), where usually C is a symmetric matrix of order n,  and x,  

 

. Usually the scalar 

 is omitted, as it does not affect the location of an optimal solution. Therefore, in the sequel we shall consider a quadratic function in the form

 (9.18)The subject of Quadratic Programming has been considered in several books and papers, e.g. [29-34]. Quadratic programming has, similarly to L. P., many applications; one of the most important applications is the so-called "Portfolio Selection Problem", introduced by [35, 36]. Markowitz was, for the said contribution, one of the recipients of the 1990 Nobel Prize in Economic Science. Another possible application of quadratic optimization is the following one: consider the problem of approximately solving an over-determined linear system 

 where A has more rows than columns. We might want to solve the problem

Now note that 

 and so this problem is equivalent to

which is in the format of a quadratic programming problem.
The assumption that C is symmetric is not restrictive, as it holds.

for any 

 and so we can replace the non-symmetric matrix C by the symmetric matrix 

 The matrix 

 is called the "symmetric part" of C;  therefore, in this section we assume, without loss of generality that in (9.18) C is symmetric. Note that

and

Note that if in (9.18) we have 

 then 

 becomes a quadratic form:

 (9.19)We recall (see also Chap. 1) that a quadratic form (9.19) and its associated symmetric matrix C are positive semidefinite if

If, in addition,

then the quadratic form (9.19) and the matrix C are positive definite.
In [37] it is proved the following result.

Theorem 9.29
The symmetric matrix C of order n is positive semidefinite if and only if





Proof
(a) We have

so that 

 cannot occur, and, therefore, 

 


(b) Assuming 

 to hold for all 

 we have to prove that 

 implies 

 For every 

 

, we have




The relation 

 cannot hold for all 

 but if 

 and this holds for all 

 only if 

.    



We remark furthermore that:
The positive semidefinite matrix C is positive definite if and only if it is non-singular. In this case the inverse 

 is symmetric and is also positive definite.

We have proved, in Chap. 3, that the quadratic form (9.19) is a convex (resp. a strictly convex) function if and only if C is positive semidefinite (resp. positive definite). These properties hold also for a quadratic function (9.18), as convexity (resp. strict convexity) of 

 depends only from matrix C,  being the addendum 

 linear.

The last result (last lines of the previous point) has been refined by [37] who proved that the quadratic function 

 is convex in any convex set 

 with a nonempty interior (e.g. 

) if and only if C is positive semidefinite.


The following results are immediate.

Theorem 9.30
Suppose that C is a positive semidefinite matrix; then the quadratic function 

 attains its (global) minimum at 

 if and only if 

 solves the system

If C is positive definite, then the unique global minimum of 

 is given by




Another, less trivial, result on the existence of optimal points for quadratic functions, is given in the following theorem.

Theorem 9.31
If a quadratic function (9.18) is bounded from below (from above) on a nonempty polyhedron, it assumes its minimum (maximum) there.

A full proof of the previous result is given, e.g. in [38].
We can describe various types of quadratic programming problems,  e.g. the following ones.










We note that the Lagrangian function for the above problems is

i.e.

It is easy, on the grounds of what expounded in the previous chapters, to write the Karush-Kuhn-Tucker conditions for the various quadratic programming problems described above (we recall that, being the constraints linear affine, the problems are automatically qualified).

We begin with 

 The related Karush-Kuhn-Tucker and feasibility conditions are (see 

 in Table 5.​1, p. xx): 







 Putting 

 and 

 we obtain 

 (9.20)


 (9.21)



The conditions (9.20) form a system of 

 equations with 

 unknowns. The vector y has the meaning of some slack vector in the initial problem while v may be interpreted as a slack vector in a dual problem. Conditions (9.21), that may be rewritten as

show that we are interested only in those solutions of the system (9.20) which have no more than 

 nonzero components.
Let us consider again the Eqs. (9.20) and (9.21)







Now letting

we can rewrite the Karush-Kuhn-Tucker conditions above as a linear complementarity problem

Linear complementarity problems are an important subject within mathematical programming (and also with reference to other types of problems), with both theoretic and algorithmic consequences. See, e.g. [39, 40]).
We write the Karush-Kuhn-Tucker and the feasibility conditions for the other types of quadratic programming problems previously considered.

For 

 we have 













For 

 we have 













For 

 we have 








For what concerns the sufficient optimality conditions, we can assert that if 

 satisfies the feasibility conditions, the Karush-Kuhn-Tucker conditions for 

 

 and the matrix C is positive semidefinite, i.e. 

 is a convex function, then 

 is a solution of problem 

 

, by Remark 6.​7(a). Obviously, we could require that C is positive semidefinite only on the corresponding feasible set, but in this case the problem becomes more complicate. If we require, in 

 and 

 that C is positive semidefinite on 

 we gain nothing: recall that a quadratic function 

 is convex on any convex set 

 with a nonempty interior, if and only if C is positive semidefinite. Let us suppose that in 

 the matrix A,  of order (m, n), has full rank: 

 In [41] it is remarked that if 

 is convex on the feasible set 

 then it is convex on the larger set 

 and the same author shows that this is so if and only if the quadratic form 

 is positive semidefinite when constrained by the homogeneous linear system 

 So, we have to solve the problem

for which the criteria on constrained quadratic forms are applicable. See Chap. 1, [30, 31].
Again: if in 

 the matrix A is of rank m and the matrix C is positive definite, i.e. 

 is a strictly convex function and hence the feasible point 

 which verifies the Karush-Kuhn-Tucker conditions, is the unique solution of the problem, we can obtain an explicit formula for the solution and for the multipliers vector. We rewrite for 

 the feasibility conditions and the Karush-Kuhn-Tucker conditions:

Being C non-singular, we can write these conditions as follows

 (9.22)or also, multiplying by A, as

 (9.23)The matrix 

 of order m,  is symmetric and positive definite; indeed

We have

if and only if 

 i.e. if and only if 

 (

 is injective, being of rank m; 

 is symmetric and positive definite). Therefore, from (9.23) and (9.22) we obtain




where we have put 


Instead of convexity of 

 i.e. of the quadratic form Q(x),  we can assume pseudoconvexity of 

 in order to obtain that the feasible point 

 satisfying the Karush-Kuhn-Tucker conditions for the various quadratic programming problems is a (global) solution of the related problem by Theorem 6.​6. We shall give, at the end of the present section, some insights on the generalized convexity of quadratic forms and quadratic functions. Finally, we remark that those quadratic forms 

 which are positive semidefinite on 

 are called copositive (the same name is used for the symmetric matrix C). Checking copositivity is, however, not a trivial task (see, e. g., [39]).
We now consider the Wolfe dual problem of a quadratic programming problem. Duality for quadratic programming problems was first studied in [42]. For simplicity we develop our analysis for the primal problem 

:

where 

 

 C is a symmetric matrix of order m and A is a matrix of order (m, n),  


The Wolfe dual of 

 can be written in the form

Indeed, the Lagrangian function of 

 is




Hence

Substituting this constraint in the objective function of the dual problem we obtain the familiar form of 

 given in [42]:










(in the second equality we have substituted 

 by 

).
If C is non-singular, 

 reduces to

with 

 

 with 


Indeed, in this case the unique solution of

is given by

Substituting in the dual problem this last relation, we have the above given formulation.
Let us denote by K and by Y the feasible sets of, respectively, 

 and 

 We have the following basic duality results for 



Theorem 9.32
Assume that C is positive semidefinite  (i.e. the quadratic function 

 is a convex function on 

). Then: (i)
(Weak duality theorem):



 (ii)
(Dorn's duality theorem). If 

 has a solution 

 then there exists some 

 such that 

 solves 

 and the two extrema are equal.
 (iii)
(Dorn's converse duality theorem). If 

 admits a solution 

, then there exists some 

 (not necessarily equal to 

), satisfying 

 that solves 

 and the two extrema are equal. If C is positive definite, then 

 is the unique solution of 


 (iv)
If both problems 

 and 

 have a nonempty feasible set, then both problems admit a solution.
 (v)
If one of the two problems, 

 or 

 has a nonempty feasible set, but the other one has an empty feasible set, then the first problem has an infinite extremal value.
 



Proof
Properties (i) and (ii) are direct consequences of the results of Wolfe for duality in differentiable nonlinear programming problems (see Theorems 8.​27 and 8.​28). Now we prove (iii). Being 

 solution of 

 there exists (see Remark 6.​5(a)) 

 such that, with

it holds

 (9.24)


 (9.25)


 (9.26)By (9.25), it follows that 

 is feasible for 

. As 

 is feasible for 

, we have 

, hence 

. Substituting in 

, it results 

. From (9.26), 

, and from (9.24), 

, in consequence

Therefore, by (i) we have that 

 is a solution of 

 and satisfies relation (9.24).
Now we prove (iv). This property results from (i) and from the fact that a quadratic function, bounded from below (resp., from above) on a nonempty convex polyhedron, reaches in the said polyhedron its minimum (resp., maximum) value (Theorem 9.31).
Now we prove (v). We have (Theorem 8.​34) that if 

 

 then 

 Conversely, let 

 

 Being 

 by a theorem of the alternative for linear systems and precisely the statements (see Sect. 2.​2, point 6)

there exists 

 such that

 (9.27)If 

 then 

 and so, 

 it holds 

 i.e. 

 we have 

 and using (9.27), 

 for 

    




Remark 9.33
The dual pairs of quadratic programming problems considered above possess a nice feature not shared by the Wolfe pairs of primal and dual problems: if C is positive semidefinite, then the objective function of the primal is convex on 

 and the objective function of the dual is concave on 



For the reader's convenience, we write the Dorn's duality formulation also for the other quadratic programming problems considered in the present section.
















We point out that Cottle [43] has proposed the following pair of primal and dual quadratic programming problems, which result to be  symmetric, i.e. for this pair it holds the involution property.










with 

 

 A of order (m, n),  B a symmetric matrix of order n.
If we write (Cottle DP) in the form

we note that the dual of 

 is just 

 and hence the involution property holds.

Theorem 9.34
(Cottle) Let the matrices C and B be positive semidefinite. Then the following properties hold: (i)


.
 (ii)
If one of the two problems 

 or 

 has a solution, then there exists a common solution for 

 and (Cottle DP) such that the two optimal values are equal. More precisely: (a)
If 

 admits a solution 

 then there exists 

 with 

 such that 

 is a solution of both 

 and (Cottle DP).
 (b)
If 

 admits a solution 

 then there exists 

 with 

 such that 

 is a solution of both 

 and (Cottle P).
 

 (iii)
If both problems have a nonempty feasible set, then both problems admit a solution.
 (iv)
If one of the two problems has a nonempty feasible set, but the other one has an empty feasible set, then the first of the two problems has an unbounded objective function.
 


Finally, we give some insights on generalized convexity of quadratic forms and quadratic functions. These topics have been extensively studied by various authors: see, e.g. [32-34, 37, 44-46].
We have seen that a quadratic form

with C symmetric matrix of order n,  is convex on 

 (resp. strictly convex) if and only if C is  positive semidefinite (resp. positive definite) and that a quadratic function

is convex on any convex set 

 with a nonempty interior, if and only if C is positive semidefinite [37]. Since the sum of quasiconvex functions is not necessarily quasiconvex, the quasiconvexity of the quadratic function 

 does not follow from the quasiconvexity of the quadratic form 

 as it is the case for convexity.
We recall that a quadratic function 

 (where C is a real symmetric matrix, of order n,  and 

) is quasiconvex on the open convex set 

 (see Theorem 3.​20(b)) if and only if, for all 

:

The quadratic function 

 is pseudoconvex on the open convex set 

 (see Definition 3.​21) if and only if, for all 



It is obvious that the convexity of a quadratic function depends only, as said before, on the matrix C,  while the pseudoconvexity and quasiconvexity may depend also on the coefficient vector c of the linear part. However, with reference to the whole space 

 we have the following basic result on the quasiconvexity of quadratic functions, given in [37].

Theorem 9.35
The quadratic function 

 is quasiconvex on 

 if and only if it is convex on 

.


Proof
Let v be any point of 

 and 

 a number such that

 (9.28)(Change the sign of v,  not of 

 if necessary).
Then

i.e. 

 this also (9.28) holds for any 

 If now 

 is quasiconvex on 

 then (9.28) implies that for all 



or equivalently

The last inequality holds for all 

 only if 

 (or 

 if the sign of v has been changed); as v has been chosen arbitrarily, one has that C is positive semidefinite and thus 

 is convex on 

 The converse statement is obvious: if 

 is convex, it is also quasiconvex by Theorem 3.​25.    



On the grounds of the previous results we have, therefore, the following equivalences (see also Theorem 3.​26):

Moreover, the previous results show also that there is no reason to study quadratic functions that are quasiconvex on 

 neither those that are convex on 

 (recall that a quadratic function 

 is convex on any convex set 

 with a nonempty interior, if and only if C is positive semidefinite). However, there are quadratic functions that are quasiconvex on 

 without being convex on the same set. Take, e.g. the function 


Different is the case of the generalized convexity of quadratic forms and quadratic functions, referred to proper subsets of 

 for example the nonnegative orthant 

 Motivated by the statement of Theorem 9.29, [32, 37, 46] introduces the following definitions.

Definition 9.36
The real symmetric matrix C of order n is positive subdefinite if for all 



The matrix C is strictly positive subdefinite if for all 



(The corresponding notions of negative subdefiniteness can be obtained by substituting 

 for C).

It is evident that positive semidefinite matrices are strictly positive subdefinite, and strictly positive subdefinite matrices are positive subdefinite. The same terminology applies to the related quadratic forms. In order to distinguish positive subdefinite matrices which are not positive semidefinite, from positive semidefinite ones, Martos inserts the word "merely" before "positive subdefinite". The following results summarize the principal theorems of Martos regarding these subjects. We omit the proofs.

Theorem 9.37
([46, 47]) The quadratic form 

 is merely positive subdefinite if and only if (i)


 


 (ii)
The spectrum of C contains exactly one negative element, i.e. C has nonpositive principal minors.
 

The merely positive subdefinite quadratic form 

 is strictly merely positive subdefinite if and only if C does not contain a row (or column) of zeros.

The quasiconvexity and pseudoconvexity of quadratic forms on 

 are characterized by [32, 37, 46] in terms of positive subdefiniteness of the matrices associated to the said quadratic form.

Theorem 9.38
(Martos) The quadratic form 

 is quasiconvex on the nonnegative orthant 

 if and only if it is positive subdefinite. The quadratic form 

 is pseudoconvex on the semipositive orthant 

 if and only if it is strictly positive subdefinite.

The following result, due to Martos, characterizes the quasiconvexity of quadratic functions on 



Theorem 9.39
(Martos). The quadratic function 

 is quasiconvex on 

 if and only if, for all 






The following result, given in [32], characterizes the matrix C and the vector c of the previous theorem.

Theorem 9.40
(Martos) The nonconvex quadratic function 

 is quasiconvex on 

 if and only if the following four conditions hold: (i)
C has exactly one (simple) negative eigenvalue;
 (ii)


 


 (iii)



 (iv)
There is a vector 

 such that 

 and 


 


We note that if C is non-singular, then (iv) of the previous theorem reduces to: 

 Moreover, putting 

 in Theorem 9.39, we can see that if 

 is quasiconvex on 

 then so is the quadratic form 

 Furthermore, we know that if 

 fails to be convex, then so does Q(x).
As for what concerns pseudoconvexity of quadratic functions 

 we report the following result of [48].

Theorem 9.41
If the nonconvex quadratic function 

 is quasiconvex on 

 then it is pseudoconvex on 

 provided 

 (i.e. if 

 is a "proper quadratic function").

It turns out that for "merely" quasiconvex quadratic functions, quasiconvexity and pseudoconvexity on 

 (but also on any open convex set of 

) are equivalent properties. Another significant result ([32, 47]) is the following one.

Theorem 9.42
(a) The nonconvex quadratic function 

 is quasiconvex on 

 if and only if the matrix

is merely positive subdefinite.
(b) If the matrix M of point (a) has no row of zeros and 

 is quasiconvex, but not convex, on the nonnegative orthant 

 then 

 is pseudoconvex on the semipositive orthant 



Thus for a quadratic programming problem of the type 

 or 

 with 

 satisfying condition (b) of the previous theorem, a nonzero feasible Karush-Kuhn-Tucker stationary point 

 must be a global solution to the related problem.

References1.C. Van de Panne, F. Rahnama, The first algorithm for linear programming: an analysis of Kantorovich's method. Econ. Plan. 19, 76-91 (1985)2.G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (Birkhäuser, Basel and New York, 2014)3.M.J. Todd, The many facets of linear programming. Math. Program. Series B 91, 417-436 (2002)4.S. Achmanov, Programmation Linéaire (Editions MIR, Moscou, 1984)5.C. Berge, Topological Spaces. Including a Treatment of Multi-valued Functions, Vector Spaces and Convexity (Dover Publications, Mineola, N.Y., 1997)6.V. Chvatal, Linear Programming (W.H., Freeman, New York, 1983)7.R.W. Cottle, M.N. Thapa, Linear and Nonlinear Programming (Springer, New York, 2017)8.G.B. Dantzig, Linear Programming and Extensions (Fourth Printing), (Princeton Univ.Press, Princeton, 1968)9.G.B. Dantzig, M.N. Thapa, Linear Programming 1: Introduction (Springer, New York, 1997)10.G.B. Dantzig, M.N. Thapa, Linear Programming 2: Theory and Extensions (Springer, New York, 2003)11.R. Dorfman, P.A. Samuelson, R.M. Solow, Linear Programming and Economic Analysis (McGraw-Hill, New York, 1958)12.D. Gale, The Theory of Linear Economic Models (McGraw-Hill Book Company, New York, 1960)13.D. Luenberger, Y. Ye, Linear and Nonlinear Programming, 3rd edn. (Springer, New York, 2008)14.K.G. Murty, Linear Programming (Wiley, New York, 1983)15.E.D. Nering, A.W. Tucker, Linear Programs and Related Problems (Academic, Boston, 1993)16.J. Nocedal, S.J. Wright, Numerical Optimization, 2nd edn. (Springer, New York, 2006)17.A. Schrijver, Theory of Linear and Integer Programs (Wiley, Chichester, 1986)18.M. Simmonard, Linear Programming (Prentice-Hall, Englewood Cliffs, N.J., 1969)19.R.J. Vanderbei, Linear Programming: Foundations and Extensions (Publishers, Boston, Kluwer Acad, 1996)20.T.C. Koopmans, Activity Analysis of Production and Allocation (Yale University Press, New Haven, 1951)21.G. Hadley, Nonlinear and Dynamic Programming (Addison-Wesley, Reading, Mass, 1964)22.G. Hadley, Linear Programming (Addison-Wesley, Reading, Mass, 1975)23.H. Nikaido, Convex Structures and Economic Theory (Academic, New York, 1968)24.H.W. Kuhn, A.W. Tucker (Eds.), Linear Inequalities and Related Systems, Annals of Mathematics Studies N. 38 (Princeton University Press, Princeton, N.J., 1956)25.T. Gal, Postoptimal Analysis, Parametric Programming and Related Topics (McGraw-Hill, New York, 1979)26.T. Gal, Linear parametric programming—a brief survey. Math. Program. Study 21, 43-68 (1984)27.J.E. Ward, R.E. Wendell, Approaches to sensitivity analysis in linear programming. Ann. Oper. Res. 27, 3-38 (1990)28.O.L. Mangasarian, Uniqueness of solution in linear programming. Linear Algebra Appl. 25, 151-162 (1979)29.J.C. Boot, Quadratic Programming (North Holland, Amsterdam, 1964)30.Y. Chabrillac, J.-P. Crouzeix, Definiteness and semi-definiteness of quadratic forms revisited. Linear Algebra Appl. 63, 283-292 (1984)31.G. Debreu, Definite and semidefinite quadratic forms. Econometrica 20, 285-300 (1952)32.B. Martos, Quadratic programming with a quasiconvex objective function. Oper. Res. 19, 87-97 (1971)33.S. Schaible, Second-order characterizations of pseudoconvex quadratic functions. J. Optim. Theory Appl. 21, 15-26 (1977)34.S. Schaible, Quasiconvex, pseudoconvex, and strictly pseudoconvex quadratic functions. J. Optim. Theory Appl. 35, 303-338 (1981)35.H.M. Markowitz, Portfolio selection. J. Financ. 7, 77-91 (1952)36.H.M. Markowitz, Portfolio Selection (Yale University Press, New Haven, 1959)37.B. Martos, Nonlinear Programming. Theory and Methods (North Holland, Amsterdam, 1975)38.E. Blum, W. Oettli, Direct proof of the existence theorem for quadratic programming. Oper. Res. 20, 165-167 (1972)39.R.W. Cottle, J.S. Pang, R.E. Stone, The Linear Complementarity Problem, 2nd edn. (Society for Industrial and Applied Mathematics, Philadelphia, 2009)40.F. Facchinei, J.-S. Pang, Finite-Dimensional Variational Inequalities and Complementarity Problems (Springer, New York, 2003)41.R.W. Cottle, On the convexity of quadratic forms over convex sets. Oper. Res. 15, 170-172 (1967)42.W.S. Dorn, Duality in quadratic programming. Quart. Appl. Math. 18, 155-162 (1960)43.R.W. Cottle, Symmetric dual quadratic programs. Quart. Appl. Math. 21, 237-243 (1963)44.M. Avriel, W.E. Diewert, S. Schaible, I. Zang, Generalized Concavity (Plenum Press, New York, 1988)45.A. Cambini, L. Martein, Generalized Convexity and Optimization. Theory and Applications (Springer, Berlin, 2009)46.B. Martos, Subdefinite matrices and quadratic forms. SIAM J. Appl. Math. 17, 1215-1223 (1969)47.R.W. Cottle, J.A. Ferland, Matrix-theoretic criteria for the quasi-convexity and pseudo-convexity of quadratic functions. Linear Algebra Appl. 5, 123-136 (1972)48.R.W. Cottle, J.A. Ferland, On pseudo-convex functions of non-negative variables. Math. Program. 1, 95-101 (1971)












© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_10





10. Introduction to Nonsmooth Optimization Problems



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es






In treating the various optimization problems described in the previous chapters, we have almost always supposed (with the exception of the characterization of saddle points of the Lagrangian function, in Chap. 8) that the functions involved in the said problems are differentiable or continuously differentiable or twice-continuously differentiable. Starting from the 70s of the last century, the necessity of studying nonsmooth (i.e. nondifferentiable) functions and hence nonsmooth optimization problems, gave rise to a new mathematical theory, called Nonsmooth Analysis  (this term was introduced by the Canadian mathematician F. H. Clarke).
The most important "supplier" and "consumer" of nonsmooth problems is perhaps optimization theory. The first well-studied classes of nonsmooth functions have been those of convex functions and max-type functions. In the 60s and 70s of the past century, modern Convex Analysis and modern Minimax Theory were created; see [1-6].
One of (if not the most) important concepts of Classical Calculus is the concept of derivative (gradient in the multidimensional case). In Convex Analysis and Minimax Theory, this role is played by directional derivatives and by subdifferentials. The concept of subdifferential allows to study convex nonsmooth problems, as in a similar way the smooth problems are studied with the help of gradients. What developed for convex functions has been subsequently adapted to locally Lipschitz functions by the basic results of the Canadian mathematician F. H. Clarke. We shall give some insights into this approach in the next section (Sect. 10.2) of the present chapter.
By now, Nonsmooth Analysis is an autonomous branch of Mathematics and has received important applications also outside optimization theory. We shall give some insights into the axiomatic approach of Elster and Thierfelder [7-10] in defining generalized directional derivatives and generalized subdifferentials in the third and last section of the present chapter.

10.1 The Convex Case
We have seen in Chap. 3 that if 

 is differentiable on the open convex set 

 then f is convex on X if and only if, for every x,  



and we have seen (Theorem 3.​6) that if f is not necessarily differentiable on the open convex set 

 then f is convex on X if and only if for every 

 there exists 

 such that for every 



 (10.1)For example, the function 

 x,  

, does not admit derivative at 

 However, there are infinite straight lines passing through the point 

 lines of equation 

 that lie (except for the point 

) below the graph of f. In other words, there exist infinite values of 

 such that, for every x,  the inequality

is satisfied. In general, this suggests that, at least for convex functions, it is possible to replace the gradient of f,  when f is not differentiable, with a vector 

 satisfying relation (10.1). These considerations allow us to give the following definition.

Definition 10.1
Let 

 be a convex set and 

 a convex function on X. A vector 

 is called a subgradient  of f at 

 if for every 

 it holds

 (10.2)The set of all subgradients of f at 

 is called the subdifferential of f at 

 and denoted by 




Example 10.2
From the previous definition, it follows at once that, for 

 

, 




Example 10.3
We recall what already remarked in Chap. 3: non-subdifferentiability can however occur on the boundary of the domain of f;  this justifies the assumption on the openness of X in relation (10.1). Consider 

, with 

 Then f is clearly convex, but 



If the set 

 is nonempty, we say that f is subdifferentiable at 

 The notion of subgradient has a useful geometrical interpretation, already previously sketched. Suppose 

inequality (10.2) means that the epigraph of f is located on or above the graph of the affine function 

 For every point 

, we have

which can be rewritten as

Consequently, 

 is an element of the normal cone 

:

We have seen in Theorem 3.​17 that convex functions are directionally differentiable at every point of their (open) convex domain. Before stating the basic results on subgradients and subdifferentials of convex functions (and before giving the proof of this last statement), we wish to recall some definitions and concepts on directional derivatives, already given, but here we make also some further considerations.
Several modern treatments of convex functions consider extended real-valued functions, i.e. functions defined on the whole space 

 and assuming also infinite values. Indeed, consider a convex function defined on a proper subset X of 

 Let be

The epigraph of the function f defined on X is identical to 

, defined on the whole space 

 In this way, we can always construct convex functions defined throughout 

 However, allowing convex functions to take on infinite values, requires some caution in arithmetic operations, such as the "indeterminate forms" 

 

 

 Those convex functions that nowhere have the value 

 and are not identically equal to 

 are usually called proper convex functions.

However, in the present book that presents the basic mathematical tools of optimization theory in 

 we shall be concerned only with the usual real-valued convex functions, not necessarily defined on the whole space 

 Now we recall the basic notions and properties concerning directional differentiability, already partially anticipated in Chap. 3. Let us define a direction as a vector 

 

 Given a real-valued function f defined on a subset S of 

, a point 

 and 

, the right-sided derivative of f at 

 in the direction v or the right-sided directional derivative of f at 

 in the direction v is defined as

if the limit exists (finite or not). Similarly, the left-sided directional derivative of f at 

 in the direction v is defined as

if the limit exists (finite or not). For 

 both 

 and 

 are defined to be zero.
The reader can easily verify that the left-sided directional derivative at 

 in the direction v exists if and only if the right-sided directional derivative at 

 in the direction 

 exists and that it holds

so in the applications only 

 is usually considered. If it holds

then we have the (bilateral) directional derivative in the classical sense: 

 We say also that f is directionally differentiable at 

 in the classical sense. In this case, we have therefore

i.e.




Example 10.4
Let us consider a fixed point 

 and the convex function 

 defined by 

 This function admits a right-sided directional derivative at every point 

 in the direction v and we have




A well-known result is: if a function 

 is differentiable at a point 

 then the directional derivative (in the classical sense) of f at 

 in all directions v exist finite and is given by

Other important results on directional derivatives are contained in the following theorem.

Theorem 10.5
If 

 admits a finite directional derivative 

 at 

 this derivative is positively homogeneous of the first degree with respect to the direction v. The same is true for 

.


Proof
The assertion is quite immediate to get. We have, for each 



   



In the sequel, we shall use the notation 

 to denote the right-sided directional derivative of f at 


If 

 exists for all 

 and is linear in v, then f is said to be Gâteaux differentiable at 

 In this case, we have

We come back to convex functions. We have seen in Example 10.4 that the convex function 

 admits a right-sided directional derivative at every point and for every direction v. Indeed, this property is typical of convex functions. More precisely, we have the following result, already anticipated (without proof) in Theorem 3.​17.

Theorem 10.6
Let X be a nonempty open convex set in 

 and 

 a convex function on X. Let 

 and 

. Then: (a)
The "difference quotient" 

 is a monotonically increasing function of 

 i.e. 

 for all 

 with 


 (b)
The directional derivative 

 exists finite and we have 



 (c)
For every 

 the function 

 is sublinear, i.e. positively homogeneous and subadditive. Hence, 

 is a convex function of v and it holds 



 



Proof
(a) Let be 

 with 

 (and hence also 

). Being f convex, we have

This inequality implies

(b) Let be given 

 with 

 and 

 The convexity of f implies




From here, it follows that

Hence, the difference quotient q(t),  for 

 is bounded from below; on the other hand, q(t) is a monotonically increasing function of 

 and hence the existence of a finite directional derivative 

 holds true, with the property

(c) 

 is a sublinear function of the direction v,  i.e.

and

The homogeneity of the directional derivative with respect to the direction has already been proved. Let us prove the subadditivity: if 

 then for any 

 sufficiently small the inequality

implies the relation




from which, taking the limit for 



We recall that linear homogeneity plus subadditivity produces convexity, since

(also the vice versa holds true: linear homogeneity and convexity imply subadditivity).
Finally, as 

, one has

by subadditivity. Therefore,

   



We note that the above theorem holds also if 

 where 

 is a (not necessarily open) nonempty convex set. The same is true also for the next results. The following statement is a consequence of the previous theorem.

Theorem 10.7
Let 

 be an open convex set and let 

 be convex. Then it holds





Proof
Let 

 x be any two points of X. Being f convex on X,  we have

for all 

 From this relation, we obtain, for all 



Taking Theorem 10.6 into account, we obtain, for 

 the thesis.    



In particular, when f is differentiable we have the relation

as seen in Theorem 3.​7(d). Another consequence of the above results is the inequality

Indeed, by Theorems 10.7 and 10.6(a), we have

and so

by Theorem 10.7.
In particular, when f is differentiable, we have the relation

as seen in Theorem 3.​7(f).
As for what concerns differentiability of convex functions, we have the following result, which is a particular case of a more general result, due to Rademacher; see, e.g. [11].
If 

 is convex on the open convex set X,  it is differentiable with continuous partial derivatives everywhere on X,  except for a set of measure zero (in the Lebesgue sense).
Summing up (see also [2, 11, 12]): Let 

 be convex on the open convex set X,  let 

 (or, more generally, let f be convex on the convex set X and let 

). Then the following properties are equivalent: (i)
The function f is differentiable at 


 (ii)
The function f is directionally differentiable at 

 in the classical sense, for any direction 


 (iii)
The function f admits at 

 the n partial derivatives, with respect to its n variables.
 (iv)
The function f is continuously differentiable at 


 

Now we consider subgradients of convex functions and their relations with directional derivatives.

Theorem 10.8
Let 

 be a nonempty open convex set and 

 a convex function on X. Then the subdifferential 

 

 is a nonempty convex compact set.


Proof
We first prove the nonemptiness of 

 We recall that, due to the convexity of f,  the set 

 is a convex set (see Theorem 3.​6). Noting that 

 belongs to the boundary of 

, and recalling the supporting hyperplane theorem (Theorem 2.​19), we have

 (10.3)for some nonzero vector 

 It follows that 

 (otherwise, a contradiction will occur in (10.3) for a large y). If we suppose 

 then we have 

 and 

 

 Since X is an open set, we can choose a positive number 

 and a point 

 such that 

 Consequently, we have 

 which contradicts 

 Hence, 

 Letting 

 and dividing (10.3) by 

 we have

Since 

, 

 we obtain

This implies 

 Hence, 

 The convexity of 

 is obvious. Now we prove the compactness of 

 From the definition of 

 it appears that 

 is a closed set (it is given by the intersection of linear weak inequalities); it remains to prove that it is also a bounded set. Since X is an open set, we choose a positive number 

 satisfying 

 If we suppose that 

 is not bounded, then there exists a sequence 

 such that 

 It is clear that there exists a subsequence, that we denote again by 

 and an index 

 such that 

 as 

 Define a sequence 

 by 

 

, 

. Then it follows that 

 Since a convex function is continuous on an open convex set (see Theorem 3.​13), it follows that the sequence 

 is bounded. Thus, the inequality

does not hold for a large k. But this contradicts the fact that 

 We can therefore conclude that 

 is bounded since 

 and 

 is a compact set. Hence, 

 is a convex compact set.    



We recall here the following characterization of convex functions on an open convex set 

 already given in Chap. 3 (see Theorem 3.​6(e)): Let 

 be an open convex set and let 

. Then f is convex on X if and only if, for every 

 there exists 

 such that

i.e. if and only if f is subdifferentiable at every point 



Theorem 10.9
Let X be a nonempty open convex set in 

, 

 and let 

 be a convex function on X. Then

In other words: if X is open (or, more generally, if 

), and f is convex on X,  then 

 if and only if





Proof
Since by Theorem 10.6(b), 

 is given by

it holds that for arbitrarily fixed 



Hence, 

 We next show the inverse inclusion. For arbitrarily fixed 

 satisfying

we have



 

 Since X is a convex set, every vector 

 can be expressed by 

 for some 

 and 

 Thus, the above inequalities imply 

 Hence,

   




Theorem 10.10
Let 

 be a nonempty open convex set, 

 and let 

 be a convex function on X. Then




(It is also said that 

 is the support function of 

).

Proof
Let 

 be arbitrarily fixed. The compactness of 

 (Theorem 10.8) and Theorem 10.9 imply

Then we have only to show that there exists a vector 

 such that 

 From Theorem 10.6, we get that 

 is a convex function on 

 and from Theorem 10.8, we have that the subdifferential of 

 at 

 is not empty. Hence, we can choose a vector 

 satisfying

 (10.4)Taking 

 we derive that 

 while 

 (

) yields 

 Therefore, we have

 (10.5)From (10.4) and (10.5), it follows that

and hence

We thus have

with 

, which implies 

 This, together with (10.5), completes the proof.    



The following result establishes a relation between gradient and subgradient of a convex function on an open convex set 



Theorem 10.11
Let 

 be a nonempty open convex set and 

 a convex function on X. If f is differentiable at 

 then 

 Conversely, if f has a unique subgradient at 

 then f is differentiable at 




Proof
Since f is differentiable at 

 we have 

 for any 

 Hence, from Theorem 10.9, we have that for 

 it holds

This shows that

Replacing v with 

 we see that the opposite inequality also holds and thus we conclude that

Hence, this shows that 


Conversely, let us assume that f has a unique subgradient 

 at 

 By Theorem 10.10, we have

But it results

Hence, 

 

 In other words, f is directionally differentiable in the classic al sense at 

 for every direction 

 Being f convex, this assures that f is differentiable at 

.    



From what said above, it is once more clear that the subgradient inequality for convex differentiable functions satisfies the relation

 (10.6)for every 

 (

 open convex set). But, for what said in Chap. 3 (see Theorem 3.​7(d)), also the converse is true: if a differentiable function on the open convex set 

 satisfies relation (10.6) for every 

, then f is convex on X.

Example 10.12
The Euclidean norm 

 is differentiable at every point 

 

 and hence in these points 

 At 

 f is not differentiable, it is subdifferentiable and 

 In other words, 

 is given by the unit closed ball in 




Example 10.13
The convex function

is differentiable at any point 

 (and hence also subdifferentiable). At 

 this function is neither differentiable nor subdifferentiable.


Example 10.14
If 

 is a nonempty convex set, then indicator function of the set S is defined as

We have that 

 is given by the normal cone of S at x (empty if 

). Indeed, by definition, we have that 

 if and only if

This condition implies that 

 and

that is, s is normal to S at x : 




From the definition of subgradients and subdifferentials, it is immediate that

The following theorem, due to J.-J. Moreau and R. T. Rockafellar (in a more general version) gives an important calculus rule for subdifferentials of convex functions.

Theorem 10.15
(Moreau-Rockafellar) Let 

 be an open convex set and let 

 If 

 and 

 are convex functions on X,  then the function 

 is convex on X and it holds





Proof
The first part of the thesis has already been proved in Theorem 3.​34. Let now be 

 the inclusion 

 is evident. Suppose that there exists 

 such that 

 By Theorem 10.8, this last set is nonempty, convex, and compact. By the strong separation theorem (Theorem 2.​17), there exists 

 such that

Therefore, it is verified the inequality

inequality which can be rewritten by Theorem 10.10 in the form

Taking into account that

we get the inequality

which, by Theorem 10.9, cannot hold. Hence, we have the thesis of the theorem.    




Remark 10.16
We have to note that also Theorem 10.15 holds under the weaker assumption that 

 is a nonempty convex set, 

, 

 and 

 are convex functions on X, 

 is compact, 

 finite and 

 is closed.

Now we report some optimality conditions for various optimization problems, where the functions involved are convex. We begin with an unconstrained optimization problem, of the type 

 We recall first the basic optimality conditions for 

 in absence of convexity assumptions, and expressed in terms of directional derivatives.

Theorem 10.17
Let be 

 and 

 let 

 admit a (finite) directional derivative 

 for all 

 For the point 

 to be a local minimizer of f over X,  it is necessary that

 (10.7)If f is locally Lipschitz in a neighborhood of 

 (see further, Definition 10.27), and if

 (10.8)then 

 is a strict local minimum point of f over X (i.e. condition (10.8) is a sufficient condition for a strict local minimum of f).


Proof
The necessity part is immediate. Since f is directionally differentiable at 

 we have

This implies (10.7).
For the sufficiency part, see, e.g. [13, 14], or [15].    



A point 

 satisfying (10.7) is called by some authors an inf-stationary point of f.
We now revert to convex optimization, which may be considered a "first path" to enter into the more complex and recent results on nonsmooth optimization. The following proposition generalizes to the nonsmooth convex case a well-known property of differentiable convex functions.

Theorem 10.18
Let 

 be an open convex set and 

 a convex function; let 

 Then the following conditions are equivalent: (a)
f admits at 

 a global minimum point, i.e. 

 


 (b)



 (c)


 


 



Proof
The implication (a)

(c) is evident and, as previously remarked in Theorem 10.17, holds also in absence of convexity assumptions on f. The implication (c)

(b) follows from Theorem 10.9. The implication (b)

(a) follows at once from the definition of subdifferential of f at 

 the inequality 

 

 when 

 gives relation (a).    



We now consider a convex programming problem of the type 

 i. e. with a (convex) set constraint.

Theorem 10.19
Let 

 be convex on the open convex set 

 and let C be an arbitrary convex subset of X. A point 

 is a solution of the problem

if and only if

 (10.9)where 

 is the normal cone to C at 




Proof
Let us first assume that 

 is a solution of the above minimization problem. Then it is clear that 

 is also a solution of the following unconstrained problem:

where 

 is the indicator function, previously introduced. By Theorem 10.18, since 

 is a (global) minimum point of h(x),  we have

and by the sum rule for subdifferentials (Theorem 10.15 and Remark 10.16), we have

But, being 

 we get relation (10.9). For the converse case, observe that the condition 

 means that there exists 

 such that 

 This shows that from the definition of 

 it holds 

 

 Since 

 we see that

This shows that for all 

 we have 

 i.e. 

 is a global minimum point of f over C.    



In terms of directional derivatives, under the same assumptions of Theorem 10.19, relation (10.9) becomes

where 

 is the Bouligand tangent cone to C at 

 (see Definition 2.​35). Indeed, from (10.9) there exists 

 such that 

. By Theorem 10.9, one has 

 for all 

. As 

, we have 

 for all 

, and therefore, 

 for all 

.
Moreover, as C convex, it holds 

 by Theorem 2.​41, hence relation (10.9) becomes

Let us now consider an open convex set 

 we study the case of a convex optimization problem of the type 

 but with no differentiability assumptions on the functions involved in the problem. Instead of gradients, we make use of subdifferentials.

where 

 and every 

 

 are convex functions on X and every 

 

 is a linear affine function on 

 Note that under the said assumptions the feasible set

is a convex set.
We give first a Fritz John-type result for 

 We follow the approach of [16].

Theorem 10.20
Suppose that 

 is a solution of the convex problem 

 Then there exist multipliers 

 not all zero, such that





Proof
Without loss of generality, we can suppose that all inequality constraints are active at 

 i.e. 

 Take

and

It is easy to see that the properties of f,  g and h ensure the convexity of A,  while the convexity of B is obvious. On the other hand, if a common element of A and B exists, then there is also 

 with 

 

 

 which would contradict the (global) minimality of 

 for 

 Hence, 

 by the separation theorem (Chap. 2), we can deduce the existence of elements 

, 

,...,

, 

,...,

, not all zero, such that

for all 

 

 

 

 

 It is not possible to have 

 Indeed, if we suppose this case, letting 

 we arrive to a contradiction, since the right-hand side is fixed, while the left-hand side goes to 

 A similar argument employed for 

 (for all 

) allows us to conclude that 

 for all 

 Letting 

 

 

 and 

 we actually get that

for all 

 Since 

 we deduce that 

 for all 

 Finally, we can write

for all 

 which means that

Theorem 10.15 allows us to write

Since 

 one has 

 The same argument is applicable to the equality 

 for all 

 The equality 

 for all 

 is true by the fact that h is linear affine.    



If in the previous result, we have 

 i.e. 

 we obtain the related Karush-Kuhn-Tucker conditions for 

 expressed in terms of subdifferentials. Since problem 

 is convex, we can use a Slater constraint qualification:
There exists 

 such that 

 

 and the gradients 

 

 are linearly independent.
(Note that the affine functions 

 

 are differentiable everywhere and that the gradients 

, 

 are the same for all 

).

Theorem 10.21
Suppose that 

 is a solution of the convex problem 

 and that the above Slater constraint qualification holds. Then, there exist real numbers 

 such that





Proof
It is sufficient to show that, under the assumptions made in the present theorem, we cannot have 

 in the Fritz John conditions of Theorem 10.20. Suppose absurdly that 

 Then

that is, for every 



i.e.

For 

 (the element of the Slater constraint qualification), this becomes

which is possible only if 

 for all 

 So, in fact

This means that 

 is a minimum (unconstrained) for the function 

 and, by Fermat's theorem, we get

But the linear independence of the gradients 

 

 says that the above relation holds only if 

 

 But then we have that 

 

 

 which is a contradiction to the thesis of Theorem 10.20. The proof is complete.    




Remark 10.22
(a) The Karush-Kuhn-Tucker conditions of Theorem 10.21 are also sufficient  for 

 to be a solution of 

 being 

 a convex problem.
(b) If in 

 we have, besides the functional constraints, also a set constraint (or abstract constraint), represented by 

 being C closed and convex, the related necessary Karush-Kuhn-Tucker conditions must be suitably modified. Call 

 this last problem. In this case, the point 

 which satisfies the Slater constraint qualification must be interior to C : 

The other requirements remain the same as the ones of Theorem 10.21. We have the following result.

Assume that 

 is a solution of the convex problem 

 and that the above Slater constraint qualification is satisfied. Then there exist 

 and 

 such that 

 (10.10)


 (10.11)



Conversely, if for some feasible point 

 for 

 conditions (10.10) and (10.11) are satisfied, for some 

 and 

 then 

 is a solution of 



(Here 

 is, as usual, the normal cone of the convex set C at 

).
Subgradients of convex functions can be used also to establish a duality result for a nondifferentiable convex programming problem, on the lines of Wolfe's duality theorems for the differentiable case (see Chap. 8).
We consider the "primal" problem

where f and every 

 

 are convex functions on the open convex set X. We furthermore assume that the Slater constraint qualification is satisfied, i.e. there exists a vector 

 such that 

 

 Based on the Karush-Kuhn-Tucker conditions for (P),  expressed in terms of subdifferentials, we relate (P) to the following dual problem, of the Wolfe-type:

We recall the said Karush-Kuhn-Tucker conditions for (P) :  if 

 is feasible for (P) and the Slater constraint qualification is satisfied, then 

 is optimal for (P) if and only if there exists 

 such that 

 

 and

Furthermore, if the functions 

 

 are all linear affine, we get the same conclusion without assuming the Slater constraint qualification. Then we have the following analogous result of Wolfe's duality theorem (see [17, 18]).

Theorem 10.23
If 

 is optimal for problem (P),  then there exists 

 such that 

 is optimal for problem 

 Furthermore, the two problems have the same extremal value. If the constraints 

 

 are linear affine, this conclusion holds without assuming the Slater constraint qualification.


Proof
Let (x, y) be feasible for problem 

 Then 

 and furthermore, there exist 

 and 

 

 such that 

 Then

This shows that, for every (x, y) feasible for 

 one has

 (10.12)Furthermore, by the Karush-Kuhn-Tucker conditions, there exists a vector 

 such that 

 is feasible for 

 and 

 so that

 (10.13)Comparing (10.12) and (10.13), we get the conclusions of the theorem.    





10.2 The Lipschitz Case
We have seen that a convex function 

 possesses finite directional derivatives at every interior point of the convex set X and that these directional derivatives are convex for all directions 

. Being also homogeneous functions of the first degree, they are therefore sublinear functions of 

. The Canadian mathematician F. H. Clarke presented [19-21] a generalized directional derivative which, for locally Lipschitz functions, (non-necessarily convex) always exists finite and is convex and homogeneous of the first degree for all directions 

. This generalized directional derivative, called Clarke directional derivative, and its associated subdifferential, called Clarke subdifferential, provide useful tools in obtaining optimality conditions for nonsmooth and non necessarily convex mathematical programming problems.
Clarke theory has become an established theory. The literature on Clarke theory and its applications to optimization (both scalar and vector), control theory, numerical methods, etc., is very huge (mostly the papers, published on journals or on proceedings of meetings). Here, for the reader's convenience, next, we give only some basic references: [13, 21-36].
To go on, we need first the definitions of Lipschitz functions and locally Lipschitz functions.

Definition 10.24
Let 

 be a nonempty set and 

. The function f is said to be Lipschitz over X (or Lipschitz continuous over X) if there exists a real number 

 such that, for every 

 we have

 (10.14)


The smallest constant k for which the previous relation holds is said "the Lipschitz constant" or "the Lipschitz rank". Then f is said to be "Lipschitz of constant k". If 

 then f is said to be non-expansive and if 

 then f is said to be a contraction.

Note that if f is Lipschitz on X,  then it is (uniformly) continuous on X,  but the converse is not true: take, e.g. the continuous function 

 

; with 

 we see that there is no constant 

 satisfying (10.14). To understand the meaning of (10.14), rewrite it as follows:

Hence, a function is Lipschitz on the set 

 if and only if all its difference quotients are bounded.

Example 10.25
(a) The function 

 

 is Lipschitz on 

 with 


(b) The function 

 is not Lipschitz on the whole space 

 Indeed, by choosing 

 we have

which holds only if 



A sufficient condition for f to be Lipschitz on a set contained in its domain is given by the following proposition, which is a consequence of the mean value theorem.

Theorem 10.26
Let be 

, with X open convex set. If f is differentiable on X and if all its partial derivatives are bounded on X,  then f is Lipschitz on X. Moreover, for every 

 such that

then relation (10.14) holds with 




Definition 10.27
Let 

 be a nonempty open set and 

. Given a point 

 if there exist a neighborhood 

 of 

 and a nonnegative number k such that

then f is said to be locally Lipschitz at 

 or Lipschitz near 

 or Lipschitz around 

 with constant k.
We say that f is locally Lipschitz on X if f is locally Lipschitz at each 



Thus, a function which is locally Lipschitz at a point means that the function satisfies the Lipschitz condition in a neighborhood of that point. However, it is important to note that the value of the Lipschitz constant k in general could change as we change the point. Obviously, we have the implication

but the converse is in general not true. If, however, a locally Lipschitz function has a uniform Lipschitz constant k at every point 

 then f is Lipschitz on X in the sense of Definition 10.24.
A sufficient condition for f to be locally Lipschitz at a point 

 of its domain is given by the following proposition.

Theorem 10.28
If a function 

 is continuously differentiable (i.e. of class 

) in a neighborhood of 

 then f is locally Lipschitz at 




Proof
Continuous differentiability around 

 means that all n partial derivatives of f are continuous on a neighborhood of 

 It follows that there exist constants 

 and 

 such that

Suppose that 

 Then, by the classical mean value theorem, there is 

 such that

We now have

i.e. f is Lipschitz continuous at 

.    



The following result gives an important property of convex functions for what concerns Lipschitz continuity.

Theorem 10.29
Let 

 be a convex function on the open convex set X. Then f is locally Lipschitz on X.


Proof
Consider any 

 Since 

 is a convex function and X is open, then f is continuous at 

 Hence, f is locally bounded, i.e. there exist 

 and 

 such that 

 for all 

 Consider x and y to be two distinct points in 

 Let be 

 and let be

Thus, we have

This shows that 

 Note that y can be expressed as

Using the convexity of f,  we have

Hence,

Interchanging the roles of x and y yields

thereby establishing the result.    



The definition of Lipschitz continuity of a function allows to give another useful representation of the Bouligand tangent cone to a set 

 at 

 (see Definition 2.​35) and it will be useful also to characterize the so-called Clarke tangent cone to a set 

 at 

 See further and see, e.g. [37-40]. We first need the following definition.

Definition 10.30
Let 

 be a given set and let 

 Then the distance of S from x is given by the function




If 

 then it is clear that 

 The following result reveals a basic property of the distance function.

Theorem 10.31
For a given set 

 the distance function 

 is a Lipschitz function of rank 1 on 

 and if S is convex, then the distance function 

 is a convex function on 




Proof
Let 

 be an arbitrary scalar number. By definition, there exists a point 

 such that, for some 

, one has 

 Let 

 Then 

 This shows that 

 Hence, noting that 

 is arbitrary, we deduce

 (10.15)Now switching the roles of x and u in (10.15), we get that

thus proving that 

 is a Lipschitz function on 

 of rank 1. For the proof that 

 is a convex function on 

 if S is convex, see, e.g. [41].    




Theorem 10.32
Let be given 

 and let be 

 Then




We follow the proof of [37]. We first need a preliminary result.

Lemma 10.33
Let 

 be a locally Lipschitz function on the open set X, 

 and 

. Then





Proof
The left-hand side expression of the above equality can be written as




Now the Lipschitzian property of f shows that

 (10.16)Hence, this shows that




Using (10.16), we get

 (10.17)Since in the right-hand side of (10.17) u plays no role, we conclude that

   




Proof of Theorem 10.32.
Consider 

 Then there exist sequences 

 with 

 and 

 such that 

 We know that 

 is Lipschitz and that 

 Then

exists and is finite. Now we have

 (10.18)As 

, it follows that

Therefore, from (10.18), we have

Since 

 is a Lipschitz function by Theorem 10.31, then, by using Lemma 10.33, we have

This shows that

But, as 

 and 

 we have

and hence

Now we prove the converse. Assume that v satisfies

Hence, there exists 

 such that

Now, by the definition of 

 for each k, we have 

 such that

Consider 

 Then we have

This shows that 

 as 

 Hence, 

 and 

 Therefore, 

.    



Similarly, it can be proved that the cone of attainable directions 

 can be characterized as follows:

from which it appears at once that 


It is worth noting that when S is convex, 

 is a convex function (besides a Lipschitz function), on the grounds of Theorem 10.31. Hence, in this case, we have




being 

 the right-sided directional derivative of 

 at 

 in the direction v. Hence, for a convex set 

 and 

 we have

Clarke [19-21] generalized this last characterization, by defining a tangent cone which is always closed and convex, also when S is not necessarily convex. See further.
We are now ready to give the basic definition of Clarke directional derivative or generalized directional derivative of a function 

, 

 open set.

Definition 10.34
Let 

 be a nonempty open set and 

 be a locally Lipschitz function on X. The Clarke directional derivative, denoted 

 of f at 

 in the direction 

 is defined by

 (10.19)


Since f is locally Lipschitz, the difference quotient

is bounded and the limit in (10.19) exists finite.
Other generalized directional derivatives have been introduced and used in optimization theory, for example, the following ones:

called the lower Dini directional derivative (of f at 

 in the direction 

), and

called the upper Dini directional derivative (of f at 

 in the direction 

).
We note that 

 and 

 always exist, finite or not. From the definitions we have, for a locally Lipschitz function f, 

 (10.20)In order that the usual (right-sided) directional derivative 

 exists finite, we must have

In this case, we have, if 

 exists finite,

On the grounds of Theorem 10.32, it turns out that

 (10.21)where 

 is the lower Dini directional derivative of 


For other notions and applications of Dini directional derivatives to optimization, see, e.g. [42-45].
The Clarke directional derivative has several interesting properties, not possessed in general by the Dini directional derivatives. We give below the main of the said properties.

Theorem 10.35
Let 

 be locally Lipschitz with rank k at 

 with X open subset of 

 Then: (i)
The Clarke directional derivative of f at 

 in any direction 

 exists finite, 

 is a positively homogeneous and convex function on 

 with respect to the direction v (i.e. it is a sublinear function), and it holds 

 (10.22)

 (ii)
It holds 

 (10.23)

 (iii)
The function 

 is Lipschitz of rank k on 


 (iv)
The function 

 is upper-semicontinuous at 


 



Proof
(i) Since f is locally Lipschitz near 

 it holds for any 

 and x which are sufficiently close to 



Then it follows that 

 exists finite and (10.22) holds. Now we prove the positive homogeneity and convexity of 

 It holds that for any 

 and 



Hence, 

 is a positively homogeneous function on 

 Also, for any 

 we have







Hence, from the positive homogeneity of 

 we get that 

 is a convex function on 

 indeed, homogeneity and subadditivity imply convexity. See, e.g. [46].
(ii) For arbitrarily fixed 

 we have

The transformation 

 yields

(iii) By the subadditivity and relations (10.22), (10.23), one gets that, with v and w two vectors of 



Interchanging the roles of v and w establishes property (iii).
(iv) For the proof of this property, see, e.g. [21].    



We have to remark once more the following important property of 

 even if f is a nonconvex function (but it is locally Lipschitz at 

), then 

 is guaranteed to be a positively homogeneous convex function on 


Clarke introduced also the concept of "generalized subdifferential" for a locally Lipschitz function, in the same spirit of the usual subdifferential in Convex Analysis.

Definition 10.36
Let 

 be locally Lipschitz at 

 X open set of 

 Then the Clarke subdifferential of f at 

 or Clarke generalized gradient of f at 

 denoted by 

 is given by




The following basic properties of the Clarke subdifferential are due to [19-21].

Theorem 10.37
Let 

 be locally Lipschitz, with rank k,  at 

 X open set of 

 Then: (i)


 is a nonempty compact convex set and we have 

 (10.24)

 (ii)
It holds 

 (10.25) In other words, 

 is the "support function" of the set 

 See [21].
 



Proof
(i) From Theorem 10.35, 

 is a convex function. Thus, 

 has a nonempty subdifferential at 

 (in the Convex Analysis sense) and hence there exists a vector 

 such that

This means that 

 and hence 

 is nonempty. If we next suppose that 

 for some 

 then from (10.22) of Theorem 10.35 we obtain

which contradicts 

 Therefore, (10.24) holds and so 

 is bounded. The closedness and the convexity of 

 follow immediately from the definition of 

 and the convexity of 


(ii) From the definition and the compactness of 

 it holds that for an arbitrarily fixed vector 



Thus, all we have to show is the existence of 

 satisfying 

 Since 

 is a convex function, we can choose an element, say 

, of its subdifferential at 

 and it follows that

 (10.26)Letting 

 we have 

 Meanwhile, (10.26) with 

 

 yields 

 We thus have

 (10.27)It follows from (10.26) and (10.27) that 

 

 showing 

 Thus, (10.25) follows from (10.27).    



We now give some basic information on the relationships between the Clarke subdifferential and the usual gradient of a locally Lipschitz function. The first question to be pointed out is that even if 

 is locally Lipschitz and differentiable at a given point 

 the Clarke subdifferential may not be a singleton, i.e. it need not coincide with the gradient of f at 

 However, if the function is continuously differentiable around a point 

 then the Clarke subdifferential is a singleton, given by the gradient of f at 

 More precisely, we have the following result.

Theorem 10.38
(a) Let 

 be locally Lipschitz and differentiable at 

 X open set of 

 then

(b) Let 

 be continuously differentiable around 

 X open set of 

 then




The above theorem can be illustrated by the following example, given in [21].

Example 10.39
Let 

 be given by

This function is differentiable for all 

 and 

 Being 

 bounded on each neighborhood U(0),  then f is locally Lipschitz around 

 and we have that 

 The reader is invited to calculate 



The results of Theorem 10.38 can be ameliorated. Clarke [21] proved that the Clarke subdifferential 

 contains a unique element, 

 if and only if f is strictly differentiable at 

 A function 

 is strictly differentiable at 

 if

where 

 Let us observe that strict differentiability at 

 implies differentiability at 

 but the converse does not hold. If f is 

 at 

 then it is strictly differentiable at 

 , but the converse does not hold. However, 

 is strictly differentiable on the open set 

 if and only if f is 

 on X. See [33].
The next theorem gives a useful result for calculating the Clarke subdifferential of a locally Lipschitz function, as in general, it is not easy to get the expression of the said subdifferential. For the proof of the theorem see [21].

Theorem 10.40
If a function 

 is locally Lipschitz at 

 X open set of 

 then we have

where 



In other words, as an important theorem of Rademacher says that a function which is Lipschitz continuous on an open set 

 is differentiable "almost everywhere" on U (i.e. except of sets of measure zero), the aspect of the Clarke subdifferential is "independent" from sets of measure zero.
The following example which makes use of Theorem 10.40 is taken from [37].

Example 10.41
Consider 

 given by 

 This function can be represented as

Obviously, f(x, y) is not differentiable only at the points along the x-axis and y-axis of the two-dimensional plane. We want to calculate 

 At all other points the gradient is given by

Using Theorem 10.40, we have

i.e. 

 is a square in 

 with the above four points as its vertices.
We have seen that it holds

provided that these quantities exist. However, even in the Lipschitz case, the above inequality may be strict: besides the case of Example 10.39, consider the following case.


Example 10.42
Let be given the function 

 

, and let be 

 It is easy to see that

Being 

, by Theorem 10.35(ii),  we get 

 and being 

 we deduce that 

, 



An important result states that for convex functions the one-sided directional derivative 

 and the Clarke directional derivative 

 coincide. For the proof of this property, see, e.g. [21].

Theorem 10.43
Let 

 be convex on the open convex set X. Then

Hence, 





Following [21] we give the next definition.

Definition 10.44
Let 

 be a locally Lipschitz function on the open set X. The function f is called regular at 

 or Clarke regular at 

 if (a)


 exists (finite) for all 


 (b)
It holds 

 The function f is regular on X if it is regular at every 


 


Therefore, any convex function on an open convex set 

 is a Clarke regular function on X. There are regular but non-convex functions and there are non-regular functions. We give an example for the first case. The second case can be illustrated by Example 10.41.

Example 10.45
Consider the function 

 given by

It is easy to check that 

 

 Now consider the function 



It is clear that 

 is convex. We have 

 Hence, 

 This shows that f is a regular function, even if it is not convex.

Other sufficient conditions for f to be regular at 

 are: (1)
f is continuously differentiable around 


 (2)


 where 

 

 and every 

 is regular at 

 

 We note, moreover, that if f is differentiable and regular at 

 then 



 

In other words, regularity guarantees that the gradient is the unique Clarke subdifferential of a differentiable function.
We now give some calculus rules for the Clarke subdifferential, which are in a certain sense, a generalization to the nonsmooth Lipschitz case of the calculus rules of the classical (smooth) analysis. For the related proofs, see, e.g. [21].

Theorem 10.46
Let 

 be locally Lipschitz on the open set X. Then, for any scalar 

 and for any 

 it holds





Theorem 10.47
Let 

 be locally Lipschitz on the open set 

 Then it holds, for each 



More generally, with 

,

If every function 

 is Clarke regular, then, with 







Theorem 10.48
If 

 and 

 are locally Lipschitz on the open set 

 then 

 is locally Lipschitz on X and, for every 



If, in addition, 

 

 and f and g are both Clarke regular, then 

 is also Clarke regular and equality holds in the above inclusion.


Theorem 10.49
Let 

 and 

 be locally Lipschitz on the open set 

 let be 

 

 Then the ratio 

 is locally Lipschitz on X and, with 



If, in addition, 

, 

 and f and g are both Clarke regular, then the equality holds in the above inclusion and 

 is also regular.

The next result is a chain rule for locally Lipschitz functions.

Theorem 10.50
Let 

 be such that 

 where 

 is locally Lipschitz at 

 (i.e. each of its components is locally Lipschitz at 

) and 

 is locally Lipschitz at 

 Then f is locally Lipschitz at 

 and

Moreover, if g is Clarke regular at 

 and h is Clarke regular at 

 and for any 

 we have 

 then the above inclusion holds as equality. The same is true if g is regular at 

 and h is continuously differentiable around 



We now discuss briefly some geometric concepts associated to the Clarke directional derivative and to the Clarke subdifferential, i.e. we give some insights on the notion of Clarke tangent cone and Clarke normal cone. We have seen that the Bouligand tangent cone (or contingent cone) 

 to a set 

 at 

 is a closed cone, with vertex at 

 but not necessarily convex. Clarke [19-21] introduced a local cone approximation of a set 

 at 

 called Clarke tangent cone, which is always closed and convex, even if in some particular cases it may not be a "good" local approximation of the set in question (i.e. it may be too small). The Clarke tangent cone to a set 

 at 

 here denoted by 

 can be represented in several equivalent ways (see, e.g. [40, 42, 43]).

Definition 10.51
Let be given 

 and 

 The Clarke tangent cone to S at 

 is given by




In terms of neighborhoods, we have

Another interesting description of the Clarke tangent cone is given in terms of the Clarke generalized derivative of the distance function 

 which is a Lipschitz function on 

 (Theorem 10.31).

Theorem 10.52
Let 

 and let 

 then it holds

 (10.28)



Proof
We use the definition of 

 in terms of sequences. Let us denote by 

 the second set of the equality in (10.28). Suppose first that 

 and that sequences 

 with 

 and 

 are given. Then 

 and since 

 we have

It follows that the limit exists and is zero. Then, for all 

 there exists 

 such that

If we now define

we have

as 

 and

Thus, 


Now for the converse. Suppose that 

 and choose sequences 

 and 

 such that

 (10.29)In order to prove that 

 it suffices to show that the quantity in the left side of (10.29) is nonpositive. Indeed, one has always 

 since 

 attains a minimum at 

 (see further Theorem 10.56). Let 

 such that

 (10.30)Then we have

as 

 Then by assumption, there exists a sequence 

 converging to v such that 

 By Theorem 10.31, the distance function 

 is Lipschitz continuous with Lipschitz constant 

 and, in view of (10.30), we get

This implies that the quantity in (10.29) is nonpositive and hence we have 

 i.e. 

.    




Theorem 10.53
For any set 

 and any point 

 the Clarke tangent cone 

 is a closed convex cone (with vertex at the origin). Moreover, 




Proof
From Theorem 10.35, we know that the Clarke directional derivative 

 is a positively homogeneous convex function. This leads to the fact that 

 is a convex set by Theorem 10.52 since 

 is the level set 

. Convexity of 

 also guarantees the continuity of 

 which in turn gives the closedness of 

 Consider now 

 we have therefore (Theorem 10.52) 


By applying inequality (10.20) to the function 

, we obtain

and so 

 since always 

. Now, from (10.21), we conclude that 

. Hence, 

.    



As already remarked, in some cases the Clarke tangent cone is however too "small" to be a good local approximation of 

 at 

 If 

 is a set such that at 

 we have 

 we say that S is Clarke regular at 

 It is now possible, utilizing polarity, to define the Clarke normal cone.

Definition 10.54
Let 

 and let 

 Then the Clarke normal cone to S at 

 is the cone




The following theorem (for its proof, see, e.g. [21]) presents the main properties of the Clarke normal cone.

Theorem 10.55
(i) Let 

 and let 

 Then the following properties hold.
(a)


 is a closed convex cone.
 (b)



 (c)


.
 (ii) Suppose that 

 is a nonempty convex set and that 

 Then S is Clarke regular at 

 and we have







Moreover, it can be shown that the Clarke normal cone is the closure of the convex hull of the Mordukhovich normal cone (see [47], vol. 1, Sect. 6.4):

As for the convex case, also the Clarke normal cone has an interesting geometric interpretation. Indeed, it holds, if 

 is locally Lipschitz at 



i.e. 

 if and only if 

 As a consequence we have that if 

 is locally Lipschitz at 

 then similarly to the convex case (previous Section), we have

The above considerations have been used to fit the Clarke nonsmooth calculus to a class of functions larger than the class of locally Lipschitz functions, namely the class of lower semicontinuous functions; see, e.g. [48]. The same considerations are also a basic tool to introduce the axiomatic approach of K.-H. Elster and J. Thierfelder to nonsmooth calculus. See the next Section.
We now establish necessary optimality conditions for an unconstrained optimization problem involving a locally Lipschitz function.

Theorem 10.56
(Fermat rule for Lipschitz functions) Let be 

 and let 

 be a local minimum point or a local maximum point for f over X. Let f be locally Lipschitz at 

 then

 (10.31)or equivalently





Proof
One has, if 

 is a local minimum point, that

On the other hand, if 

 is a local maximum point,

Hence, in both cases, 

 for any 

 which proves the conclusion.    



A point 

 satisfying relation (10.31) is also called a Clarke stationary point.

We now consider a minimization problem involving a Lipschitz objective function and a set constraint, i.e. a problem of the type 



where 

 is a locally Lipschitz function on the open set X and C is an arbitrary subset of X. The following result is given in [48].

Theorem 10.57
Consider the above problem 

. If 

 is a local minimum point of f over C,  then

 (10.32)where 

 is the Bouligand tangent cone to C at 




Proof
If 

 the result is trivially true. Let us now consider the case where 

 and 

 By the definition of the Bouligand tangent cone, we can find a sequence 

 in C and a sequence of scalars 

 with 

 

 such that 

, and so 

.
Hence

 (10.33)Since f is locally Lipschitz, we have

where k is the Lipschitz constant. Hence,

Again we have 

 Hence, from the equality (10.33), it follows that

From the definition of the Clarke directional derivative, we see that

This shows that 

 Since 

 is arbitrary, the result is proved.    




Remark 10.58
In order to obtain the dual relation of (10.32) expressed by means of the Clarke subdifferential, as shown by [48], we have to consider a convex subcone of the Bouligand tangent cone 

 More precisely:
Let 

 be a local minimum point for problem 

 and let 

 be a nonempty closed convex subcone of 

 Then we have 

 where 

 denotes, as usual, the polar cone of 




If we choose 

, we obtain the necessary optimality condition for 

 given in [21] with a different proof, i.e.

Under the same assumptions of Theorem 10.57 (f locally Lipschitz on X), we can obtain

See [49]. Being 

 we have that the above condition is sharper than condition (10.28). Note that, contrary to what asserted in [49], it is not true the following necessary optimality condition

Indeed, consider the following counterexample: let 

 and 

 defined by 

. One has that f is Lipschitz and 

 is a minimum for f over C, however, 

 for 

.

Now we wish to give Fritz John-type optimality conditions for a constrained problem of the type 



where the objective function f and the constraint functions 

 

 are supposed to be locally Lipschitz on the open set X. Let us denote by 

 the feasible set of 

 We follow the treatment of [23]. Without loss of generality, we can scalarize the multiple constraints of 

 by introducing the total constraint function 

 defined by

We need the following result.

Theorem 10.59
Let be 

 where each 

, 

 is locally Lipschitz on the open set X. Then f is locally Lipschitz on X and

where 




Proof
Define 

 and 

 by




Now we have 

 For all 

 and 

 it holds

which means that g is convex on 

 and hence locally Lipschitz on 

 (Theorem 10.29). Therefore, 

 is locally Lipschitz on X as can be easily checked. Let be 

 Then the directional derivative of g is




Thus,

Being g convex, it is also Clarke regular (Theorem 10.43) and therefore we have 

 which gives

Now it is not hard to see that

and so we can calculate the Clarke subdifferential of g at 

 by

By applying Theorem 10.50 to f, we get

   




Remark 10.60
In Theorem 10.59 if, in addition 

 is Clarke regular at x for all 

 then f is also Clarke regular at x and it can be proved that the inclusion of the thesis of the same theorem holds as equality.

We are now ready to prove for 

 a Fritz John-type necessary optimality condition, expressed by means of Clarke subdifferentials.

Theorem 10.61
Let 

 be a local minimum point for 

 Then, there exist multipliers 

 

 not all zero, such that








Proof
It is clear that the function 

 defined by

is locally Lipschitz on X by Theorem 10.59. Since 

 is a local minimizer for 

 there exists 

 such that 

 and

Since 

 we have 

 implying

Moreover,

because if 

, then 

 and 

, and if 

, then 

, and so 

. In other words, h(x) attains a local minimum at 

. Then, due to Theorem 10.56, we have

If 

, we have 

 and thus, due to Theorem 10.59, we get

Then the assertion of the theorem is proved by choosing 

 and 

 for 

 On the other hand, if 

 we have 

 and thus, again by Theorem 10.59, we get

Furthermore, we have

where 

 Then, due to the definition of convex hull, there exist 

 and 

 for 

 

 and 

 not all zero, such that 

 for 

 (since 

) and

The assertion of the theorem is now proved by choosing 

 for 

.    



We now prove for 

 the Karush-Kuhn-Tucker-type necessary optimality conditions. As usual, to avoid the case 

 in the Fritz John conditions, we need a constraint qualification. Let us consider problem 

 under the same assumptions as before.

Theorem 10.62
Let 

 be a local minimum point for 

 and assume that the following Arrow-Hurwicz-Uzawa constraint qualification or Cottle constraint qualification is fulfilled:
There exists 

 such that 

 




Then, there exist scalars 

 

 such that (i)


;
 (ii)



 



Proof
It is sufficient to show that under the above constraint qualification, in the Fritz John conditions of Theorem 10.61, it holds 

 (and hence 

). Let us assume on the contrary that 

 We have therefore

Since 

 and the multipliers 

 

 are not all equal to zero, there will exist at least one 

 such that 

 Also as 

 we see that there exists 

 

 such that 

 Hence, for any 

, we have 

 By assumptions of the theorem, there exists 

 such that 

 

 Hence, from the definition of the Clarke subdifferential, we see that 

 

 Again, as there exists 

 such that 

 we have 

 which is clearly a contradiction. Hence, we conclude that 

 and without loss of generality we can take 

 Putting 

 

 we get the thesis.    




Remark 10.63
Hiriart-Urruty [50] has obtained for 

 "sharper" Fritz John and Karush-Kuhn-Tucker necessary optimality conditions, in the sense that this author obtains the following necessary optimality conditions, expressed in terms of the Clarke subdifferential of the Lagrangian function (recall Theorem 10.47):







Clarke [20] has obtained a Fritz John-type necessary optimality theorem for a problem of the type 

 but with also a set constraint, i.e. for the problem

where C is an arbitrary subset of the open set 

 and all functions are locally Lipschitz at the local minimum point 

 of 

 Clarke uses rather sophisticated tools, such as the Ekeland variational principle (see [51, 52]). We report the result of Clarke without proof.

Theorem 10.64
Let 

 be a local solution of 

 Then there exist multipliers, not all zero, 

 such that










Under appropriate constraint qualifications, it is possible to choose, in the above Fritz John optimality conditions, 

 In other words, there exists then a set of multipliers 

 such that the following Karush-Kuhn-Tucker conditions hold for 









Nguyen et al. [53] consider problem 

 but with the assumption that the functions 

 

 are continuously differentiable on X. These authors impose the following constraint qualification for 

 at the optimal point 


(CQ) :  The gradients 

 

 are linearly independent and there exists 

 such that 

 

 and 

 




Under the assumptions of Nguyen, Strodiot, and Mifflin, the Karush-Kuhn-Tucker conditions for 

 become







Let us denote by 

 the set of multipliers 

 

 

 which satisfy the above Karush-Kuhn-Tucker-type optimality conditions. The quoted authors prove that if 

 the condition (CQ), besides assuring the satisfaction of the above necessary KKT conditions for local optimality of the feasible point 

 in the problem considered, is both necessary and sufficient, for 

 to be a nonempty closed, convex, and bounded set. Hence, the above constraint qualification can be viewed as a nonsmooth generalization of the Mangasarian-Fromovitz constraint qualification, given for the differentiable case. If there are no equality constraints, then in (CQ) it is possible to replace 

 by 

 and to delete the assumption that 

 Note that if C is open or 

 then 

 and 


We have mentioned in Chap. 6 the "enhanced Fritz John conditions" of [54] for a continuously differentiable optimization problem with mixed constraints and a set constraint. In [37] it has been obtained the enhanced Fritz John conditions for a problem of the type 

 with C an arbitrary convex subset of the open set 

 We report their result, without proof.

Theorem 10.65
Let us consider problem 

 where C is a convex subset of the open set 

 and where all functions are locally Lipschitz at 

 with 

 local solution of the problem. Then, there exist scalars 

,

, not all zero, such that (i)


;
 (ii)
Consider the index sets 

 and 

 If 

 then there exists a sequence 

 such that 

 and such that for all k sufficiently large we have 

 

 for all 

 and 

 for all 

 We have also 

 where 

 and 


 


We conclude the present section with some considerations on generalized convex functions under a Lipschitz assumption. Pseudoconvex and quasiconvex functions (see Chap. 3) have been extended by various authors to the Lipschitz case; see [23, 37, 55, 56]. See also the useful handbook [57], in particular the contributions of N. Hadjisavvas and S. Komlosi.
We recall that a differentiable function 

 is pseudoconvex on the open convex set 

 if, with 

 we have

The function f is quasiconvex on X if, with 

 we have

If f is locally Lipschitz on the open convex set 

, but not necessarily differentiable, the most natural generalizations of the previous traditional definitions are given as follows.

Definition 10.66
Let 

 be a locally Lipschitz function on the open convex set 

 Then f is said to be Clarke pseudoconvex on X if, with 

 we have

or, equivalently,





Remark 10.67
The previous characterization can be given also in the form: with 

 we have

or





Definition 10.68
Let 

 be a locally Lipschitz function on the open convex set 

 Then f is said to be Clarke quasiconvex on X if, with 

 we have

or, equivalently,





Remark 10.69
The previous characterization can be given also in the form: with 

 we have

or




Bector et al. [37] prove the following two results. We recall that the original definition of a quasiconvex function does not require any differentiability assumption (see Definition 3.​18).

Theorem 10.70
Let 

 be locally Lipschitz on the open convex set 

 Then f is quasiconvex on X if and only if, with 

 we have




The immediate consequence of the above theorem is that both Clarke pseudoconvex functions and Clarke quasiconvex functions are quasiconvex functions in the usual sense.

Theorem 10.71
Let 

 be locally Lipschitz on the open convex set 

 and let f be regular (in the sense of Clarke) and quasiconvex on X. Then f is Clarke quasiconvex on X.

The notion of Clarke pseudoconvexity allows to obtain sufficient optimality conditions for an unconstrained minimization problem involving a locally Lipschitz function.

Theorem 10.72
If the function 

 is Clarke pseudoconvex on the open convex set 

 then f attains its global minimum at 

 if and only if





Proof
The necessity has already been proved (Theorem 10.56). On the other hand, if 

 and 

 by definition of Clarke pseudoconvexity we have






Example 10.73
([23]) The function 

 defined by 

 is locally Lipschitz, but not convex nor pseudoconvex (it is not everywhere differentiable). However, f is Clarke pseudoconvex and at its global minimum point 

 we have 



It is also possible to give sufficient optimality conditions for a problem of the type 

 i.e. with a set constraint, by means of Clarke generalized convex functions. It is not difficult to prove the following result.

Theorem 10.74
If 

 is Clarke pseudoconvex on the open convex set 

 and C is an arbitrary convex subset of X,  then 

 is a solution of the problem

if and only if




We recall that, being C convex, we have 


For sufficient Karush-Kuhn-Tucker conditions in terms of Clarke generalized derivatives or Clarke subdifferentials, see, e.g. [23, 58, 59].
Finally, we give some insight into the generalization to the Lipschitz case of the notion of invex functions. We recall (see Definition 3.​33) that invex functions were introduced by [60] as a generalization of differentiable convex functions: let 

 be an open set and let 

 be differentiable on X;  if there exists a vector-valued function, called also "the kernel function", 

 such that

then f is called invex.
The definition of invexity can be extended to a function 

, X open subset of 

 f locally Lipschitz on X.

Definition 10.75
A locally Lipschitz function 

 is Clarke invex on the open set 

 if there exists a vector-valued function 

 such that

that is, equivalently if




We have seen that if 

 is a locally Lipschitz function on the open set 

 and 

 is a local minimum or also a local maximum point of f over X,  then 

 is a Clarke stationary point, i.e.

The following result gives a characterization of Clarke invex functions, similar to the one given in Theorem 4.​20 for differentiable functions.

Theorem 10.76
Let 

 be locally Lipschitz on the open set 

 then f is Clarke invex on X if and only if every Clarke stationary point 

 is a global minimum point of f over X.


Proof
First, assume that every Clarke stationary point 

 is a global minimum point of f over X. Let us consider the following two cases.
(1)
If 

 are points such that 

 it is sufficient to choose 


 (2)
If 

 are points such that 

 then 

 cannot be a Clarke stationary point and hence there exists a direction 

 such that 



 

Define the function

Then we have

Therefore, f is Clarke invex with respect to

The vice versa is quite immediate: if f is invex, then 

 implies 

 

.    



The above theorem has been proved by [58], however, under a superfluous assumption. See also the related papers of [61-65].
Clarke invex functions have been used also to obtain sufficient Karush-Kuhn-Tucker conditions for an optimization problem with inequality constraints. See, e.g. [58, 59]. For this type of problems in [66] it has been obtained, by using a class of functions more general than Clarke invex functions, saddle points conditions and also some duality results. Consider the problem

X open set, 

 and every 

, 

 locally Lipschitz on X.

Theorem 10.77
Let 

 be feasible for 

. If the objective function f is Clarke invex, with respect to a kernel function 

 and every 

 

 is Clarke invex, with respect to the same function 

 and the conditions (a)



 (b)


 


 (c)


 

 hold at 

 then 

 is a solution of 

 and 

 is a saddle point of the Lagrangian function 





 

Conversely, assume that 

 is a solution of 

 that f and every 

 

 are Clarke invex with respect to the same kernel function 

 and that an appropriate constraint qualification holds (e.g. the Cottle c. q. of Theorem 10.62). Then, the Karush-Kuhn-Tucker conditions (a), (b), and (c) hold and the pair 

 is a saddle point of the Lagrangian function 





10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder to Nonsmooth Optimization
As we have previously mentioned, starting from the 60s and 70s of the last century, several mathematicians have studied the possibility to generalize the classical concepts of differentiability (Gâteaux, Fréchet, Hadamard, etc.) in order to treat problems described by nonsmooth functions. Besides the approaches of Rockafellar to convex functions and of Clarke to locally Lipschitz functions, it is worth mentioning the approaches of [4, 13, 47, 67-70] that will not be treated in the present book.
The variety of the various approaches, proposed to study nonsmooth functions and nonsmooth optimization problems, has led to define axiomatic constructions which include, as particular cases, several of the said above approaches. We briefly examine the axiomatic approach of [7-10], but we point out also the interesting approaches of [71-73].
The approach of Elster and Thierfelder is based on an axiomatic definition of local cone approximation of a set at a point. In some previous chapters and also in the present chapter we have introduced and used various local cone approximations. Elster and Thierfelder give the following general axiomatic definition (they consider a locally convex Hausdorff space, but we continue to consider the Euclidean space 

). See also the papers of [40, 74-77].

Definition 10.78
A map 

 is a local cone approximation if for each set 

 and each point 

 a cone 

 is associated such that the following properties are fulfilled: 1.



 2.


 


 3.


 


 4.


 


 5.


 for any linear homeomorphism 


 6.


 

 where 

 is the recession cone of S (see [2]). Moreover, we set 


 



Theorem 10.79
The axioms 1-6 are independent, i.e. for each axiom there exists a map 

 which fails exactly the said axiom and satisfies the remaining axioms.

Almost all local cone approximations used in optimization theory verify the previous axioms. We give below a list of the most used local cone approximations which are a particular case of the axiomatic definition described above (some of these cones have already been presented and used in the previous chapters). We adopt the various descriptions in terms of neighborhoods.

Definition 10.80
Let be 

 and 


The cone 

 is called cone of feasible directions to S at 



The cone 

 is called cone of weakly feasible directions or radial tangent cone to S at 



The cone 

 is called Bouligand tangent cone or contingent cone to S at 



The cone 

 is called cone of interior directions or cone of interior displacements to S at 



The cone 

 is called cone of attainable directions or Kuhn-Tucker tangent cone or Ursescu tangent cone  [78] to S at 



The cone 

 is called cone of quasi-interior directions to S at 



The cone 

 is called Clarke tangent cone to S at 



The cone 

 is called Rockafellar hypertangent cone to S at 



The cone 

 is called cone of epi-Lipschitzian directions to S at 






Remark 10.81
The descriptions of the cones 

 

 and 

 are slightly different from the original definitions (see, e.g. [79]), where the point 

 belongs to the set 

 The present description, taken from [7-9], allows to verify the third axiom of Definition 10.78. However, the consideration of the set 

 does not involve the original behavior of the map. More precisely, in [38] it has been shown that if 

 the descriptions given in Definition 10.80 for 

 

 and 

 coincide with the original definitions.

For a quick overview of the main properties of the cones previously defined, it is useful in the following scheme.

With regard to this scheme, the following assertions hold true.

The cones of the first row are open and it holds 

 The cones of the third row are closed and it holds 

 The cones of the second row verify the property 




The cones of the first column are convex; the cones of the second and third column are isotone, i.e. 





By means of the axiomatic characterization of a local cone approximation, always following [8, 9], but see also [75, 76], it is possible to give the following definition of generalized directional derivative.

Definition 10.82
Let be 

, 

 such that 

 and 

 a local cone approximation, according to Definition 10.78. Then the function 

 defined by

is called the K-directional derivative of f at 

 It is assumed 



It is worth noting that in [80] it was perhaps noticed by first time the connection between the Dini directional derivatives and an appropriate local cone approximation of the epigraph of f at 

 It is quite immediate to remark that 

 is positively homogeneous. Moreover, it can be proved that the topological properties of the local cone approximation 

 are reflected on the K-directional derivatives, as described in the following theorem, given in [9].

Theorem 10.83
Let be 

, 

 and 

 a local cone approximation. Then: (i)
If 

 is convex, then 

 is sublinear.
 (ii)
It holds 

 In particular, if 

 is closed, it holds 

 and 

 is lower semicontinuous.
 (iii)
It holds 

 where 

 is the strict epigraph of the K-directional derivative. In particular, if 

 is open, it holds 

 and 

 is upper semicontinuous.
 


By means of Definition 10.82 it is possible to get a family of generalized directional derivatives. In particular, if we make use of the local cone approximations previously recalled, we obtain the following results. We use the following notations, taken from [69, 70]:







Also the definitions of "

" and "

" operations are taken from [69, 70]. Let 

 and 

 extended real-valued functions. We have










Let be 

 and 

 Then:
The lower Dini-Hadamard directional derivative at 

 in the direction 

 is 




The upper Dini-Hadamard directional derivative at 

 in the direction 

 is 




The lower Dini directional derivative at 

 in the direction 

 is 




The upper Dini directional derivative at 

 in the direction 

 is 




The lower Ursescu directional derivative at 

 in the direction 

 is 




The upper Ursescu directional derivative at 

 in the direction 

 is 




The Clarke generalized directional derivative at 

 in the direction 

 is 

 Here H is the hypertangent cone (do not make confusion with the upper Dini-Hadamard directional derivative!).

The Clarke-Rockafellar generalized directional derivative  at 

 in the direction 

 is 




The epi-Lipschitzian directional derivative  at 

 in the direction 

 is 






Remark 10.84
When f is lower semicontinuous, the convergence 

 becomes simply 

 and, moreover, if f is continuous, it becomes 


If f is locally Lipschitz, then: (a)


 i.e. we obtain the usual Definition 10.34 of the Clarke directional derivative.
 (b)




 (c)




 


It follows that f is (right-sided) directionally differentiable at 

 in the direction 

 if and only if

Moreover, f is Gâteaux differentiable at 

 if and only if

is linear.
Similar to the inclusion scheme concerning the various local cone approximations, we obtain the following scheme showing the relationships between the various generalized directional derivatives previously considered.

The following assertions hold true.
(1)
The directional derivatives of the first row of the scheme are upper semicontinuous and it holds 

 The directional derivatives of the third row of the scheme are lower semicontinuous and it holds 

 For the directional derivatives of the second row of the scheme, it holds 



 (2)
The directional derivatives of the first column of the scheme are convex (more precisely: sublinear). The directional derivatives of the second and third column are isotone, in the sense that they verify the following property: 



 

In a similar way with respect to the definition of K-directional derivative, it is possible to introduce the concept of K-subdifferential.

Definition 10.85
Let be 

, 

 and 

 be a local cone approximation. The set (possibly empty)

is said the K-subdifferential of f at 

 and the elements 

 are said the K-subgradients of f at 

.

Note that 

 if and only if 

 

 When 

 then 

 is a closed and convex set. As the K-directional derivative of f is directly related to the local cone approximation 

 of its epigraph, something similar holds true also for the K-subdifferential.

Theorem 10.86
Let be 

, 

 and 

 a local cone approximation. Then it holds

where 

 is the polar cone of K.


Proof
We have the following chain of equivalences:










   



Now we consider briefly some optimality conditions expressed in terms of K-directional derivatives. We begin with an unconstrained minimization problem.

Theorem 10.87
Let be 

 and let 

 be a local minimum point of f over X. If 

 is any local cone approximation such that 

 then it holds (i)


 


 (ii)



 



Proof
(i) Let us assume 

 for a vector 

 Then, because 

 we have

and hence

which means 

 

 

 



which contradicts the assumption that 

 is an unconstrained local minimum point of f.
(ii) The assertion follows from Definition 10.85.    



For example, we have, under the assumptions of Theorem 10.87,

or also the sharper condition

or also, in terms of upper Hadamard directional derivatives,

or also the sharper condition

Now we consider a minimization problem of the type 

 i.e. with a set constraint, and of type 

 i.e. with inequality constraints. First, we introduce the following sets.

The cone of descent directions of f at 

 is: 




The linearizing cone of f at 

 is: 






.



. Where 

.


Obviously, these cones are convex, if 

 is convex.
In the following, we assume, when it is necessary, that the local cone approximation 

 satisfies the following conditions.


 K is convex and closed.


 




 




 


Let us consider problem 






Theorem 10.88
If 

 is a local solution of 

 and 

 satisfies conditions 

 and 

 then (i)


;
 (ii)


.
 



Theorem 10.89
If 

 is a local solution of 

, if 

 and 

 are verified, and if one of the following conditions is verified:


 




 


then it holds




Now let us consider problem 

 i.e.

with X open set of 

 In order to avoid confusion with the cones 

 we denote by 

 the feasible set of 

 [9] obtain for 

 the following Karush-Kuhn-Tucker-type necessary optimality conditions.

Theorem 10.90
Let 

 be a local solution of 

 and let 

 either 

 or 

 be verified. Moreover, the following constraint qualification is satisfied:

where

is the convex cone generated by K-gradients of 

 

 at 


Then, there exist multipliers 

 

 such that (i)


;
 (ii)


.
 


Let us now consider the following further constraint qualifications (

).



 Generalized Guignard-Gould-Tolle constraint qualification:









 Generalized Abadie constraint qualification:









 First generalized Slater constraint qualification:






 Second generalized Slater constraint qualification:








We have the following result.

Theorem 10.91
([9]) Let be 

 and let conditions 

 be verified. Moreover, let be verified the condition

Then we have the following implications:




The same authors obtain also Fritz John-type optimality conditions for 

 in terms of K-directional derivatives.

Theorem 10.92
Let 

 be a local solution of 

 and let the conditions 

 be verified. Then: (i)
There exist multipliers 

 

 not all zero, such that 






 (ii)
There exist multipliers 

 

 not all zero, such that 






 


Under other appropriate conditions, the same authors obtain the following version of the Fritz John necessary optimality conditions for 


There exist multipliers 

 

 not all zero, such that 








Under an appropriate constraint qualification, it is possible to obtain 

 i.e. 

 in the above conditions.

References1.J.-J. Moreau, Fonctionelles sous-différentiables, C. R. Acad. Sci. Paris. Sér. A-B 257, 4117-4119 (1963)2.R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)3.A.D. Ioffe, V.M. Tichomirov, Theory of Extremal problems (North Holland, Amsterdam, 1979)4.B.N. Pshenichnyi, Necessary Conditions for an Extremum (Marcel Dekker, New York, 1971)5.J.M. Danskin, The Theory of Max-Min and Its Application to Weapons Allocation Problems (Springer, New York, 1967)6.V.F. Demyanov, V.N. Malozemov, Introduction to Minimax (Wiley, New York, 1974)7.K.-H. Elster, J. Thierfelder, The general concept of cone approximations in nondifferentiable optimization, in Nondifferentiable Optimization. ed. by V.F. Demyanov, D. Pallaschke (Springer Verlag, Berlin, Motivations and Applications, 1985), pp.170-1898.K.-H. Elster, J. Thierfelder, On cone approximations and generalized directional derivatives, in Nonsmooth Optimization and Related Topics. ed. by V.F. Demyanov, F. Giannessi (Plenum Press, New York, 1988), pp.133-1549.K.-H. Elster, J. Thierfelder, Abstract cone approximations and generalized differentiability in nonsmooth optimization. Optimization 19, 315-341 (1988)10.K.-H. Elster, J. Thierfelder, Generalized notions of directional derivatives. Quaderni della Sezione di Matematica Applicata, Gruppo di Ottimizzazione e Ricerca Operativa, Università di Pisa, no. 155 (1989)11.W. Fenchel, Convex Cones, Sets and Functions, Lecture Notes (Princeton University, 1953)12.A.W. Roberts, D.E. Varberg, Convex Functions (Academic, New York, 1973)13.V.F. Demyanov, A.M. Rubinov, Constructive Nonsmooth Analysis (Verlag Peter Lang, Frankfurt a. M., 1995)14.A. Ben-Tal, J. Zowe, Directional derivatives in nonsmooth optimization. J. Optim. Theory Appl. 47, 483-490 (1985)15.L. Qi, On an extended Lagrange claim. J. Optim. Theory Appl. 108, 685-688 (2001)16.M. Durea, R. Strugariu, An Introduction to Nonlinear Optimization Theory (De Gruyter Open Ltd., Warsaw/Berlin, 2014)17.S. Schaible, Second-order characterizations of pseudoconvex quadratic functions. J. Optim. Theory Appl. 21, 15-26 (1977)18.M. Schechter, More on subgradient duality. J. Math. Anal. Appl. 71, 251-262 (1979)19.F.H. Clarke, Generalized gradients and applications. Trans. Amer. Math. Soc. 205, 247-262 (1975)20.F.H. Clarke, A new approach to Lagrange multipliers. Math. Oper. Res. 1, 165-174 (1976)21.F.H. Clarke, Optimization and Nonsmooth Analysis (Wiley, New York, 1983)22.Q.H. Ansari, C.S. Lalitha, M. Mehta, General Convexity, Nonsmooth Variational Inequalities and Nonsmooth Optimization (CRC Press, Boca Raton, 2014)23.A. Bagirov, N. Karmitsa, M.M. Mäkelä, Introduction to Nonsmooth Optimization (Springer, Heidelberg, 2014)24.J.M. Borwein, A.S. Lewis, Convex Analysis and Nonlinear Optimization (Springer, New York, 2000)25.F.H. Clarke, V.F. Demyanov, F. Giannessi, Nonsmooth Optimization and Related Topics (Plenum Pub. Corp, New York, 1989)26.F.H. Clarke, Y.S. Ledyaev, R.J. Stern, P.R. Wolenski, Nonsmooth Analysis and Control Theory (Springer, New York, 1998)27.V.F. Demyanov, P.M. Pardalos, M. Batsyn, Constructive Nonsmooth Analysis and Related Topics (Springer, New York, 2014)28.J. Ferrera, An Introduction to Nonsmooth Analysis (Academic, New York, 2014)29.G. Giorgi, A. Guerraggio, J. Thierfelder, Mathematics of Optimization: Smooth and Nonsmooth Case (Elsevier, Amsterdam, 2004)30.J. Gwinner, Bibliography on non-differentiable optimization and nonsmooth analysis. J. Comput. Appl. Math. 7, 277-285 (1981)31.J.-B. Hiriart-Urruty, Miscellanies on nonsmooth analysis and optimization, in Nondifferentiable Optimization: Motivations and Applications. ed. by V.F. Demyanov, D. Pallaschke (Springer, Berlin, 1985), pp.8-2432.J.P. Penot, Calculus Without Derivatives (Springer, New York, 2013)33.R.T. Rockafellar, R.J.-B. Wets, Variational Analysis (Springer, Berlin, 2009)34.J. O. Royset, R. J.-B. Wets, An Optimization Primer (Springer, New York, 2022)35.W. Schirotzek, Nonsmooth Analysis (Springer, Berlin, 2007)36.K. Shimitzu, Y. Ishizuka, J.F. Bard, Nondifferentiable and Two-Level Math. Program (Kluwer Academic Publishers, Boston, 1997)37.C.R. Bector, S. Chandra, J. Dutta, Principles of Optimization Theory (Alpha Science International Ltd., Harrow, U.K., 2005)38.G. Giorgi, A. Guerraggio, On a characterization of Clarke's tangent cone. J. Optim. Theory Appl. 74, 369-372 (1992)39.G. Giorgi, A. Guerraggio, On the notion of tangent cone in mathematical programming. Optimization 25, 11-23 (1992)40.G. Giorgi, A. Guerraggio, Characterizations, computations, algebraic and topological properties of tangent cones. J. Stat. Manag. Syst. 5, 275-294 (2002)41.M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economics and Mathematical Systems, vol. 122, (Springer, Berlin, 1976)42.G. Giorgi, S. Komlosi, Dini derivatives in optimization—Part I. Riv. Mat. Sci. Econom. Social. 15(1), 3-30 (1993)43.G. Giorgi, S. Komlosi, Dini derivatives in optimization—Part II. Riv. Mat. Sci. Econom. Social. 15(2), 3-24 (1993)44.G. Giorgi, S. Komlosi, Dini derivatives in optimization—Part III. Riv. Mat. Sci. Econom. Social. 18(1), 47-63 (1995)45.B. Jiménez, V. Novo, Alternative theorems and necessary optimality conditions for directionally differentiable multiobjective programs. J. Convex Anal. 9(1), 97-116 (2002)46.A. Cambini, L. Martein, Generalized Convexity and Optimization (Springer, Berlin, Theory and Applications, 2009)47.B.S. Mordukhovich, Variational Analysis and Generalized Differentiation, vol. 1, 2 (Springer, Berlin, 2006)48.J.-B. Hiriart-Urruty, On optimality conditions in nondifferentiable programming. Math. Program. 14, 73-86 (1978)49.M. Castellani, M. Pappalardo, First-order cone approximations and necessary optimality conditions. Optimization 35, 113-126 (1995)50.J.-B. Hiriart-Urruty, Refinements of necessary optimality conditions in nondifferentiable programming I. Appl. Math. Optim. 5, 63-82 (1979)51.I. Ekeland, On the variational principle. J. Math. Anal. Appl. 47, 324-353 (1974)52.J.-B. Hiriart-Urruty, A short proof of the variational principle for approximate solutions of a minimization problem. Am. Math. Mon. 90, 206-207 (1983)53.V.H. Nguyen, J.-J. Strodiot, R. Mifflin, On conditions to have bounded multipliers in locally Lipschitz programming. Math. Program. 18, 100-106 (1980)54.D.P. Bertsekas, A.E. Ozdaglar, Pseudonormality and Lagrange multiplier theory for constrained optimization. J. Optim. Theory Appl. 114, 287-343 (2002)55.B.M. Glover, Generalized convexity in nondifferentiable programming. Bull. Austral. Math. Soc. 30, 193-218 (1984)56.M. Soleiman-Damaneh, Characterization of nonsmooth quasiconvex and pseudoconvex functions. J. Math. Anal. Appl. 330, 1387-1392 (2007)57.N. Hadjisavvas, S. Komlosi, S. Schaible (eds.), Handbook of Generalized Convexity and Generalized Monotonicity (Springer, New York, 2005)58.T.W. Reiland, Nonsmooth invexity. Bull. Austral. Math. Soc. 42, 437-446 (1990)59.R.N. Kaul, S.K. Suneja, C.S. Lalitha, Generalized nonsmooth invexity. J. Inf. Optim. Sci. 15, 1-17 (1994)60.M.A. Hanson, On sufficiency of the Kuhn-Tucker conditions. J. Math. Anal. Appl. 80, 545-550 (1981)61.E. Caprari, 

-invex functions and 

 -convex functions: properties and equivalences. Optimization 52, 65-74 (2003)62.G. Giorgi, A. Guerraggio, Various types of nonsmooth invex functions. J. Inf. Optim. Sci. 17, 137-150 (1996)63.T.D. Phuong, P.H. Sach, N.D. Yen, Strict lower semicontinuity of the level sets and invexity of a locally Lipschitz function. J. Optim. Theory Appl. 87, 579-594 (1995)64.Y. Tanaka, M. Fukushima, T. Ibaraki, On generalized pseudoconvex functions. J. Math. Anal. Appl. 144, 342-355 (1989)65.Y. Tanaka, Note on generalized convex functions. J. Optim. Theory Appl. 66, 345-349 (1990)66.V. Jeyakumar, Equivalence of saddle-points and optima, and duality for a class of non-smooth non-convex problems. J. Math. Anal. Appl. 130, 334-343 (1988)67.V.F. Demyanov, L.C.W. Dixon (eds.), Quasidifferential Calculus. Math. Program Study 29 (1986)68.V.F. Demyanov, A.M. Rubinov (eds.), Quasidifferentiability and Related Topics. (Kluwer Academic Publishers, Dordrecht/Boston/London, 2000)69.R.T. Rockafellar, Generalized directional derivatives and subgradients of nonconvex functions. Canad. J. Math. 32, 257-280 (1980)70.R.T. Rockafellar, The Theory of Subgradients and Its Applications to Problems of Optimization: Convex and Nonconvex Functions (Heldermann-Verlag, Berlin, 1981) (French version: La Théorie des Sous-gradients et ses Applications àl'Optimization, Les Presses de L'université de Montréal, Montréal)71.F. Giannessi, Semidifferentiable functions and necessary optimality conditions. J. Optim. Theory Appl. 60, 191-241 (1989)72.F. Giannessi, Constrained Optimization and Image Space Analysis. Vol. 1: Separation of Sets and Optimality Conditions (Springer, New York, 2005)73.S. Komlosi, M. Pappalardo, A general scheme for first order approximations in optimization. Optim. Methods Softw. 3, 143-152 (1994)74.A.D. Ioffe, On the theory of subdifferential, in Fermat-days 85: Mathematics for Optimization. ed. by J.-B. Hiriart-Urruty (North Holland, Amsterdam, 1986), pp. 183-20075.D.E. Ward, Isotone tangent cones and nonsmooth optimization. Optimization 18, 769-783 (1987)76.D. Ward, The quantificational tangent cones. Canad. J. Math. 40, 666-694 (1988)77.D.E. Ward, Directional derivative calculus and optimality conditions in nonsmooth mathematical programming. J. Inf. Optim. Sci. 10, 81-96 (1989)78.C. Ursescu, Tangent set's calculus and necessary conditions for extremality. SIAM J. Control Optim. 20, 563-574 (1982)79.J.P. Aubin, H. Frankowska, Set-Valued Analysis (Birkhäuser, Boston, 1990)80.M.S. Bazaraa, J.J. Goode, Extensions of optimality conditions via supporting functions. Math. Program. 5, 267-285 (1973)












© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al.

Basic Mathematical Programming Theory


International Series in Operations Research & Management Science
344


https://doi.org/10.1007/978-3-031-30324-1_11





11. Introduction to Multiobjective Optimization



Giorgio Giorgi1  , 
Bienvenido Jiménez2   and 

Vicente Novo
2  




(1)
Department of Economics and Management, University of Pavia, Pavia, Italy


(2)
Department of Applied Mathematics, National University of Distance Education, Madrid, Spain

 



 
Giorgio Giorgi (Corresponding author)

Email: 
giorgio.giorgi@unipv.it



 

Bienvenido Jiménez


Email: 
bjimenez@ind.uned.es



 

Vicente Novo


Email: 
vnovo@ind.uned.es






Frequently, optimization problems appear in any technique or scientific activity, and the optimal decisions have traditionally attended to a unique criterion. However, in areas such as Economics, Social Sciences, Engineering, or Industry it is usually necessary to consider multiple objectives, confronted each other, that requires the use of decision techniques based on a finite number of objectives or criteria (multiobjective optimization or multicriteria decision), on a nonfinite number (vector optimization) or even on the resolution of problems in which the aim is to optimize a set-valued function. This fact has motivated the creation of mathematical theories, which are currently in process of development. To expand knowledge of this area, the interested reader can consult the monographs by Ehrgott [1], Miettinen [2] and Sawaragi, Nakayama and Tanino [3] in finite-dimensional spaces, and Jahn [4] and Luc [5] in infinite-dimensional spaces.
From the historical point of view, it seems that the first to deal with multiobjective problems were Francis Y. Edgeworth (1845-1926) and Vilfredo Pareto (1848-1923). In 1881 at King's College (London) and later at Oxford, economics professor Edgeworth was the first to define an optimum for multicriteria economic decision-making [6], and he did so for a two-criteria problem. Pareto, graduated from the University of Turin in 1870 with a degree in Civil Engineering, while working in Florence as a civil engineer (1870-1893), was one of the first to analyze economic problems with mathematical tools. In 1893, he assumed the chair of Political Economy at the University of Lausanne, where he created one of his most famous theories, The Pareto Optimum [7]: "The optimal allocation of the resources of a society is not achieved while it is possible to make at least one individual better in his own estimation while maintaining others as well as before".
The translation of Pareto's work into English, in 1971, prompted the development of multiobjective methods in Applied Mathematics and Engineering. The growth of this field was particularly strong in the United States with pioneering contributions, among others, by Stadler [8] and Steuer [9], and in the publication of two books already focused on the theoretical aspects of multiobjective optimization, those by Sawaragi et al. [3] and Luc [5] in the vectorial case, without forgetting the famous work by Kuhn and Tucker [10]. In the last decades, the applications of multiobjective optimization have grown steadily in many areas.
Multiobjective optimization methods can be broken down into different categories, but as a first approximation we can speak of two approaches, the scalarization approach and the Pareto approach. In the first group of methods, the multiobjective problem is solved by translating it into a single objective problem, that is, a scalar problem. Pareto methods keep the initial elements in their vector framework and use some concept of dominance based on a preference relation to compare possible solutions.

11.1 Optimality Notions
We are interested in the following multiobjective optimization problem

where 

, 

, are the objective functions, X is an open set, 

 is an arbitrary nonempty subset, called the feasible set; 

 and 

 are called decision space and objective space, respectively. We denote 

 which is called the objective function.
The first thing we have to do is to say what means "min" in 

. For this purpose, we consider that in 

 the order is given componentwise. For 

 we write 

 if 

, for 

, and 

 if 

, for 

.
We denote 

, and 

. Let us observe that 

 and 

.
Given 

, we say that 

 dominates (or is better than) 

 if 

.
Related to solutions of problem 

, the ideal would be to find a point 

 such that

A point 

 satisfying this condition is called an ideal point for 

. This point is the minimum of all the objectives 

, 

, over S. Such a point 

 usually does not exist, the common is that the objectives are in conflict with each other, in the following sense: to pass from 

 to 

 we can improve e.g. 

, i.e. 

 but we worsen, e.g. 

, i.e. 

. When we find a point 

 such that we cannot improve it, we say that 

 is an efficient solution to problem 

. Next, we give the rigorous definition with the different notions of optimality for 

.

Definition 11.1
Consider problem 

 and 

.
(a)


 is called efficient or Pareto minimal if there exists no 

 such that 

 and 

 for some 

, or equivalently, 

 and 

.
 (b)


 is called weak efficient or weak Pareto minimal if there exists no 

 such that 

.
 (c)


 is called strict efficient or strict Pareto minimal if 

 for all 

, 

.
 


We denote the set of all efficient solutions of 

 and weak efficient solutions by 

 and 

, respectively, and they are called the efficient set and the weak efficient set. The set of all strict efficient solutions is denoted by 

.
Other equivalent notions of efficiency are used in the literature, next we collect some of them.

Remark 11.2
(i)
The following statements are equivalent: (a)


 is efficient.
 (b)
There is no 

 such that 

.
 (c)


 for all 

.
 (d)


.
 (e)


.
 (f)
The implication
 


   holds.
 (ii)
The following statements are equivalent: (a)


 is weak efficient.
 (b)
There is no 

 such that 

.
 (c)


.
 (d)


.
 

 (iii)
The following statements are equivalent: (a)


 is strict efficient.
 (b)


 is efficient and 

.
 (c)


, 

.
 

 


The following inclusions are obvious:

We can also define (weak) efficient points for a set 

. If 

 is the identity map, i.e. 

 for all 

, then we say that 

 is an efficient point of A if 

, which means that 

. Similarly, 

 is a weak efficient point of A if 

, which means that 

. We denote by 

 and 

 the sets of efficient and weak efficient points of A, respectively. It is obvious from the definition that 

 and 

.
The following equivalences are also obvious:

 (11.1)For this reason, many times we prefer working in the objective space with the image set f(S). Moreover, if 

 then 

, and if 

 then 

.
Next, we give an example to illustrate the notions introduced (Fig. 11.1).

Fig. 11.1
Illustration of efficiency. 

 and 

 are efficient, 

 is not efficiency since is dominated e.g. by 

, 

 is weak efficient since 

 but it is not efficient since 

 and 




The first questions we approach are the existence and the basic properties of the efficiency set. It is convenient to consider 

 as we have seen, with 

. First let us show through examples that the efficient set can be empty or a singleton.

Example 11.3
(a) Let 

 defined by 

 and 

. One has that 

. In consequence, 

 and 

 are singleton.
(b) Let 

. One has 

.
We invite the reader to draw the sets f(S) in part (a) and Y in part (b).

Extension to an arbitrary convex cone
We can consider in 

 another relation 

 instead of 

. A binary relation 

 over a set 

 comes defined by a set 

 so that 

.

Definition 11.4
A relation 

 defined on A is called (a)
reflexive if 

 for all 

,
 (b)
symmetric if 

 for all 

,
 (c)
antisymmetric if 

 and 

 

 

 for all 

,
 (d)
transitive if 

 and 

 

 

 for all 

. It is said that 

 is a preorder if it is reflexive and transitive. A preorder is total if, for all 

 one has 

 or 

, it is called a partial preorder otherwise.
 


Let us note that the usual order 

 on 

 is partial. It is important to note that in a partial order, two arbitrary elements cannot be compared, in general.

Definition 11.5
A relation 

 defined on 

 is said to be compatible with the linear structure if (a)


 for all 

 and 

, and
 (b)


 and 

 

 

 for all 

.
 


A characterization of a partial preorder on 

 is given in the next result.

Theorem 11.6
(i) If 

 is a partial preorder on 

 compatible with the linear structure, then the set

is a convex cone. If, in addition, 

 is antisymmetric, then K is pointed (i.e. 

).
(ii) Conversely, if K is a convex cone in 

, then the relation defined by

is a partial preorder compatible with the linear structure. If, in addition, K is pointed, then 

 is antisymmetric.

The proof is easy and it is left to the reader.
In vector optimization, it is common to consider that the order is given by a convex cone. Note that the usual order 

 on 

 is given by the closed convex cone 

.
We can extend the notions of efficiency for an arbitrary preorder 

 given by a convex cone 

 as follows.

Definition 11.7
Consider problem 

 and 

.
(a)


 is called efficient if 

.
 (b)


 is called weak efficient if 


 (c)


 is called strict efficient if 

 for all 

, 

.
 


Of course, we can also define efficient points for a set 

 with respect to a convex cone K similarly as we have done for 

. In this introductory chapter to multiobjective optimization we prefer to continue our study with the cone 

. Most of the properties studied here are also true for an arbitrarily pointed closed convex cone with a nonempty interior. The interested reader can see Sawaragi et al. [3] or Jahn [4].
We can define Pareto maximal points as follows. 

 is a maximal point of A if 

. Therefore, a Pareto maximal point with respect to K is a Pareto minimal point with respect to 

. For this reason, in this chapter we only deal with minimal Pareto points.
Next, we establish some basic properties. Let 

 be a nonempty set.

Theorem 11.8
(i) 

.
(ii) 

.


Proof
(i) First, let 

, then 

. This condition implies that 

, i.e. 

. Indeed, assume by contradiction that there exists 

, 

 such that 

. Hence 

, 

 since 

 is a convex cone and 

. Otherwise, 

, and it would be 

, which is a contradiction. Therefore, 

 with 

, which contradicts the hypothesis. Thus 

.
Second, let 

, with 

 and 

. We affirm that 

. Indeed, if we assume that 

 then 

 (since 

) and 

, and as 

 it follows that 

 is not an efficient point of 

, which contradicts the hypothesis. Thus 

, and so 

, and as 

 it follows that 

 because 

 implies 

.
(ii) The proof of this fact is similar to that of the first part of part (i), for this reason we omit it. 



The inclusion 

 is in general false. For example, in 

, if 

, then 

 while 

.

Theorem 11.9


.
In consequence, if A is open or 

 is open, then 

.


Proof
We only have to prove 

. Let 

 and assume that 

. Then 

, and so there exists a neighborhood 

 such that 

. Pick up 

. For a fixed 

 small enough one has 

 and 

. In consequence, 

, which contradicts the fact that 

. 




Theorem 11.10
Let 

 be nonempty subsets of 

. We have (i)


.
 (ii)


 for all 

.
 


The proof is easy and it is left to the reader.
We provide next, without proof, an existence result.

Theorem 11.11
(Borwein [11]) Let A be a nonempty subset of 

 and suppose that there is some 

 such that the section

is compact (we say "A contains a compact section"). Then 

 is nonempty.


Theorem 11.12
Consider problem 

 and suppose that S is compact and each 

, 

, is continuous. Then 

 is nonempty.


Proof
We know that f(S) is a compact set since f is continuous. Hence, for any 

 the section 

 is compact, and by Theorem 11.11 it follows that 

. In consequence, 

. 



The proof of Theorem 11.11 is based on Zorn's Lemma. An easier proof can be done to prove an existence result for weak efficient points (see Theorem 2.25 in Ehrgott [1]).

Theorem 11.13
If 

 is compact, then 

.

In Definition 11.1 global efficiency has been introduced. Another important concept is local efficiency.

Definition 11.14
Consider problem 

 and 

.
(a)


 is called local efficient or local Pareto minimal if there exists a neighborhood 

 of 

 such that 

 is efficient in 

, i.e. 

 (11.2)

 (b)


 is called local weak efficient or local weak Pareto minimal if there exists a neighborhood 

 of 

 such that 

 is weak efficient in 

, i.e. 



 (c)


 is called local strict efficient or local strict Pareto minimal if there exists a neighborhood 

 of 

 such that 

 is strict efficient in 

, i.e. 

 for all 

, 

.
 


Naturally, any global (weak) efficient point is local (weak) efficient. The converse is valid for convex problems.

Theorem 11.15
Assume that S is a convex set and each component 

, 

 is convex on S. If 

 is local efficient, then it is global efficient.


Proof
By hypothesis, condition (11.2) is satisfied for some neighborhood 

 of 

. By contradiction, let us assume that 

 is not global efficient. Then there exists 

 such that

 (11.3)Define 

, we have 

 for all 

 due to the convexity of S. For 

 small enough, one has 

. As each 

 is convex on S, we derive

Hence, 

, where 

 by (11.3). Therefore, 

, and consequently 

 since 

. This is a contradiction to (11.2). Thus, 

. 



We can improve this result with some weaker assumptions. Recall that quasiconvex functions were introduced in Definition 3.​18, p. 65.

Theorem 11.16
(Ruiz-Canales and Rufián-Lizana [12]) Assume that S is a convex set and each component 

, 

, is quasiconvex on S and at least one is strictly quasiconvex on S. Then every local efficient solution is a global efficient solution.


Proof
Recall that 

 is quasiconvex on S if for all 

, and all 

 one has 

, with strict inequality if g is strictly quasiconvex and 

.
By assumption there exists a neighborhood 

 of 

 such that 

.
As above, by contradiction, let us assume that 

 is not global efficient. Then there exists 

 such that

 (11.4)Define 

, we have 

 for all 

 due to the convexity of S. For 

 small enough, one has 

. As 

 is quasiconvex on S, from (11.4) it follows 

, for 

. Moreover, as 

 is strictly quasiconvex on S for some 

 one has 

. We have obtained a contradiction to the fact that 

 since 

 and 

.
Let us observe that the second condition in (11.4) has only been used to assure that 

. 



Next we are going to give a geometrical characterization for the sets 

, 

 and 

. To this aim, recall and introduce the level sets of a function 

. Given 

, the sets 

, 

 and 

 are called level set, level curve and strict level set of g at 

. Obviously, 

 and 

.

Theorem 11.17
(Ehrgott [1], Theorem 2.20) Let 

, 

 and define 

, 

. Then (i)


 is efficient 

 

.
 (ii)


 is weak efficient 

 

.
 (iii)


 is strictly efficient 

 

.
 


The proof is easy and it is left to the reader. This theorem is useful when the level sets are geometrically known when 

. We illustrate this theorem with two examples.

Example 11.18
Consider the unconstrained biobjective Pareto problem:

In this example, it is easy to obtain all the efficient points by applying the method of level sets. If we select a point a in the feasible set 

, the set of feasible points that improve it with respect to 

 are those that verify 

, that is the interval [b, a] (see Fig. 11.2). Similarly, the set of those points that improve it with respect to 

 is given by the interval [a, c], so 

, and by using part (iii) in Theorem 11.17 a is strictly efficient. Therefore, it is clear that if the point a is between the abscissas of the vertices of the two parabolas, the above condition is verified and consequently all points in 

 are strict efficient. If a is outside the previous interval, the intersection no longer reduces to the point a, and, therefore, it is not efficient (not even weak). In conclusion, the set of strict efficient points is 

. Moreover, 

.



Fig. 11.2
Example 11.18. Method of level sets



Fig. 11.3
Example 11.19. Feasible set



Example 11.19
Consider now the constrained biobjective Pareto problem:

Determine if the points 

 and 

 are efficient, weakly efficient, or strictly efficient, by the method of level sets.
The feasible set S is the triangle with vertices A(3, 5), 

 and 

, whose sides are 

, 

 and 

 (see Fig. 11.3).
The strict level sets associated to the point 

 are given by 

, 

. The second one is the parabolic region 

 (we can assume that 

, because the feasible set is contained in this half-plane). Since they cut into the interior of the feasible set S, from part (ii) of Theorem 11.17, it follows that 

 is not weakly efficient (and, therefore, neither efficient nor strict efficient) (see Fig. 11.4).
The level sets associated to the point 

 are given by 

, 

. The second one is the parabolic region 

. They only intersect with S in 

, so taking into account part (iii) of Theorem 11.17 we conclude that the point 

 is strict efficient (see Fig. 11.5).



Fig. 11.4
Level sets for 





Fig. 11.5
Level sets for 




Proper efficiency
Proper efficient points are efficient points that satisfy a suitable property. There are two important reasons to introduce proper efficient points. First, some authors observed that some efficient points had undesirable properties. Second, mathematical methods usually allow to obtain a subset of the efficient set.
One of the ideas of proper efficiency (particularly from Geoffrion's definition) is that unbounded trade-offs between objectives are not allowed.
Until now there are many types of concepts of proper minimality. The notion of proper Pareto minimality (or proper efficiency) was first introduced by Kuhn and Tucker [10]. Then some further concepts of proper efficiency were given by Geoffrion [13], Borwein [14], Benson [15], Henig [16], etc.; see also Guerraggio et al. [17] where the relationships between several notions are studied.

Definition 11.20
(Geoffrion [13]) A point 

 is said to be proper efficient in the sense of Geoffrion if it is efficient and if there is a real number 

 such that for all i and 

 satisfying 

 there exists an index j such that 

 and




According this definition, proper efficient solutions are those efficient solutions that have bounded trade-offs between the objectives.

Definition 11.21
A point 

 is called proper efficient (a)
in the sense of Borwein if 



 (b)
in the sense of Benson if 



 


Recall that 

 denotes the Bouligand tangent cone (Definition 2.​35, p. 47).
In this definition we can work with a set 

 and a point 

 because f plays no role. In consequence, we say that 

 is a proper efficient point of Y(a)
in the sense of Borwein if 

.
 (b)
in the sense of Benson if 

.
 


Remark 11.22
(a) Note that 

 is proper efficient in the sense of Borwein (resp., Benson) if and only if 

 is a proper efficient point of f(S) in the sense of Borwein (resp., Benson).
(b) If 

 is proper efficient of Y in the sense of Borwein, then it is also efficient.
Indeed, by contradiction assume that 

 is not an efficient point of Y. Then there exists 

 such that 

. Let us check that d is a feasible direction to 

 at 

, i.e. 

. Let 

, then

since 

 and 

. Therefore, by the definition 

, and by Remark 2.​45, it follows that 

. As 

 we have a contradiction with the fact that 

 is proper efficient of Y in the sense of Borwein.

Next, we are going to introduce the notion of proper efficiency in the sense of Kuhn-Tucker. This notion is only defined when the feasible set is given by functional constraints. These kinds of problems are very important in applications and we will deal with them later. So we are going to study a multiobjective optimization problem with inequality constraints and equality constraints as in Chap. 6, but there it was with only one objective.
We consider the following multiobjective optimization problem:

where 

 is an open set contained in the domains of the functions involved in 

, 

, 

, 

, 

 and 

, 

, are real-valued functions defined on 

.
We make the assumptions that every 

, 

, every 

, 

, are (at least) differentiable on X and that every 

, 

, is (at least) continuously differentiable on X. We also denote 

, 

 and 

.
We denote by 

 the set of all feasible points of this problem, i.e.

Let us observe that this set was denoted by 

 in Chap. 6. Given 

, we denote by 

 the set of indices of active constraints at 

, i.e. 

.

Definition 11.23
Consider problem 

. A point 

 is said to be proper efficient in the sense of Kuhn-Tucker if it is efficient and if there is no 

 satisfying

 (11.5)


Next we study the relations between these notions. See also Ehrgott [1], Sawaragi et al. [3] and Guerraggio et al. [17].
We say that a set 

 is 

-convex if 

 is a convex set. Clearly, if A is convex, then A is 

-convex.

Lemma 11.24
Consider problem 

. If S is convex and each 

, 

, is convex on S, then f(S) is 

-convex.


Proof
Let 

, 

 and 

. We have to prove that

 (11.6)Each 

 is convex on S, and so 

, for 

 where 

 due to the convexity of S. Hence, 

, that is 

. Therefore, in view of (11.6)

because 

 since 

 is a convex cone. 



A function 

 such that 

 is a convex set is called convex-like on S.

Theorem 11.25
Let 

, 

.
(i)
If 

 is proper efficient of Y in the sense of Benson, then it is also proper efficient in the sense of Borwein.
 (ii)
If Y is 

-convex, then both definitions coincide.
 (iii)
Consider problem 

 and 

. If S is convex and each 

, 

, is convex on S, then 

 is proper efficient in the sense of Benson if and only it is proper efficient in the sense of Borwein.
 



Proof
(i) It is a direct consequence of the inclusion 

 (see the proof of Theorem 2.​41) with 

.
(ii) Since 

 is convex by assumption, it follows from Theorem 2.​41 that 

, and so the statement is obvious.
(iii) It follows from part (ii) in view of Lemma 11.24 and Remark 11.22(a) choosing 

 and 

. 




Theorem 11.26
(Benson [15]) Consider problem 

. A feasible point 

 is proper efficient in the sense of Benson if and only if it is proper efficient in the sense of Geoffrion.


Proof
Geoffrion 

 Benson. Suppose 

 is efficient, but not properly efficient in Benson's sense. Then, we know that a nonzero 

 exists. Without loss of generality we may assume that 

, 

, 

 (otherwise we can reorder the components of f and rescale d). Consequently, there are sequences 

, 

, for each n, 

, 

 such that 

.
Choosing a subsequence if necessary, we can assume that 

 is the same for all n and nonempty since 

 is efficient. Moreover, 

 because 

 and so 

 for all n large enough since 

. Let 

. From convergence we get existence of 

 such that for all 



 (11.7)and

 (11.8)In particular, for 

 , we have

 (11.9)and, therefore, from (11.7) and (11.9)

 (11.10)Because L was arbitrarily chosen, 

 is not properly efficient in Geoffrion's sense.
Benson 

 Geoffrion. Suppose now that 

 is efficient, but not properly efficient in Geoffrion's sense. Let 

 be an unbounded sequence of positive real numbers. Without loss of generality we assume that for each n there is an 

 such that 

 and

 (11.11)Choosing a subsequence if necessary, we can assume

is constant for all n and nonempty since 

 is efficient. We are going to construct appropriate sequences 

 and 

 such that the sequence 

 converges to some 

 with 

.
Define 

 for all n. Define now 

 through

 (11.12)With these sequences we have

 (11.13)This sequence converges due to the choice of 

 to some 

, where 

 for 

. Thus, from (11.13) 

, 

, 

, 

, 

. So 

, and so 

 is not properly efficient in Benson's sense. 




Lemma 11.27
Assume that 

 is differentiable and X is an open set. Let 

, 

 be a sequence converging to 

 and 

 with 

. If 

, then





Proof
Let 

 and so 

.
If there are infinite 

 such that 

, then clearly 

 for infinite j and so 

. And also 

.
Therefore, we can assume that 

 for all j and so 

 for all j. As f is differentiable at 

, one has by definition 

. Replacing x by 

, it follows that 

. As 

, one has that the sequence 

 is bounded, and we derive that 

. From here, the thesis follows. 




Theorem 11.28
(Geoffrion [13]) Consider problem 

 and 

. Assume that the involved functions are differentiable at 

 and 

 satisfies the Abadie constraint qualification (see p. 185). If 

 is proper efficient in the sense of Geoffrion, then 

 is proper efficient in the sense of Kuhn-Tucker.


Proof
Suppose 

 is efficient, but not properly efficient in the sense of Kuhn-Tucker. Then there is some 

 such that (without loss of generality, after renumbering the objectives)

 (11.14)By the Abadie constraint qualification one has 

, and as 

 by (11.14), we have 

. This means that there exist sequences 

 and 

 such that 

 for all n and 

.
By Lemma 11.27, one has 

, and so 

 for all n large enough. Taking a subsequence if necessary we can assume that the set

is the same for all n and nonempty since 

 is efficient.
By Lemma 11.27, we have 

 for all 

. In view of (11.14) one has 

, and therefore,

But since 

, the latter imply that for 

 one has

because 

 for all i by Lemma 11.27. Hence 

 is not properly efficient in Geoffrion's sense. 



The original proof given by Geoffrion uses the Kuhn-Tucker constraint qualification, but we know that this constraint qualification implies the Abadie constraint qualification (see p. 185).
The converse implication of Theorem 11.28 is true under convexity. It is not necessarily a constraint qualification because really convexity is yet a constraint qualification (see the Slater constraint qualification at p. 187). The following theorem is a consequence of some results in the next Sect. 11.3, but we present it here for completeness.

Theorem 11.29
(Geoffrion [13]) Assume that 

, 

 and 

, 

, are convex and 

, 

 are linear affine. If 

 is proper efficient in the sense of Kuhn-Tucker, then 

 is proper efficient in the sense of Geoffrion.


Proof
By Theorem 11.48(i), conditions (a), (b), (c) in that theorem are satisfied, and by Corollary 11.49 we conclude that 

 is proper efficient in the sense of Geoffrion. 



We sketch the relationships obtained in the following scheme. 





11.2 The Weighted Sum Method and Relations with Proper Efficiency
Most used method to solve a multiobjective optimization problem (in short, MOP) is scalarization. Scalarization means that the problem is transformed into a scalar or a family of scalar optimization problems, so we can use all powerful tools and methods developed for scalar optimization problems. The solutions to the scalar problem are some kind of solution to the MOP. In this introductory chapter, we will only deal with linear scalarization, or in other words, the Weighted Sum Method.
The idea of this method is to associate a weight coefficient 

 to each objective 

 and minimize the weighted sum of the objectives. To be more precise, consider the following scalar optimization problem:

where 

, X is an open set, 

 and 

.
The set of solutions of 

 is denoted by 

.
Let Y be a nonempty subset of 

. We denote




It is clear that 

.
In this section, we study the relationships between the solutions of the scalar problem 

 with 

, 

 or 

 and the efficient or weak efficient points of Y, and between solutions of 

 and solutions of 

.

Theorem 11.30
(i) 

.
(ii) If Y is 

-convex, then 

.


Proof
(i) Let 

 and 

. Then 

 for all 

.
Suppose that 

. Then there is some 

 with 

 for 

. Thus, 

 because at least one of the weights 

 must be positive. This is a contradiction and the result follows.
(ii) Taking into account part (i), we only have to prove that 

. Let 

. By Theorem 11.8(ii) we have that 

 and so 

. Then

By hypothesis, the set 

 is convex and so 

 is also a convex set. By a separation theorem (see Theorem 2.​20), there exist 

 and 

 such that

 (11.15)On the one hand, choosing 

 and 

 we derive that 

. On the other hand, choosing 

 with 

 and 

, it follows that 

 for all 

. Taking the limit as 

 we deduce that 

 and so 

. Thus in view of (11.15), we have 

 for all 

. As the function 

 is continuous it follows that 

 for all 

. In particular, if we choose 

, where 

 is the k-th unit vector, we obtain 

, for 

. Thus 

.
Finally, using (11.15) with 

 we get 

 for all 

, or equivalently, 

 for all 

, and, therefore, 

. 




Theorem 11.31


.


Proof
Let 

. Then there is some 

 satisfying 

 for all 

. Suppose 

. Hence there exists 

 with 

 and 

, and multiplying componentwise by the weights gives 

 for all 

 and strict inequality for at least one k. This strict inequality together with the fact that all 

 are positive implies that 

, contradicting the fact that 

. 




Corollary 11.32
If Y is 

-convex, then 

.

It follows from Theorem 11.30(ii) and the fact that 

.

Theorem 11.33
If 

 is the unique element of 

 for some 

, then 

.

As usual, the proof is "by contradiction" and is left to the reader because it does not have difficulty.
Next, we obtain the corresponding results for problem 

 from the above results.

Theorem 11.34
Consider problem 

. Suppose that 

 is a solution of problem 

 for some 

. Then the following statements hold: (i)
If 

, then 

.
 (ii)
If 

, then 

.
 (iii)
If 

 and 

 is the unique solution of 

, then 

.
 



Proof
The assertions are immediate consequences of Theorems 11.30(i), 11.31 and 11.33 taking into account relation (11.1). 



Now we will state the relationships between proper efficient points and solutions of the problem 

.
We denote by 

 the set of all proper efficient points of Y in the sense of Benson.

Lemma 11.35
Let 

 be a closed cone. If there exists 

 such that 

 for all 

, then 

.
The converse statement is true if, in addition, C is convex.


Proof
Assume by contradiction that there exists 

, with 

. Then, on the one hand, as 

, 

 and 

 we have 

. On the other hand, as 

, by assumption it follows 

, which is a contradiction.
Now assume that 

. Let 

. Clearly 

 is a compact convex set contained in 

, and from the assumption, we derive that 

. By the strong separation theorem (Theorem 2.​17), there exist 

 and 

 such that

 (11.16)Choosing 

, we obtain 

, and in consequence

This condition implies that 

. Indeed, if we choose the point 

, where 

 is the kth unit vector, we have 

 for all 

. Thus 

.
Now, by contradiction, assume that 

 for some 

. Then 

 for all 

, and 

, which contradicts (11.16). Therefore, 

 for all 

, and the proof is finished. 




Theorem 11.36


.


Proof
Let 

. Then 

 for some 

, so 

 for all 

, 

. Therefore, 

, and consequently, 

 for all 

. By using Lemma 11.35, we conclude that 

, that is, 

. 




Theorem 11.37
If Y is 

-convex, then 

.


Proof
We only have to prove 

. Let 

, then 

. By hypothesis, 

 is a convex set, and so 

 is also convex. By Theorem 2.​6, 

 is a convex cone. Hence 

 is a closed convex cone and 

. By using Lemma 11.35, we conclude that there exists 

 such that 

 for all 

. From here, 

 for all 

, 

. Choosing 

, it results that 

 for all 

, which means that 

. 




Theorem 11.38
Assume S is convex and each 

, 

, is convex. Then 

 is efficient in the sense of Geoffrion if and only if 

 is a solution of the problem 

 for some 

.


Proof


 By Theorem 11.26, 

 is efficient in the sense of Geoffrion if and only 

 is efficient in the sense of Benson. In view of Remark 11.22(a), this statement is equivalent to 

. By Lemma 11.24, f(S) is 

-convex, and using Theorem 11.37 we derive 

. Therefore, 

, which means that 

 is a solution of the problem 

 for some 

.


 It is enough to revert the above reasoning. 




Theorem 11.39
If Y is 

-closed and 

-convex, then 

.

We omit the proof because is very technical, it can be seen in Ehrgott [1], Theorem 3.17, or in Sawaragi et al. [3], Theorem 3.4.6 and Corollary 3.2.2.
The inclusion 

 is not always satisfied, see Example 3.19 in Ehrgott [1] or Example 3.4.2 in Sawaragi et al. [3], both examples are the same.
The reader interested in delving into these topics is directed to Ehrgott [1] and Sawaragi et al. [3].
We summarize the results obtained: (i)
If 

 then 

 and 

.
 (ii)
If Y is 

-convex then 

.
 



11.3 Optimality Conditions
In this section, we study first and second-order necessary and sufficient optimality conditions for the general problem 

 and also for the problem defined by inequality constraints and equality constraints 

.
We start providing optimality conditions for problem 

. We assume that 

 is differentiable and X is an open set.

Theorem 11.40
(General necessary condition) If 

 is a local weak efficient solution for 

, then the system

is incompatible in 

, i.e. 

 for all 

.


Proof
By contradiction, assume that 

 for some 

. Then there exist sequences 

 and 

 such that 

 and 

. By applying Lemma 11.27, we derive 

. So, for all k large enough one has 

, and, therefore, 

 for all k large enough, which contradicts the local weak efficiency of 

 since 

 and 

. 



Recall that the cones of linearized directions and strict linearized direction for problem 

 are defined by




Of course, we can consider the constraint qualifications defined in Sect. 6.​2 because only the constraints are involved, and not the objectives.
Next we establish the Fritz John necessary optimality conditions for problem 

. Its proof follows the line of the proof of Theorem 6.​3. We assume that the involved functions are continuously differentiable on X.

Theorem 11.41
(Fritz John necessary conditions) Let 

 be a local weak efficient solution for 

. Then there exist multipliers ("Fritz John multipliers") 

 such that (i)


;
 (ii)


;
 (iii)


, 

, and 

.
 



Proof
If the vectors 

 are linearly dependent, the thesis of the theorem is trivial. Assume, therefore, that these vectors are linearly independent. From Theorem 6.​1 it follows 

, and in view of Theorem 11.40 we have that the system

is incompatible in 

. Taking into account the definition of 

, the previous statement is equivalent to say that the system

admits no solution 

 By Motzkin's theorem of the alternative (Theorem 2.​31), there exist vectors 

 such that 

, 

, 

 and

By choosing 

 for all indices 

, we obtain the thesis. 



Conditions (i), (ii) and (iii) in Theorem 11.41, by analogy to Theorem 6.​3, are called Fritz John conditions.
Now, we state for 

 the Karush-Kuhn-Tucker optimality conditions.

Theorem 11.42
(Karush-Kuhn-Tucker) Let 

 be a local weak efficient solution for 

 and let the Abadie constraint qualification be satisfied (page xx). Then there exist multipliers ("Karush-Kuhn-Tucker multipliers") 

 such that

 (11.17)


 (11.18)


 (11.19)



Proof
By the Abadie constraint qualification we have 

 and in view of Theorem 11.40 we have that the system

is incompatible in 

. Taking into account the definition of 

, the previous statement is equivalent to say that the system

admits no solution 

 By Motzkin's theorem of the alternative (Theorem 2.​31), there exist vectors 

 such that 

, 

, 

 and

If we choose 

 for all 

, the thesis follows. 



This theorem has been proved e.g. in Singh [18], Theorem 3.1, and in Lin [19], Theorem 7.1, under the Kuhn-Tucker constraint qualification.
In contrast to Theorem 6.​4, where it is required the Guignard-Gould-Tolle constraint qualification, in Theorem 11.42 we require the Abadie constraint qualification. This is a gap between multiobjective optimization and scalar optimization that has been pointed out by several authors [20-22]. We can show it in the following example.

Example 11.43
Let us consider the next multiobjective optimization problem:

where the feasible set is 

.
It is easy to check that the point 

 is an efficient solution using e.g. Theorem 11.17, that 

 and that 

, that is, the Guignard-Gould-Tolle c. q. is satisfied. On the other hand, the Karush-Kuhn-Tucker conditions are not satisfied, since the condition (11.17) is only satisfied with 

 and any value of 

. Note that the Abadie c. q. is not satisfied.

Next we provide (first-order) sufficient conditions for global weak efficiency for problem 

 under generalized convexity following the same ideas as in Theorems 6.​6, 6.​8 and 6.​10.

Theorem 11.44
Let 

 be a point such that 

 satisfy the Karush-Kuhn-Tucker conditions (11.17)-(11.19) for some 

. Let 

 be pseudoconvex on the open convex set 

, let every 

 

 be quasiconvex on X and let every 

 

 be quasiconvex and quasiconcave on X. Then 

 is a weak efficient solution of 

.


Proof
We are applying Theorem 6.​6. Let us observe that the functions 

, 

, 

, 

, 

, satisfy the assumptions of Theorem 6.​6 at the point 

 with the multipliers (u, v), and consequently, 

 is a (global) solution of the problem 

. As 

, 

, from Theorem 11.34(i) it follows that 

 is a weak efficient solution of problem 

. 




Corollary 11.45
Let 

 be a feasible point of 

 and assume that every 

, 

, and every 

, 

, are convex on the open convex set 

 and every 

 

 is linear affine. If 

 satisfy the Karush-Kuhn-Tucker conditions (11.17)-(11.19) for some 

, then 

 is a weak efficient solution of 

.


Proof
The function 

 is convex since 

. By Theorem 3.​26(i) one has that 

 is pseudoconvex and by Theorem 3.​26(i)-(ii), each 

, 

, is quasiconvex. Now, the conclusion follows from Theorem 11.44. 



Similarly to Theorem 6.​8 we can give a version for the multiobjective problem 

. We omit the proof because it is easy.

Theorem 11.46
Let 

 be a point such that 

 satisfy the Karush-Kuhn-Tucker conditions (11.17)-(11.19) for some 

, and in addition, 

. Suppose that 

 is pseudoconvex on the open convex set 

 and every 

, 

, and every 

 

 is quasiconvex on X. Then 

 is a weak efficient solution of 

.

Similarly to Theorem 6.​10 we can provide a sufficient condition of weak efficiency for problem 

 with strict pseudoconvexity, in this case based on the Fritz John conditions.

Theorem 11.47
Let 

 be a point such that 

 satisfy the Fritz John conditions (i), (ii) and (iii) in Theorem 11.41 for some 

, and in addition, 

. Suppose that every 

, 

, is pseudoconvex on the open convex set 

 and every 

, 

, and every 

 

 is strictly pseudoconvex on X. Then 

 is a weak efficient solution of 

.

The proof is very similar to the proof of Theorem 6.​10 changing f by 

, 

 and so we omit it. Other sufficient conditions using different convexities of the involved functions are given in Singh [18], Lee [23], Aghezzaf and Hachimi [20], Cambini and Martein [24] and Giorgi et al. [25].
Next we establish optimality conditions of proper efficiency in the sense of Kuhn-Tucker.

Theorem 11.48
Consider a differentiable problem 

 and 

.
(i)
If 

 is proper efficient in the sense of Kuhn-Tucker, then there exist multipliers 

 such that (a)


;
 (b)


;
 (c)


, 

.
 

 (ii)
Conversely, assume that the previous conditions (a), (b) and (c) are satisfied, 

 is pseudoconvex on the open convex set 

, every 

 

 is quasiconvex on X and every 

 

 is quasiconvex and quasiconcave on X. Then 

 is proper efficient in the sense of Kuhn-Tucker.
 



Proof
(i) By hypothesis there is no 

 satisfying system (11.5). Defining the matrices

the incompatibility of system (11.5) is equivalent to saying that the system

has no solution 

. By applying the theorem of the alternative of Tucker (p. 45), there exist vectors 

 such that 

, 

 and

If we choose 

 for all 

, the thesis follows.
(ii) By the theorem of the alternative of Tucker, saying that conditions (a), (b) and (c) are satisfied is equivalent to saying that system (11.5) has no solution. So we only have to prove that 

 is efficient.
Proceeding as in the proof of Theorem 11.44, by applying Theorem 6.​6 to 

 instead of f, we derive that 

 is a (global) solution of the problem 

. As 

, from Theorem 11.34(ii) it follows that 

 is an efficient solution of problem 

. 




Corollary 11.49
Let 

 and assume that every 

, 

, and every 

, 

, are convex on the open convex set 

 and let every 

 

 is linear affine. If conditions (a), (b), and (c) in Theorem 11.48 are satisfied for some (w, u, v), then 

 is proper efficient in the sense of Kuhn-Tucker. If, in addition, every 

, 

, is convex, then 

 is also proper efficient in the sense of Geoffrion.


Proof
The proof of the fact that 

 is proper efficient in the sense of Kuhn-Tucker is as in the one of Corollary 11.45, but now we apply Theorem 11.48(ii) instead of Theorem 11.44.
To prove the second part let us note that 

 is convex, and so it is pseudoconvex, and every 

, 

 is quasiconvex. We have seen in the proof of Theorem 11.48(ii) that 

 is a solution of problem 

 with 

. In view of Theorem 11.38, we conclude that 

 is proper efficient in the sense of Geoffrion. We have been able to apply Theorem 11.38 because S is a convex set since 

, 

, are convex and 

, 

, are linear affine. 



To illustrate the previous results, we provide some examples.

Example 11.50
Consider the biobjective Pareto program with constraints:

Taking into account that the Abadie c. q. is verified at every feasible point because all involved functions are convex, (a)
obtain the points that satisfy the necessary Karush-Kuhn-Tucker conditions to be a weak efficient point, and
 (b)
which ones satisfy the necessary conditions in Theorem 11.48(i) to be a proper efficient point in the sense of Kuhn-Tucker?
 (c)
We are going to apply Theorem 11.42, conditions (11.17)-(11.19). We have 

, 

, 

, 

, 

 and 

, so 

 and the equation (11.17) becomes 

 (11.20) The feasible set 

 is given in Fig. 11.6. We also highlight there the points 

, 

 and 

.
 


Fig. 11.6
Example 11.50. Feasible set and points that satisfy Karush-Kuhn-Tucker conditions


No point 

 in the interior of 

 verifies the K-K-T necessary conditions because 

 and 

, and, therefore, 

 and 

, consequently, equation (11.20) has no solution verifying (11.19).
Now suppose that 

 is a point on segment AB. If 

 is not a extreme point of AB, then 

 is not active (

), then 

 (by the Eq. (11.18)), and we have the solution 

, 

, 

, 

. Solution that is also valid for 

 and for 

 (although for these points, 

 and other solutions can be found with 

).
If 

 is a feasible point of the arc of the circumference BA different from the extremes, then 

 is not active (

), and, therefore, 

. Equation (11.20) becomes

 (11.21)that is

If 

, then 

 and (11.19) is not verified. We can, therefore, assume that 

 (specifically, we chose 

 to simplify, it could also be solved for an arbitrary value 

). Since 

 must be positive (at most one of them can be 0), it follows that 

, 

. Therefore, the only points of the arc BA that verify the necessary conditions are those in the arc BC. For all of them, 

, so 

, and 

, so 

. The only point for which 

 is C, but since 

, satisfies the Kuhn-Tucker condition.
In short, the only feasible points that verify the K-T necessary conditions are the points of the segment AB and those of the arc BC, with all the extreme points included (set that we will call T). See Fig. 11.6.
(b) As we have seen in part (a), between the points that verify the K-T necessary conditions, the only one for which there is no solution with 

 is 

.
Remarks: 1.
By Corollary 11.45, taking into account that all functions 

 are convex, and there is a solution with 

, 

, it follows that all points in T are weak efficient.
 2.
By Corollary 11.49, it follows that the points in the set 

 are proper efficient solutions in the Kuhn-Tucker sense and also in the Geoffrion sense.
 



Example 11.51
Consider Example 11.19 and determine all the points that verify the Karush-Kuhn-Tucker necessary conditions. Which are proper efficient? and weak efficient? We leave the development to the reader as an exercise and we provide only the solution.
(a)
There is a solution with 

 at the points 

 with 

.
 (b)
There is a solution with 

, 

, at the points (x, 0) with 

.
 

Since all the functions are convex, the points for which exists 

 are proper in the sense of Kuhn-Tucker and in the sense of Geoffrion (Corollary 11.49). By Corollary 11.45, all the points of parts (a) and (b) are weak efficient. Using Theorem 11.17 one can check that the only efficient point, apart from the points of part (a), is (8, 0).


Example 11.52
Consider the biobjective Pareto program with constraints:

Find all feasible points that satisfy the Kuhn-Tucker necessary conditions of weak efficient point or proper efficient point in the Karush-Kuhn-Tucker sense, and knowing that all the functions are convex, determine which points of the previous ones are proper efficient in the Kuhn-Tucker sense. We also leave the development to the reader as an exercise and we provide only the solution
Let us note that all the feasible points satisfy the linear independence c. q., and so they also satisfy the Abadie c. q., and we can apply the Karush-Kuhn-Tucker conditions (11.17)-(11.19) in Theorem 11.42. In this case, conditions (11.17)-(11.19) become

 (11.22)We have that: (a)
There is a solution with 

 and 

 if 

, 

 or if 

, 

. Since the program is convex, by Corollary 11.49, they are Geoffrion proper efficient points, and using the same Corollary 11.49), they are also Kuhn-Tucker proper efficient.
 (b)
There is a solution with 

 and 

, if 

 and there is a solution with 

 and 

, if 

. In both cases, we can only ensure that they satisfy the weak efficient point necessary conditions (Theorem 11.42) and since they do not satisfy the necessary conditions of Theorem 11.48(i), we can say that they are not proper efficient points in the Kuhn-Tucker sense. The obtained points have been represented in Fig. 11.7.
 




Fig. 11.7
Example 11.52. Points that verify the n.c. of K-K-T proper efficiency (red) and weak efficiency (blue)



Example 11.53
Consider the biobjective Pareto program with constraints:

Knowing that all feasible points satisfy the Abadie constraint qualification (because the linear independence c. q. is fulfilled), obtain all feasible points that verify the Karush-Kuhn-Tucker necessary conditions of weak efficient point or proper efficient point in the Kuhn-Tucker sense. Can we apply Corollary 11.49 to see if these points are proper efficient?
The feasible set for this program is given in Fig. 11.8.

Fig. 11.8
Example 11.53. Feasible set


We have 

, 

, 

 y 

, and so Eq. (11.17) becomes

that is

 (11.23)We study several cases depending on the feasible point is an interior or boundary point in the feasible set.
(1)
(x, y) is an interior point. Then 

, and system (11.23) becomes 

 (11.24) which has a non-trivial solution (

), if and only if 

, that is, if and only if 

. From (11.24) we have that 

. Therefore, there is a solution 

, 

 if 

 and


, any 

 and 

;



, any 

 and 

, which gives us the point (0, 0), but this point is not feasible.


Since 

, points (x, 0) with 

 and 

 are feasible. Although for 

 and 

, the points (2, 0) and 

 are not interior points, they satisfy the necessary conditions of K-K-T, and so in what follows we can assume that 

. The solution of system (11.23) can be obtained, for example, by Cramer's rule (we assume 

), and is given by 

 (11.25)

 (2)
If 

 is not active (

) and 

 is active (

). The system (11.25) is 

 This system has a solution with 

 and 

 if the following system is fulfilled: 

 whose solution (to obtain feasible points) is 

, 

.
 (3)
If 

 is not active (

) and 

 is active (

). The solution of system (11.25) now is 

 There is a solution with 

 and 

 if the following system is fulfilled: 

 whose solution is 

, 

, resulting 

 for these values.
 (4)
If 

 and 

 are active (then 

 and 

), we obtain the points 

 and 

. We already know, from part 3), that for 

 there is a solution. Let's see what happens with the point 

. From (11.25) it results: 

 There is a solution with 

 and 

 if the following system is fulfilled: 

 But this system with 

, 

 only has the solution 

 which does not give a valid solution since it would be 

. In short: (a) There is a solution with 

 at the following points: 

 (x, 0) with 

, 

 (x, y) with 

, 

, 

 (x, y) with 

, 

. (b) There is a solution with 

, 

, at the previous points, and also at the points (x, y) with 

, 

, that is the points 

, (0, 2) and 

 (see Fig. 11.9).
Corollary 11.49 can be applied to the points in parts 

 and 

, except to the point 

 and 

, and so they are proper efficient in the sense of Kuhn-Tucker. For the points 

, 

 and for the points in parts 

 and (b), Corollary 11.49 cannot be applied because the function 

, which is active, is not convex (note also that the feasible set is not convex). Other procedures would have to be used to decide if the points that satisfy the necessary conditions of K-K-T of Theorem 11.48(i) are proper efficient points. For example, in this case, if we consider the same biobjective Pareto problem but now we replace the constraint 

 by 

, it results a convex problem whose feasible set contains the feasible set of the original problem. Now, all the points in parts 

 and 

 satisfy Corollary 11.49 with the same values of w, u and so they are proper efficient in the senses of Kuhn-Tucker, Geoffrion, and Benson, and the same happens for the original problem. For other considerations, see also Exercise 11.79.
 




Fig. 11.9
Example 11.53. Points that satisfy the K-K-T necessary conditions


Next, we define the notion of strict local efficient point of order m for the general problem 

. This notion was introduced by Jiménez [26] generalizing the notion given for a scalar function (Definition 1.​11).

Definition 11.54
(Jiménez [26]) Let 

 be an integer number. We say that 

 is a strict local efficient (or Pareto minimal) point of order m for 

 if there are a neighborhood 

 and a constant 

 such that

 (11.26)or equivalently

 (11.27)


This notion extends to multiobjective optimization the usual notion of a strict local minimizer of order m (see Definition 1.​11) for a scalar function. Indeed, if 

 then (11.27) becomes 

, for all 

, which is equivalent to

which is just the definition of a strict local minimizer of order m.

Remark 11.55
Some basic properties are the following: (i)
Every strict local efficient point of order m is also a strict local efficient point of order s for all 

.
 (ii)
Every strict local efficient point of order m is also a strict local efficient point.
 


The behavior under a linear application is stated in the next result.

Theorem 11.56
(Jiménez and Novo [27], Proposition 2.7) Let 

 be a linear application such that 

. If 

 is a strict local efficient point of order m for Af on S (with respect to 

), then 

 is a strict local efficient point of order m for f on S (with respect to 

).
(Here, Af is the function 

).


Proof
By assumption, there exist a neighborhood U of 

 and 

 such that

 (11.28)As A is linear, it is also continuous. Hence there exists 

 such that 

, and, therefore, 

, where 

. In consequence, by linearity

 (11.29)Let us prove that

By contradiction, suppose that there exist 

 and 

 such that

Then, from (11.29) we deduce that 

 with 

, contradicting (11.28). 



As a simple application we give an example.

Example 11.57
If 

 is a strict local minimizer of order m for 

 on S for some 

, then 

 is a strict local efficient point of order m for f on S.
Indeed, we define 

 by 

 (the projection on the kth component). Clearly, 

 and 

. Now the result follows from Theorem 11.56.

Next, in Theorem 11.59 we state a characterization for strict local efficient points of order 1 under differentiability. Previously we need a lemma.

Lemma 11.58
(Jiménez [26], Proposition 3.4) Let 

. Then 

 is not a strict local efficient point of order m for 

 if and only if there exist sequences 

 and 

, such that 

 and

 (11.30)



Proof
"If" part. Since 

 converges to 

 and (11.30) holds, for all 

 there exists 

 such that for every 

 we have 

, 

 and 

, that is, 

.
Reasoning "ad absurdum", suppose 

 is a strict local efficient point of order m for 

. Then there exists a n.b.h. 

 and 

 such that (11.26) holds. Now, for 

, there exists 

 such that for each 

 we have 

 and

contradicting (11.26).
"Only if" part. By assumption, for all 

 and for all 

 there exists 

 such that

In particular, for 

 and 

, there exist 

 and 

 such that

that is,

and the claim follows. 




Theorem 11.59
Assume that f is differentiable at 

. Then 

 is a strict local efficient point of order 1 if and only if

or equivalently, 

, where

is the cone of descent directions of f at 

.


Proof


 Let 

 and by contradiction assume that 

. Without lost of generality we can suppose that 

. As 

, there exists a sequence 

 with 

 and such that 

. By Lemma 11.27, we have

 (11.31)On the other hand, as 

 is a strict local efficient point of order 1, there exist a neighborhood 

 and 

 such that 

, for all 

, or equivalently

As 

, there exists 

 such that 

 for all 

, and, therefore, 

 for all 

. Since 

 is a closed set, in view of (11.31) it follows that 

. As 

, we conclude that 

, which contradicts the assumption 

.


 By contradiction, assume that 

 is not a strict local efficient point of order 1. Then by Lemma 11.58 there exist sequences 

 and 

, such that 

 and

 (11.32)Without lost of generality we can suppose that 

 with 

, and applying Lemma 11.27, we have 

. From (11.32) it follows that 

. From here and since 

 and 

 is closed, we derive that 

. Therefore, 

, which contradicts the hypothesis. 



Theorem 11.59 is contained in Theorem 4.8 in Jiménez [26], but the proof here is different.

Corollary 11.60
Consider problem 

 and 

. If 

, then 

 is a strict local efficient point of order 1 for 

.

It is a straightforward consequence of Theorem 11.59 since 

 by Theorem 6.​1.
Next we give an equivalent condition to the hypothesis of the previous corollary in a more operative way.

Theorem 11.61
(Giorgi et al. [28], Theorem 3.4) Consider problem 

 and 

 and assume that among the vectors

there are n linearly independent. Then 

 if and only if there exist Karush-Kuhn-Tucker multipliers 

, 

, 

, 

, 

, 

, such that




We omit the proof, which can be seen in the aforementioned reference.
Next, we provide a sufficient condition for efficiency of order 1 based on the Fritz John conditions.

Theorem 11.62
Let 

 be a point satisfying the Fritz John conditions (i), (ii), and (iii) in Theorem 11.41 for some 

. If the vectors

span 

, then 

 is a strict local efficient solution of order 1 for 

.


Proof
Suppose that 

 is not a strict local efficient solution of order 1 for 

. Then, by Theorem 11.59 there exists a vector 

, 

, such that 

, 

. By Theorem 6.​1, we have 

, and so 

, which means that 

, 

 and 

, 

. Then, multiplying condition (i) in Theorem 11.41 by 

 and using condition (ii), we obtain

Taking into account that 

, 

, it results

In view of the facts that 

, 

, 

, 

 and 

 we derive that 

, 

, and 

, 

. By virtue of our assumption on the gradient vectors, the vector y is orthogonal to every vector in 

. This implies 

, which is a contradiction. 



Second-order Conditions
We provide in this part second-order necessary and second-order sufficient optimality conditions for problem 

. We assume that the involved functions in 

 are twice-continuously differentiable.
Assume that 

 is a point satisfying the Fritz John conditions (i), (ii) and (iii) in Theorem 11.41 or the Karush-Kuhn-Tucker conditions for some 

. The Lagrangian function is defined by

 (11.33)We define the cone of strict descent directions of f at 

 by




Lemma 11.63


 if and only if the Karush-Kuhn-Tucker conditions hold at 

.


Proof
This result follows from Motzkin's theorem of the alternative (Theorem 2.​31). 



The cone 

 is called the critical cone. Next we establish second-order necessary optimality conditions of the Fritz John-type.

Theorem 11.64
Let 

 be a local weak efficient solution for problem 

. Then for any 

 there are multipliers 

 such that the Fritz John conditions (i), (ii) and (iii) in Theorem 11.41 are satisfied at 

 and, moreover,





Proof
We follow the same lines as in the proof of Theorem 6.​39. Let 

. If the gradients 

 

 are linearly dependent, then there exists 

 such that 

. Hence 

 and 

 are Fritz John multipliers that satisfy the (first-order) Fritz John conditions. Moreover, condition (11.36) is satisfied either by 

 or by 

 since

Therefore, for any 

 we can choose one of the two possibilities, so that (11.36) is satisfied.
We now assume that the gradients 

 

 are linearly independent. Consider the following linear programming problem in the variables 

:

 (11.34)where 

. The optimal value of this problem is nonnegative. Indeed, otherwise there exists z which satisfies

 (11.35)By Lemma 6.​37, there exists a path 

 satisfying conditions (6.​22). Then, by a second-order Taylor expansion, we have for 

 small enough and for all 

 that

 due to the first condition in (11.35) and the fact that 

. Therefore, for 

 small enough, 

 is feasible and 

, 

, which contradicts the local weak efficiency of 

. This proves that (11.34) has a nonnegative optimal value.
Since 

 

 are linearly independent, the equality constraints of (11.34) have a feasible solution because 

 and so 

, and thus there exists 

 such that 

 for all 

, and hence, since 

 can be made arbitrarily large, problem (11.34) is consistent. Therefore, problem (11.34) has a finite nonnegative optimal value. Since (11.34) is a linear programming problem, it follows, by the Strong Duality Theorem of Linear Programming (see Remark 9.​19), that its dual, in the variables w, u, v, with 

 for 

, has the same optimal value. The dual of (11.34) is

subject to:







Since an optimal solution of this dual problem is a Fritz John multipliers vector associated with 

 by choosing 

 for 

 we get the thesis. 



This theorem has been proved, with a different proof, in Bigi and Castellani [29].
The drawback of the previous theorem is that it may be 

. If the Mangasarian-Fromovitz c. q. is satisfied, this case cannot occur.

Theorem 11.65
Let 

 be a local weak efficient solution for problem 

 and let 

 verify the Mangasarian-Fromovitz c. q. Then for any 

 there are multipliers 

 (that depend on y) such that the Karush-Kuhn-Tucker conditions are satisfied at 

 and, moreover,

 (11.36)



Proof
The result follows as a consequence of Theorem 11.64 taking into account that the Mangasarian-Fromovitz c. q. allows to assure that 

. 



Some authors as Bigi and Castellani [30] have discussed the uniqueness of the Karush-Kuhn-Tucker multipliers in multiobjective optimization. They state that, fixed w, there is uniqueness if and only if the strict Mangasarian-Fromovitz c.q. (SMFCQ) holds. In order to obtain uniqueness without fixing a unit vector w a priori, they introduce a new regularity condition, strengthening (SMFCQ) in such a way that the objective functions 

 are also involved, introducing a quite strong regularity condition. We refer to the paper by these authors for more details.
The boundedness of the set of Karush-Kuhn-Tucker multipliers has been also studied under a regularity condition involving the objective functions in Dutta and Lalitha [31]. We refer to this paper to study this topic.
Let 

 be the set of all the Karush-Kuhn-Tucker multipliers (w, u, v) at a feasible point 

. Under the validity of the Mangasarian-Fromovitz c. q., it is then possible to write the thesis of Theorem 11.65 in the form

Now we turn to second-order sufficient optimality conditions for 

 and 

. We follow the approach of Jiménez and Novo [32].

Definition 11.66
Consider problem 

, 

 and let 

 be differentiable at 

 and 

, 

, 

. We say that the pair (w, F) is a (lower) support for f at 

 on S if the following three relations hold: (i)


 for all 

,
 (ii)


,
 (iii)


. We say that (w, F) is a weak support if the previous relations (i), (ii), and (iii) hold and 

 (

 is admitted).
 


The scalarization process contained in the previous definition is going to allow us, on the one hand, to follow a parallel path to the scalar case and, on the other hand, to apply the results from the scalar programming.

Remark 11.67
(a) Definition 11.66 is equivalent to say that F is a support (in the Hestenes sense, see p. 102) for the scalar function 

.
(b) Consider problem 

. If the Karush-Kuhn-Tucker conditions (11.17)-(11.19) are satisfied for some 

, then, calling F to the Lagrangian function

we have that (w, F) is a support for f at 

 on 

 and the proof is immediate.
(c) If the Fritz John conditions (i), (ii) and (iii) in Theorem 11.41 are satisfied at 

, then 

 is a weak support for f at 

 on 

.
(d) If in Definition 11.66, condition (i) holds on a relative neighborhood of 

, 

, instead of on all S, we will say that F is a local support. Although the theory below developed is valid for this type of support because the notions that are used are local, we have employed (global) supports for simplicity reasons.

The following theorem provides some basic properties satisfied if a support exists. Note that the first property coincides with the first order necessary optimality condition (Theorem 11.40).

Theorem 11.68
(i) If (w, F) is a support for f at 

 on S and f is differentiable at 

, then 


(ii) If (w, F) is a weak support for f at 

 on S, F is twice differentiable at 

 and there exists 

 such that 

, then 

, that is, (w, F) is a support.


Proof
(i) Let 

. Conditions (i), (ii) and (iii) in Definition 11.66 are equivalent to the following: (1) 

, 2) 

 and 3) 

. Conditions (1) and (2) imply that 

 is a minimum of G on S. Using Theorem 4.​24, it follows that 

 

, which, taking into account condition (3), is equivalent to

 (11.37)Reasoning "ad absurdum", assume that there exists 

. Then, 

, 

. As 

 and 

, one has 

, contradicting (11.37).
(ii) We have that 

 for some sequences 

, 

. Let us assume 

. With the notation of the previous part, now 

 

, 

, 

 is a minimum of G on S, 

 and 

. But, by using a second-order Taylor expansion, one has

which is a contradiction. 



Based on the notion of support function, we give some first-order sufficient optimality conditions.

Theorem 11.69
If (a) (w, F) is a support for f at 

 on S and (b) 

, then 

 is a strict local efficient point of order 1 for 

.


Proof
Condition (b) is equivalent to

 (11.38)From Theorem 11.68(i), 

, hence, 

. Therefore, taking into account (11.38), it follows that 

. By Theorem 11.59, 

 is a strict local efficient point of order 1 for 

. 




Theorem 11.70
Consider problem 

. If the Karush-Kuhn-Tucker conditions (11.17)-(11.19) are satisfied at 

 and 

, then 

 is a strict local efficient point of order 1 for 

.


Proof
From Remark 11.67(b), 

 is a support for f at 

 on 

, and then it suffices to apply Theorem 11.69. 



Next, several second-order sufficient optimality conditions are provided.

Theorem 11.71
Let 

, 

, 

 differentiable at 

. If for every 

 there is a weak support (w, F) for f at 

 on S, which is twice differentiable at 

 and such that 

, then 

 is a strict local efficient point of order 2 for 

.


Proof
By contradiction, assume that 

 is not a strict local efficient point of order 2, then, by Lemma 11.58, there exist sequences 

 and 

, such that 

 and

 (11.39)Without lost of generality, we can suppose that

with 

. If for some 

, 

, then by Lemma 11.27 one has 

, and consequently 

. From (11.39), we have

and so 

, which is impossible because 

. Therefore, for all 

, 

, that is, 

. Hence, 

 and 

, and by assumption, there is a weak support (w, F) such that 

.
Now, applying to (11.39) the continuous linear function from 

 to 

 given by 

, it results

 (11.40)Let G be the function defined in the proof of Theorem 11.68, i.e. 

, hence 

 for 

, and replacing in (11.40) we obtain

 (11.41)As 

, it follows 

, and in consequence 

, but this is a contradiction because 

 and 

 for all n. 




Corollary 11.72
Let 

 be twice differentiable at 

. If there exists 

, 

, 

 such that (a)
 

,
 (b)
 the quadratic form 

 is positive definite on the cone 

,
 then 

 is a strict local efficient point of order 2 for f on S.


Proof
Firstly, let us suppose 

. Let 

, this means that 

 for all 

. If for some k, 

, then 

 which contradicts (a). Hence, for all 

, 

. Consequently, 

 and

 (11.42)If 

, by Theorem 11.59, 

 is a strict local efficient point of order 1 and, therefore, 

 is a strict local efficient point of order 2 by Remark 11.55(i).
If 

, then we consider 

. One has, obviously, that (w, F) is a support for f.
By assumption (b), taking into account (11.42), 

 we have that 

, since 

. Therefore, by Theorem 11.71, 

 is a strict local efficient point of order 2.
Let now 

. Rearranging, we can suppose that 

 with 

, ..., 

, 

, ..., 

 and 

. Consider the linear map 

 given by 

, i.e. the projection from 

 to 

 on the s first components, and let 

. Clearly, 

 for 

. Moreover, condition (a) and (b) of the hypothesis become:


 

 and


 the quadratic form 

 is positive definite on the cone 

.
Using the first part, we derive that 

 is a strict local efficient point of order 2 for g on S. Finally, as 

, by Theorem 11.56 we conclude that 

 is a strict local efficient point of order 2 for f on S. 




Example 11.73
Let 

 given by



 and 

. The assumptions of Corollary 11.72 are satisfied with 

. Note that 

, which is positive definite on 

. Thus, we derive that 

 is a strict local efficient point of order 2 for f.

Next, the general result (Theorem 11.71) is applied to problem 

. The following theorem is an immediate consequence of the aforesaid theorem taking into account Remark 11.67(b).

Theorem 11.74
Consider problem 

 and let 

. If for every 

 there exist multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker conditions (11.17)-(11.19) and such that 

, then 

 is a strict local efficient point of order 2 for 

.


Corollary 11.75
Consider problem 

 and let 

. If for every 

 there exist multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker conditions (11.17)-(11.19) and such that 

, then 

 is a strict local efficient point of order 2 for 

.

This corollary is a straightforward consequence of the previous theorem since 

.
The following example shows that the Lagrangian function varies on the vector. The functions have already been considered by Ben-Tal [33] in Examples 2.1 and 4.1.

Example 11.76
Consider 

 defined by



 and 

. We have that 

. The accomplished calculations by Ben-Tal prove that several Lagrangian functions (until six) are needed to get

and that just with only one it is impossible to obtain it. Therefore, 

 is a strict local efficient point of order 2.

In Corollary 11.75 the Lagrangian function 

 can vary on the vector 

. If the same Lagrangian function 

 is valid for all the vectors y we obtain the next result.

Corollary 11.77
Consider problem 

 and let 

. Suppose that there exist multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker conditions (11.17)-(11.19) and such that

Then 

 is a strict local efficient point of order 2 for 

.

Next, we are going to state in Theorem 11.78 another second-order sufficient condition with fixed multipliers. Previously, some of the notation.
Assume that 

 is a point satisfying the Fritz John conditions (i), (ii) and (iii) in Theorem 11.41 or the Karush-Kuhn-Tucker conditions (11.17)-(11.19) for some 

. Consider the Lagrangian function 

 defined by Eq. (11.33). It is clear that 

.
We define the following sets:










 (11.43)where 

 is the function of components 

,

where 

 is the function of components 

. For brevity, we have written 

 and 

 instead of 

 and 

, respectively.
Let us observe that 

 is the linearized cone associated with the set 

.

Theorem 11.78
Consider problem 

 and let 

. Suppose that there exist multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker conditions or the Fritz John conditions and such that

Then 

 is a strict local efficient point of order 2 for 

.


Proof
Let us check that

 (11.44)The inclusion "

" is obvious. Let 

. Taking into account the Karush-Kuhn-Tucker conditions or the Fritz John conditions and the definition of the sets 

 and 

, the Lagrangian function (11.33) can be written

As 

, it results

Multiplying by 

, and using that 

, 

, we obtain

 (11.45)As 

 one has 

, 

, and as 

 one has 

, 

. Hence, 

, 

 and 

, 

, and taking into account (11.45), we deduce that 

, 

 and 

, 

. From here, 

, 

 and 

, 

, which allows us to conclude that 

 in view of (11.43).
Now, the thesis follows from (11.44) and Corollary 11.77. 



This theorem is a slight modification of Theorem 5.4 in Jiménez and Novo [32]. For other results on second-order sufficient optimality conditions in multiobjective optimization, see Wang [34] and Aghezzaf and Hachimi [35].
We illustrate the previous results with an example.

Example 11.79
Consider Example 11.53. Let us recall that the points of the form 

 with 

 satisfy the Karush-Kuhn-Tucker conditions with 

, arbitrary 

 and 

. Thus,

We want to study if these points satisfy some sufficient optimality conditions. Let us observe that the unique active constraint is 

 for all 

, i.e. 

.
As 

 on A, one has 

. Moreover, the set of vectors

has rank 2 for all 

. By Theorem 11.61 we derive that 

, and from Corollary 11.60 we conclude that x(t) is a strict local efficient point of order 1 for all 

.
If 

, we have 

, and



 If 

, then 

. In view of Theorem 11.59, 

 is not a strict local efficient point of order 1.


 If 

, then 

. In view of Theorem 11.59, 

 is not a strict local efficient point of order 1.


 If 

, then 

. In view of Theorem 11.59, 

 is not a strict local efficient point of order 1.
Now, for these three points, we study the second-order conditions. The Hessian of the Lagrangian function at x(t) is given by

and we have to study the sign of the quadratic form

with 

. Let us note that 

.


 If 

, then 

 for all 

, so by applying Theorem 11.64, 

 is not a local weak efficient solution.


 If 

, then 

 for all 

, so by applying Corollary 11.77, x(t) is a strict local efficient point of order 2.
The previous results are of local type (the points are locally efficient except the point (0, 2)), and they do not allow to assure if the studied points are globally efficient. To establish global efficiency, Theorem 11.44 cannot be applied because the function 

 is not quasiconvex, but one can be applied Theorem 11.17 resulting in the following (as the reader can check):
for 

, 

 is weak efficient;

for 

, x(t) is not weak efficient;

for 

, x(t) is strictly efficient.




References1.M. Ehrgott, Multicriteria Optimization, 2nd edn. (Springer, Berlin, 2005)2.K.M. Miettinen, Nonlinear Multiobjective Optimization (Kluwer Academic Publishers, Boston, 1999)3.Y. Sawaragi, H. Nakayama, T. Tanino, Theory of Multiobjective Optimization (Academic, Orlando, 1985)4.J. Jahn, Vector Optimization. Theory, Applications, and Extensions, 2nd edn. (Springer, Berlin, 2011)5.D.T. Luc, Theory of Vector Optimization. Lecture Notes in Economic and Mathematics Systems, vol. 319 (Springer, Berlin, 1989)6.F.Y. Edgeworth, Mathematical Psychics (P. Keagan, London, 1881)7.V. Pareto, Manuale di Economia Politica (Societa Editrice Libraria, Milano, 1906) Translated into English by A.S, Schwier as Manual of Political Economy (Macmillan, New York, 1971)8.W. Stadler, A survey of multicriteria optimization, or the vector maximum problem. J. Optim. Theory Appl. 29, 1-52 (1979)9.R.E. Steuer, Multiple Criteria Optimization. Theory, Computation and Application, Wiley Series in Probability and Statistics (Wiley, New Jersey, 1986)10.H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability, ed. by J. Neyman (University of California Press, Berkeley, 1951), pp. 481-492. Reprinted in Giorgi and Kjeldsen (2014)11.J.M. Borwein, On the existence of Pareto efficient points. Math. Oper. Res. 8, 64-73 (1983)12.P. Ruiz-Canales, A. Rufián-Lizana, A characterization of weakly efficient points. Math. Program. 68, Ser. A, 205-212 (1995)13.A.M. Geoffrion, Proper efficiency and the theory of vector maximization. J. Math. Anal. Appl. 22, 618-630 (1968)14.J.M. Borwein, Proper efficient points for maximization with respect to cones. SIAM J. Control Optim. 15, 57-63 (1977)15.H.P. Benson, An improved definition of proper efficiency for vector minimization with respect to cones. J. Math. Anal. Appl. 71, 232-241 (1979)16.M.I. Henig, Proper efficiency with respect to cones. J. Optim. Theory Appl. 36, 387-407 (1982)17.A. Guerraggio, E. Molho, A. Zaffaroni, On the notion of proper efficiency in vector optimization. J. Optim. Theory Appl. 82, 1-21 (1994)18.C. Singh, Optimality conditions in multiobjective differentiable programming. J. Optim. Theory Appl. 53, 115-123 (1987)19.J.G. Lin, Maximal vectors and multiobjective optimization. J. Optim. Theory Appl. 18, 41-64 (1976)20.B. Aghezzaf, M. Hachami, On a gap between multiobjective optimization and scalar. J. Optim. Theory Appl. 109, 431-435 (2001)21.M. Castellani, M. Papalardo, About a gap between multiobjective optimization and scalar optimization. J. Optim. Theory Appl. 109, 437-439 (2001)22.S.Y. Wang, F.M. Yang, A gap between multiobjective optimization and scalar optimization. J. Optim. Theory Appl. 68, 389-391 (1991)23.G.M. Lee, Optimality conditions in multiobjective optimization problems. J. Inf. Optim. Sci. 13, 107-111 (1992)24.A. Cambini, L. Martein, Generalized convexity and optimality conditions in scalar and vector optimization, in Handbook of Generalized Convexity and Generalized Monotonicity. ed. by N. Hadjisavvas, S. Komlosi, S. Schaible (Springer, New York, 2005), pp. 151-19325.G. Giorgi, B. Jiménez, V. Novo, Sufficient optimality conditions and duality in nonsmooth optimization problems under generalized convexity, in Generalized Convexity and Related Topics. ed. by I.V. Konnov, D.T. Luc, A.M. Rubinov (Springer, New York, 2007), pp. 265-27826.B. Jiménez, Strict efficiency in vector optimization. J. Math. Anal. Appl. 265, 264-284 (2002)27.B. Jiménez, V. Novo, First and second order sufficient conditions for strict minimality in nonsmooth vector optimization. J. Math. Anal. Appl. 284, 496-510 (2003)28.G. Giorgi, B. Jiménez, V. Novo, A note on first-order conditions for Pareto problems. Numer. Funct. Anal. Optim. 29, 1108-1113 (2008)29.G. Bigi, M. Castellani, Second order optimality conditions for differentiable multiobjective problems. RAIRO Oper. Res. 34, 411-426 (2000)30.G. Bigi, M. Castellani, Uniqueness of KKT multipliers in multiobjective optimization. Appl. Math. Lett. 17, 1285-1290 (2004)31.J. Dutta, C.S. Lalitha, Bounded sets of KKT multipliers in vector optimization. J. Global Optim. 36, 425-437 (2006)32.B. Jiménez, V. Novo, First and second order sufficient conditions for strict minimality in multiobjective programming. Numer. Funct. Anal. Optim. 23, 303-322 (2002)33.A. Ben-Tal, Second-order and related extremality conditions in nonlinear programming. J. Optim. Theory Appl. 31, 143-165 (1980)34.S.Y. Wang, Second-order necessary and sufficient conditions in multiobjective programming. Numer. Funct. Anal. Optim. 12, 237-252 (1991)35.B. Aghezzaf, M. Hachami, Second order optimality conditions in multiobjective optimization problems. J. Optim. Theory Appl. 102, 37-50 (1999)













Index



A


Active constraints124, 170




C


Combination
affine24
convex24
convex conic24
linear24


Complementary slackness conditions128


Cone24
bipolar36
Bouligand tangent47
Clarke normal354
Clarke tangent154
contingent47
convex24
critical202, 419
extended critical203
finite27
finitely generated27, 38
isotone370
linearizing112, 125, 170
normal50
of attainable directions51
of critical directions202
of descent directions176
of epi-Lipschitzian directions369
of feasible directions51
of interior directions216
of quasi-interior directions216
of strict descent directions419
pointed22
polar36
polyhedral28
positive polar36
radial51
recession368
Rockafellar hypertangent369


Constraint qualification128
Abadie138, 185
Abadie II187
Arrow-Hurwicz-Uzawa138
Arrow-Hurwicz-Uzawa II187
constant positive linear dependence189
Constant Rank188
Cottle138
Guignard-Gould-Tolle129, 137, 175, 184
Karlin248
Kuhn-Tucker138, 185
linear independence140, 188
Mangasarian-Fromovitz185
Slater140, 187
strict248
strict Mangasarian-Fromovitz191
Zangwill138




D


Directional derivative63
Clarke343
Clarke-Rockafellar373
epi-Lipschitzian373
left-sided319
lower Dini344
lower Dini-Hadamard372
lower Ursescu372
right-sided319
upper Dini344
upper Dini-Hadamard372
upper Ursescu372


Dual problem
Lagrangian256
Mond Weir267
Wolfe260




E


Efficient point385
local389
local strict389
local weak389
strict385
strils local of order 

414
weak385


Efficient solution21
weak21




F


Feasible set10


Function
Clarke invex365
Clarke pseudoconvex363
Clarke quasiconvex364
Clarke regular349
coercive17
concave53
continuously differentiable4
contraction337
convex53
differentiable3
directionally differentiable320
Gâteaux differentiable64
indicator331
invex72
Lagrangian107, 177, 418
Lagrangian dual256
Lipschitz continuous337
locally Lipschitz338
lower semi-continuous14
marginal226
optimal value226
perturbation226
preinvex71
proper convex319
pseudoconvex67
quasiconvex65
semistrictly quasiconvex68
strictly concave53
strictly convex53
strictly differentiable348
sublinear54
twice differentiable3
upper semi-continuous14




G


Geometrical method104




H


Half-spaces31


Hull
affine25
convex conic25
linear25


Hyperplane5
separating32




K


K-subdifferential374


K-subgradient374




L


Lagrange multipliers rule113


Lagrange regular194


Least-squares method94


Linear programming problem
basic solution285
degenerate basic solution285
dual290
feasible basic solution285
primal in canonical form289
primal in standard form290


Local cone approximation368




M


Matrix
Hessian4
Jacobian4


Minimizer
global10
isolated local12
local11
strict global12
strict local12




N


Nonsmooth analysis317




O


Objective function10




P


Point
Clarke stationary355
critical84
Lagrangian saddle244
saddle85
stationary84


Polytope30


Problem
activity analysis277
assignment277
diet277
linear programming275
quadratic programming301
transportation277


Proper efficiency392
Benson394
Borwein394
Geoffrion393
Kuhn-Tucker395




Q


Quadratic form7
definite7
indefinite7
semidefinite7




S


Sensitivity analysis225


Set
convex23
convex hull25
lower level15
of the active constraints124
properly separable32
regular217
separable32
strictly convex23
strongly separable32
upper level61


Shadow prices240


Subdifferential318
Clarke346


Subgradient318




T


Taylor's formula4


Theorem
Caratheodory27
Cottle311
Elster and Thierfelder378
equilibrium297
Fermat84
Fermat rule for Lipschitz functions355
first fundamental on L.P.280
Fritz John127, 172, 404
generalized Weierstrass16
implicit function6
Karush-Kuhn-Tucker130, 175, 404
Kojima235
Kuhn-Tucker-Uzawa247
Minkowski-Weyl40
Moreau-Rockafellar329
saddle point and duality298
second fundamental on L.P.286
strict converse duality262
strict direct duality261
strong duality259
Sylvester criterion8
weak duality258
Weierstrass16


Theorem of the alternative41
Farkas42
Fredholm43
Gale43
Gordan44
Ky Fan43
Motzkin43
Slater45
Tucker45




W


Weighted sum method399








