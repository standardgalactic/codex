








Researching UX: User Research
by James Lang and Emma Howell

Copyright © 2017 SitePoint Pty. Ltd.

Product Manager: Simon Mackie
Series Editor: Joe Leech
English Editor: Katie Monk
Technical Editor: Kate Towsey
Cover Designer: Alex Walker

Notice of Rights
All rights reserved. No part of this book may be reproduced, stored in a retrieval system or transmitted in any form or by any means, without the prior written permission of the publisher, except in the case of brief quotations embodied in critical articles or reviews.
Notice of Liability
The author and publisher have made every effort to ensure the accuracy of the information herein. However, the information contained in this book is sold without warranty, either express or implied. Neither the authors and SitePoint Pty. Ltd., nor its dealers or distributors will be held liable for any damages to be caused either directly or indirectly by the instructions contained in this book, or by the software or hardware products described herein. 
Trademark Notice
Rather than indicating every occurrence of a trademarked name as such, this book uses the names only in an editorial fashion and to the benefit of the trademark owner with no intention of infringement of the trademark. 


Published by SitePoint Pty. Ltd.
48 Cambridge Street Collingwood
				VIC Australia 3066
				Web: www.sitepoint.com
				Email: books@sitepoint.com
ISBN 978-0-9953826-3-3 (print)
ISBN 978-0-9953827-9-4 (ebook)
						Printed and bound in the United States of America



About James Lang
James has worked in research for 20 years, for organizations including Google, British Airways, the BBC, eBay and the Alzheimer's Society. He is currently Head of Research at cxpartners.
About Emma Howell
Emma Howell is a User Experience Consultant at cxpartners. She has been a research specialist for 10 years, beginning her career in academia before moving into UX. Emma loves designing products and services that are intuitive and enjoyable to use.
About SitePoint
SitePoint specializes in publishing fun, practical, and easy-to-understand content for web professionals. Visit http://www.sitepoint.com/ to access our blogs, books, newsletters, articles, and community forums. You'll find a stack of information on JavaScript, PHP, Ruby, mobile development, design, and more.



James: To my mum and dad, Sally and Joseph, for giving me their curiosity, patience and kindness.
Emma: For raising an analytical and inquisitive creature, my fabulous parents Pauline and Leigh. My gyaldem: twerking and tequila makes deadlines feel less painful. Laura-Lea: you've been amazingly encouraging and patient. Thank you.















Preface
Foreword
I was on stage at UX Manchester and I made a flippant comment about how all focus groups were a waste of time when it came to researching the user experience. When questions came at the end of my talk, a hand shot up. "I don't agree with your comment about focus groups. They have their uses. All research methods have their strengths and weaknesses." That hand belonged to James Lang. He came and found me afterwards and we debated the merits of user research methods. At the end of the conversation, I asked if he was looking for a job. 
Emma brings 10 years of formal research experience in psychology, cognition, medicine, biology and, of course, user experience. Emma and James are two of the best researchers I've ever worked with. I've learned so much from working with them on many UX research projects over the years. 
This book represents Emma and James's many years of research experience. Their practical advice on how to run an insightful, successful research project is the key to making your digital products even better. 
Series editor Joe Leech (@mrjoe) Bristol, UK, August 2017.
                PS. I was right about focus groups - see Chapter 2. 
If You Feel Unsure, Then Read On
You're beginning a user research project. You want it to go well. You want it to be interesting, to learn something new and to generate ideas. Most importantly, you want your project to make a difference. This book will show you how to achieve all of that.
This book is about the craft, the technique and the processes involved in running a design research project. Whether you're in discovery or evaluation mode, whether your project is agile or waterfall, research is at the heart of user-centered design. Because it's so central, we believe that research should be an activity that the whole team gets to participate in and feel ownership of.
At the same time, design research can sometimes seem a daunting, confusing world unto itself. With its own codes and jargon, it can feel like the domain of specialists, forbidden to outsiders who haven't been trained in the rules. If you've ever felt out of your depth on a research project, been unsure what to do next, or wondered whether you're "doing it wrong", then this book is for you.
What We'll Cover in this Book
Over the next nine chapters, we'll pass through the stages of a qualitative design research project. The primary focus is on the practicalities: our intention is to share a step-by-step guide so you know what do to at each point... especially if you're stuck! Alongside that, though, we've provided a rationale, not least because being able to understand and justify your approach is pretty useful in itself.
The structure of the book follows the sequence of a research project:

The research cycle
Design
Chapter 1 shows how to scope and kick off your project, involving stakeholders to ensure you're working to the right objectives.
Chapter 2 walks through the process of choosing a methodology, and the different considerations which play a part in your decision.
Setup 
Chapter 3 covers the different methods for recruiting people to take part in your research, and how to ensure you get the right participants.
Chapter 4 outlines the role of a discussion guide (aka session plan, aka script) and shows you how to piece it together part-by part.
Chapter 5 looks at the runup to your research sessions, and the preparation involved with lab-based, remote and contextual studies.
Fieldwork
Chapter 6 shows you how to manage a research session, and how to be successful in the roles of observer, note-taker or moderator.
Chapter 7 focuses on the detail of interviewing, exploring the anatomy of questions and the role of observation.
Analysis
Chapter 8 lays out a system of analysis, describing each of the main phases and showing you which activities to deploy to achieve your specific purpose.
Impact
Chapter 9 shows how to bring the project to a successful conclusion, using deliverables and engagement techniques to maximise the impact of your work.
Unless you're completely new to research, you're probably more familiar with some of these aspects of the process than others. You should be able to dip into the book as required, rather than reading from front to back, with a couple of exceptions:

If you want to know how to run research sessions, it's a good idea to look at Chapters 4, 6 and 7.
If you're interested in how to ensure your projects have maximum impact, the information you need is in both Chapter 1 and Chapter 9.

The Gist of the Book
As we've already mentioned, this book is more interested in the practicalities of research than the theory. That said, if you read on you'll see several ideas surface repeatedly. Let's introduce them:
Research is a team sport.
            We believe research projects are most effective when the whole team's involved, not when one or two specialists are tasked with going away to 'do research' and come back with an answer. Working as a team - sharing the hypothesising, interviewing and analysis - brings the designers, developers, content owners and others much closer to the actual user experience, rather than having it fed back to them via a report or presentation. It's a better, more rewarding experience for everyone, but more importantly it makes the research more likely to have an impact. You may not always be able to get the whole team involved throughout, but we'll share the workarounds you can use to achieve nearly the same result.
When you're making decisions about your project, think about the end point and work backwards.
            Whether it's to generate new ideas, build empathy for users, understand a problem better, or inform decision-making, your project has an end goal. In most cases, this'll be a combination of overt, stated objectives and more obscure aims that you'll have to figure out from talking to stakeholders. Don't lose sight of the end goal, because it should inform your decisions at every point. For example, if your end point is to build empathy with users among disengaged stakeholders, then that will inform your choice of methodology and sample, the types of data you collect, and the approach you use to analyse and report it. It'll also determine the way you involve stakeholders throughout the project. We'll show you why you need to stay aware of those choices and consciously direct your approach with the end goal in mind, rather than just hoping for the best.
Successful research is about driving design decisions through engagement, not delivering documents.  To be most effective, research projects are about enabling the people who make decisions about things to experience the lives of the people who use those things. If you can give stakeholders an in-person connection with their users, you'll enhance and enrich their work, and they'll thank you for it.  You'll also help them make better decisions more easily, and therefore do better work, and they'll love you for that. Good and easy decisions don't often come from reading research reports, often because there's no human experience connected with the recommendations and they're therefore not followed. Also, it's easy to put a report away and ignore it, especially if it doesn't fit that person's agenda. But when a stakeholder has seen users first-hand as they comment on or do something, recommendations are much more likely to be implemented. We'll show you how to get stakeholders engaged, and keep them engaged, using deliverables as the final call to action.
Do as much research as you need to, and then stop.
            You need to be able to justify the time you spend on research: there's no point in large-scale research projects that deliver no outcome. Instead, we'd argue for sequences of bite-sized projects, taking a slightly different focus and methodology each time. Moving in this way, and accruing insight as you go, allows you to find out just what you need and no more, leaving your time and budget free to act on what you've found. Erika Hall calls this 'just enough research', and we think it's a great way of balancing out the risk of ill-informed decisions against the cost of further projects. We'll share some planning tools you can use to structure your project, and decide when enough's enough.
Analysis starts at the beginning.
            As you begin a research project, you'll already have ideas, hunches and preconceptions about the subject you're investigating. Instead of trying to ignore them, you should get them out in the open. Confusingly, research projects have a distinct 'analysis stage', but in practice analysis is something that you do throughout the project, by taking your initial impressions and then challenging and evolving them through talking to and observing users (a process that Roddy Glen calls 'rolling hypotheses'). Ultimately, the purpose of research is to make better decisions. The process of engaging with users is purely to arrive at better informed, more substantiated, more inspired decisions. We'll show you rigorous, practical tools you can use to turn your initial thoughts into findings and recommendations at the end of the project.
Research is about consent.
            User-centered design is based on the belief that by understanding and delivering what users need, you can achieve better outcomes for your organisation. To do this, you need empathy and respect: going beyond a superficial understanding of people as consumers, or users, or customers, and engaging with them deeply as real, rounded people with needs, motivations, emotions and desires. Think of your research as a collaboration between your team, as designers, and the people who use your product or service. If you're conscious of the reasons why they might (or might not) want to take part, the ways that the research experience might affect them, their preconceptions and concerns, then you're not just being a good person, you're being a good designer too. We'll walk you through the steps you should take to engage with participants and their data with respect and care.
Enough theory. It's time to start your project.
Acknowledgments
Many people helped us to write this book. The editorial team at SitePoint, Joe Leech and Simon Mackie, expertly guided the project with a blend of encouragement and critique. Our technical editor, Kate Towsey, offered an inspiring alternative perspective and challenged our missteps.
Particular thanks to the colleagues at cxpartners who read and responded to early drafts: Mark Skinner, James Chudley, Angelique Alexander, Mina Bach and Audun Clark. We were lucky to have input from other experts in the field too: Kristy Blazio at Usability One, Roddy Glen (formerly of Strategic Research Group), Barbara Langar (formerly of eBay, now at Insight Angels), Gemma Newell at the BBC, and David Whittle at Spotify. Finally, the people who laid the foundations: Romin Tafarodi, Alison Lyon and Pete Comley.
Conventions Used
You'll notice that we've used certain typographic and layout styles throughout this book to signify different types of information. Look out for the following items.
Tips, Notes, and Warnings

Hey, You!

Tips provide helpful little pointers.



Ahem, Excuse Me ...

Notes are useful asides that are related—but not critical—to the topic at hand. Think of them as extra tidbits of information.



Make Sure You Always ...

... pay attention to these important points.



Watch Out!

Warnings highlight any gotchas that are likely to trip you up along the way.


Supplementary Materials

https://www.sitepoint.com/community/ are SitePoint's forums, for help on any tricky web problems.
books@sitepoint.com is our email address, should you need to contact us to report a problem, or for any other reason.















Chapter 1: Begin the Project
Starting a research project can feel manic. There's lots to organise: briefs to write, objectives to agree, and stakeholders to bring on board. It's easy to feel like you're being swept away on a sea of madness. But with a bit of organisation, it doesn't have to be overwhelming. If you get the setup right, the rest of the process will be less stressful and more productive. 
In this chapter, we'll show you:

How to start off a project effectively.
What to expect at each stage of the project.
How to ensure your project generates action at the end.

Get Started
To make sure you're making a good start, it's helpful to refer to the checklist below, and tick off the things you need. It's also a good way to structure your activities.

The research cycle: design phase



You need...
How to create it
How to record it...




Research objectives
Kickoff workshop or written brief (overt objectives)
Project canvas



Stakeholder interviews (covert objectives)



Hypotheses
Desk research
Discussion guide



Stakeholder interviews



Timelines and resources
Post-it planning
Project plan



Roles & responsibilities
RASCI




Communication plan


Stakeholder buy-in
Stakeholder interviews
Engagement plan swimlanes within project plan


Risks
Pre-mortem
Risk register



1. Define Your Research
You will probably already know there's a need for research, but at this stage it might be quite vague. It's your job to get clarity about the research objectives, otherwise your work will be unfocused, and less likely to achieve anything useful.
With your colleagues, you need to define your objectives. These fall into two categories:

Business objectives are the end goal of the project. An example business objective: increase conversion rate by 5%.
Research objectives are the learning goals of the project. An example research objective: understand how customers buy shoes for their children.

You should also expect some objectives to be more obvious than others: 'overt objectives' are the ones talked about openly, while 'covert objectives' are kept quiet (but are no less important). For your project to be considered a success, you'll need to take into account both the overt and covert objectives. 
Your objectives are the single most important element in your project. As you proceed, you'll continually return to them: to help choose the right methodology, to shape your questions, to check you're on track, and to inform your analysis.
2. Define Hypotheses
When you define objectives, you're laying out the questions you want to answer. When you define hypotheses, you're making your best initial guess at what those answers will be. The rest of the project - asking users and conducting analysis - is the process of checking, challenging and refining your initial answers until you've reached solid conclusions.
We use two kinds of hypothesis in our research projects:

Formal hypotheses are statements which can be tested against the data to determine if they're supported or not. For example: "Regular shoe-store customers own more pairs of shoes than occasional shoe-store customers." This kind of hypothesis is used in quantitative research, and if you've conducted experiments at university, you'll probably be familiar with it.
Rolling hypotheses are early-stage theories or explanations that evolve throughout the project. Think of them as hunches or assumptions, which you can evolve, add to or reject by observing and talking to users. Rolling hypotheses start off vague, and become more solid as you proceed. This kind of hypothesis is used in qualitative research, but is very similar to the process of learning more about any subject you previously knew little about. 

When you start a project, it's helpful to get all of the team's assumptions (hypotheses) out in the open, so you can incorporate them into your questioning.
3. Timeline & Resources
In most research projects, time is of the essence. Generally, you'll be working towards a deadline, or in a fixed cycle of sprints, and you'll need to shape your approach accordingly. Also, you'll have finite resources to work with.
Defining the right approach in terms of timelines and resources - and ensuring you're able to stick to it - is one of the main skills of running research projects. You may be lucky enough to have a dedicated project manager, but if not, you'll be in charge of putting together the plan, and reviewing progress each day to check you're on track.
4. Engage Stakeholders
If you want your research to have an impact, you'll need to make sure your colleagues are engaged in the process. To do that, you need to be communicating and collaborating throughout the project, not just at the end. The earlier you get started, the more stakeholders will care about your results, and want to own and act on them. Therefore, you need to plan. 
The trick to successful communication is to think of it as an ongoing sequence, rather than one-off messages. Think strategically and plan it as a campaign, running from the beginning of the project and on past the final documentation. We'll show you how to do this later in the chapter.
5. Identify Risks
All projects have risks: things that might go wrong. It's important to face up to these possibilities and plan for them, rather than just hope for the best. Otherwise, you may find you get caught out, and the project runs over time or budget, or threatens to under-deliver.
Risks emerge throughout the project, but nonetheless you should have a pretty clear idea at the beginning what might happen, based on the team's collective past experience. If you deal with these possibilities openly, you can agree on an appropriate response (which might be to take no action at all!). Either way, tackling risks is a decision for the whole team, not one you should have to take on your own.
Tools You Can Use
Now that we've described the building blocks you need to get started, it's time to look at the tools you can use to create them.
Use Desk Research to Generate Hypotheses
Desk research sounds dull, but it's actually a great way to get your head into a subject right at the beginning. If you approach it creatively, you can use many different approaches - see below. 

How to generate hypotheses
Spend some time looking at the site and service that you are working on. Take a look at the top competitors as well. This can often give you insight into problems, directions you may want to head in or even things to avoid. Look on forums, review any analytics you can get hold of and chat to your colleagues for any insights they may have. This can all help set the direction of your research.
Don't feel like you need to take ages over desk research: you can achieve a lot by choosing two or three of the methods above and spending a couple of hours in total exploring them. As you go along, write your hypotheses on Post-It notes. There's no right or wrong choice of method: just go for the ones that are easiest and quickest for you to use.
Hold a Kickoff Workshop
Whatever else happens, you should always hold a kickoff workshop for your research project. This can vary in length. For a sprint, it may only be half an hour; for a large-scale project with a new team, it could be a whole day.
Kickoff workshops follow a standard agenda:

Introductions: If the team don't know each other, it's a good idea to go round the room so everyone can say their name, their role, and their relationship to the project.
Provide background: The main sponsor (ie, normally the most senior person in the room) should provide an introduction covering the reasons why the project needs to happen, the business, and the context. Note that the main sponsor is the starting point for understanding the project, but it's not the only point of view that matters: there will be other stakeholders and other perspectives that need to be taken into account.
Agree objectives: Ask all of the participants in the workshop to write their objectives for the research on Post-It notes. These can then be de-duped and sorted in order of importance. It's likely that your project won't be able to cover all the objectives proposed, so this is a good opportunity for the group to agree on any that are specifically out of scope at this stage. If the same objective is suggested by several people, it's likely to be an important one.
Generate hypotheses: Once again, ask the participants to propose their hypotheses, written on Post-It notes. A good way to do this is to read out each of the research objectives and ask people to provide their hypotheses, then stick the Post-It notes around the relevant objective. Sometimes it can be hard for participants to think in terms of hypotheses. If that's the case, ask them to finish a sentence that starts with 'I reckon...' or 'I believe...'. You can also ask them to say which of their hypotheses are supported by data, by sticking different coloured dots onto the Post-It notes - eg, a black dot for hypotheses that are strongly supported by existing data, an orange dot for those that are somewhat supported by existing data, and a blue dot for those that are pure guesswork at this stage.
Define resources: To complete the project, you'll need to marshal your resources with the help of the rest of the team. Ask specifically about:
Any sources of potential participants, such as mailing lists.
Who will be available to help with the research, as observer or note-taker. You may want to create a RASCI to define roles (see next section).
Any existing data sources or reports. Tip: you can refer back to the black and orange dots in the previous exercise to help nudge people to provide this.
Something to test: a prototype, concept boards or existing product.
Time and budget.


Define roles: You'll need to be clear about who's doing what on the project, to avoid overlap or mistakes. There are two stages to do this:
First, create a RASCI. This is a document which captures the people's different relationships to the project.
R stands for Responsible. This is the person charged with leading the project (probably you).
A stands for Accountable. This is the stakeholder who will ultimately be judged on the project, and has signed off the budget. This is likely to be the head of your department.
S stands for Supporters. These are the other people who'll support you in getting the job done, for example by taking notes. You should have most, if not all of these people in the workshop with you.
C stands for Consulted. These are other stakeholders who will have an important point of view on the project, or who will be affected by its outcomes.
I stands for Informed. This is the broader audience for the research. They're likely to be less engaged than those in the Consulted category.


Next, write all the different jobs that will need to be done on Post-It notes. Create several columns - one for yourself, and others for each of the people in the Supporters category of the RASCI. Allocate the jobs under each of these columns until you're confident that everything is covered. You may find that you add additional supporters as part of this process, if you've forgotten someone.


Define the approach: You'll probably want to define this in your own time (see Chapter 2), but the team may have some initial preferences or expectations for the approach.
Define the sample: Again, you will define this more solidly later (see  Chapter 3), but at this stage it can be useful to hear the team's suggestions about the kinds of people you should be approaching to interview. 
Arrange stakeholder interviews: Now is a good time to define the other stakeholders you should be speaking to, and arranging times to interview them. 
Define communications approach: Agree the format, frequency and communications tools you'll use to catch up and review work.
Pre-mortem: Now you've got a good idea of the project objectives and approach, the team should consider the project risks. We do this using a 'pre-mortem' exercise: ask the team to project their thoughts forward to the end of the project, and assume it hasn't gone well. In this imaginary scenario, what are the elements that went wrong? How could they have been avoided? This is a surprisingly fun activity, and extremely effective at identifying risks.
Personal objectives: Finally, research projects are also a time for you and your team to learn and grow. Is there a new research technique that you want to try? Or a new piece of software that you and your team want to trial? Challenge yourself to include something new in your plans every time you run a research project.

If you've got less time, another way to structure a kickoff workshop is to begin with an empty research canvas document (see below), and fill it in as a team. This works well when you know each other better, or when the project is a continuation of a previous study.
Talk to Your Stakeholders
Stakeholder interviews provide a counterpart to the kickoff workshop. For all of our bigger research projects, we carry out stakeholder interviews. 
Stakeholders are the main people who'll refer to your research to make decisions in the future. They be may responsible for a part of the organisation that your research relates to, or they may have an interest in the results. For example, if you were working on a piece of research for an online shoe retailer, your stakeholders could include the Head of Marketing, Copywriter, User Experience Designer, Lead Developer and Commercial Director. 
Stakeholder interviews serve four key purposes:

They help you define your research objectives and research hypotheses. 
They give you a chance to gain a better understanding of the organisation you're working with, the dynamics of the business, who's who, and the relationships between them. It's your way to minimise the impact of any existing politics on your project!
They're a brilliant way of getting lots of people from many different areas of the business on board with your project. Having them onside can be invaluable and insightful. 
If you're working for a client, often stakeholders will appreciate having someone outside of the organisation to chat to. It can end up being quite cathartic for them to have someone to vent at!

Who should you include? Obviously this will depend on the time available, and the willingness of participants. However, a good guide is the RASCI. If you completed one in your stakeholder workshop, include the people listed under the Accountable and Consulted categories. It's a good idea to include a mix of the most senior people who have a relationship to your project, and those 'on the ground', who will be asked to implement any changes.
It also pays to be mindful that stakeholders (especially senior ones) are often pushed for time, so can be difficult to pin down. You can increase the chances of them agreeing to chat to you if you keep the following in mind:

You will need to convince them that meeting with you and giving up some of their day is worth their while. You can do this by briefly explaining your research and how you believe this will help. Try to explain the value of the project in their terms, rather than yours.
You need to have done your homework and go into the interview with a good understanding of the business, the role of your research and how it can help them.
You should treat the interview like a meeting, so we recommend sending over an agenda. This gives them a good idea of what to expect, and gives them time to prepare their thoughts.
It also pays to show your enthusiasm! 

Create a Research Canvas
A research canvas is a fantastic way to summarise your project on one page. Put this up on the wall of your project area and you'll have a succinct view of your entire project. A research canvas summarises your objectives, approach and other key aspects of your plan in a table that's easy to refer back to throughout the project (see example below).

An example research canvas
Some headings may be more relevant than others, so feel free to play with the format and change the section titles until you find a version that's right for you. 
Having a research canvas will help you to:

Define the objectives of your project.
Make sure you ask all the questions you need at the beginning of the project.
Have something to refer back to if you are considering changes to your approach mid-project.
Help you to onboard new team members.

Your research canvas should be visible. Ideally, it will be printed out and posted in your team's working area, as the start of a research wall or project space (see Chapter 8).
Project Plan
Running a research project involves co-ordinating a lot of resources and people: participants, stakeholders, note-takers, research facilities and recruiters, among others. Without a project plan, it would be chaos. 
A project plan is essentially a timeline, showing what will happen when, and enabling you to make sure you've got enough to complete each activity before your deadlines. Once you've got a project plan, you can specify when you need particular resources in place - for example, when you need recruitment completed by.
All research projects follow the same basic pattern: 

A more detailed look at the research cycle
Within that basic framework, though, there's a lot of variation, depending on your target audience, your methodology, your recruitment method and the scale of your project. It's a good idea to leave a little bit of wriggle room to allow for unexpected overruns.
Make a Plan to Engage People
We've mentioned already that you should plan your research projects for impact, not just to deliver a report. For this to happen, you'll need to get buy-in and engagement from stakeholders. This is part of a deliberate process we call engagement planning.

First, you should be clear about who you need to get buy-in from. If you've created a RASCI, this would be the people in your Accountable and Consulted categories. In some cases, the Informed category is important, too.
Identify what each of these audiences are interested in. Do they have a business need that relates to your work? Does it have the potential to affect one of their KPIs? What are their overt and covert objectives? If you talk in their terms, they're more likely to take an interest and act on your findings. You can do this in your kickoff workshop and stakeholder interviews.
Identify the key messages you'll need each audience to take out of the research. For your main project sponsor, it might be: "I understand how best to spend my budget to increase shoe sales." For the people who'll put the findings into action, it might be: "I understand what information shoe shoppers need in the checkout process."
Identify the moments at which each audience needs to hear about the project. For senior stakeholders, and those who are less engaged, this might be a handful of times in the process: perhaps an interview at the beginning, an update midway through, and a debrief at the end. For others, you might have a weekly catchup session. Bear in mind when you want decisions to be made: sometimes this will be at the end, but if it's a fast-moving project, you will want to feed information through earlier.
Identify the communication methods that will work best for each audience at each stage. Bear in mind how interested, engaged, and motivated each audience is to hear about the details. For some, it may be best to offer a resource they can dip into, like a project blog or pizza session. For others, they may want a short and punchy format like a 10-minute face-to-face update. Others may be happiest to wait for the full version, in a final debrief session. Best of all, though, is to encourage your audience to attend the research sessions. If you can get them to show up for the first two interviews, they may stay around for the rest, too.

We find it easiest to visualise this as an additional set of swimlanes on your project plan. Once you've created your plan, it's a good idea to sense-check it with your colleagues to ensure it works for them, too. As well as ensuring you've got the right approach, this also helps to set expectations and build anticipation.

Engagement planning
If you follow this approach, you'll find you engage your audience and bring them with you on the journey through the project. Ultimately, it'll mean your results are acted on, which is the whole point of doing research!
What to Watch Out For
When you're planning engagement, there are a few pitfalls to watch out for:

Be ruthless. Keep focused on the audiences that matter - ie, the ones you need to act or make decisions. Aim for efficiencies by looking for communication methods that will work for multiple audiences. Don't hold a feedback session that's not required. In particular, avoid the temptation to save everything up for a 'big reveal' at the end. If you can, engage your audience sooner.
Move quickly, if you can. Fast findings (even if they're not perfect) are usually better than polished findings that arrive too late.
If you want to get your audience involved, showing them is better than telling them. Involving them in the process is best of all.
To get maximum impact, you should expect to spend as much time communicating the research as you do conducting it. That sounds like a lot of extra work, but in fact you can be efficient by involving your team in activities like note-taking and analysis. Not only will you achieve greater buy-in, you've reduced the need for extra debrief sessions or documentation.
Make sure you know how and when senior stakeholders want to be kept informed. If you're not careful, you can over-communicate with them, or use the wrong channel, and run the risk of them tuning out. Instead, ask them early on how they'd like to be kept informed: a summary email, three-slide deck or project blog are good methods to suggest.

Tactics for Engagement
To help you make your plan, it's worth thinking about some of the methods you can use to engage your audience. This isn't a complete list - use it as a starting point to add your own ideas to:

Stakeholder interviews (see above)
Project space (see Chapter 8)
Show & tell (see Chapter 9)
Topline findings (see Chapter 9)
Project blog / website (see Chapter 9)

4. Decide How You Will Communicate With Your Team
Encouraging good communication within the team is key to the smooth running of your research project, and happy colleagues.
We use a number of different communication patterns on our projects:

Regular stand up meetings. These could be daily or a couple of times per week, and shouldn't last more than around 15 minutes. 
More in-depth milestone meetings to review documents, make more complex decisions or get signoff from stakeholders. These might last up to an hour, and will be scheduled well in advance as part of the project plan, to ensure everyone can attend. 
Shared documents that the whole team can access. These include the project canvas, project plan, and others we've mentioned already, but also the recruitment brief, discussion guide, analysis plan and deliverables. To make them accessible, we use software such as Google Docs and Dropbox.
Collaboration tools can be incredibly helpful, especially if you're working with a distributed team. We love Trello, Evernote, Slack and Google Hangouts.
For some research projects, you may be building a prototype with your project team. Make sure you pick software with a decent sharing feature so that it's easy for you to share feedback with your colleagues.

When you decide on your approach, it's worth bearing in mind a few factors:

Who are the key people you'll need to contact. What are their communication preferences?
What software are you able to use? For example, your organisation may have rules that prohibit certain products or limit their effectiveness.
It's better to have a flawed tool or meeting setup that's accessible to everyone, than to have multiple different setups for different people. In the latter scenario, confusion reigns. We've experienced projects where the team have attempted to use a mix of Google Hangouts, Skype, Slack, email and conference calls, with the result that messages got lost and key people were excluded from the conversation.

Work Through Risks to the Project
A risk register is a list of the potential pitfalls that might affect your project, and your team's planned response to them. Normally, you'd produce this in two bursts: firstly as a team, and then adding in detail yourself later. 
A risk register has five columns:

The first column describes the risk - eg, "Prototype isn't ready in time for testing."
The second column rates the probability of this problem occurring, normally on a scale of one to five, where one means very unlikely and five means very likely.
The third column rates the impact of the problem if it does occur, again on a scale of one to five where one means minimal impact and five means major impact on the business.
The fourth column is the importance of the risk. You generate this by multiplying the probability and impact columns, to generate a score from 1 to 25.
The fifth column is response. This is what you plan to do to address the risk. You may choose a plan to mitigate it (such as "Assign additional developers to the prototype team"), or ignore it if the importance score is low.

Risk registers work best in a spreadsheet format. Once you've completed your table, it's a good idea to sort it by the fourth column, so the most important risks are at the top.

A risk register
Summary
A good research project takes planning, preparation and a considered approach.

Clearly define your objectives using workshops, briefs, desk research and stakeholder interviews.
Involve your colleagues in generating hypotheses.
Include your stakeholders as soon as possible. Be strategic about engaging them through the project.
Figure out the best ways to keep in touch with your team.
Minimise the chances of things going wrong during your project by running a pre-mortem and discussing what you think could fail.

















Chapter 2: Choose an Approach
Once you've conducted your kickoff session, stakeholder interviews and desk research, you're ready to design your research methodology. 

The research cycle: design phase
Designing a research project is easy, if you've grasped a few core principles. In this chapter, we're going to explain those principles, and show you a useful tool to apply them, so you can work out:

Which research methods to use
How to use different methods together
How many participants to include in your research

In addition to choosing the right approach, there's another big benefit to understanding how to design a research project. When you have to justify the need for research, or when your stakeholders are challenging your findings, you'll be able to argue your case with confidence.
The Core Concepts
This next section is going to get a bit theoretical. Don't worry: we'll show you how to apply it later in the chapter. For now, though, you need the basic building blocks of research design.
In this section, we're going to run through 10 concepts. Some may already be familiar to you, others less so. They are:

What is data?
Qualitative vs. quantitative
Discovery vs. validation
Insight vs. evidence vs. ideas
Validity and representativeness
Scaling your investment
Multi-method approaches
In-the-moment research
Ethics
Research as a team sport.

What is Data?
The research process involves collecting, organising and making sense of data, so it's a good idea to be clear what we mean by the word 'data'. Actually, data is just another word for observations, and observations come in many forms, such as:

Seeing someone behave in a certain way
Or do something we're interested in (such as click on a particular button)
Hearing someone make a particular comment about your product
Noting that 3,186 people have visited your Contact Us page today

But how do you know what's useful data, and what's just irrelevant detail? That's what we'll be covering in the first few chapters, where we'll talk about how to engage the right people, and how to ask the right questions in the right way. 
And how do you know what to do with data when you've got it? We'll be covering that in the final two chapters about analysis and sharing your findings. In particular, we'll be showing you how to transform raw data into usable insight, evidence and ideas. 
Qualitative vs. Quantitative
When it comes to data analysis, the approaches we use can be classified as qualitative or quantitative. 
Qualitative questions are concerned with impressions, explanations and feelings, and they tend to begin with why, how or what. Such as:

"Why don't teenagers use the new skate park?"
"How do novice cooks bake a cake?"
"What's the first thing visitors do when they arrive on the homepage?"

Quantitative questions are concerned with numbers. For example:

"How many people visited the skate park today?"
"How long has the cake been in the oven for?
"How often do you visit the website?"

Because they answer different questions, and use data in different ways, we also think of research methods as being qualitative or quantitative. Surveys and analytics are in the quantitative camp, while interviews of all sorts are qualitative. In general, you'll be leaning on qualitative research methods more, so that will be the focus of this book.
Discovery vs. Validation
The kind of research will depend on where you are in your product or project lifecycle.
If you're right at the beginning (in the 'discovery' phase), you'll be needing to answer fundamental questions, such as:

Who are our potential users?
Do they have a problem we could be addressing?
How are they currently solving that problem?
How can we improve the way they do things?

If you're at the validation stage, you have a solution in mind and you need to test it. This might involve:

Choosing between several competing options
Checking the implementation of your solution matches the design
Checking with users that your solution actually solves the problem it's supposed to.

What this all means is that your research methods will differ, depending on whether you're at the discovery stage or the validation stage. If it's the former, you'll be wanting to conduct more in-depth, multi-method research with a larger sample, using a mix of both qualitative and quantitative methodologies. If it's the latter, you'll be using multiple quick rounds of research with a small sample each time.
At the risk of confusing matters, it's worth mentioning that discovery continues to happen during validation - you're always learning about your users and how they solve their problems, so it's important to remain open to this, and adapt earlier learnings to accommodate new knowledge.
Insight, Evidence and Ideas
Research is pointless unless it's actually used. In some cases, the purpose of research is purely to provide direction to your team; the output of this kind of project is insight. Perhaps you want to understand users' needs in the discovery phase of your project. If so, you need insight into their current behaviour and preferences, which you'll refer to as you design a solution.
Often, though, you need research to persuade other people, not just enlighten your immediate team. This can be where you need to make a business case, where your approach faces opposition from skeptical stakeholders, or where you need to provide justification for the choices you've made. When you need to persuade other people, what you need is evidence. 
And sometimes, your main objective is to generate new ideas.  Where that's the case, rigorous research is still the best foundation, but you'll want to adjust things slightly to maximise the creativity of your outputs.
Research is great at producing insight, evidence and ideas. But... methodologies that prioritise one are often weaker on the others, and vice versa. It's much easier if you plan in advance what you'll need to collect, and how, rather than leaving it till the end of the project. The takeout: you should think about the balance of insight, evidence and ideas you'll need from your project, and plan accordingly.
When it comes to planning your approach, bear in mind your analysis process later on. If you give it thought at this stage, you'll ensure you're collecting the right data in the right way. We talk about this more in Chapter 8.
Validity
Validity is another way of saying, "Could I make trustworthy decisions based on these results?" If your research isn't valid, you might as well not bother. And at the same time, validity is relative. What this means is that every research project is a tradeoff between being as valid as possible, and being realistic about what's achievable within your timeframe and budget. Designing a research project often comes down to a judgement call between these two considerations.
Let's look at an example. You want to understand how Wall Street traders use technology to inform their decision-making. If you were prioritising validity, you might aspire to recruit a sample of several hundred, and use a mix of interviewing and observation to follow their behaviour week by week over several months. That would be extremely valid, but it would also be totally unrealistic:

Wall Street traders will be rich and busy. They're unlikely to want to take part in your research.
A sample of several hundred is huge. You're unlikely to be able to manage it and process the mountain of data it would generate.
A duration of several months is ambitious. You would struggle to keep your participants engaged over such a long period.
Even if the above weren't issues, the effort and cost involved would be huge.

Undaunted, you might choose to balance validity and achievability in a different way, by using a smaller number of interviews, over a shorter duration, and appealing to traders' sense of curiosity rather than offering money as an incentive for taking part. It's more achievable, but you've sacrificed some validity in the process.
Validity can take several forms. When you design a research project, ask yourself whether your approach is:

Representative: Is your sample a cross-section of the group you're interested in? Watch out for the way you recruit and incentivize participants as a source of bias.
Realistic: If you're asking people to complete a task, is it a fair reflection of what they'd do normally? For example, if you're getting them to assess a smartphone prototype, don't ask them to try it on a laptop.
Knowable: Sometimes people don't know why they do things. If that's the case, it's not valid to ask them! For example, users may not know why they tend to prefer puzzle games to racing games, but they will probably still take a guess.
Memorable: Small details are hard to remember. If you're asking your participants to recall something, like how many times they've looked at their email in the past month, they'll be unlikely to remember, and therefore your question isn't valid: you need a different approach, such as one based on analytics. If you were to ask them how many times they've been to a funeral in the past month, you can put more trust in their answer.
In the moment: If your question isn't knowable or memorable, it's still possible to tackle it 'in the moment'. We'll say more about this below.

Takeout: You want your research approach to be as valid as possible (ie, representative and realistic, as well as focused on questions that are knowable and memorable) within the constraints of achievability. Normally, achievability is a matter of time and budget, which leads us to...
Scaling Your Investment
Imagine you were considering changing a paragraph of text on your website. In theory, you could conduct a six-month contextual research project at vast expense, but it probably wouldn't be worth it. The scale of investment wouldn't be justified by the value of the change.
On the other hand, you might have been tasked with launching a game-changing new product on which the future of your organisation depended. You could go and ask two people in the street for their opinion, but that would be a crazy way to inform such a major decision. In this case, the scale of the risk and opportunity justifies a bigger research project.
So when you look at your research project, ask yourself: what's the business value of the decisions made with this research? What's the potential upside? What's the potential risk? Then scale your research project accordingly. Incidentally, it's also good practice to refer back to the business impact as a project KPI. You'll find it much easier to justify the value of your research later on if you can show how it's made a difference to the business numbers your colleagues care about, such as revenue, conversion rate or Net Promoter Score.
Multi-Method Approaches
You'll sometimes hear people talking about qualitative and quantitative methods as if they're in opposition. Not so: they're friends. And your research projects will always be better if you can combine both, because they counteract each other's blind spots.
In fact, all research methods have blind spots. Although you've got to make a judgement call about which method to use in any given situation, you should always be aware of its limitations. But the best way to overcome these limitations is to team it up with another approach, so you can have the best of both worlds. Kristy Blazo from U1 Group describes the cycle of qualitative and quantitative stages as a spiral. Each stage builds on the last as you work round it, until you get to the point where the benefits of increased certainty are outweighed by the costs of further research.

The spiral of qualitative and quantitative stages
In-The-Moment Research
Earlier, we talked about research needing to be knowable and memorable in order to be valid. Actually, that's not always the case. If you can be present when the event you're interested in is actually happening, you don't need to rely on their patchy memory and interpretation to figure out what's going on.
Imagine you're interested in the experience of sports fans at a game. You could interview them afterwards, but it would be more insightful to be there at the event. That way, you could look at the features you're interested in, and compare your observations to visitors' own comments. Rather than asking them to recall the state of the toilets and the quality of the catering, you could observe yourself and interview people there and then.
In-the-moment research, then, gives a more realistic view of events than asking people afterwards. The main methods for in-the-moment research are contextual interviewing and observation, diary studies and analytics, which we'll talk more about later in this chapter.

In-the-moment research
Takeout: If you're interested in events and behaviour that people aren't likely to recall accurately afterwards, you should consider in-the-moment methods, instead of approaches that involve asking them about their experiences weeks or months later, such as depth interviews and surveys.
Taking Care
Research has the power to do harm. 

By revealing participants' identities, you could expose them to consequences in their work or community. Because of this, we hide people's identities as default.
Depending on what you're researching or testing, you risk upsetting people, particularly if they're young or vulnerable. Because of this, we take care to set up interviews in as unthreatening a way as possible, and ensure participants know they can leave at any point.
For researchers themselves, there are risks. Visiting participants in their home requires care. Working in a state of deep empathy, sometimes on distressing subjects, can be emotionally hard to deal with, and researchers can and do get burned out as a result. Because of this, we take care with physical safety, and make sure we're managing the emotional burden together.

Takeout: When you design your research project, consider the impact it may have on both participants and the project team. If you're working with adults on an shoe retail website, then this isn't something you need to worry about too much. But if you're working with vulnerable teenagers to create an app about domestic violence, then it's a different story.
Research as a Team Sport
Research is most effective when the whole team's involved. Consider the difference: a project where a researcher takes a brief, goes away for a few weeks, then comes back with a report, versus a project where the whole team decides on the approach together, take turns interviewing and observing all the interviews, and analyse collectively. In the latter, you're going to have better understanding, greater buy-in, and quicker, more effective results. Research isn't just about generating insight, evidence or ideas: it's also about building consensus among a multidisciplinary group who are about to tackle a problem together. The UK's Government Digital Service calls this 'research as a team sport', and that's the way we think it should be played, too. 
We talk about how to work as a team in Chapter 2, and how to engage and activate the research with your wider group of stakeholders in Chapter 9.
Research Methods
As you can see, there's a lot to consider when you design a research project. Don't panic though! In this section, we'll show you how to bring this information together to choose the right approach. Now that you've been introduced to the core concepts of research, it's time to walk through the main methods.
There are a great many research methods out there. The good news is you only need a couple of them to be able to do effective research. What's more, the rest are mainly just variations on a theme. So if you want to branch out later on, you'll find that they're easy to pick up.
Depth Interviews

How it works. Asking questions in a relatively unstructured conversation. Normally one-to-one.
Type of data. Qualitative.
Discovery, validation or post-launch? Discovery.
Insight vs. evidence vs. ideas Mainly insight, but also evidence and ideas.
Investment Medium.
In-the-moment? No.

User Testing

How it works. Observing users while they complete a series of tasks with the product being tested. Also includes elements of qualitative interviewing.
Type of data. Qualitative, although task data can sometimes be quantitative.
Discovery, validation or post-launch? Validation.
Insight vs. evidence vs. ideas Insight and evidence.
Investment Medium.
In-the-moment? Yes, although the moment is artificial

Guerrilla Interviews

How it works. Stopping people in a public place to conduct short (5-15 minute) interviews or tests.
Type of data. Qualitative.
Discovery, validation or post-launch? Discovery and validation.
Insight vs. evidence vs. ideas Insight and evidence.
Investment Low.
In-the-moment? No.

Contextual Research

How it works. A mix of observing behaviour in context and conducting short spontaneous interviews.
Type of data. Qualitative.
Discovery, validation or post-launch? Discovery.
Insight vs. evidence vs. ideas Mainly insight, but also evidence and ideas.
Investment High.
In-the-moment? Yes

Web Analytics

How it works. Exploring, monitoring and testing hypotheses using a tool such as Google Analytics.
Type of data. Quantitative.
Discovery, validation or post-launch? Discovery, and also monitoring post-launch.
Insight vs. evidence vs. ideas Insight and evidence.
Investment Low.
In-the-moment? Yes.

Co-design

How it works. Bringing together a group of stakeholders and users to work on creative group exercises, to both define a problem and explore solutions.
Type of data. Qualitative.
Discovery, validation or post-launch? Discovery.
Insight vs. evidence vs. ideas Ideas. While co-design does provide some insight, it should always be checked with another methodology.
Investment Medium-high.
In-the-moment? No

Card Sorting

How it works. Types of content are written on cards, which are then sorted into groupings based on their conceptual similarity. Can be done online or in-person
Type of data. Both qualitative and quantitative.
Discovery, validation or post-launch? Discovery.
Insight vs. evidence vs. ideas Insight.
Investment Medium.
In-the-moment? No

Tree Testing

How it works. Users are asked to find particular items of content within a tree structure, eg, "Which aisle are the bread rolls in?" Mainly done online but sometimes in-person.
Type of data. Usually quantitative, although can be used for qualitative research too.
Discovery, validation or post-launch? Validation.
Insight vs. evidence vs. ideas Mainly evidence, with some insight.
Investment Medium.
In-the-moment? No

Surveys

How it works. Large numbers of users are asked to fill in a structured set of questions, usually online.
Type of data. Quantitative, although some qualitative data may also be gathered
Discovery, validation or post-launch? Discovery and post-launch.
Insight vs. evidence vs. ideas Insight and evidence.
Investment Medium.
In-the-moment? Yes, if the survey is an intercept (e.g. website popup). Otherwise no.

A/B testing

How it works. The behaviour of test and control groups are compared on a live product, to see which scores best against a specific metric.
Type of data. Quantitative.
Discovery, validation or post-launch? Post-launch.
Insight vs. evidence vs. ideas Insight and evidence.
Investment Low.
In-the-moment? Yes.

Eyetracking

How it works. Like a user test, but participants' eye movements are monitored to see where their gaze is moving across a web page, picture or room.
Type of data. Qualitative, although some quantitative data may also be gathered.
Discovery, validation or post-launch? Validation.
Insight vs. evidence vs. ideas Mainly evidence, with some insight.
Investment Medium-high.
In-the-moment? Yes.

Diary Studies

How it works. Participants keep a record of their behaviour, thoughts or feelings over a period of time, typically a few days to a couple of weeks
Type of data. Qualitative, although some quantitative data may also be gathered.
Discovery, validation or post-launch? Discovery.
Insight vs. evidence vs. ideas Mainly evidence, with some insight.
Investment High.
In-the-moment? Yes.

Focus Groups

How it works. A group of customers are gathered to answer questions about a particular subject. Similar to co-design, but with more emphasis on talking rather than activities.
Type of data. Qualitative, although some quantitative data may also be gathered.
Discovery, validation or post-launch? Discovery.
Insight vs. evidence vs. ideas Ideas. While focus groups do provide some insight, it should always be checked with another methodology.
Investment Medium.
In-the-moment? No.

Necessary Skills
When you're starting out in user research, the two most important skill sets for you to develop are:

One-to-one qualitative research. We'll spend most of the rest of this book taking you through this. Once you've got the hang of this core skill, you'll find you can apply it in a number of variants: depth interviews, user testing, guerrilla research and contextual research.
Analytics. This is covered in Luke Hay's recent book (https://www.sitepoint.com/premium/books/researching-ux-analytics), so we won't say much more about it here.

Once you've picked up these two approaches, you may be curious about others. We're not going to go into each of these in detail, but it's useful to know what else is in the toolkit. After one-to-one interviewing and analytics, we think the next two methodologies to learn are:

Co-design
Card sorting

And after that:

A/B testing
Surveys
Tree testing
Eyetracking
Diary studies

There are plenty more (especially if you include all the remote testing tools out there), but by now we're getting pretty niche. The important thing to remember is that most design questions are answerable with one-to-one qualitative research or analytics. So to get started, that's all you need in your toolkit.
How to Choose Research Methods
Choosing research methods can seem complicated, but actually it's pretty simple if you refer to the rules we talked about earlier in the chapter. To make it easier, we've provided the table above. So when you're thinking about your approach, ask yourself these questions:

What stage of the project are we at? Discovery or validation?
How important is the question I'm trying to answer? What's the appropriate scale of investment?
What mix of insight, evidence and ideas do I need? Do I need to convince anyone else (in which case evidence is important), or is it just for the information of me and my immediate colleagues (in which case focus on insight)? Or do I need to focus on coming up with some fresh ideas?
Do I need qualitative answers (ie, to understand things from a user's perspective), or do I need quantitative answers (ie, an idea of how many, how often or how much)? Or both?
Is the behaviour I'm interested in something that people can remember accurately? If not, I may need an in-the-moment methods.

Once you've got answers to those questions, you're ready to choose your methods. If the answer to any of the questions above is "it depends" or "both", then you may need to use a multi-method approach.
How Many People?
We're often asked, "How many people should I include in my research?" Here are three simple rules of thumb to help you size your a sample:

Firstly, how confident do you need to be in the answer? The more important the outcome of the research, the bigger the sample. 
Secondly, how many different sub-groups do you have? Often there are a couple - say, 'customers' and 'non-customers'. For each sub-group, include at least three people, so in this case our sample size would be six. 
Finally, what stage of the project are you at? If it's discovery research, you'll want a larger sample. 20 people is ideal - not too big to manage, but enough that you're getting a real cross-section of experiences. 

Using these rules, the numbers will look something like this:

Discovery: 5-20 people in a single round
Validation: 5-12 people per round, in multiple rounds
A least three people from each sub-group in every round of testing.

Even the smallest qualitative study should include five people, otherwise you're running the risk of your data misleading you.
Quantitative research follows different rules, but here you should be thinking in the hundreds rather than single figures. 300-500 is plenty for most basic quantitative research, although more advanced techniques require a couple of thousand participants. Just like qualitative research, you need to ensure you have enough people from each sub-group, but this time we tend to use a minimum of 100 people per audience, rather than three.
Summary
Like any kind of design, research design is about understanding the problem before you apply a solution. 

Ask yourself the questions we showed you in the 'How to Choose a Research Methodology' section.
Look up the most suitable option (or options) in the table of methods.
Work out your sample size using the rules above.
And if in doubt, remember that in the majority of cases, the most flexible, all-round-useful approach is one-to-one qualitative interviewing.

















Chapter 3: Finding Participants
Once you've started your research project, planned the logistics of how you will run your fieldwork, and decided on your approach to your analysis and outputs, you need to find your participants: the people who you'll be interviewing, observing, or asking to try your product. 
The process of finding participants is called 'recruitment', and it's the number one cause of headaches in research projects! You can encounter problems at several stages of the recruitment process - during set-up, while recruiting, and even on the day. Participants can be difficult to find, and even harder to convince to give you some of their time. Because of this, it can be tempting to cut corners, but if your recruitment is flawed, then everything else that follows in your research project will be flawed, too.
You should start planning your recruitment during the kickoff phase of the research cycle (see Chapter 1). From the activities you do here, such as stakeholder interviews and your desk research, you will have started to form a good picture of who you need to talk to. 

The research cycle: setup
Who To Recruit
Begin by defining your sample: the small group of people who'll be giving you insights into your audience's needs and behaviour. We talked about the concept of a sample in Chapter 2. Now that we're getting into the practicalities, you need to be aware that your choice of sample design has to take into account both validity and achievability. 
Validity is about ensuring that the people in your research are a good reflection of what your users or customers actually do in real life. When we do research, we're engaging with a small group of people: the sample. We do this in order to draw conclusions about a much larger group: the 'population'. For example, we might talk to 10 Shoestore customers in order to draw conclusions about the needs of all Shoestore customers. This principle only works if your sample is truly representative of the population. If not, your conclusions won't be valid.
Achievability is how realistic it is that you can find and recruit participants who are the best fit for your research. You will have to consider how likely it is that you can contact them, and how willing they will be to take part. Also, will the incentive that you are offering be appealing enough to them? 
In practice, you'll usually have to strike a balance between the two. Say, for example, you wanted to understand astronauts' use of social media when in space. 

You would probably struggle to find people who meet the criteria. It would be difficult to achieve, and you may have to slightly relax the definition - for example, by including trainee astronauts, rather than solely those who have been in space. 
On the other hand, you wouldn't just want to include your friends and family, because their feedback would be of little value to the question: it wouldn't be valid.

You need to be fussy about who you include, without being a perfectionist.
Defining Your Sample
In the kickoff workshop, you'll have done some initial talking about who to include, but your ideas will probably need a bit more work before you're ready to use them for recruitment. Also, it's beneficial to have time to do some desk research and stakeholder interviews, and to reflect on the practicalities of recruitment (ie, the achievability aspect) before you commit. 
To define the sample, we find it helpful to run a prioritization exercise with the project team and stakeholders:

Take a piece of flipchart paper or a whiteboard, and divide it into four columns. Title the first column 'Primary Variables', the middle column 'Secondary Variables', and the final column 'Nice-to-Have'.
Now, ask the team to propose variables, and add them to Post-It notes. Examples might be things like 'Device ownership', 'Recent shoe-buying behaviour', 'Customer/non-customer', or 'Age'. You're going to sort these into columns in a minute, but at this stage just put them into an unsorted grouping on the wall.
Now, facilitate the group as they allocate the Post-It notes to the three columns you've created. The rules are: no more than two Post-Its in the Primary column, and no more than seven in the Secondary column. The rest go either into the Nice-to-Have column, or the group agrees to discard them totally.
Once you've prioritised your variables, you'll need to define them in a bit more detail. For example, what do you mean by a 'customer'? Someone who's ever shopped in Shoestore? Someone who's shopped there in the past six months? Someone who makes an active decision to shop there? Someone who shops on the website, rather than in-store?
In many cases, you'll also need to define values. If you've decided that age is important, you'll need to define age bands.


Sample planning session
Once you've done this, you're ready to define your sample. We do this in a document called a 'recruitment brief'.
Creating a Recruitment Brief
A recruitment brief is a document specifying the details you need to complete recruitment successfully. It contains:

 The sample definition. Here, you'll list the variables, definitions and values you created in the exercise above as recruitment criteria.
The logistics. Dates, times and locations of research sessions.
Details of the incentive payment for participants.
If you're planning to outsource the recruitment, then some background on the project is also helpful. Offering insight into why you're asking for the type of people you're looking for can give more of a steer, if a potential participant doesn't neatly fit into any of your groups. 

However, you're planning to tackle your recruitment, writing a brief is a good idea. If you're taking a DIY approach, it's a helpful document for you to refer back to when you're considering participants for your research, especially if there are several of you working on it. If you're outsourcing the recruitment to a supplier, it's even more important. You won't always be there to explain anything that is slightly ambiguous or wrong, so you have to be as clear as possible.
You can see an example recruitment brief below:

Example recruitment brief
Defining Criteria
Earlier, we mentioned that it's a good idea to have no more than two primary variables. Here's why: you want these variables to work as a quota matrix (to 'interlock', in the jargon). If you have more than two variables in your matrix, it starts to get complicated.

Example primary variables
Note that we've specified how many participants to recruit within each cell, and the total for each row and column. It can sometimes be helpful to make this a little more flexible, eg, '1-3 participants' rather than '2 participants'.
Once you've dealt with your primary variables, you'll need to specify your other criteria. You can do this in several ways:

Screening criteria are used to exclude people who wouldn't be suitable. For example, you should avoid anyone who works in design, as they wouldn't be representative of 'normal' customers. 
Quotas are used to produce a good mix of participants, or to ensure that you don't get too many or too few of one kind. For example, you might want to include quotas on device ownership, or require that at least two of your participants already have accounts with Shoestore.
Information capture should be used sparingly. You definitely need contact details, and it may be helpful to know a little bit more about your participants (for example, their occupation) to get the conversation started. Other than that, save your questions for the session!

 Here are some tips to help you get it right:

Limit the number of expert users of your product/service. It is important to talk to expert users as well as novices, but you also want to make sure you have a good spread.
Consider the level of web experience your participants have, and how important this is to your research.
Screen out people that have done too much research, especially in the last six months.
Ask yourself whether you should be including people with specific accessibility requirements.

Getting The Right People
Once you've decided who you want to include in the research, and defined it in a recruitment brief, you'll need a way to ensure that you're actually getting those people. There are two ways to do this.

Evaluating against the recruitment brief: Once you've identified a potential participant, you just size them up against the criteria in the recruitment brief, based on what you know about them or an informal conversation. This is the rough-and-ready method, and is most commonly used in DIY recruitment (see later in this chapter).
Using a screener: Once a potential participant has been identified, they're asked a series of questions that evaluates them against the criteria in the recruitment brief, and allocates them to a quota. This is the more robust, credible approach, as used by recruitment agencies.

There are pros and cons to both approaches. Evaluating against the recruitment brief can be inaccurate, risking misleading results and undermining the credibility of your project. On the other hand, a screener takes additional time to create and apply.
There are some workarounds. If you hire a recruitment agency, they will often write the screener on your behalf. If you're conducting guerrilla research, the screener will be very short. We'll say more about both of these scenarios later in the chapter.
Creating a Screener
A screener is a set of questions that are asked to potential participants, based on the sample criteria you defined in your recruitment brief. These questions are designed to figure out how suitable participants are for your project. 
You can see an example screener here, showing the key questions you would want to ask to recruit for a project about outdoor gear. It establishes what activities the potential participants do without leading them to give certain answers. The other questions are written to probe more into their experiences and habits when buying outdoor equipment, without being leading. The final question is written to catch out anyone that is trying to trick their way onto the research.

Example screener
Screener questions contain several elements:

A question number.
The question itself - This should be phrased as it would be read, even though in practice you should expect a little flexibility in the way a recruiter reads out the text you've written.
Instructions to the recruiter. These won't be read out, but give guidance on how to ask the question and how to classify the response. Common instructions include 'Read out all options', 'Don't read out options', 'Tick one', 'Tick all that apply'.
A response area: normally multiple choice options, or an empty box for writing in. For each, there should be an instruction on what to do if it's ticked, eg, 'Thank and close' (ie, reject the candidate and end the screener), 'Recruit to quota', or just 'Continue'.

As you can see, screeners have a certain amount of jargon attached to them, but you shouldn't worry about this. If you're doing your own recruitment, you just need to make it clear to yourself, while if you're using a recruiter, they will be able to interpret your instructions once you've talked them through it.
Some tips for creating a good screener:

Use precise language. For example, rather than asking ,"How many times have you been to the cinema recently?", a better question would be: 'How many times have you been to the cinema in the past 30 days?"
Try to make your questions as factual as possible, so participants aren't tempted to exaggerate or misrepresent their behaviour. For example, if you want to know how frequently someone exercises, don't ask them, "How many times do you exercise a week?" People will tend to exaggerate because they don't want to look bad! A better question would be: "Which of the following have you done in the past week: running, cycling, gym, cinema, reading, etc."
Try to make your questions easy to answer. In particular, it can be hard to remember events that took place a long time ago. You can prompt with options, as in the example above, but make sure you disguise the answer you're interested in among other choices.
Make sure your questions are essential to selecting the best participants. The more questions you add, the more time consuming it is for you and the people you are screening. 
The ideal order to sequence your questions is to cover screening criteria first, then primary quotas, then secondary quotas, and finally information capture for contact details.
In most cases, it's a good idea to conceal the purpose of the research and the organisation you're working for. The participant will probably guess to some extent, based on the questions you're asking, but try to keep the details hidden. Otherwise, they may be tempted to do some prior reading up before attending the research session.
Finally, try to focus on and categorise people based on behaviour if you can. If not, ask about attitudes. Demographics are least useful of all.

It's also important that you give potential participants some briefing information about the session during the screening process. For example:

Telling them they'll be asked to use a website or app.
Reminding them to bring their glasses, if they need to.
Asking them to bring a form of photo identification.
Confirming the incentive and how it will be paid.
Making sure they've got a contact number in case of any problems finding the venue or last-minute cancellations.
            Giving this information ensures that participants are making an informed decision about whether to participate, and there are no nasty surprises on the day.


Look Out for Professional Research Participants

If you are screening people yourself, keep in mind that there are some people who will try and say whatever they think they need to say to get a place on your research. Incentives can be very alluring! To avoid this, include a question designed to catch out those individuals that are not being entirely truthful.
Let's take our example of a project for an outdoor equipment company. In the brief, we have asked for all of our participants to have visited of at least two of the big brands. One of your screener questions could be:
Out of the following UK brands, which have you visited during the past six months?

Go Outdoors
Snow + Rock
Ellis Brigham
Hiking Gear R Us

Hiking Gear R Us are our invented brand, so you can be sure that anyone who picks this screener should not be included in your fieldwork.


Different Kinds of Screeners
Screeners vary in length and complexity. A typical screener for a depth interview or user test is around 10 - 30 questions long. This allows you to capture one or two primary variables, up to 7 secondary variables, plus capture contact details. Any longer than this, and you'll find that candidates lose interest.
If you're conducting guerrilla research, your time is extremely limited. You'll want to get screening over with as quickly as possible, which means five questions in total is plenty. Incidentally, that's about as much as you can fit onto a single side of paper on a clipboard, so there are practical reasons for keeping it short, too.
Finally, you may choose to run your screener as an online survey, and have candidates complete it themselves rather than talk them through it. If you take this approach, it's important to:

Put even more thought into the phrasing of your questions.
Keep it short - no more than two or three minutes.
Pilot test your questionnaire with at least three people before you launch it.
            On the plus side, this is a great way to save time, especially if you're sourcing people online from websites like Gumtree or Facebook.

Methods of Accessing People
Let's talk more about locating people for your fieldwork.
            There are four main methods of recruitment:

Recruitment agencies
Guerrilla
DIY 
Gatekeepers

1. Recruitment Agencies
Recruitment agencies are almost always the best option for recruitment. Professional recruiters will find you high-quality participants, and will be able to give you advice and guidance along the way. 
A recruitment agency will normally charge a per-person fee for each participant they find and book in for you. This cost will vary depending on the recruit, and the recruitment fee will increase the harder your recruitment criteria are. If you're looking for a very specific and niche audience, the fee will increase. This can seem like a big cost up front but it's actually an incredibly cost-efficient approach, compared with finding people yourself.
Usually, recruiters like to have at least two weeks' notice before you are doing your interviews, to give them enough time to find the people you need. If you are looking for a particularly niche audience, you may need to allow even more time.
Appointing a Recruitment Agency
Developing a good relationship with a decent recruitment agency is incredibly valuable and will make your life much easier when it comes to research. But it takes time, and it may take some trial and error. You will want to consider the area of expertise the recruiter has and how relevant that is to your audience. You will also want to check that they are insured and reliable. 
There are a range of other less tangible qualities that we have found are important in the recruitment agencies we work with:

Good communication We've found that the highest-quality participants come from recruiters who keep in touch, and openly communicate while they are finding people for you. They may allow you to double-check the details of potential participants before confirming and booking them in. This helps prevent any misinterpretation of the recruitment brief or a mis-recruit. This works both ways - if you have any problems and changes come up midway through the project that will impact recruitment, be sure to let your recruiter know as soon as possible.
Honest It's important that your recruiter is honest with you, and that you can be honest with them. Having difficult conversations early on and throughout the recruitment can be tough but is also important, especially on hard recruits. If they are struggling to find who you need, you want to know that they will tell you as soon as possible. That gives you time to figure out a solution well in advance of testing. If you're asking for an impossible recruit, you want a recruitment agency who aren't afraid to tell you that you're being unrealistic. You also need to feel that you are able to give them open and honest feedback. If the people they are suggesting to recruit are not quite right, you need to be able to have these conversations to avoid poor quality participants.
Transparent A good recruiter will be open with you about their methods and processes. They will explain how and where they will be advertising and looking for participants. They will share documents early and often throughout the recruitment process. This is important because it gives you insight into how the recruit is going and how they are working. It's also useful for when other people in your project team ask you how recruitment is going. 
Have a range of recruitment methods Good recruiters will have a decent tool kit and lots of ideas about how they will try and recruit the people you need. They may have their usual methods, such as a database, but they will have ideas about what to do if the recruit gets tricky or if you are after a niche group of people.
 Low no-show rate You need to know how a recruiter will handle people not turning up to your sessions. The first thing to know is what their no-show rate is, and you want that to be low. There will be times when people just don't show up and there is nothing anyone can do about that. Yet in these instances, you need to know how the recruiter will deal with this. They may offer you a refund for that participant. They may offer to re-recruit for that slot at no extra cost. One of the key advantages of using a recruitment agency is that it is not your responsibility to find people for your test slots. So find an agency that's reliable and can take responsibility for doing the recruitment. And importantly, that the participants they find for you are of high quality.

2. Guerilla Recruitment
Guerrilla testing is research that you do instantly with people you find in cafes, shops, bus stations or wherever is appropriate for the thing you are testing. On these research projects, the research you are doing will need to be quick, immediate and cheap. Where that's the case, your recruitment will be quick too, because it's happening on the spot.
We've already mentioned that the recruitment brief and screener you use for guerrilla recruitment will be short, compared with the version you use for pre-arranged interviews. You'll also need to think about where to try and find participants, and how to approach them.
Finding Participants for Guerrilla Testing
You then need to think about where you will find these people. To find people to give feedback on our health app, a good place may be outside a gym. Targeting a health or sports store could also be a good tactic. Make a list of all the places you could potentially go, then plan your route. Keep in mind that you should also ask permission of the owner or manager if you're testing in spaces such as libraries and cafes.
When you are recruiting in this way, it's really important to be efficient with your time. If you have a chosen a location and not successfully found someone to talk to within 10-15 minutes, move on. The places you've chosen to target should be close together so you can move between them quickly.
It can't be sugar-coated. Guerrilla recruiting can be really hard work, and a little soul-destroying when people won't stop to talk to you. It can also be tricky to switch from recruitment mode to interview mode. You can minimise the effect of this and save some energy by working in pairs and swapping roles half way through the day.
Top tips:

Consider the time of day. If you start early in the morning or late in the evening, people are likely to be in a rush to get to work or to get home. In the middle of the day, you may not get enough people or they may be the wrong kind of people.
Locations that are good in the morning may not be so good later in the day. One way of checking this is searching for the location (of a cafe you are thinking about going to, for example) on Google. In the summary box about the business you'll see an indication of the busiest times of day.
Because of the above two points, try and do your testing during different hours on different days.
Go to places where people are likely to be having a break or taking some time out. 
People standing outside waiting for trains and buses are easy to approach and are more likely to have a little spare time to help you out. 

3. DIY Recruitment
Doing recruitment yourself can be a poor use of resource, and will almost always cost you more than using a recruiter, once you've taken your own time into account. It can be really arduous, so we wouldn't recommend doing it unless really necessary. Yet every now and then, it may happen. 
Recruiting this way is really labour intensive and unpredictable. People will be unavailable to talk when you try and contact them, contact details could be out of date, they may be difficult to get hold of and it may take several attempts to talk to each person. Then there is no guarantee that they are quite right to take part, or even willing.
It isn't all negative though. Recruiting in this way is a good way to build relationships and can be the only way to contact very niche participants.
As with other kinds of recruitment, you'll need to create a recruitment brief, and it's a good idea to have a screener too. You'll also need to spread the word to potential participants. You may want to use social media, advertising on sites such as Gumtree, word of mouth, forums or posters and flyers in suitable locations. Be creative and use as many methods as you can to increase your ability to reach the right audience, much as you would in a marketing campaign. If you're taking this approach, it can be helpful to set up an online survey as your screener, although bear in mind that personal contact makes candidates more likely to want to take part, so weigh up the effort of screening against the need to get participants on board!
Keep in mind that the sites and locations where you advertise will have an effect on the type of people you get responding to your advert. Gumtree won't get you lots of high net worth people. Pubs won't necessarily find you non-drinkers. A good rule of thumb is that if it would be a good place to advertise products to that group, it's a good place to recruit participants.
4. Gatekeepers
Sometimes a client or someone within your organisation will play the role of a 'gatekeeper' to a group of individuals. The gatekeeper will usually have access to a list of potential participants and their contact details. 

If you are working with a business-to-business product or service, this will often be the sales or marketing team, or account managers. 
Customer services are also useful to talk to as they will be on the front line and will have access to users.
It is also worth asking if any research panels already exist. This is a list of people that have agreed to be contacted to help out with research.

There are two main benefits to this approach. Firstly, the people you're accessing have already agreed in principle to take part in research, so they may be more open to your approach. Secondly, you may already have some information about them that will help to focus your efforts. For instance, if you're looking at a customer database, you may have information about whether they've purchased in the past six months. If that's important to you, you could use this information to shortlist people to approach (although you should always confirm the information in the database when you speak to them).
If possible, we'd recommend handing over the list or database to a recruitment agency to contact, screen and schedule. However, there may be data protection implications involved in doing so, so check before you share any information with third parties.
Persuading People to Take Part
Sometimes, people choose to take part in research purely because it's a subject they care about. Mostly, though, you'll need to provide them with an incentive of some sort.
In research terms, an 'incentive' is a thanks-you - usually monetary - for people's time. Because of this, it helps to consider: "Is what we are offering fair and sufficient payment for what we are asking them to do, the effort to come along to the research and for the amount of time we are asking them to give us?
For most of our user interviews and depth research, we offer people between £40 and £100 (roughly $50 to $130). The exact amount you will offer your participants will depend on who you are trying to recruit. If you are using a recruitment agency, they will be able to advise on the most suitable incentive for your audience.
For guerrilla interviewing, we tend to offer people a cup of coffee or a voucher for somewhere like Amazon.
Why Offer an Incentive?
For some projects you may simply not have the budget to offer an incentives at all. If this is the case, be aware that not offering an incentive could result in a few things happening:

It will be harder to recruit.
The risk of no-shows increases.
Participants are likely to be extreme fans for the product or service which could bias or skew your findings.
Or they will be disgruntled customers of the product or service and will have an axe to grind. Sometimes the extreme fans or disgruntled people are great to talk to, but you need to make the decision that they are the type of people you want to talk to.
It will be likely that a recruitment agency won't take on your project if you're not offering an incentive as it makes their job almost impossible.

Some people will need convincing with figures, so here is how much of a monetary hit offering no incentives could be to a project:

If you pay incentives, you can expect a no-show rate of about 10%. It is easy to adjust for this by over-recruiting, etc. So this could add up to around £200-300 ($260-$400) for 10 user tests.
If you don't pay incentives, you can expect a no-show rate of about 50%. This means you have wasted half of the day (staff time + studio hire + the cost of re-recruiting + the cost of running the research again another day, which is normally more inconvenient and therefore more expensive). This could add up to around £1,000-£2,000 ($1,300-$2,600) for 10 user tests, not including the value of the team's time and the impact on timelines from having to re-recruit (normally an extra 1-2 weeks). You may be on a project where you decide that you cannot take the above risks. You may have a tricky recruit (for example, CEOs) and you need a more moderate spread of participant attitudes, not just the fans or disgruntled customers.

Some companies think their customers will be willing to help them out, or that it's payment enough to be involved in helping improve a service. Not always! People are busy and have better things to do than take part in your testing. Ouch. But we can make it more appealing by offering them an appropriate incentive. On the other hand, not offering incentives is usually a false economy: any saving will be more than cancelled out by the waste of your team's valuable time.
Offering an Appropriate Incentive
Offering appealing incentives takes some empathy and understanding for the type of people you are trying to attract.
For example, if you are targeting an audience who are working full-time then the incentive has to be high enough to attract them to leave work for a portion of their day. If you set an incentive that's too low, the risk of participants not showing up increases dramatically. Too low an incentive will also not attract the 'best' participants. 
There are some organisations that will not allow you to give your participants cash, and there will be some occasions where it will not be possible or appropriate to offer cash. 

For wealthy people, cash incentives are relatively insignificant and don't hold much appeal. Instead, you'd be better off making a donation to a charity they'd like to nominate - or at least giving them the option.
Charity donations are also useful for participants who feel ethically unable to accept an incentive themselves. This often occurs if you're interviewing people about their work.
Don't underestimate the pull of the research experience itself. If you're having trouble recruiting a certain group, you could offer a taxi to and from the session and a fine buffet when they arrive. The location of your venue - in a prestigious building or part of town - can also play a part.
Finally, you could get more creative. Offer the latest gadget or a stay in a five-star hotel. We've even offered chickens and gold bars in the past!

Arranging Sessions
Now you know who you want to talk to, you need to plan the times and dates that you will be doing your research.
For guerrilla research, this will be straight away. Exactly where you found them! For fieldwork in the lab, home or in workplaces, you will need to book them in.
Running Order
If we are doing hour-long interviews or testing sessions, a typical day might look like this:
10.00 - 11.00: Participant 1
11.30 - 12.30: Participant 2
12.45 - 13.45: Participant 3
13.45 - 14.45: Lunch break
14.45 - 15.45: Participant 4
16.00 - 17.00: Participant 5

Starting at 10am gives you time to troubleshoot in the morning if any problems crop up (see Chapter 6). You will also see that there is a half hour break between Participant 1 and Participant 2. This is so you have time to talk to the team and decide on any amends or tweaks to the discussion guide based on how the first session went. 
Later in the day, we allow 15 minutes between sessions. This allows flexibility for people showing up a little late. It also allows you to run over if you're having a particularly fruitful session. And it gives whoever is moderating the session a breather and a bit of downtime between participants.
Avoiding No-shows
It is difficult to completely eliminate the risk of no-shows, but there are a few things you can do to manage the situation:

Avoid holidays and weekends. It's best not to run sessions on Fridays and the days before and around big holidays such as Christmas. People are likely to find the allure of Christmas shopping or the promise of the weekend suddenly more appealing than your research session, unfortunately. Also bear in mind your audience. Big sporting occasions, for example, can also have an effect on some demographics.
Book a spare participant or over-recruit. Book in an all-day-standby or over-recruit by several participants. An all-day standby is paid to be available throughout so they can fill the slot of anyone who doesn't turn up. This is particularly valuable if you have senior stakeholders watching your testing. It can feel awkward and look unprofessional if you don't have a back-up. You also have the option of using this person at the end of the day if you think it would be valuable.
Include after-office slots. Be mindful of the time of day when scheduling your research. It can be difficult for some people, such as office workers, to take part during office hours, so you may need to include after-hours sessions, too. You may also want to include testing during school holidays - teachers and some parents may free up in the day during these times. This will avoid your recruitment being skewed towards people that are studying, unemployed or self-employed. If you're using a recruitment agency, they will be able to help and advise you on the best time of day for the people you are trying to attract. 
Confirm the sessions close to day. Contact participants the day before and on the morning of your research to make sure they can still take part and to remind them where to go. It also gives you time to find replacements if there are drop outs. Do this on the phone and text as other methods of communication are too easy to miss or ignore. If you are using a recruitment agency, they will confirm the session with participants for you.

Data Protection
When doing research, you have to remember your obligations under the data protection guidelines and laws in the country in which you're conducting your research. In the UK, this is the Data Protection Act and the Market Research Society Code of Conduct. In the USA, the American Marketing Association are a good source of guidance. And for general international information on research codes and conduct, see the European Society for Opinion and Marketing Research (ESOMAR),
These guidelines outline how you, as a researcher, have a responsibility to look after your participants and their data. It is worth taking the time to read through these guidelines properly.
The key takeaways are that when collecting and using data, you have to make sure the information you collect is:

Used fairly and lawfully.
Used for limited and specific purposes, which you have explained to your participants.
Kept safe and securely.

Informed Consent
As a researcher, you have an ethical duty to make sure that potential participants are able to make an informed decision about whether or not they want to take part in your research. This means you have to make sure your potential participants clearly understand what the research is about, what you expect of them, any consequences of taking part and what you are going to do with their data. This is called 'informed consent'.
You have to ask participants for their consent to take part in your research before you start collecting any data from them. If you are meeting people face-to-face, you can ask for written consent.
Make it simple for participants by using checkboxes to ensure they understand each part of your consent form. It is not enough for you to hand over a consent form and to expect them to fill it in and understand. You will need to take a few minutes to explain the project to them. 
The consent form will then confirm that they have understood what you have told them, which may include:

That they may be recorded.
Reassurance that these recordings will not be shared outside of the project team.
Reassurance that they can withdraw at any point.
Confirmation that their personal and contact details will not be kept after the testing.
Reassurance that their data will be stored in accordance with the appropriate data protection guidelines.

Consent When Remote Testing
Sometimes you will be testing participants remotely and they won't be in the room with you. On these occasions, you have two options. You can email them in advance and get them to sign a digital consent form. Or you can get verbal consent. To get verbal consent, you need to read your consent form to participants and verbally ask them to agree to each checkbox, while recording the conversation.
Testing With Young People
If you need to conduct research with under 18's, there is a fair amount of legislation and rigour that you need to be aware of before you begin the project. It is worth seeking specific guidance on this well in advance of a project that involves minors. 
Keep in mind that you will need to get consent from the child's parent or guardian. The consent form will be very similar, but with additional wording to allow for the parent or guardian to give consent on behalf of the child.
Summary

Recruitment is a balance between validity and achievability.
There are three main methods you can use: a recruitment agency, guerrilla and DIY. Using a recruitment agency is generally the most cost and resource efficient method of finding people.
Your recruitment brief specifies who you want to include in your research - who, where and when.
Your screener should make sure you get high-quality participants who fit your criteria.
Always try to offer an appropriate, compelling incentive. Not offering participants incentives is a massive false economy. 
Make sure you protect your participants and their data according to the guidelines and data protection laws of the country you are collecting and using your data in. 

















Chapter 4: Writing a Discussion Guide
It sounds obvious, but your research sessions will be better if you think them through beforehand. You do this by imaginatively playing through what might happen, plotting out how to achieve your aims, and weighing up different questions and activities you might use. Most of this planning takes place in your head, but it also has a physical product, which goes by the name of the discussion guide. 

The research cycle: setup

An Artifact of Many Names

Discussion guides go by many names: script, session plan, topic guide, task guide. They're used interchangeably, and all mean pretty much the same thing, so it's a matter of personal preference which term you use. However, we'll call them discussion guides in this book.


What's the Discussion Guide For?
A discussion guide has three jobs:

As mentioned above, the main purpose is to think through your approach. The process of writing a discussion guide forces you to do this.
Getting agreement from colleagues. A discussion guide is a great way to prompt debate among the project team and stakeholders. It'll also help to make them feel involved and invested in the outcome. You'll probably find that your colleagues have different views on priorities, and how best to tackle things. Allow for an iterative process, and when you're finished, the agreed discussion guide can be signed off by your stakeholders.
A reminder of what to cover in your session. When you've finished your discussion guide, you probably won't need to refer to it much in the session: it's in your head. But it can still be useful to have a guide to refer to, if you think you might have forgotten something, or if you've lost your place. 

What's a Discussion Guide Not For?
A discussion guide isn't a script. Think of it as a set of questions to answer, not questions to ask. Nor is it a rigid sequence that you have to follow, because you should allow for some improvisation depending on what the participant says or does. Think of the guide as the skeleton around which the real discussion is shaped.  
Elements of a Discussion Guide
Whatever your research is about, the discussion guide will always include certain standard elements. In a depth interview, these elements will be topics: the aspects of the user and their world you'd like to understand better. In a usability test, they will be tasks: the product features or journeys you need to evaluate. The sequence of tasks or topics, plus the intro and outro sections that you shape around them, are the core structure of your discussion guide. So whether you're in the discovery stage or the validation stage of a product lifecycle, the structure will be roughly the same:

Introducing the session (5 minutes of a 60-minute session)
Participant introduction (5-10 minutes)
Setup for the main task or topic (3-5 minutes)
Main task or topic (5-20 minutes)
Exploring the detail (10-20 minutes)
New versions or comparisons with competitors (0-10 minutes)
Summing up (5 minutes)

What goes into each of these sections? We've described them in more detail below, and later on in this chapter you can see how this varies for different kinds of project.
1: Introducing the Session
In this first section, you're going to lay the ground rules for the participant, explaining what you need from them in the session, and answering any questions they may have. It's also important to tell them about any recording or observation you're planning to do. In the session, this is also the moment at which you'd give the participant a consent form to read and sign. It's also a good idea to offer them a hot or cold drink at the same time.
Here's an example from one of our projects:
Meet and greet the participant in reception, then transfer to interview room once they're comfortable.
Thanks for coming to our research session
It'll take about 60 minutes
I'd like to record it, so we can remember what happened properly. Is that OK?
Some of my colleagues would like to watch, but we've put them in a separate room so they don't distract us. I might go to ask them if they've got any questions at the end
Views shared and recording are confidential. They'll only be shared anonymously, and only within the project team
Just to be clear: I don't work for the company that's made this website. That means that I'm neutral: I can't take the credit for anything you see today. And I won't be upset if you don't like it, either
There are no right or wrong answers. I'm just interested in the way you see things
At the end of the interview, we'll give you $60 as a thank you
Do you have any questions about what we're going to be doing to?

Don't reveal the client identity at this stage

Try to make this section conversational and relaxed, rather than formal. Use the guide as a reminder, rather than reading directly from it, otherwise your introduction will feel robotic and awkward. Treat this as a checklist rather than a prepared speech, and try to get the participant talking using easy, closed, questions such as "Have you done this before?", "What was it about?".
Time: Around five minutes, but may be longer if the participant takes a while to relax.
2: Participant Introduction
The purpose of this section is to get the participant talking and feeling comfortable with the interview setting. It also provides you with some background information about their life and habits, which you can refer to later on. If you're testing a fully-functional prototype or product, you can use this information to create scenarios. 
For example, a participant has said they're going to a friend's wedding in a few weeks' time, and they want to get some shoes to go with their outfit. We could use this scenario as the basis for one of our tasks later in the session, because it will be more realistic than a made-up scenario, and the participant will therefore engage with it more truthfully.
Here's an example of a participant introduction section:
Participant to introduce themselves in general terms:
 What have you been doing today, before you came along to the interview?
 Do you live locally, or have you had to travel a distance to get to the interview?
 What's your occupation?
 Do you have any children?

Once they're warmed up, participant asked to tell the story of the last time they bought a pair of shoes:
 What was the trigger?
What did you buy?
Where did you buy them?
Who did you buy them for?
What other options did you consider?
What stopped you from buying those other options?


In the first section, you'll notice that these questions are the kind of small talk you expect if you were chatting to a stranger in any situation. There's a reason we start with these kind of questions: people find them unthreatening and are very used to giving answers to them. Just as you would in a social situation, though, you should choose your questions to fit the person, and avoid reading from a script. For example, if you're talking to a student, they will probably be used talking about their course, but a question about children might be inappropriate. It's good practice to avoid questions that put participants under pressure at this stage. For that reason, it's best to avoid asking about favourite websites or hobbies: these questions can make participants feel under pressure to invent an answer. 
In the second section, we're using storytelling, another familiar format, to put participants at ease and get them used to talking, while at the same time giving us useful information about past behaviour.
Time: 5-10 minutes. This is often the hardest section to judge. On the one hand, it's best not to hurry if you feel the participant is nervous. If that's the case, try to establish a rapport with them before you move on to the next section by focusing on easy questions and uncontroversial topics, otherwise you may find they freeze up in the most important part of the session. On the other hand, if they seem comfortable don't linger too long: it's easy for this section to turn into general, unfocused chit-chat, which means you'll run out of time later on!
3: Setup for the Main Task
Before you go into the main task, you need to lay the groundwork correctly. 
A Repeat Briefing
This is especially important if you're testing a prototype. In this, you should explain:
            
Not every link will work. Don't worry about breaking it!
It's not a test of your internet skills, it's a test of the thing in front of you. You're here to get feedback for the designers, so don't hold back
There are no right or wrong answers.

It might feel like you've already said these things at the beginning of the session. Don't worry. The participant may not have taken them in properly at the time, and it's good to recap.
Setup Questions
You may want to establish a benchmark against which to compare the actual experience. For example:
            
What are you expecting this thing to be like?
Have you used this thing before? What do you remember about it?
Tell me about the last time you needed to achieve this objective. This information will be very useful to refer back to later on, once your participant has tried out the thing you're getting them to explore.

Time: 2-5 minutes. This is a short section, but it's important. 
4: Main Task
This is the heart of your session. Although it may only be a fraction of the total running time of your session, it's crucial because it's the point at which your participant will be responding most naturally to the topic or product. From here on in, it's likely that they'll become more and more familiar with it (and increasingly aware of what you want to know about it, based on your line of questioning). So make the most of it.
Because you need to make the most of this key moment, you'd be wise to focus on the task that's most important to you. If your research is about testing an e-commerce journey, then you would get your participant to complete the journey now. If your research is about getting reactions to a new concept, then this is when you would do the big reveal. If it's about understanding participants and their needs, then you would focus on the main area you're interested in.
You're aiming for as natural a response as possible, so it's best to dial back on your questioning at this point. If you're testing a product, get the participant to think aloud, and try not to interrupt them. If you're getting a reaction to a new concept, keep your questions extremely open-ended, such as "What do you think?", or "What do you make of it?". Once they've reviewed the thing you're interested in, you can ask them to summarise, as in the example below:
Having completed the task, participant to talk through:
 How did you get on?
 How did you feel the site performed?
 What was easy / difficult?
 How clear was it?
 What (if any) were the points where you had to work harder?
 How easy was it to make a decision about which product to go for?
 Were there any points where you were uncertain what to do next?
 Were there any points where you were worried about what would happen?
 What feedback would you give to the website's designers?
 How 'Shoestore-like' did it feel?
 What impression did it give of Shoestore?

Time: It depends on the length of the activity you're focusing on. If it's a concept test, it might only be five minutes. If it's a full e-commerce journey, it could be half an hour.
5: Exploring the Detail
Once your participant has been exposed to the prototype / concept / main topic and given their initial reaction, it's time to explore it in more detail. This is where the session can be most unstructured, because the order in which you tackle things may depend on what exactly happened in stage 4. So rather than have a rigid order of questions, we'd recommend creating two lists: tasks or activities to use, and areas to cover.

Tasks or activities to use. These are different ways to get your participant to explore the topic or product, especially the parts that they might not otherwise have discovered. For example, you might set them a task to cancel an order in their account section. They might not otherwise have chosen to do this, so you need a task that will nudge them in that direction if you want to understand how the account section works. 
Areas to cover. These are questions or rolling hypotheses that you're interested in. By listing them here, you're reminding yourself to get answers, whether it's through spontaneous actions or comments of the participant, through a task that you set them, or by probing with questions.

Another reason why it's a good idea to keep an open mind about the order in which you tackle the tasks and areas in this section is that you can then tackle them in a different order with each participant. This means you're reducing the bias from one question preceding another (AKA the 'order effect'). Also, you can tailor your approach to each person, making the session feel more realistic.
You can see how this approach works in the example below:
Tasks & activities
 You're going to visit your cousin in Canada, and you need to buy a pair of snow boots. What would you expect to spend in a situation like this? Now, try to find a pair for that price.
 Your friend has recommended a brand of snow boots called Aggi. Try to find them on the Shoestore website.
 Your trip to Canada has been called off. Try to cancel your order for snow boots. 
 You want to leave a Google review of the Shoestore website. What would you write?

Areas to cover
Homepage
             What draws your attention? 
 Who does it appear to be aimed at? 
 Is it clear what Shoestore's offering is, from this page? 
 Is it clear what you can do here? 
 How can you move on from this page? 


Category page
             Reactions to the product range shown on the page
What sense of Shoestore's strengths / offering / style / range do you get from this page? 
 To what extent do you engage with 'Shoe Discovery'? How does this compare to 'Shoe Rack'? 
 How easy is it to move on from this page?


Search / product listing page
             How easy is it to find the search function?
 How well does this work? 
How do you feel about the presentation, sort order, abundance of results?
If you wanted to change any of this, how would you go about it?
How easily can you filter the results by size or any other important facet?
How do you feel about the amount of information about each product?
How well supported does this feel on mobile, eg, predictive, filtering, subcategorization, null results?


Account section
             How easy is it to find the Account section? 
 How clear is the status and delivery details? 
 How easy is it to cancel an order? How confident are you that the cancellation is confirmed?
 How easy is it to change a password?


Time: 10-20 minutes. However it's a good idea to include more tasks or activities than you need, so you have a selection to choose from depending on how the session unfolds. So we'd recommend writing enough for 20-30 minutes, and cherry-picking the ones that are most useful to you.
6a: New Versions
If you've spent most of the session looking at an existing product or a relatively complete version of a new product, then towards the end you're in a position to show some new variations. The reason for doing it here is that participants will have enough knowledge from their earlier activities to be able to put isolated pages or lo-fi sketches in context. If you do it earlier, it's harder for them to envisage how they'd work.
Time: 5-10 minutes.
6b: Comparison
If there are no new designs or concepts to look at, we can use this part of the session for other purposes. One of the most common ways to do this is to look at one or two competitors' versions of the same journey and see how they compare. This is useful because a) it's easier for participants to evaluate your product if they've got other examples to refer to, and b) you may see how alternative approaches to the same problem work, before you adopt them yourself.
Time: 0-10 minutes. This section is generally the most expendable of all, which is one of the reasons why we do it virtually at the end of the session: if you're running out of time, it's ok to ditch it.
7: Summing Up
In this section, you're asking the participant to summarise their experiences and reactions. It's unlikely you'll learn anything new, but it's an important section for a number of reasons:

You get a sense of priorities and proportion. For example, your participant may have encountered several issues over the course of the session, and now you can ask them to say which felt like the most important.
You can ensure your observing colleagues feel involved in the session, by asking them for any additional questions.
You will often get your best quotes here. In fact, you can ask participants to give a quote 'direct to camera', which is useful for your outputs.
It's also important to give the participant a sense of closure, so they understand that the session is over and their contribution is complete.
You can ask if the participant has any questions for you.

Different Kinds of Session
Every research project is different. While the core structure we've outlined above works for any kind of one-to-one session, there are variations in the detail depending on whether you're running discovery research (eg, understanding someone's life and needs) or validation research (eg, testing a product's usability). You can see how these differences play out in the table below:



Discovery
Evaluation




Introduction
Introduction


Warmup subject
Context of behaviour


Focus on main journey or question
Big reveal or main task


Explore context (e.g. look round home)
Follow-up tasks


Wrap up
Wrap up



Questions, Tasks, and Activities
There are a few problems with interviewing users. Firstly, they're not always great at telling you what they need. On top of that, they struggle to remember what they've done, they aren't always honest about what they think, and they don't always do what they say they'll do. These problems are the main reason why we try to rely on observable behaviour, not people's opinions. In fact, given all of these problems you might wonder why we bother asking users at all. The reason is that it's often our only way of finding out (if, for example, we're talking about something that happened in the past). And it's also our only insight into why something happened: observation alone can't tell us about user's perceptions or motivations. So we do need to ask questions, but we shouldn't just take the answers totally at face value. 
The best research uses questions and observed behaviour in combination to try and get around these problems (an approach we referred to as 'triangulation' in Chapter 1). We compare and contrast data from these two complementary perspectives, to get around the blind spots in each. So when it comes to writing your discussion guide, you should plan how you'll use questions and activities together. For your most important questions, it's a good idea to approach them from several different angles, using a mix of more direct and more playful questions, tasks and creative activities. Each of these will give you a different perspective, and in combination they'll be much more insightful (and less misleading) than any single approach.
For our Shoestore research, we're interested in how parents buy school shoes for children. As it's an important question of our project, we'll approach it in several different ways, at different points in the session:

As a question: "How do you buy school shoes for your children?" The weakness of this question is that participants will tend to simplify and generalise, giving explanations that are overly-rational or that paint them in a good light. It's useful to ask, but we need additional perspectives.
As a question: "Tell me about the last time you bought school shoes for your eldest child." This question is more specific, and therefore less prone to bias. However, the example we're asking about may have been atypical, and it doesn't leave room for the participant to give a broader sense of how they approach this task.
As a task: "You've got $40 to spend on school shoes for your eldest child. Go and shop for a pair online." This is the behaviour we're interested in, however it lacks context. For example, their child may not currently need shoes, or they may not be using their normal device.
As an activity: "Imagine you had to write a blog post advising parents how to shop for school shoes online. What would you write?" This gives an insight into the participant's perceptions and knowledge. However, it risks being too general, and ignoring real-world constraints like budgets.

None of these approaches on their own gives the entire truth. Taken together though, they add up to a much richer picture of what participants are doing, and why. Additionally, by exposing contradictions, they enable you to raise probing questions that the participant might otherwise dismiss. For example, you could observe: "When you were talking about your approach to buying school shoes, you said that you always went for the cheapest pair, but when you were using the website you spent quite a lot of time looking for more stylish pairs that weren't the cheapest. It feels like cost isn't the only thing that's influencing your approach. What do you think?"
Types of Content
As you have seen, a discussion guide is constructed of several types of content, arranged within the skeleton structure we described earlier. Let's look at each of these in more detail:
Tasks
Tasks are the tool we use to be able to observe users' behaviour. By asking users to perform a task, we're directing them down a broad path of action, so we can sit back and watch the options they choose, what works and what doesn't.
Tasks can range from the very basic:
"Buy a pair of shoes on the Shoestore website."
To the very elaborate:
"Imagine you're going to start a new job next Friday. You've just found out that the dress code at your new workplace requires all staff to wear unbranded black shoes. Because your job involves standing on your feet for most of the day, you need your shoes to be as comfortable as possible. You have $60 to spend, and you're only going to be at home on Tuesday. Buy a pair of shoes that are suitable for your new job."
The difference between the two is that the first makes no assumptions about how or why the user should be buying the shoes, whereas the second includes a lot of extra detail. We call this extra detail the scenario. Knowing how to write a good scenario is the key to creating effective tasks. You need to strike a balance between giving enough information, but not too much. 
While the second version above looks more realistic, there are actually several problems with it:

It's overly-prescriptive. It's leading them towards a particular course of action or solution. For example, by mentioning that they're only going to be home on Tuesday, we're suggesting that they would prefer to get the shoes delivered rather than collect them.
It may be unrealistic. The participant may be used to working at a desk, and so might find it hard to identify with the role in the scenario where they have to stand at on their feet all day.
It'll be hard for the participant to remember all this information while they complete the task.

On the other hand, the first example can feel too broad. It's very unlikely that someone would go to shop on a shoe website with absolutely no context: no trigger, no sense of budget or urgency, and no reason for choosing to buy shoes.
The solution lies in three principles:

Wherever you can, use scenarios that are realistic to the participant. If they've got a new job coming up, ask them to buy shoes for the job. If they've got a trip to the ski slopes coming up, ask them to buy snowshoes. By taking this approach, the participant brings realistic context with them, rather than you having to impose made-up context on them.
Provide just enough context to set the objective, but don't specify the route to get there. "You're going to a job interview next Friday, and you need shoes to go with your suit."
Have the rest of the context ready, but don't share it unless you need to. This involves creating a more detailed backstory around the task, but only providing it if the participant is unable to come up with their own details. For example, if the participant asks, you might invent the colour of the suit they're going to wear, the nature of the job, or their address.

Protocols
When you're asking participants to complete a task, you need to give them guidance on how to verbalise their thoughts. There are a number of different ways of doing this, which we refer to as protocols.
The Thinking aloud protocol asks the participant to complete the task while giving a running commentary on their thoughts.

 Pros: The most generally useful protocol, which gives a good balance of observable behaviour and insight into that behaviour.
Cons: Greater cognitive load for the participant, which can make it harder for them to complete the task itself. Participants can also drift into silence. 

The Silent completion protocol asks the participant to complete the task in silence, unless they want to ask a question.
Pros: More realistic and less unnecessary cognitive load for the participant.
Cons: Little insight into how participants perceive the product, their decisions or behaviour.

The Reconstructed thinking aloud protocol aims to bring together the best features of the above two protocols. In this version, participants complete the task in silence, but are then shown the recording of their journey and asked to narrate their thoughts and decisions.
Pros: Realistic cognitive load, more thoughtful reflection on the process.
Cons: Complex and time-consuming to set up. Also, if they have to explain their behaviour retrospectively, participants might want to choose explanations that flatter their choices, rather than the real reasons.

The Deconstruction protocol involves the participant as a critic, rather than a user. This is particularly relevant when the person you're talking to is an expert on the subject or the product you're using, for example if you're testing enterprise software.
Pros: Can be more engaging for expert participants, leading to more useful feedback.
Cons: Misses out on some of the detailed usability feedback you'd get from other protocols.


Eyetracking

In some research sessions, we use eyetracking equipment to get a more detailed understanding of where users are looking. Eyetracking is a great tool for determining precisely how participants moved and focused their gaze, but it has its limitations, too. You will need to allow more time for setup, and your session will be more rigidly structured than a standard user research session. Also, the equipment and calibration process involved in eyetracking can feel intimidating, so you'll need to spend more time on warm-up activities to help your participants relax.


It's a good idea to change protocols through the session, as the participant becomes less natural in their responses and more used to the interview setup. So you might start with silent completion, before moving on to thinking aloud protocol and perhaps even deconstruction protocol at the end.
You also don't have to stick to the same approach for each interview. Over the course of a day, we sometimes use silent completion protocol for the main task in the first couple of sessions, then use thinking aloud protocol thereafter.
Questions
We'll cover how to ask questions in much more detail in chapter 7. At this point, it's just worth mentioning that your bigger research questions and hypotheses should definitely be included in your discussion guide. You may also want to add some possible probes and follow-up questions, to help you think through how to approach each topic. Also, after each session you will be updating your rolling hypotheses, and you may want to update the guide to cover these.
Activities
Activities are another way to get an insight into participants' decision-making and behaviour. Unlike tasks, we're not asking them to use the product we're interested in; instead, they tend to be more lateral, often using playful or creative approaches.
A word of warning. While activities can much more energising than asking questions, and often more insightful too, they have drawbacks:

They can be time-consuming, both in terms of setup and within the session itself.
Not everyone is willing to engage with them. In some settings (in research with business people, for example), creative activities may be inappropriate. In other cases, openness to activities is down to the individual, and you will need to use your judgment in the session.
The outputs are harder to interpret than questions or tasks

Don't let these problems put you off, though. Often activities are the highlight of a research session, and generate the most engaging outputs. Here are some examples, but there are many more:

Card sort adjectives to describe the website you've just used.
            
Take a print advert / bill / screengrab from the product website, and rewrite it in red pen.
Using a highlighter, mark up any parts of the content that don't make sense.
Using Post-It notes, create a timeline of your most recent process of buying new shoes.
Imagine the Shoestore website as a person. What job would they do? What kind of house would they live in? What would they dress like? What would they be like if you met them?
Create a collage from magazines to illustrate how buying shoes makes you feel.


Write a pretend Amazon review of the website you've just used.

How to Write a Discussion Guide
When you start writing a discussion guide, it's tempting to piece together sections from previous guides to save time and effort. Resist the temptation, and always start from scratch. The reason it's important is that if you don't write the guide yourself, you'll miss the vital process of imagining and internalising your approach. You'll have created a long document, but you won't have done the actual work of thinking through how you're going to approach the research.
Before you starting writing the detail, plan out your approach at a high level:

Write out your main research questions or rolling hypotheses. Remember, you don't need to worry at this stage about how you're going to ask these questions, you just want to be clear about what your priorities are.
Check how long you've got, and divide up your time into rough sections using the approach described earlier in this chapter.
Identify your main task, activity or topic. This will make up section 4 of your guide.
Think about your secondary activities and areas to cover. These may be different angles on your main questions, or other aspects of the experience that you're interested in. These will go into section 5.
If you've got any new designs to include, these will go into section 6. Otherwise, create a list of competitors or other products you'd like to compare.
Think about the context that will be useful to understand about the participant and their relationship to the product. This will form the basis of section 2.

Once you've sketched out your approach at a high level, you can go through and add in more detailed questions, activities and tasks to do the rest. Remember to approach your key research questions from several different angles, as described above.
A moment ago, we said that you should always start your discussion guide from scratch. The exception to this is section 1. Because the items on this list should almost always be the same, you can copy this from a previous guide, while remembering to check if there are any changes for the project you're currently working on.
Use Your Imagination
When athletes are training for a competition, they spend time envisaging it beforehand, mentally pre-living each stage of the race and preparing for how they'll react when the time comes. You can use a similar process for writing a discussion guide. Go somewhere quiet, and think through each part of the session. How do you expect participants will respond to your questions, tasks and activities? How long will it take? What kind of guidance will they need? By anticipating what'll happen, you can avoid being caught out, and plan for different eventualities.
Summary


Discussion guides have several jobs, but the main one is to help you thinking through the session beforehand.
Structure the outline of your session first, focusing on the main questions, tasks and activities you want to use.
If you include more material than you can use, you'll have the option of tailoring some aspects of your session to each participant.
Don't treat it as a script, but as a flexible framework you can depart from when you need to.
Use your imagination to think through how the session might unfold, so that you can plan for different outcomes. 

















Chapter 5: Set Up Your Sessions
If you want your research sessions to run smoothly, you will want to take some time in the days beforehand to prepare. That way, you can be sure that everything you need is ready, the project team know their roles, and you've got time to fix any problems that come up. Research sessions are pretty full-on, and you want to be able to concentrate participants without getting distracted or disrupted on the day.

The research cycle: setup
This chapter covers the process of preparing over the days running up to your research sessions. There are three main locations where you might find yourself running research - in the lab, in the field, and remotely. We'll cover each of these settings individually as while much of the setup will be similar, each one of them does involve slightly different preparations. In each case, we'll imagine you're running the session on a Thursday, and show you what you need to do in the days beforehand.
Getting Prepared for Research in the Lab
As you approach the day of your research session, we would expect that you'll have written your discussion guide, and recruitment is well underway. From here on in, you'll need to ensure everything's on track day by day.

Overview of the testing week
Monday: Three Days Before Your Session
On the Monday, allow two to three hours for setup activities.
Run a Pilot Session
We always recommend that you find time to pilot your discussion guide. A pilot just means a test run - it's a chance for you to test out your guide with a pretend participant. This serves a few purposes. 

Firstly, it allows you to figure out timings. It will show if you are being optimistic with the amount you are trying to cover or if you are able to add more questions or activities.
Secondly, it allows you to consider what equipment you need and what notes you need to take. 
Finally, it gives you time to refine how to ask your questions and to develop your rolling hypotheses (We talk more about rolling hypotheses in Chapter 1).

We usually grab a colleague for an hour to be a pretend participant and give them a cup of tea and a biscuit to thank them for helping us with our pilot. They can pretend to be a suitable participant, it is ok if they are not perfect and don't fit your recruitment brief. Remember the idea here is not to collect data but to test drive your approach. You will often find that you will need to make tweaks to your guide off the back of your pilot test.
If your research involves using a prototype or other material that'll be shown to participants, this is the right time to take a final walkthrough. If it's not complete or fully-functional (a common situation), then you'll need to be clear about what bugs and unexpected behaviours exist, so you can work around them in your session. If there's time for any further development, this is an opportunity to highlight the priorities.
Check Your Test Venue
The other thing that you should do is check your testing venue. If you  are testing in-house, check that you have a room booked, and that you'll be able to access it beforehand. If you are testing at an external test facility, give them a call and check that everything is ok for later in the week. If you can, get some photos of the testing venue, including the actual rooms you'll be using. You can then plan how you'll use the space - think about how you will arrange the furniture, where you want the participants to sit and where you will stick up your post-it notes. It's also a good idea to re-confirm with your colleagues who'll be coming to observe.

Labs and Two-Way Mirrors

For your project, you may be running interviews in a lab (also known as a viewing studio). Your lab could be a facility that you have in your company, or you may be using an external venue. Some labs will have an observation room attached to the testing room separated by a two-way mirror. Other testing rooms may be linked to the observation room using cameras and microphones. Observers are then able to watch and listen. But all of these are nice to haves and you don't need anything fancy to carry out your research. The minimum that you need is a quiet room and some equipment or materials to test with.
We wouldn't recommend using a room with a two-way mirror for a couple of reasons. Firstly, the people that are watching will be forced to sit in a really dark room so that they can't be seen by the people in the testing room. This is really tiring and generally not a very nice experience for the people watching. 
                        Secondly, it also means that they are physically very close to the testing room and there is a danger that they will be heard by the participants. It makes it more obvious to participants that they are being watched and that feels unnatural and disconcerting. We find that using remote cameras and an observation room linked to the testing room with a big monitor is much more engaging and effective. 


Tuesday: Two Days before your session
Now that you've dealt with the pilot session, prototype and venue, you can focus on the roles each member of the team will play.
Agree Roles
If you're working as part of a team, it's important to agree roles, so that you don't overlap or miss something. You may have one person who's interviewing, one person who's note-taking and someone else who's managing the observers (you will need this if you have a client or stakeholders watching). We'll describe these roles in more detail in Chapter 6.
There may only be two of you, in which case, the note-taker can take care of the observation room as well. You may decide that the interviewer and note taker want to switch roles every few sessions or half way through the day. In fact we would recommend doing this. Interviewing is draining and you don't want to start to burn out towards the end of the day. 

Agreeing roles for team members
The exact activities and roles that need doing may change depending on your project and the type of research that you are doing. It's down to you and your team how you allocate your roles. 

Testing on Your Own

Ideally, there should always be at least two people involved in a research session. You need one person to run the interviewing, and another taking notes. There is enough for you to be doing if you are running the interview session without having to worry about taking notes as well. 
If you do find yourself working on your own without a note-taker, it's best to record the sessions and review them afterwards, in the Absorbing the Data phase of analysis (see Chapter 8). Taking detailed notes while interviewing is the worst possible scenario, and you should avoid it if at all possible.


If you do find yourself working on your own without a note-taker, it's best to record the sessions and review them afterwards, in the Absorbing the Data phase of analysis (see Chapter 8). Taking detailed notes while interviewing is the worst possible scenario, and you should avoid it if at all possible.
Agree a Checklist
A really worthwhile activity at this stage is to write out a checklist of all the things you need to prepare for your test session. This could include things like printing discussion guides and making sure you have power cables for your equipment. If you are working in a team, allocate each activity to a person. This makes sure everything gets prepared and that everyone is clear who is responsible for what. 
Here is an example of one of our checklists:

Example checklist
Wednesday: The Day Before Your Session
One day to go! There's still more you can to do to make sure your session runs smoothly.
Mark Up Your Guide
When you wrote your discussion guide (see Chapter 4), it was likely to have been quite detailed, and you will have used it as a way to agree what topics to cover with your team. It also will have given you a chance to imagine how the session was going to play out.
On the day of testing, your discussion guide will need to play a slightly different role for you. You will need it as a prompt to help you out if you forget what you are covering or if you want to check you are on track. 
So we recommend making a condensed version of your discussion guide. Start by marking up your guide with the key sections of the questioning that you have planned. If you take our example of the project interested in people who buy outdoor equipment, one section could be "Information expected about equipment for sale". Aim to get this down to two pages, so that it's easy for you to scan while you're interviewing. 
To condense your guide, go through these steps:

Start by summarising the main objectives for the session. What do you absolutely need to have covered by the end?
Then go through and pull out one or two main points for each section. In the example above, the first big chunk is about information needs - so what do people need to know about the product or service? The second section is about expected sources - where do the participants expect to be able to find this information? The third chunk is about the expectations they have of the specific product or service we are testing. And on this goes throughout the guide.
Also, if there are any specific activities (such as visiting a web page or trying to complete a task), add these to your condensed guide in the relevant place.
Finally, we also recommend having a few activities or extra questions in reserve. These are things that you can use if you rattle through your discussion guide and find yourself with a bit of time at the end of the session. They can also be useful to use if you are having a difficult session and need something to mix it up and bring a bit of energy into the room. We talk more about this in Chapter 7.


Condensed discussion guide
Set Up the Research Room
The day before your session you'll want to set up your research room. If you are using an external venue, it is worth calling them to check if everything you need is there and working. This is also where the checklist that you created earlier in the week can be useful to see what's left to sort out.
You will want to make sure that the testing and viewing rooms are tidy, clean and set up appropriately for your research. 

Is the equipment that you need in the rooms at working? 
Do you have print outs on the walls and Post-it notes and Sharpies ready? 
Is your participant list and discussion guide printed?
Are your incentives ready?
Do you have consent forms?
Where are you going to meet and greet you participants?

Remind Participants
If you are using an external recruitment agency, they will do this for you. It's worth checking in with them to make sure everybody is good to go and there are no last-minute drop outs.
If you have done the recruitment yourself, you'll want to send them a reminder confirming the location, time of their session and anything that you may need them to bring along with them. We recommend doing this by text rather than email, as they are more likely to look at it and they will have the address to hand when they're travelling to you. Encourage them to get in touch with you as soon as possible if there are any problems or if they can no longer make your session: it's better to find out that someone's going to drop out now, rather than on the day.
Once your participants are confirmed, you can print out the details to refer to in the session. Do two versions: one with full name and contact details on for yourself, and another with first names only and no contact details to share with the wider team of clients or stakeholders.
Thursday: The Day of Your Session
This is it. The big day! You should have aimed to do most of the set up and preparation the day before, so that you have enough time to do any troubleshooting and to get in the right headspace. Give yourself an hour before starting your research to troubleshoot.
The key checks for the morning are:

Double checking that your equipment is working, charged and has enough disk space.
Make sure you have back up equipment (spare laptop/tablet).
Checking your emails for any last minute participant cancellations.
Checking your research and observation rooms are ready.
Check that your prototype (or whatever you are testing) is working.

If you are doing the interviewing, we really recommend allowing yourself time alone to go over the discussion guide. Find a quiet spot to do this where you won't be interrupted. There have been times when we have resorted to hiding in a toilet cubicle to do this! 
The purpose of doing this is to give you confidence with the guide, remind yourself of the structure of the sessions and to get yourself in a calm and collected place to begin testing. Once you've done that, you're ready to go! We talk about how to introduce the session and manage the day in the next chapter.
Getting Prepared for Research in the Field
When you're doing contextual research in the field, there is usually a little less that you can prepare before hand. This is because you don't have a room to get ready, and if you're running a guerrilla session you won't have participants to send reminders to either.

Example week for guerrilla testing
Tuesday: Two Days Before Your Session
The start of the week is about checking your discussion guide and planning your visit.
Run a Pilot Session
Just like research in the lab, you may have a short discussion guide to pilot and test. If you're doing guerrilla research, this discussion guide will be a lot shorter than if you were running lab sessions, so you may have the chance to run it past a few different people in a short space of time. On the other hand, you'll be under more time pressure, so you need to be really clear about what's important and what you should cut from your guide, based on the pilot.
We also recommend that you think about what your opening line will be so people don't mistake you for someone selling something or a charity collector, as you are more likely to be shut down or ignored. 
We have found something like "Hey, I'm doing some work on XX and I wondered I could get your help" is a good opener.
Fine-tune Your Travel Plans
This can take a little while to figure out, especially if you are visiting an area that you are not too familiar with. You'll probably already have decided on locations, so your checklist now should be:

Have you got permission to be there, if you require it?
What are the busiest times of day to be there? You can check this via Google Maps, if you search for the location.
What are the best transport links or parking options?

Wednesday: The Day Before Your Session
The day before testing is about making sure everything is working, that you have everything that you need and that you know where you are going.
Prepare Test Materials and Equipment
You need to make sure that whatever you are testing is ready. You will also need to check that any equipment that you need is available and working.
            We use a checklist like the one below to make sure that we have everything that we need.

Example field checklist
Thursday: The Day of Your Session
The day is here - you are taking your test materials into the wild. Contextual interviews and guerrilla research can be gruelling. You need to be more organised and willing to improvise than in lab-based research. In guerrilla projects, you'll also need to put a thick skin on and prepare for a bit of rejection: the people you approach may potentially be a little rude and not want to help you out.

Make sure you have decent clothing for the weather.
Figure out how you will be getting around between your locations - take money for public transport or parking.
Take a bottle of water and some snacks.
Check you have all the materials you need printed and ready.
Make sure you pick up all equipment (including chargers) that you need.
Make sure you have your incentives and consent forms.
On some occasions, using a banner or t-shirt to explain that you're doing research will get people chatting to you.

Getting Prepared For Remote Research
Remote research brings with it a unique set of challenges. Not only do you have to be aware of and check your own equipment and technical set up, you now have someone else's to worry about too. Additionally, you don't know this person and they are potentially in another city or even country. All in all, remote testing has more considerations you need to be on top of, but there's no reason why it can't run smoothly, so long as you're organised and provide clear instructions.

Remote testing week
Monday: Three Days Before Your Session
At the start of the week, you need to make sure that your participants are ready so that you can iron out any technical problems. 
Check the Software Works for Your Participants
Well in advance of the test session, you will want to send the links to join your session to the participants. If you are using a recruitment agency, they will do this on your behalf. Now, it's time to ask your participants to try the remote software you are using. It's a good idea to have a ten minute phone call with your participants to check that everything's working ok, and to build a relationship. This'll come in useful if you encounter problems later on, as you have some rapport and multiple communication methods that you know are effective. It's also a good time to email your participants a consent form to sign and return to you digitally, because you can cover off any questions in the same call.  
Run a Pilot Test
As with lab-based testing, it's a good idea to run a pilot because it will help to tighten up your discussion guide, highlight any issues with the prototype (if you're using one), and clarify your approach to note-taking. With remote research, it's also important as a technical check on the software. In this case, we recommend that you run a pilot with friends or family rather than colleagues, as it's more likely to highlight any technical issues. This will give you an idea of the problems people may come across and how you can help them.
Check Your Test Venue or Room
As with lab testing above, you will want to check your venue or rooms well in advance of the sessions, and that the equipment that you will need available.
Send Consent Forms
As mentioned above, you'll need to send consent forms to your participants, and ensure they've got the opportunity to ask any questions. Doing this early means you've got plenty of time to chase up digitally signed forms before you start the research.
Tuesday: Two Days Before Your Session
Tuesday follows a similar procedure to lab testing, which is detailed above. You will want to:

Agree roles and responsibilities with your research team.
Create a checklist to make sure you know everything that needs doing to prepare for the test sessions and who is responsible for what.
You may have people in the project team who want to join and watch the session remotely. Make sure you remind them that they must mute the microphones on their laptops.

Wednesday: The Day Before Your Session
Wednesday will also run similar to the day described for lab testing above:

Mark up your discussion guide to create a condensed version.
Set up your research room.
Make sure reminders are sent to participants including a nudge to try the remote testing software if they haven't done so yet.
Check that you have consent forms from your participants and chase those that haven't yet completed them.
The day before you are remote testing, it is vital that you check all of your equipment and carry out a dummy run using the software and all test materials. It gives you time to iron out any problems.
Set up the observation room.

Thursday: The Day of Your Session
This is the same as the lab testing day, with additional technical setup. You will want to double-check that your equipment and testing material is working, and that there are no last-minute cancellations. Give yourself some quiet time to go over the guide and prepare and then you should be ready to go.
Summary
The key to smooth testing is preparation, trying to foresee any potential problems and allowing yourself time to troubleshoot the things that inevitably will go a little wrong.

Having a checklist will help you get organised and will make sure everything that needs doing will get done.
Make sure the project team all have clear roles and responsibilities and that everyone knows what they are.
Ensure all equipment and material is checked over and charged well in advance of your testing.
Make sure that your observation room is set up for useful and productive note taking.
On the morning of testing, find 20 minutes to have some quiet time to collect yourself and check through your guide to prepare for a busy and tiring day. You'll almost inevitably have to go and hide somewhere!

















Chapter 6: Running Your Sessions
The big day is here. You are about to run your research sessions. As we discussed in Chapter 5, you'll have done a lot of your preparation in the days beforehand, which takes most (but not all) of the stress out of it. 

Research cycle: fieldwork
Roles
We spoke about giving everyone in the research team roles and responsibilities in Chapter 5. 
The four key roles on the day of research are:

Interviewer. This person is responsible for talking to the users and running the test sessions.
Host (of the observation room). This person is responsible for looking after the people watching the research in the observation room. They will facilitate discussions and make sure observers know how to get the most out of watching the research.
Note-taker This person is in charge of capturing the information from the test session, such as positive moments, pain points, quotes or suggestions.
Observer This person has come along to watch the testing but is encouraged to get involved and take notes.

Research sessions are most productive when all of these roles are working in harmony with each other, so it's worth having a discussion beforehand about who's going to do what. Even so, on the day it's a good idea to re-iterate what each person's supposed to be doing, and to lay out the ground rules. We'll talk about these roles in the following sections.
The Interviewer
The primary role of the interviewer is simply to interview. You want your entire focus to be on your participant, whether that is in person or remotely. We'll say a lot more about the role of the interview in the next chapter.
The Host
The host's role is to manage the observation room, to make sure there's productive engagement with the session, and the outputs are on track. Without someone to keep them on-task, observers can become boisterous and unfocused, which can make it hard for others to concentrate and listen. So the host needs to juggle people-management and task-management responsibilities.
The type of responsibilities the host can expect are:

Lead on-the-spot analysis activities - for example, sticking Post-It notes onto screengrabs.
Ensuring the observers are being catered for with food and drink.
Keeping an eye out for any support the interviewer might need, and giving them encouragement or feedback.
Liaising with the venue staff.
Manage the observers' behaviour.
Fielding any last-minute recruitment problems.
Facilitating conversations about findings and implications.
Social hosting and small talk.
Collating and passing on questions from the observers to the interviewer.

The host's role is really hands-on, and it demands stakeholder management skills, the ability to juggle tasks, and a bit of authority, as you may need to be assertive to keep control of the room. 
Testing can be a long day, and it can difficult for people to stay focused and to keep listening and paying attention. You may also need to discourage observer/note-takers from getting on their phones or checking their emails. To do this, you need to keep their hands and minds busy, so encourage them to help out by taking notes. We'll explain more about how to do this later in the chapter.
Explain the Rules to Observers
At the beginning of the research session, the host needs to explain the rules of the day to observers. This is important to make sure that their involvement in the day is productive and enjoyable for them. 
Rules of the day:

Encourage everyone to introduce themselves and explain who they are, what their role is and their involvement with the research project. 
Reflect on the objectives of the research and what you are there to learn about. This can help observer/note-takers to focus on what they need to be paying particular attention to and listening out for.
Share copies of the discussion guide and information about the participants (without personal details).
Tell people that any calls must be taken outside of the observation room to minimize disruption.
Discussion during the sessions must be kept to a minimum so that everyone can concentrate on watching and listening to the session. The real discussions can be done during the breaks.
If you are watching sessions using a two-way mirror, the lights must be down and there must be no loud talking or laughing.
Questions should be saved up during the sessions and given to the host towards the end. The host can then pass this on to the interviewer.

But the main instruction - over and above taking part in any activities or note-taking - is for them to watch and to listen.
Explain the Research Process to Newcomers
If you're working with stakeholders or project members who are new to user research, it's worth giving them some background information on why we run the sessions the way we do:

Over recruiting. You need to prepare observers for the possibility that participants won't show up as planned. Hopefully you or your recruiter will have confirmed the participants on the morning of the research. However, there is still a chance of no-shows . Overall, you can expect around 10% of your participants to not show up, but this does vary depending on the demographic and topic. Reassure them by telling them how you've over-recruited to minimize the disruption and risk of a no-show, and that a spare participant is available to jump in should someone not arrive.
Reviewing the approach. Let observers know that there will be a gap between sessions. This gives everyone in the observation room time to chat about how it went, and reflect on anything that could be tweaked or improved.
The first session will probably overrun. Give observers a warning that the first session nearly always overruns, and will likely be the longest of the day. Explain that the sessions are likely to get shorter as the day goes on, because the interviewer becomes more confident with the discussion guide and interviews get more concise and focused.
Collect questions during the interview. Let observers know that they'll have the opportunity to put questions to the participant the end of the session. The host should collect them throughout the session rather than firing them over to the interviewer in real time, as this can be incredibly distracting and disruptive. Explain to observers that there will be 5-10 minutes at the end of the session for these questions to be fed in by the interviewer.
Take stock after three or four sessions. Explain that after half of the sessions, you'll take time out to reflect on how the day has gone so far. This can give you a chance to think about improvements or tweaks to the session, any new activities you want to take into the session, or anything you want to remove.

Note-taker
As note-taker, you're responsible for capturing the salient and important comments, thoughts, behaviours and suggestions you hear from participants. Because there's so much that you could record, it can sometimes be difficult to know what to note down during a research session, which is why it's important to pilot your note-taking beforehand and discuss it with the rest of the team.
The note-taker also often acts as assistant to the host, so their full list of jobs includes:

Capturing notes
Starting and stopping the recording
Troubleshooting any problems with the prototype or technology
Anything else that the host may delegate to them

To help with this, we'll often print out the objectives and keep them on the wall in the observation room. You also need to consider how you are going to analyse your results. 
Finally, we should emphasize that, although the note-taker is specifically tasked with taking detailed notes, it's a good idea for the observers to join in too. They're likely to do this in different ways:

The note-taker will be concentrating on creating notes throughout. They'll be capturing more detail, possibly in a different format from the observers.
The observers will be creating notes whenever they feel the urge, but they shouldn't be expected to be doing so consistently throughout.

Taking Notes
There are various different ways to take notes during a research session. Below, we'll walk you through the different formats and approaches.
The way that you take notes will depend on the type of analysis you will be doing and the deliverables of your research. This can save you heaps of time later in the project.
Post-It Notes
Post-It notes are a really fantastic tool for note-taking. They're great for capturing issues and mapping out processes. What's more, they lend themselves to color coding and sorting activities, and their tactile nature makes them more engaging to work with as a group than notepads or laptops.
In the observation room, it's a good idea to use three colors to allow you to take different types of notes.

We use pink Post-It notes to make notes about pain points that come up during the session. These are problems that participants encounter, things they find confusing or difficult or goals they can't achieve because something is missing or poorly labelled. 
Green Post-It notes are for positive comments or interactions. A participant may successfully complete a journey or express delight or excitement at a particular feature. 
We use yellow Post-It notes for suggestions or more general observations. Suggestions are things that the participants express - maybe they would like a way to compare several products. Or maybe they would like web chat as an additional way to get in touch. 


Using Post-It notes
There's no hard and fast rule: depending on the nature of the research you may want to use colors to signify other types of note, such as quotes or steps in a journey.
Our rules of recording on Post-It notes are:

One comment or observation per Post-It.
Make sure the participant number is on the Post-It note.
Include the time on any key moments that you may want to go back and re-watch or use in presentations or compilation videos of your testing.

Post-It notes are a great format because they force you to be selective with what you capture. You can't write everything you hear verbatim, as you might be tempted to do if you had a blank document open on your laptop. It forces you to focus on the key points.
Post-It notes are also helpful in analysis, as they can be moved around and grouped. If you have lots of observers, they can be a great indication of the salient points or issues that matter because you'll have lots of duplicates. We talk more about using Post-It notes for analysis in Chapter 8.
When it comes to arranging your notes, you have a number of options:

You can stick them directly onto printed out screengrabs of your product.
You can arrange them as a journey map, grouping them under each stage of the process.
You can agree headings mid-way through the session, and group your Post-Its under those headings.
You can create a group for each participant.
You can conduct an affinity sort (see Chapter 8), to uncover themes.

Taking Notes in a Spreadsheet or Trello
Earlier, we mentioned that the outputs of some research you're doing may be a list of issues. It is likely that you will be asked to prioritize that list so the team knows what to tackle first.
Using a spreadsheet to capture usability issues is useful if:

You're working on sprints and/or iterating on your designs.
You've been asked to produce a prioritized list of issues.
You need to provide a set of recommendations.

Taking notes straight into a spreadsheet can speed up your analysis and output. Otherwise, you may find that you spend time writing up your Post-It notes into a spreadsheet, which is a waste of your time!
Here's a format that works well for note-taking:

In the first column of the spreadsheet, we place screen grabs of each of the screens we're testing. 
If it's a live website, the second column would have the URL of the page. This is especially useful for people who weren't able to see all of the research, or if you're going to be referring back to the document for some time. 
The third column may have the name of the page - this is useful for cross-referencing with the discussion guide. It makes it clearer and easier to follow during the session, as well as in the analysis, if each page has a name.
The fourth column is where we list the issues. Each issue has its own line. The fourth column can be used for tallying up how many users encounter the same issue - this can be useful in your analysis when you're prioritising the issues you find.
The final column is used to propose solutions - this will be filled in after your analysis.

Alternatively, you can use Trello in a similar way:

Create a list for each page.
In each list, create a card and add a screengrab of the page and the URL.
Then add a new card for each issue or observation, within the relevant list.
Use colors to indicate which participant the cards apply to.

Taking Typed or Written Notes
If you're running depth interviews, you may not necessarily be showing users a prototype or a thing. You may just be exploring a journey, or trying to understand the participants' needs and experiences. Because this kind of discovery research is more open-ended, you're likely to need to use a mixture of Post-It notes and written notes to be able to capture what you're hearing and seeing.
If you're using your laptop to take notes, you can use whatever word processing software you like the most. Something like Pearnote or Evernote works well.
Here are some tips for taking notes on a computer or paper during discovery research:

At the start of the session, write down the participant number.
As with writing Post-It notes, jot down the time when you hear or see something that is salient or particularly interesting that you may want to go back to.
Create a code so you can label every comment you capture. This is the equivalent of using color-coded Post-It notes. For example, you may use 'O:' at the start of an observation, while 'P:' can be used to signify a pain point, and 'Q:' indicates a quote. If you're using a computer, then these codes enable you to find quotes and so forth in the document later using control + F.
You can also use a code system that relates to particular points in the discussion guide, for example '111' might be used to indicate content about the delivery process.
Use square braces if you want to comment or say that you missed a bit.
Try using markdown to simplify your note-taking.
Consider how you want to phrase the things you write down - ie, do you just write it down verbatim or do you want to paraphrase? Do you inject your own thoughts or just record what happened?


Example of note taking code
Having a code will make your analysis easier and more efficient. It also helps you to focus and narrow your note-taking. It will also stop you taking notes verbatim, which could lead to pages and pages of unstructured content.
Taking Notes in Guerrilla/Field Research
If you're guerrilla-testing as a pair, one of you can do the interviewing and running of the session while the other takes notes.
If you're guerrilla-testing on your own, you'll need to take notes as well. This is no different to taking notes in a lab testing session, which we talked about earlier in the chapter. However, it's difficult to take notes and interview at the same time, so avoid it if you can.
In guerrilla research, the medium for note-taking will depend on the setting:

If you are able to run your sessions from somewhere like a cafe, you may want to take typed notes. 
If you are testing people on the go, for example on a bus, taking notes on a laptop may be more difficult, and you may not have access to anywhere to charge your laptop. In this case, it's worth having a semi structured form that you can fill out. Have a box for each main question area, with a space for you to jot down your notes and observations.

Taking Notes after the Interview
Whatever type of interview you're doing, and whichever note-taking method you're using, you should always try to jot down your thoughts after the interview. Ideally, try to do this immediately after the session, but if not you can do it at the end of the day or on the journey home. You don't need to write lots: half a page is plenty. Try to cover off the participant's main priorities, the answers to the main research questions, changes to rolling hypotheses, your feelings and impressions during the interview, and any ideas that occurred to you.
Tools For Recording
Where possible, we would always recommend that you record your test sessions. There are a few reasons for this. 

There will be occasions where you may not have time to take proper notes about something you heard. On these occasions, you will make a note that there is something interesting to listen to at a certain point in the recording. This allows you to go back to it when you have more time. It is important that the quotes you use are accurate.
Recordings are also great for providing evidence. There is nothing as powerful for stakeholders as hearing real users struggle with parts of what you are testing. That can be one of the most helpful things to drive improvements in a website or service.
Recordings are also helpful at refreshing your memory about what happened in the session, or who the participant was. 
They enable you to make a transcript and review the whole session if you need to.
Finally, they are a great training tool. Take some time to watch some of your sessions to see how you can improve your interviewing technique.

The way you record your sessions will depend on what you are testing and where you are testing it.




Lab
Guerrilla
Remote




Audio

Stand alone microphone Built in laptop/desktop microphones Recording software, such as Pearnote.
Dictaphone Or use the voice recording software built into your smartphone.  Recording software, such as Pearnote.
Built in laptop/remote microphones.Stand alone microphones may also be able to pick up the sound. Recording software, such as Pearnote.


Video
Most labs will have cameras built into the set up. If not, you can use a portable video recorder. Record the screen of mobile devices using Quicktime through your labs desktop.
Camera phone, portable video recorder such as a GoPro. Record key moments to cut down on editing time later.
Screen share using something like GoToMeeting. Screen recording software, such as Quicktime.


Photos
Stills from video recording software.
Camera phone is perfect. You may want to opt for something handsfree like the Narrative Clip. Take photos of people using the thing you are testing - action shots are great
Stills from video recording software if you are camera sharing.



Top Tips For Recording Your Sessions
Getting back to base to discover that you've got a poor recording, or no recording at all, is extremely disheartening, so make sure you're prepared:

Take a test recording. When you arrive in a new location, take test recordings of your video and audio.
Get permission. Also ask your participants before you start recording. Some people may not feel comfortable, and you have to respect that. It can also be a good idea to check at the end, especially if the participant has shared some personal information.
Be aware that recording in public places can be noisy. This can make it difficult when you try and listen back to your recordings. Place your recording device as close as you can to your participant, use a directional mic or a lapel mic, if you have access to one and the participant is OK with it.
Always take photos of your sessions and outputs. They are great for deliverables and can help to jog your memory in the analysis.
Small and discreet recording equipment is best. We've found that this makes people feel more comfortable, and they quickly forget there is a camera around.
Make sure you have enough space and charge on your equipment. You don't want to run out halfway through a session or when you're out in the field away from power.
Take spares. Spare batteries, chargers and spare recording equipment. Be prepared for your equipment to fail, and have alternatives ready.
Some recording software will record the sound of your key taps. If you're using a laptop to record sound as well as taking notes, check whether or not you can hear your key taps. It can really affect the quality and usefulness of your recordings.
If you're working in the lab, using multiple recorders. Use several cameras to capture different angles (for example, recording the screen as well as a shot of the participant's hands interacting with the device). Use at least two audio recorders. Multiple recordings means you've got backup if anything goes wrong.
Record the screen when testing on a mobile device. These can be used for deliverables and can be powerful evidence to support your findings. You can use software like Quicktime through the desktop in your lab to connect to your mobile device. 
Be aware that using software such as Quicktime in the lab means you can't record picture in picture. This means that your recording won't have input from any other cameras that you may have set up in the lab.
Find software that records audio as well as your screen. We use Silverback but there are lots of other similar tools that you can try, like Camtasia or Screenflow. Something like this is ideal as it saves you time cutting together the audio and the video after testing.


Some guerrilla research
The Practicalities of Using Different Devices
Because there are an ever-growing range of screen sizes and devices available, you may find yourself working on prototypes for one or more of these devices, so you need to be prepared to test on all of them.
The practicalities of testing on any of these devices is pretty much the same. You just may find that the facilities you're using are more geared up to testing on one - usually desktop. That means that testing on another sort of device will take a bit more planning and preparation.
If you are using a lab that is geared towards testing on desktop, you need to first make sure you have access to the devices that you want to test on. Check that the lab supports the devices. If you're not sure, arrange to visit in the week beforehand to check the setup. You then need software that allows you to hook the testing device to the desktop screen so you and observers can see what the participant can see. We tend to use something like Quicktime so we can view the device screen on the desktop. This makes it nice and big in the observation room, and we can record it all as if we were testing on desktop.
Remote Testing When Using Different Devices
Remote testing can take a little more consideration, as we mentioned in Chapter 4. Screen-sharing software is a good option - you can then check everything is working on your machine, share your screen with the participant, and give them control of your screen. You can also record your screen using screen capture tools.  Products like GoToMeeting, Google Hangouts or Skype will allow you to do this.
It is a little trickier with mobile and tablet remote testing as it takes more setting up. However, there is software available that allows your participant to join the session with the device that you need to run the research on, such as GoToMeeting. Keep in mind that they may need to be sent links to websites or prototypes depending on what you are testing, and this will need to be prepared and sent well in advance.
Guerrilla Testing With Different Devices
Before you go out testing, you need to make sure you have access to the devices you need, and that they are fully charged. If you're testing with a specific smartphone, you'll want to check that your potential participants are users of that smartphone. For example, if your users haven't handled an Android phone before, the learning curve and potential frustration could take a substantial chunk of your session, which is already pressed for time.  
Summary

The key to smooth research sessions is in the preparation leading up to them.
There are four main roles your project team will need to take on: Interviewer, Moderator, Observer/Note-taker and Note-taker
The host is in charge of the observation room and needs to set the rules, guide the discussion and encourage observers to take part in activities or help with the note-taking.
The note-taker will be capturing the insights from the sessions. The type of notes needed will depend on the deliverable. Key insights are: pain points, positive observations, quotes and suggestions.

















Chapter 7: Interviewing
In this chapter, we'll show you how you can get better at running user research sessions. We'll cover interviewing techniques, managing tasks, and how to deal with tricky situations that can throw you off balance. As we mentioned in Chapter 6, interviewing is only one of the activities that takes place while you're running the session. But because it's so important, it gets a whole chapter to itself.

Research cycle: fieldwork
Show Participants How to Help You
Research interviews are a strange, artificial social interaction. If they're in a purpose-made research lab with cameras and recording equipment, they're even stranger. 
Fundamentally, an interview is an exchange of information between two people. But think of how many variants that includes: job interviews, police interviews, dates, quizzes, journalistic interviews... the list goes on. In each case, there are subtle differences in the rules and dynamics. Through personal experience - or from watching television - most people have an understanding of how that social situation works.
Think now of research interviews. In many cases, participants have no idea what to expect. Is it a test? Is it a chat? Will I be expected to give away intimate information? Because they don't know what the rules are, they'll be nervous, and they'll look for analogies in other interview-like situations that they're more familiar with to make sense of it. They want to help you, but they don't know how.
This is where you can show the way. By clearly communicating the rules, process and expectations of the session, you can show them how to help you. They'll be relieved, and you'll get a better, more open, session.
The rules of a research session:

There are no right or wrong answers.
Negative answers are OK.
We're testing the product, not you.
If you don't want to answer, you don't have to.
If you don't want to stay, you can leave at any point.
The researcher isn't an expert on this subject either: they're here to learn from you.
If you've got a problem with your account or a complaint about the client company, the researcher won't be able to help with it.
Phones should be turned off.

By stating the rules at the beginning (and reminding the participant about them as necessary later on), you can build trust, and avoid misunderstandings. Sometimes, we find it helpful to post the rules on the wall of the interview room for further emphasis.
If you want a session to run smoothly, the first thing you can do is be clear about what you need:

As you're briefing the participant about the session and introducing them to the consent form, ask them what they're expecting. Tell them what will happen. Make it a conversation, not a speech.
At transition points in the session, remind them. Typically this would be just before you introduce the first main task, and in the final five minutes, before you ask them to sum up.
If the participant is doing something you don't want, say so. Be firm (but pleasant and polite) in your moderating. If they're rambling or veering off track, say something like: "That's not a topic we've got time for today. I need to ask you about this instead." You'll be surprised how receptive participants are to this. Don't forget: you're giving them clarity about what they need to do and how they can be helpful.


Dressing for Your Interview

Consider what you wear when you're running interviews. Use your clothing to make your participants feel at ease, and to set the tone of the session. We tend to dress informally and comfortably to reflect the way we run our sessions. Also consider who you are testing with. There may be occasions when more formal clothes are a better option, for example when researching with businesspeople or on a more serious subject.


Observing vs. Asking
When we think of interviews, we tend to think of a series of questions and answers between two people. In reality, the words are just the beginning - you have many more tools at your disposal. 

Your observations of the participant as they complete tasks and activities. The classic scenario is to ask someone to carry out a task on a website, but it could be a game, a card-sorting exercise, a worksheet, or many other things.
Nonverbal communication: body language, gestures and the like. Does it echo what's been said, or contradict it?
The participant's tone of voice, energy, mood, cadence, and how these are changing over time.
If there's more than one participant, the dynamic and interaction between them.

Because this kind of concentrated listening goes beyond just the words that the participant voices, we call it 'paying deep attention'.  
Paying Deep Attention
When we train researchers, they're often most nervous about how to ask questions. Actually, the core skill is simple: stop worrying about your next question, and instead pay attention to the participant. You'll find your next question comes naturally from what they say or do.
Obviously there's a bit more to it than that. Firstly, paying deep attention is harder than it looks, especially when you need to sustain it over time and avoid the temptation to judge. Secondly, there are better and worse ways to ask a question (which we'll cover below). Thirdly, as moderator you'll normally be juggling several other tasks: making sure the prototype is working, keeping an eye on the clock, ensuring you're covering off the topic areas in your guide.
There's no shortcut to mastering deep attention. You may find it easier if you've practiced mindfulness, or if you're gifted with strong powers of concentration or empathy. The best way to develop this skill is to practice it:

In your research interviews, try to catch yourself if your mind is wandering. Recognise why this is happening: are you bored, distracted, hungry? Maybe you disagree with something the participant has said, or find their personality objectionable. Maybe you're thinking about solutions. In each case, you've stopped paying deep attention. Mentally acknowledge what's interrupted you, and refocus.
After interviews, watch one or two recordings. Pay attention once again to the participant, and critique your questions. Could you have followed up on what they said or did more effectively? Also, watch out for the ratio between listening and talking. In a depth interview, you should be speaking for approximately 15% of the time, compared with the participant's 85%. If it's closer to the 50/50 split you'd expect in an everyday conversation, then you're talking too much. Next time, give the participant more space to talk and think.
In your everyday life, practice paying attention in your interactions: really focus on people's words, body language, tone and the relationship between what they say and what they do. Practice listening without judging. Apart from the boost this will give your interviewing, it's also a great transferrable skill, applicable in many areas of your life.
Try to become more comfortable with pauses and silence in conversation (we'll say more about this below).

Starting the Session
If we're doing lab testing, we always introduce ourselves outside of the testing room and explain what is going to happen during the session. We've found that this makes people more comfortable than taking them straight into the test room, because it puts them at ease while they're getting used to you and the rules of the session.

Our waiting area
In our waiting area we have a comfortable sofa, some magazines, and we offer everyone a cup of tea or coffee. The interviewer gives the participant a few minutes to settle in and then goes to say hello. We introduce ourself and thank them for taking the time to come in and help us out. We explain what we're doing and what they can expect from the session, and give them a chance to ask any questions.
Make Sure You Get Consent
You need to explain your consent form to your participants and be ready to answer their questions. You can read about writing a consent form in Chapter 3. They have to understand what is happening and provide their consent before you can start the session with them. At this stage, you should also make them aware of any codes of ethics or professional standards that apply. For example, at cxpartners we abide by the MRS Code of Conduct.
At the end of the session, you may also want to re-confirm the participant's consent by asking if they're still OK for you to keep a recording. 
Starting Guerrilla Testing Sessions
If you're guerrilla testing, you'll have less time with people to introduce yourself. Also, while you're introducing yourself you're also trying to explain what the research is about, and persuade them to help you. That's tricky and needs some consideration.
What you shouldn't do:

Avoid opening by asking a question that could be answered with a "no". For example, "Have you got 10 minutes?" People will have no idea what you will be expecting them to do, so this is going to make them reluctant to commit their time. They're also likely to be busy. Why should they give you anything?
There is also a chance that you will be mistaken for a charity collector, which will make it even more likely that people won't stop.

What you should do:

Ask a question related to the subject or product you're researching, to start the conversation. So if you're developing an app that will allow people to buy bus tickets, you could ask something like, "Hi, sorry to trouble you. I was just wondering if you bought a bus ticket in the past week?"
If they answer yes, you could say, "I've been working on something to try and make it easier to buy tickets. Would you mind taking a look at it for me and telling me what you think?"

This gives people context, establishes their eligibility, and starts a more natural conversation.
How to Ask a Question
In this section we're going to look at how questions work:

Individually, questions have their own syntax. If you follow these rules, it'll be easy for participants to understand what you're asking them.
 In sets, questions have a combined power. If you use questions effectively in combination, you'll get to the answers you need more quickly and with less effort.
Good questioning relies on timing. Choosing the right moment makes your questions more thought-provoking and revealing.

Here are 10 pointers to making you a better interviewer. Try to focus on one or two of these each time you run a session, and ask your colleagues for feedback on how you did.
1: Clearly State the Subject and the Query
Think of a question as having two parts:

The subject (what the question's about: football, ice cream, holidays).
The query (what you want to know about it: what's your favourite? what was your most recent experience?).

On their own, neither is much use:
Subject: "Let's talk about ice cream."
Query: "What's your favourite flavor?"

Yet when we combine them, it's clear what we're talking about and what we want to know:
            "Let's talk about ice cream. What's your favourite flavor"
Asking the subject first, then the query, makes it slightly easier to process the question. But you can introduce them in either order:
            "What's your favourite flavor of ice cream?"
2: Don't Use Leading Questions: Establish Relevance Instead
A question like, "What's your favourite flavor of ice cream?" introduces a new issue. With this structure, we've assumed that the participant has a favourite ice cream flavor, and therefore the query is relevant to them. We've asked a leading question. This is bad news, because the participant may feel under pressure to pretend to like ice cream, and invent a favourite flavor. That's worse than no answer at all.
To avoid this problem, we should use a qualifying question to establish the relevance of our query:
"Do you like ice cream?"
"What's your favourite flavor?"

3: Keep Your Question As Short As It Can Be
It's easy to ramble on about the subject and let it turn into a kind of introductory statement, as in the example below. Apart from wasting time and patience, it's possible that the participant will forget what you were asking about! 
Subject:"The next thing I'm going to ask you about is ice cream, which is something that we'll talk about now, and then later on in the interviews, but in the meantime I want to ask you about it initially."
Query: "What's your favourite type?"

It's best to avoid this kind of rambling, but if you do need use an introductory statement, always restate your subject immediately before or after the query:
Introductory statement:"The next thing I'm going to ask you about is ice cream. We'll talk about it later on in the session too. But I've got some initial questions that I need to ask you first"
Query and subject reminder together: "So, what's your favourite ice cream flavor?"

4: Closed Questions and Open Questions Have Complementary Strengths and Weaknesses
Closed and open questions both have their role, and it's best to use them together.

Closed questions (eg, "Do you like ice cream" or "Which do you prefer, cupcakes or donuts?") are easy to phrase and understand. They require less cognitive effort from the participant to answer. They're better for putting people at ease than more challenging open questions. And as we saw above, they're good for communicating the subject and establishing relevance.
Open questions (eg,"What do you like about ice cream?"; or "What's your favorite flavor?") do most of the real work. They give participants the liberty to explore and talk about the subject in their own way, revealing their thought processes, needs and preferences in the process. The disadvantage is that they're harder to answer, can be more intimidating, and can be a cue to ramble for some people. Open questions tend to begin with words like 'what', 'who', 'when' or 'how'. It's generally best to avoid 'why', because it can lead to post-rationalised answers.

5: Look Out For 'Value Words'
There's a certain kind of word or phrase that you should be particularly attentive to when a participant is speaking. We call these 'value words': adjectives or descriptions that appear meaningful, but are actually open to wide interpretation. Some examples: "corporate", "cluttered", "gritty", "feels like the real thing", "my kind of place".
When you hear value words, you should do one of two things:

Follow up with a probe there and then. You do this by repeating back the exact phrase or word, and then asking an open clarification question: "You said the website felt corporate. What do you mean by 'corporate'?" "You said the shop 'feels like my kind of place'. What makes it feel that way to you?"
It might not be the right moment to follow up. Make a note of the value words on a pad or Post-It note, and keep it in reserve to return to later.

Value words are your doorway to real insight in the interview. Don't waste them!
6: Listen For Contradictions and Gaps
Imagine you're a detective. The participant will be wanting to present a certain version of him or herself to you: perhaps someone who exercises every day and eats plenty of fruit and vegetables. Whether or not this is a conscious effort on their part, it's unlikely to be the whole picture.
If you can be attentive to contradictions in the research session, you're more likely to get under the skin of the topic, and find out what's really going on. This might be a contradiction between what someone said and what they did:
            "Earlier on, you said your preferred holiday destination was Mexico, but when you went onto the website, the first page you visited was South Africa. That's interesting isn't it? Tell me more about that."
            Or it might be an inconsistency between two different statements that they made:
            "Earlier on, you said that your favourite ice cream flavor was rum and raisin, but just now you said it was coconut. Do you have more than one favourite flavor, or is there another factor at play here?"
When you've spotted the contradiction, follow it up. It's absolutely essential that you're respectful in your phrasing, but participants are generally curious about their own internal processes, and intrigued by what you've shown them. 
Sometimes it can be as interesting to note what's not happened. Perhaps the participant had mentioned a subject they were interested in, but flicked straight past it in the material you were asking them to look at. Or perhaps you were expecting them to comment on a particular design, but they said nothing.
It's ok to draw attention to this. Your expectations (your rolling hypotheses, in other words) need checking, so ask:"A moment ago, I was wondering if you were going to click on to the information about Mexico, but you didn't. Looks like I was wrong! Can you help me to understand your thought process?"
7: Use Question Chains
Now that you've been introduced to the main question types, you can learn to use them in sequence, as 'question chains'. Here's an example:
            
Subject: "Let's talk about going on holiday."
Relevance:"Have you been away this summer?"
Query: "Where to?"
Participant responds: Sri Lanka
Open question: "What drew you to Sri Lanka?"
Participant responds: It was a great deal, and it's a bit unusual.
Probe: "When you say 'unusual'...?"
Participant responds: I like to go to places that are a bit unusual. Somewhere a bit different. Not just the usual places that everybody goes to. And it's a resort, so you've got your home comforts too, there's a bit of predictability.
Query contradiction: "Let me check then. So you're after somewhere that's a bit unusual, a bit different. And you also want your predictability, your home comforts?"
Participant responds: "I hadn't really thought of it like that. I suppose what I want is a taste of adventure, without really going off the beaten track. Something to show off about at the water cooler when I get back to the office.

In that example, we've gone from using closed questions to establish relevance and initial facts, before using an open question to really kick off the conversation. We jumped on the value word 'unusual', and then explored the contradiction between adventure and home comforts. And in doing so, the participant has shared something that really matters to them: it's important to them to be able to show off about their holiday afterwards. In other words, we've gone from some very neutral facts, to a statement about feelings and self-perception.
Once your chain runs out of steam, you can start another one. As you get more practiced, you'll be able to run several question chains at once, spotting the contradictions between them as you go, and reviving them when the time is right.
8: Prompt, But Don't Lead
When you want the participant to keep talking, but you don't want to ask a new question, you can use prompts. It's helpful to have a repertoire to use. These can include:

Short phrases such as "OK", "tell me more" or "carry on". It's important to keep these neutral so they don't lead the participant. If you were to say "yes!" or "that's right", then you'd be tempting them to tell you more about what you wanted to hear.
Non-word noises like "um-hm" or "uh-huh". These are better because they're less of an interruption to the participant's flow. On the other hand, they can feel awkward, so experiment to find one you're comfortable with. 
Body language. A nodding head can lead participants in the same way as"yes", so go for something more subtle. One way is to tap your foot in time to the rhythm of their speech, and then keep it going if they stall. Or raise your eyebrows to indicate "go on".
Silence is a great prompt (see below).

9: Choose The Right Moment
The timing of your question is as important as the phrasing. If you choose the right moment, you'll barely have to give any explanation: the participant will understand what you're interested in and give you a long, detailed answer. Choose the wrong moment and your question will fail, or get a radically different response. 
Here's an example. Imagine you wanted to get feedback about a new website design from your participant. Your plan is to ask them:
            "I'd like to know what changes you'd like the designers to make to this website. What are your top three suggestions?"
            If you asked this question after the participant had used the site for just 60 seconds, then you'd be likely to get comments that focused on visual design: "the colours are too garish", "I don't like the photography", etc. If, on the other hand, you asked them at the end of the session, they might concentrate on difficulties with completing tasks, or missing functionality. Be flexible about the order in which you tackle subjects, and don't feel obliged to follow the sequence in the discussion guide.
10: Be Quiet
Most people who are learning to interview talk too much. They don't give the participant enough space to talk or think, and as a result they miss valuable insights. Get used to silence - become comfortable with it. Some participants (particularly more introverted personalities) appreciate a moment to gather their thoughts before or after answering a question. What's more, silence is a great prompt.
As you get more accustomed to interviewing, you'll create your own methods and favourite questions. You'll develop your own style. And because you're comfortable with the technical side of interviewing, you'll be able to pay deep attention at the same time as juggling your various other tasks. Once you're up and running, interviewing participants can be fascinating, and great fun. Enjoy it!
How To Get Out Of Trouble
The vast majority of problems that occur with participants during interviews relate to your setup. If they've been correctly recruited, you've piloted the session and prepared your material, warmed them up, and been clear about your expectations, you'll find that sessions run smoothly most of the time. 
Occasionally, though, you'll find yourself in a difficult situation. See it as a challenge: there are plenty of techniques you can use to get yourself out of trouble. If you're finding a participant uncooperative, select from the escalating scale of tactics below to help turn it around.

Getting out of trouble: an escalating scale
The main point to remember is: never panic. You're in charge. Easier said than done, perhaps, but don't forget, it's your interview and you're the one setting the rules. Even if you can't control how the participant acts, you do get to choose how the session is run, and whether to terminate it. Just having that knowledge in mind can be enough to avert a drama.
Summary

Be clear about your expectations with participants, and they'll be better able to help you.
Practice paying deep attention, and you'll find your questions flow from participants' answers and behaviour.
Get to grips with question syntax, and learn to use question chains, so the structure of your interviewing comes more easily. That'll leave you with extra capacity for paying attention.
Dig deeper into participants' responses by using value words.
Sometimes you might get into trouble, but there's always a way out. Never panic. 

















Chapter 8: Analyzing Your Data
Analysis is the core of the research process. It's where you transform your raw data (in other words, your observations about what users did or said) into insight and ideas. It's where you organize your evidence and agree upon a shared understanding of the facts. It's the foundation of good design work to follow. 

Research cycle: analysis
Despite its importance, analysis is often overshadowed by more flashy parts of the process, such as debrief presentations or the interviews themselves. But it shouldn't be. It often happens behind closed doors, but it shouldn't do. Analysis should involve the people who will use the research - such as product managers, designers, developers and marketing colleagues - not shut them out.
In this chapter, we'll take you through a more systematic way of doing what we all do on a daily basis: making sense of the world as we encounter it. You don't need a particular academic background or theoretical framework to do this kind of analysis, but it can appear to be intimidating if it doesn't have a structure. If you plan your activity and approach it step by step though, you don't need to worry.
Why Bother?
You've finished interviewing, and you want to get on and use what you've learned. You feel like you've already got some of the answers in your head. In those circumstances, analysis can feel like it's an unnecessary extra hurdle, getting in the way of your progress. But if you skip it, you're missing out. Here are six good reasons for spending time on analysis:

Just because you have a lot of data, doesn't mean you've digested it. You need to understand it before you can make good decisions with it.
It will stop you from feeling overwhelmed. You might have a sense of what's going on, but you need to organize your observations. When we feel overwhelmed, we have a tendency to jump to conclusions based on the most vivid, memorable evidence.
You saw what happened, but you still need to figure out why it happened. If you don't do the analysis, you won't be able to separate out different causes, and you won't know what to act upon.
You need to organize examples of compelling evidence to make your case to others. To a skeptical audience, your off-the-cuff reflections won't convince them to change their minds. Analysis allows you to process the data into assets that can be shared with the team. 
You may need to use your data generatively, to come up with ideas. If you want to get beyond the obvious and avoid a rerun of ideas that have been tried before by others, you'll need to really dig into the data.
 Involving your colleagues in the process of analysis can help them to weed out personal bias and build team spirit around the research project. 

Phases of Analysis
See analysis as an ongoing activity throughout the project. It begins right at the start, and runs all the way to the end, when you've got the insight, evidence, ideas and story you need. There are five distinct phases for analysis, and if you base your approach on these phases, you're less likely to get lost. You can be realistic about whether you're on track, and avoid wasting valuable time. 
The first three phases are non-negotiable. You'll have to do these to some extent, even if your project is very short.

Make a plan. You'll do this right at the start of your project, and return to it when you get into fieldwork.
Absorb the data. After fieldwork, you'll need to tidy up the data you've collected into a usable shape. This phase focuses on organizing and digesting the evidence.
Find patterns. Sift the data to uncover common themes and explanations. This phase focuses on generating the insights.

Phases 4 and 5 are optional, depending on the outputs you need from the project.

Use patterns. Reconfigure the patterns you've uncovered to generate new ideas. This phase focuses on producing ideas.
Create your narrative. Rework the insights and evidence as a communication. This phase is about creating a story.

The reason they're optional is that research projects aren't always about generating new ideas, or producing communications. If you're working in an agile environment, and you just need to get answers and share them informally or add them to a backlog, then you can skip phases 4 and 5.
Cherry-picking Analysis Activities
Once you understand which phases you need to include, you can start to figure out what you'll be doing in each of them. It's a good idea to take a modular approach: depending on what you're trying to achieve, and how long you've got, you can keep it simple by choosing one quick module, or go into more depth by going with multiple modules in each phase. The different modular activities are described later in this chapter. Taking this approach has several benefits:

You can choose the mix of modules that best fit your needs, objectives and experience.
You can invent or add new activities and slot them alongside your existing favourites.
If analysis ever starts to feel stale or formulaic, you can mix things up to keep it fresh!


Analysis modules
As an illustration of how this works, you can see the mix of modules for three example projects below:
 
            

Small discovery project

Large discovery project

User test
How Much Time Do I Need?
The more research sessions you're running, and the more data you're dealing with, the greater the stakes when it comes to analysis. It means there's much more to discover, but it also means it's easier to become lost. It's obvious, but you should allow much more analysis time for a major discovery research project (where you want to understand behaviour in depth, and may hope to generate novel ideas) than you would do for a quick round of user testing.
Sometimes, of course, you just don't have much time for analysis. Where that's the case, you need to be hyper-organized before you start interviewing: you can see a time breakdown for this kind of research in the table below.



Stage
Discovery research
User testing
Quick & dirty day of research




Planning
An hour
15 minutes
5 minutes


Absorb the data
Equivalent of the research session time (ie, one hour of interview equals one hour of re-listening), plus one to two days for other activities
An hour to collate notes
None. All of the data will be collected in a pre-prepared format (eg, a spreadsheet or the output of a workshop activity), which makes it easy to use immediately


Finding patterns
Two days
Two hours
One hour, on the same day


Working with patterns
One to two days
One to two hours (optional)
One to two hours (optional)


Creating a narrative
Two hours
Half an hour
Half an hour



For a large discovery project, it can be helpful to think of the analysis phase as a distinct sprint, and plan accordingly.
Phase 1: Make a Plan
The purpose of this phase is to make sure you're getting maximum benefit out of the rest of the project. You'll make sure that you're recording the data in a format that makes it easy to work with, and you'll make best use of the time you've got for analysis afterwards. 
Who's involved: the core project team, including designers and researchers.
How long: 5 minutes for a small, simple project, to two hours for a more complex discovery project.
Where to do it: in the project space, or a meeting area with a large wall or whiteboard.

Activities
You'll need to work through a series of activities. If there are several people in the team, it can be best to do this in a structured way, as a mini-workshop. If it's just one or two of you, it can be more informal.

First, be clear about your end output. Do you need ideas? A backlog of improvements? A better understanding of your users' needs? A business case?
Secondly, clarify your resources. How much time do you have for analysis after the interviews? What kind of space will you have to work in?
Third, sense-check the kinds of data you're going to collect, the equipment you're going to use, and the evidence you might need (see Chapter 2). Example: you have a hypothesis that customers are ignoring letters from your company because they see them as junk mail. If it's true, you expect your marketing team to be resistant to the finding. Because you know you will need evidence, you decide it would be helpful to collect photos of participants' piles of unopened letters. Add a camera to the list of equipment to take with you to the interview.
Fourth, decide whether you need to generate ideas or not - in which case, you can drop Phase 4, and whether you need to create a story or not - in which case, you don't need Phase 5. 
Fourth, map out the time available on a wall or whiteboard. 
Now, choose activities to go into those spaces. As a guideline, there's usually time for two activities in the morning and two in the afternoon. Use a Post-It for each activity. Make this planning process a discussion with the team, as it will help to build consensus and highlight any disagreements about the best way to proceed.


Analysis planning
What to watch out for:

Analysis planning is also a great time to discuss hypotheses. Doing so at this stage will help you write your discussion guide and plan logistics for interviews.
Use the session to surface any doubts or misunderstandings about analysis. Expect some of your team to be unfamiliar with the process, or with particular methods.
The clearer you can be about your analysis approach before you begin fieldwork, the better your notes and data collection will be, especially if you're relying on other people. Planning well saves time and wasted effort.
Be prepared to come back to your planning and rethink it as the project goes on. Because your planning is always subject to change, keep it in a format that's easy to revisit and revise. If you can't hang on to your project space, take a photo or use software like Trello or Excel. 

Phase 2: Absorb the Data
When you finish interviewing, your data probably isn't in a very tidy format. You may have audio recordings that need to be exported, notes that need to be tidied up or printed, and photos that need to be categorized. If you've done more than a handful of interviews, it's likely that you've begun to forget what happened in the first sessions, and can only recall the most recent or vivid participants.
The purpose of this phase is to re-absorb the detail of the data, and to get it into a format that's easy to work with for the following phases. When you're finished, you'll have the detail in your head and also in an external format such as Post-Its, written notes or a spreadsheet.
Who's involved: the people who conducted the research, working individually
How long: extremely variable, from hours to weeks
Where to do it: somewhere quiet, where you're less likely to be disturbed

Depending on your requirements, and the time you've got available, you'll want to select some activities from the options below (or others you may prefer). Don't worry that you haven't got time for all of them, or even most of them! If you're in a hurry just choose the quickest ones.
Create a Space
If you don't already have one, now is a good time to create a project space. Ideally, this would be a whole room, but if not, you can get by with a wall, a whiteboard or a large sheet of brown paper.

Example project space
The purpose of a project space is for the team to be able to immerse themselves in the data and cut out distractions. Handily, it's also a good way to share your work with curious colleagues as a sort of mini-exhibition for a show and tell (see Chapter 9).
To create your project space, begin by building a stimulus wall, using a selection of the different printed resources available to you. These could include:

Participant quotes
Photos of participants or their environment
Screengrabs
Leaflets
The project sample structure
Infographics or slides 
A map of your travels
Sketches
Post-It notes of observations.
            Don't feel like you need to be completely exhaustive: a selection is fine. Leave another blank area of wall (at least two metres squared) for working on in the next phase.

If you don't have a handy wall space, don't panic. It's not essential, and you can create an online equivalent using digital spaces like Trello for quotes and observations, and Tumblr for videos and images. However, do be careful of data protection rules when you choose where to upload sensitive information from interviews.
Collate Sources
Even in the simplest project, you're likely to have data in several different sources or locations. Gather it together. 
If you've been thorough in your analysis planning earlier, you should already know what types of data you were intending to collect, but you may have added others in the meantime (by opportunistically picking up a leaflet while you were conducting ethnography, for example). You may also have other sources, such as analytics or reports that you could be referring to. Make sure you get what you need from the whole project team, and ask for it in plenty of time. Waiting for your colleague to get back from holiday so you can access their notes is an irritation best avoided!
Reformat
Sadly, the format you found convenient for capturing data is probably not the most convenient format to work with in the analysis. For example, dictaphone recordings may be in a proprietary format, and need converting to MP3. Photos may need printing. Expect to spend some time re-formatting your data: for video content, handbrake.fr is a free and effective tool.
Rejecting Bad Data
It feels somehow wrong to throw away data, but now's the time to be ruthless. Bad data is your worst enemy: it will lead you to the wrong conclusions. If you're working with colleagues who don't have much experience of research, it's even more important to get rid of it, because they will be tempted to take it at face value.
The main source of bad data in qualitative research is mis-recruitment. If you had a participant who wasn't part of your target user group, then it's best to jettison them from your analysis rather than include them just to make up the numbers. Botched questions or activities can also deliver bad data. If your prototype didn't work then your observations aren't likely to be helpful, and if you asked a leading question then you should reject the answer too.
Prioritize
By the time you've finished interviewing, you'll probably have many hours of recordings. In all likelihood, you don't have time to review all (or even most) of them. You need to decide how best to spend the time you've got. 
The best way to avoid this problem is to have a note-taker present throughout the sessions (see Chapter 6). But if that's not possible you'll need to prioritize which to return to. One way to do this is to rate each session out of ten, with a score of ten meaning that it felt like a helpful, fruitful session, and one meaning that it felt like a waste of time. Then, starting with your highest-rated sessions, work through them until it's time to move on to the next module.
Another way to prioritize is to sort your sessions into three groups:

Clear and helpful
Confusing or complicated
Clear and unhelpful.
            Having done so, leave enough time to listen to as many as possible from the second group, one or two from the first group, and none from the third group. This might seem counter-intuitive. Why go back to the second group rather than the first? The reason is that you will extract more insight from the sessions that at the time seemed confusing. For the clear ones, your notes are often a sufficient guide.

You can apply these approaches to whole recordings, or to sections of recordings. For example, you may think that the last 20 minutes of a particular recording would be worth watching again, but you can rely on your notes for the rest of the session.
Review Recordings
By re-watching or re-listening to your recordings, you achieve two things. Firstly, you take yourself back to the moment of the interview, rekindling your memories and feelings at the time. Secondly, you're able to listen more clearly, because you're not being distracted by thinking about what question to ask next, wondering if the prototype is working, and so forth. In short, reviewing the recordings means that you get more insight out of your research.
It's up to you whether you review whole recordings, the same section of each recording - for example, the middle 20 minutes - or snippets from different sessions. Mostly, this will be a matter of time and the decisions you've made (see previous module). Whatever you decide to do, try to make time to listen to at least five minutes of every recording. The last five minutes is normally best, because the participant will be summing up. It's amazing how much of a memory boost you'll get from just hearing a participant's voice again for five minutes. 
What should you be doing while the recording is playing? It's a bit like the approach to note-taking we described in Chapter 6. Some people like to transcribe in full, others like to do nothing but watch and listen. Our preference is to make handwritten notes on Post-Its. Hand-written because it ensures you only capture the important details, not every single thing that's said or done. Post-Its because it enables you to use them in affinity sorting later on. You should also be listening out for good quotes, and then either typing them up or creating a timestamp to go back to later.

Improving Your Technique

Listening back to your own interviewing is the single best way you can get better at it. You'll hear your messy questions and the moments where you interrupted too soon. For this reason alone, you should try it.


Transcribe
Researchers tend to have a love-hate relationship with transcripts. On the one hand, they enable you to scan and make notes more easily than any other format. On the other hand, they can be time-consuming to create manually, and they miss a lot of the important detail of what people actually do, not what they say. So we might consider them for depth interviews, but not normally for user tests. 
One time-saving option is to use Google Docs' voice-typing feature. We find this achieves about 85% accuracy, which is fine for many situations, but because they're so laborious to make, we wouldn't normally recommend transcribing interviews, other than the exact wording of quotes that we intended to use later on. However, if you need to, it's possible to pay a transcription service to produce them for you, or use a time-saving app like otranscribe.com
If you do have transcripts, you can go through and write notes to capture your thoughts and observations on what's been said. This is a great way to start to generate ideas for the following phase of the analysis process. The ideal scenario is to have someone else create a transcript for you to use in this way while at the same time watching the recording, but this is often prohibitively expensive.

Transcript example, with researcher comments added
What to Watch Out For

In terms of how long it takes, data preparation is the most variable phase of the process. If you're not careful, it can eat up your remaining analysis time, and you'll have nothing left to generate actual insights. In particular, don't underestimate how long activities like transcription can take. In most cases, it won't be worth the effort. You can also save a bucket load of time in analysis if you get note-taking right in the first place!
Data preparation is best done individually and in a quiet space: we try to do it at home, or lock ourselves away in a quiet area of the studio. However, you do need to communicate with your colleagues regularly to ensure you're all working to the same format and the same timelines, so plan to catch up at least once or twice every day.
If you're working in evaluative research mode like user testing, rather than a discovery approach like depth interviewing or contextual research, then note-taking is easier. You can probably fast-forward through this phase rather than spending lots of time re-immersing yourself in the interviews.

Phase 3: Finding Patterns
Your groundwork is done. Now it's time for the fun part! The purpose of this phase is to go from individual observations (what your individual participants did or said) to patterns and rules (the general conclusions you can draw based on your data).
Who's involved: the core project team. Later on, you may chose to involve other people, such as stakeholders and/or service users.
How long: half a day to two days. 
Where to do it: in a room with plenty of space to move around and stick things onto walls. Ideally, you'll already have set up a project space in the previous phase. If not, a large meeting room will do. If you can't have sole use of the space, stick brown paper to the walls first so you can transport your work when you're finished.

Here are some of the activities you can choose from. Choose those that work best for you, depending on your time and preferences.
Review Objectives or Rolling Hypotheses
Begin phase three by collectively reminding yourselves what your purpose is. If you wrote a shortform brief, now's the time to read it out loud to the group. If you created research objectives, you should summarize these instead. If you started with rolling hypotheses, recap them. This phase marks the transition from individual analysis to working as a group, so it's important that the whole team is present, so you can read your objectives out loud and discuss them if necessary.
Brain Dump
It can be helpful to begin your group analysis in an unstructured way. Just chew the fat about your experiences of conducting the research, and your top-of-mind impressions of what happened. 
Don't: 

Worry about keeping to the data. It's fine to digress into your own feelings about the research, conclusions you've drawn, or related topics.
Try to take structured notes. Let the conversation flow.
















































            Do:
            Keep strictly to the time. This is really a warm-up activity. 30 minutes is plenty.
Let everyone speak. The person who's managing the timing should also act as moderator, if one or two people are dominating the discussion.
Pay attention to the topics and concepts that are emerging from the discussion. These will be useful later.
Capture the highlights. While written notes get in the way, there may be an interesting point raised in the course of the conversation.

Who Were the People?
This is a great exercise to bring to life the participants and reduce bias in your analysis, especially if not everyone in the analysis team was present at all of the research sessions.
Here's how it works. For each participant, use three Post-Its.

Post-It 1: a participant number, first name, and three to four immediate observations about them.
Post-It 2: the participant's needs. Again, use three to four bullet points.
Post-It 3: finally, three to four participant pain points.
            Work as a group, with the person who did the interview describing the participant, someone else writing the Post-Its, and the rest of the team acting as the audience and asking questions to clarify.


Who were the people?
Take about five minutes per person. It'll probably feel like a drag when you're raring to get going, but there are good reasons for taking the time to do it. It ensures that all participants are represented equally in your analysis, not just the loudest or most memorable. It begins to generate patterns, as you observe the themes that keep re-emerging in your Post-It summaries. And it gives you a tool for sense-checking hypotheses later on, as you can easily refer back to the individuals you've posted on the wall.
Conceptual Diagrams
Through your earlier activities and hypotheses, you'll have started to get a sense of themes emerging. Let's attempt to visualize those patterns. 
The key question here is, "How do these two observations relate to each other?" Your task is to draw these relationships, and you can do this in a variety of ways: on a spectrum, 2x2 matrix, Venn diagrams, concentric circles, timeline, whatever works for you. I wouldn't try to pre-judge which you'll use either, just let it emerge as you draw (and throw away) your initial sketches. 

Conceptual diagrams, roughly drawn
Taking a spectrum as an example, here's how to approach the activity:

First, draw a line, and give the end points provisional labels (eg, 'cautious' at one extreme, and 'loves risk' at the other).
Add your participants as marks on the spectrum.
As you go along, debate and challenge:
Where should participants be placed?
What should the labels at the extremes say?
Is this spectrum useful?
Are you mashing together two different variables in one spectrum (for example, does our 'cautious - loves risk' spectrum mask a 'novice - expert' spectrum within it?).
Is the format you've used the right one? Perhaps you'd be better with a 2x2 grid instead?


It can also help to label different parts of the spectrum.
Force yourselves to create several different spectrums, and ask which of them provides the best explanation or insight.

The process is similar for all the other kinds of visualization. If you're doing it right, then quite a lot of good-natured arguing is involved. A colleague of ours uses the phrase 'strong opinions, lightly held', and I think that's the perfect mentality for this kind of work. Be vocal, but be prepared to be persuaded.
Once again, when you've done your visualizations, stick them up on the wall. Your project space should be filling up nicely now.
Maps & Sketches
As well as abstract conceptual diagrams, it can also be useful to draw maps and sketches. For instance, if your work involves designing digital products in stores, you might want to draw a map to show how customers move around the floor. If you're designing an app, you might want to draw an idealized version of a screen for a particular user - not because you're planning to implement that design, but because it will help you think about what they need.
Tablecloth
A more formal, structured approach involves creating a special sort of matrix called a tablecloth. In the past, researchers would spread a large sheet of paper on a table and divide it into columns and rows, hence the name. Nowadays, you have the option of using a spreadsheet instead; both approaches have their advantages. 
To create the tablecloth, add a column for each participant (or group of participants if you've got a larger sample). In the rows, add the variables you're interested in. These might be answers to particular questions, observations on whether or not participants were able to complete individual tasks, or sections from your discussion guide. Once you've got your matrix, populate each cell: this can simply be a yes/no if you're interested in task completion, or a paragraph description if you're wanting to conduct more detailed analysis.
The benefit of a tablecloth is that it allows you to spot patterns and easily make relatively structured comparisons between groups. If this is one of your main objectives (for example, if you want to compare users in different markets, or customers versus non-customers), then a tablecloth can really help. Bonus feature: if you opt for a spreadsheet, you can use conditional formatting to help highlight patterns, creating a 'rainbow tablecloth'.

Using a Spreadhsheet

Bonus feature: if you opt for a spreadsheet for your tablecloth, you can use conditional formatting to help highlight patterns, creating a 'rainbow tablecloth'.


Affinity Sort
Affinity sorting is one of the most popular methods for making sense of data from qualitative research. It's actually very simple:

First, you need your observations on Post-Its, which you should have done either when you were actually observing the interviews, or in the data preparation phase when you were reviewing recordings or notes. Remember: one observation per Post-It. Don't write an essay on each one.
Add them to the wall in a jumble. Don't try to impose any sort of order at this stage. You'll organize them in a moment.
Now, as a group, move the Post-It notes into groupings, where you can see common themes between them (see photos below). Work as a group. It's vital that you discuss your thinking with the team as you go along, because this conversation is the analysis as much as the configuration of Post-Its you end up with.
Once you've got your groups, use a different colored Post-It to give the group a title.
Finally, you can choose to highlight or prioritize certain groupings as more important than others. We do this using dot voting: each participant gets a small number of colored dots to stick onto the title Post-It, and the votes are then counted.

Affinity sorting is absorbing, and really insightful. Expect to be stumped for the first couple of minutes as you stare at the Post-Its, but after that it's surprising how quickly an order emerges.
It's common practice to run the sort more than once, to see what other patterns might emerge. However, be aware that you're unlikely to be able to do it more than two or three times: your group will get tired, and your Post-Its will lose their stickiness eventually! If you do run another sort, remember to take photos each time.
Affinity sorting has one other benefit. It's the best way to construct a narrative about the findings, as you'll see in phase 5.
Use Theory to Help You Understand the Data
Unlike analysis in an academic context, design researchers don't tend to rely on using a particular theoretical framework to explain the data. Sometimes, though, it can be helpful to lean (lightly) on theory to help find insights. We've found it useful to draw on ideas from human-computer interaction, social psychology, anthropology, systems theory, game design and elsewhere.
For example, the anthropologist Mary Douglas's theory of category outliers was originally intended to explain food taboos in ancient societies. But it's a great way to think about categorization problems in information architecture, too. 
If you take this approach, remember that any theory is there to help you, not get in the way. Don't worry about using a pick-and-mix approach (the technical term is 'bricolage'). Whatever you do, don't get bogged down in debates about whether you're applying theories correctly or not: just think of them as a toolbox of metaphors that might give you a different perspective on the data. If an idea isn't useful, ditch it and move on. 

Avoid Getting Heavy With Theory When Presenting Your Findings

 By all means have fun with theory while you're doing the analysis, but be aware that it can feel excluding and off-putting for team members who don't have the same background as you. For the same reason, don't refer to theory in your debriefing to stakeholders, even if you found it really useful in the analysis. It will confuse your message, and alienate your audience.


Check Your Biases
As you work through some of the activities mentioned above, it's a good idea to keep checking back on your biases and assumptions. Ideally, the whole team will adopt a culture of doing this for each other, but you can help facilitate it if you set an example and do it to yourself to begin with.

Consider your cultural biases. For analysis in particular, a diverse team is a good team. Is there something about your own background or experiences that is predisposing you to look at the data in a certain way? You probably can't avoid this totally, but at least if you're aware of it you can factor it into your interpretation. It can be easier for other people to spot this, so encourage them to do so, and be grateful rather than defensive if they do!
Watch out for your cognitive biases. Are you being influenced by the availability heuristic in your interpretation? Are you making attribution errors? Are you at risk of confirmation bias? Cognitive biases are great theoretical tools for analysis in their own right, so it's worth reading up on them before you begin - there are lots of resources online that explain what all these phrases mean!
Create and test deductive statements. Although the analysis approaches described above are mostly inductive, it can be useful to use deductive rules to check your working. Whereas inductive conclusions are drawn from observing the same thing happening on a number of occasions, deductive thinking typically follows the pattern if a=b and b=c, a=c. Do this towards the end of phase three, rather than at the beginning. For example, you might work through a thought process like the following: "People on unstable incomes are most interested in the content on homelessness. Therefore people on unstable incomes are concerned about becoming homeless." with the check "Does our other data support that conclusion?"

What to Watch Out For

It's a good idea to take a break between the Absorbing Data and Finding Patterns phases. Overnight is best, but if that's not possible then take a lunch break or go for a 15-minute walk. These two phases demand very different kinds of mental effort, and you need to refresh yourself before you begin.
Aim to create a culture of analysis where it's OK to challenge and be challenged. Try to remove hierarchy within the analysis team, and avoid the debate being dominated by one or two people. If you can foster a spirit of playfulness and a sense of humour, then this will really help people to work to the rule of 'strong opinions, lightly held' without feeling defensive or under-appreciated.
You can't re-run activities many times: tiredness sets in, and sticky notes lose their stickyness.
Sometimes it's possible to over-analyse a particular point. If you feel you've got what you need, move on.
Don't forget that you're cherry-picking from these modules, not doing them all. You'll get diminishing returns from using activity modules that are too similar.
These activities are immersive, and it's easy to lose track of time. Have an agenda and appoint one member of your analysis group as timekeeper.
After each activity, check back on your analysis plan and consider whether you need to change anything.

Phase 4: Working With Patterns
The purpose of this phase is to expand your understanding of your users' needs through creative activities. If your aim is to generate ideas, it's particularly important to spend time in this phase, as the playful nature of many of the activities is ideal for generating fresh thinking.
Who's involved: the same group who were involved in phase 3.
 How long: half a day to a day.
Where to do it: in the project area.

This phase flows naturally on from phase 3. In fact, sometimes it can be beneficial to move back and forth between the two phases, so don't think of them as completely separate. Nonetheless, it's good to come to these activities fresh, so try to schedule a lunch break or overnight rest between them if you can.
Again, you should cherry-pick modules like the ones below depending on your preference, your objectives, and how much time you've got.
Thought Experiments
Thought experiments are a game-like approach to understanding your users' needs better. The idea here is to achieve insights by manipulating some aspect of your themes, by asking a lot of "what if?" questions
A well-known example of this is the "if this product was magic, what would it do?" question used in product design. But there are lots of what if-style games you can play along the same lines - adding, removing or stretching to understand how that might result in a different outcome.
Some example thought experiments:

What if cooks didn't have access to spatulas. What would they use instead, and why?
What if cooks had someone to help them. What would that person be doing?
What if cooks were able to build their kitchen specially to create this meal, what would it include/look like?

The purpose of this is to stretch your themes, to give yourself another angle on why people do things the way they do them. But do keep returning to the data to sense-check and challenge your thinking. You may find you want to update or amend your themes and visualizations as a result of this exercise. You can also sketch up the new concepts and metaphors you come up with to decorate your project area. 
Extension
A variation on thought experiments, extension involves taking one attribute of your product or experience and greatly exaggerating it or eliminating it. What difference might it make for users?

What would be missing if there was no sound whatsoever?
What option would these users choose if money was no object?

Think By Making
The idea of prototyping needs no introduction, but it's a great way to extend the ideas you've developed already and begin to 'think by making'. Imagine you've been researching the TV needs of football fans. If you had to create a personalized homepage for one of your participants, what would it look like? Going through this exercise will help you consider and challenge your findings in greater depth.
Another, more abstract version of this activity is the cereal box. Imagine you were creating the ideal product for your participants. What would the box show on the outside? What would it say about the product? Rather than doing this in words, create an actual 'cereal box' in pairs, then compare your results.
Metaphor
A strong, unfamiliar metaphor can be a powerful design tool. At this stage in the analysis process, you're in a position to try out some new ways of describing users' relationship to the product. This can be a good activity to use after thought experiments, as metaphors can sometimes emerge in the process.
As an example of metaphor, flat-pack furniture construction is generally communicated as a DIY task. If, in research, you found that some customers enjoyed the challenge of constructing furniture (perhaps comparing it to a jigsaw puzzle), then a new metaphor presents itself: flatpack furniture presented as a rewarding challenge like Lego, rather than a chore. In turn, this metaphor might impact on how you design instructions, on marketing, the store and possibly even the product itself.
What to Watch Out For

Timing is important at this stage. Spend too long, and it can start to feel forced and stale. Don't spend long enough, and it can be superficial.
Don't forget to capture ideas as you generate them. It can be easy to get swept up in the fun, and lose track of why you're there.
Take breaks between activities, and swap around teams and roles so it stays fresh. If it's a small team, consider hosting one activity each. 

Phase 5: Creating a Narrative
In most situations, you'll want to tell people outside your immediate team about your findings. The key to doing this effectively is to have a clear, logical core narrative that you can use in different media to tell your story.
Who's involved: the whole team
How long: 30 minutes to a day
Where to do it: in the same area you used for phases 3 and 4

By the time you're finished, you'll have a flexible narrative at your disposal:

It's compact. You could tell your CEO in two minutes.
It's expandable. You can also tell the long version, diving into the detail of particular sections (or not) as required.
It's hard to argue with, because it traces a clear relationship between the main points and the evidence that informs them.

Here's how you do it:

Return to your affinity sort. You've already grouped the individual observations together into findings, and given them titles on a different-colored Post-It note.
Now, group these into themes. Give them a title too.
Repeat step 2 until you've arrived at a set of 8 or fewer high-level findings.
Finally, state your conclusion in a single sentence. This should be a logical extension of your themes - ie, because x, y and z are true, we therefore conclude...
You'll now have created a pyramid of findings, with the individual data at the bottom, and your conclusion at the top. Incidentally, this is why this approach is known as the 'pyramid technique' for creating a narrative.


A pyramid of findings

Now it's time to arrange your narrative. 
Start by restating the reason for the research: "We wanted to know whether travellers could use the new app to book hotels..."
Then state your conclusion: "... and the answer is yes, but there are problems that are affecting conversion."
Then state your meta findings (the ones that inform your conclusion): "That's because a) all the people we tested with were able to find and book accommodation, but b) they struggled to do so and took several wrong turns, and c) they were confused by the terminology and icons used by the app."
Easy. If your audience doesn't want or need to know any more, you can just leave it there. Or, if they are happy with points a) and b), but unconvinced by point c), you can then dig down lower into your pyramid: "The reasons why they were confused were that a) a pin icon isn't understood to mean 'map', b) 'basket' is the expected label in place of 'my rooms' and c) generally, the site gives little explanation and assumes a lot of knowledge."



If your audience still wants to know more about c), you can dig down further. And so on. At the bottom of the pyramid are your original observations: your evidence, in other words. So use these quotes, video clips and photos to help tell your story if you need to.

Arranging a narrative from the elements created in the affinity sort
We'll talk about different ways of sharing your narrative in the next chapter.














Chapter 9: Turning Research Into Action
You've designed an elegant project. You've recruited the right participants. You've run great sessions. Your analysis has been thorough and revealing. But if you don't succeed in turning your research into action, then you've probably been wasting your time.

Research cycle: impact
It's common to associate the end of a research project with some kind of debrief session or report, where the person who did the research tells everyone else what the answer is. Actually, that's the wrong way to think of it, because it's only part of the picture.

Communication and engagement work best when they're happening throughout the project. If you leave it to the end, you've missed your best opportunities to build engagement and ownership of the results.
Research doesn't have value unless it results in decisions and actions. So when you think about the end product of your project, don't settle for being heard. Plan for the findings, evidence and ideas to be acted upon.

Making Your Research Relevant
As we noted in Chapter 2, you need your wider team and stakeholders to feel ownership of the research if it's going to be successful. You can achieve that in a number of ways:

Careful listening to what your stakeholders actually need from the research, at the beginning of the project.
Framing the objectives in the language of your stakeholders KPIs (eg, number of signups), not just in terms of an improved user experience.
Planning engagement touchpoints through the project, and using a variety of tactics to reach out to different audiences (see next section).
Involving them in activities such as note-taking, observation and analysis.
Being enthusiastic and persistent.

Engaging Stakeholders Throughout the Project
There are a number of ways you can involve your colleagues and stakeholders throughout the project. This isn't a complete list - use it as a starting point to add your own ideas to.
Attending Research Sessions
It might sound obvious, but one of the best ways to get your colleagues thinking about the research is to persuade them to attend some of the interview sessions. Hearing about users' needs directly is much more powerful than having a researcher relay them second hand: it establishes a personal connection with customers that can have a lasting effect. The more actively involved in the sessions your observers are, the more powerfully involved they'll feel, so try to get them to take notes, contribute on Post-Its, or participate in a follow-up workshop discussion (see Chapter 6). We find that if stakeholders attend the first couple of sessions they'll often want to stay for more. One note of caution: stakeholders who only attend one or two sessions can sometimes over-generalize from what they've seen, so make sure they're aware of the full range of interviews.
Show and Tell (AKA Pizza Sessions)
Show and tells are a great way to build interest and engagement with your research project, before the final results are ready. Firstly, the rough-and-ready format makes it clear that the results are provisional, not the final word. Secondly, it's a flexible approach that allows you to focus on the topics your audience are interested in. Finally, it brings your audience closer to the project by showing them the actual material that's been generated, without the need for lots of preparation on your part. If you've got a project space set up, you may find that show and tells happen naturally. If not, you may want to invite a broad audience to a separate session, part way through the project. The actual show and tell should be short - anywhere between five and 20 minutes - but allow plenty of time for questions and open discussion afterwards.
Here's an approach you can use:

Start by providing background on the project: the objectives and approach. 
Then choose four or five of your most colorful and interesting examples, and demonstrate them using mixed media: video clips, photographs, quotes and anecdotes. 
For each example, provide a takeout. Once you've finished walking your audience through it, say something like, "And the way we're interpreting this session is..." Invite your audience to offer their own interpretations too.
Offer a summary of what you're finding, while making it clear that this is still work in progress: "The main themes we've been discovering so far are..." Answer any specific questions, while being clear that there's still more work to do.
Finally, let your audience know how they can stay in touch with the project and when they can expect the more robust version of the results.

Show and tells are also known as pizza sessions, for the obvious reason that it helps to entice people along if there's free food on offer. Of course, lunchtime pizza may not be the most tempting or appropriate reward for your audience, so try experimenting with different times and treats.
Topline Findings
Once your research sessions have begun, it's a good idea to share a regular update of your findings. It's best to keep this rough, and not go into too much detail, because you don't want to waste time or suggest that these are definitive answers. An ideal format is a page or so of bullet points, with a message at the beginning making it clear that these are early findings and there's more to come. 
Even if most of your audience attended the research sessions, it's still a good idea to create topline findings. It reduces the risk that your attendees will pass on a version of events that you disagree with, and it helps to keep everyone on the same page, by summarising the current state of your rolling hypotheses.
Some people like to summarize topline findings at the end of a day, either off the top of their head or in collaboration with the other observers. Alternatively, you can ask an observer to capture and iterate findings through the day, in a rough format such as Markdown, or as a Trello board. Doing it in this way makes it easier to share, however you may need to tidy it up somewhat before it will make sense to other people.
Project Blog / Websites
Taking the idea of topline reporting a step further, it's worth considering a project blog, website or intranet page. 
Creating a resource like this takes time, but it's a good way to give the project an ongoing presence (especially if your audience works across multiple locations), and minimize the amount of in-person communicating you need to do. In terms of content, we'd recommend including:

A summary of the project objectives.
The plan: timings, methodology.
Who's who on the project, and contact details.
Regular updates of progress, including photos, quotes and stories from the field.
A summary of the hypotheses, which you can update as they evolve and become [should there be another word here? KM].
Links to any output documents.
Information on how to find out more - for example, the date of a show and tell session.
            Creating a resource like this takes time, so it's probably not justified for a small project with minimal profile. However, if you're working on a more ambitious discovery project, or you want to maximize awareness of your work, then this approach can be a surprisingly efficient way to do so.

Documenting What You've Learned
Even when you've successfully engaged your audience throughout the project, it's likely that you'll still want to create some sort of documentation. By doing so, you're helping to ensure that your work lives on in the organization, because your findings will probably be relevant to future projects, too. This isn't an alternative to the communication you do through your engagement plan: they're complementary. 
When you document research, there are three elements you need to be aware of:

The findings. The core of your communication is made up of your interpretation of the evidence from the analysis process. Normally, this takes the shape of a story, because it's easier for your audience to engage and remember it that way. Think of your story as having two versions: a summary that you could tell in 60 seconds (see below), and a more in-depth version that lays out your reasoning in more detail.
Examples. At a basic level, your audience needs to be convinced that what they're hearing is true. The evidence you've collected (or rather, specific examples) provides that substance.
The recommendations. Once they've absorbed the story, your audience needs to be clear about what they should do next. 


An example story
Ideally, you should decide how you're going to document your research early in the project, because it will have a bearing on the way you set up and conduct the sessions. There are many different formats open to you, each with their own strengths and weaknesses, so bear these factors in mind:

How quickly do you need to share the documentation? Some forms of documentation are quicker to create than others.
How detailed does it need to be? 
What mix of insight, evidence and ideas do you need to capture?
What resources - such as photos, video or screengrabs - do you have access to?

Once you've considered these questions, you're ready to choose a format for your documentation. You don't just have to choose just one of these formats. They're actually more effective if you combine them, because the strengths of one cancel out the weaknesses of the other.




What it is
Timing
Insight vs evidence vs ideas
Effort





Show and tell (aka pizza session)
Informal runthrough of the research so far, with Q&A
Midway through the project, or at the end of a sprint
High insight, medium evidence
Low


Topline findings
One page bulleted summary of findings so far
After first round of research sessions
Medium insight
Low


Project blog / website
Online resource capturing project background, progress and findings
Throughout the project
Medium insight, medium evidence
High


Report deck
Slide deck summarising the findings, detailed feedback and recommendations
At the end of the project
High insight, medium evidence, low ideas
High


List reporting
Cataloguing and feeding back on research. Takes place in the project space
After each sprint
High insight, medium evidence, medium ideas
Medium


Journey map
Graphical representation of the sequence of steps taken by users to complete a task
At the end of the project
High insight
Medium


Experience map
Large-scale representation of the entire customer experience
At the end of the project
High insight
Very high


Personas
Personification of a set of user needs and behaviours
At the end of the project
High insight
Medium-high


Showreel
Compilation of video highlights, taken from research recordings
At the end of the project
High evidence, medium insight
High


Debrief workshop
Presentation of findings and workshop activities to determine actions
At the end of the project
High insight, high evidence, high ideas
High



Report Deck
The classic format for documenting research projects is a slide deck. They're popular because it allows you to combine images and text easily, and they're also easy to present in a debrief session. They're a flexible format that can showcase insights, evidence and ideas equally well. The downside is that they take time to create, which could perhaps be better-spent on other tasks, and they run a risk of sitting unnoticed and unread once the team have moved on to the next project. If you're working in an agile environment, you probably don't have time for this.
Your deck will need several sections:

A summary of your story, telling the audience what your objective was, and what the brief answer is. This should take no more than a few slides.
A brief description of your approach, including an overview of who you spoke to. To protect your participants' anonymity, this shouldn't include full names or contact details.
Detailed, page-by-page findings.
If you've used the pyramid approach described in Chapter 8, you'll already have your story, so just insert it into the structure above. To add visual interest, it's a good idea to include images in this section too. Photographs from your project are a good choice, but you can also use screengrabs of the product, diagrams or stock images.
For the detailed findings, we like to use annotated screengrabs like the ones shown below.
Finally, you should ensure that you've provided recommendations. These might be entirely your own work, but it's better if you've come up with them together with the rest of the team. Either way, you have the choice of including them on each page, or listing them in their own slides at the end.


An annotated screengrab
You may want to produce different versions of the report for different purposes. For example: 

One for presentations that includes at least one very short video clip. This version might just include the summary and main story sections. 
Another as a PDF, with links to video in a shared folder. This version would be the entire report, and include all the detail slides.

A blank report template is available at https://www.cxpartners.co.uk/ux-resources/, along with many other free deliverable formats. 
List Reporting
In contrast to report decks, list reporting dispenses with the frills and gets straight to work listing the problems and recommendations. The upside is that the output is action-focused. The downside is that it's not so persuasive or engaging, so don't use this approach unless your team has already bought into the project and its findings.
To produce a list report, follow these steps:

Choose your format. We prefer a spreadsheet, but you can also use project management tools like Trello, or even a wall with Post-Its.
Agree a system for rating your issues. A popular way to do this is to create column headings labelled Issue, Severity, Prevalence, Impact and Recommendation.
In each row, add an issue raised by the research (for example, "Users can't find the continue button"). 
Then, rate the issue for severity (ie, how much of a barrier was it for users in completing their task?) and prevalence (ie, what proportion of users did it affect?). We do this by giving a score from 1 to 5 in both columns. A rating of 1 for severity means it caused minimal obstruction, while a 5 means it completely broke the experience for users. A rating of 1 for prevalence means it only affected a couple of users, while a 5 means it affected everyone.
Calculate the impact by multiplying severity by prevalence. You can then sort the rows in order of impact to show the biggest issues at the top.
Finally, you can add recommendations for each of the issues. Again, it works best to do this as an activity with the whole team, rather than on your own.

Alongside this form of documentation, it's helpful to maintain a project area with photos, example screengrabs and sketches (see Chapter 8), and to use regular show and tells as your method of sharing back with the team.
Journey Map
Journey maps show the steps taken by a user to complete a specific task. They represent a sequence of steps or touchpoints, which might involve multiple devices or channels, and might take place over a few minutes or several days. Journey maps are an excellent way to record users goals and expectations, and the problems that they encounter in completing them. On the downside, they can become overly-complex if the exact sequence of steps needs to be recorded.

An example journey map
To create a journey map, follow these steps:

Define the user's goal, and state this at the top of the map. You may also want to associate the journey with a particular persona.
Working from left to right, map out the sequence of steps that the user takes, starting with the trigger that causes them to begin the task, and finishing with the goal.
For each step, make a note of the channel and device that's being used.
You may also want to add details like an emotion line showing the highs and lows of the journey, quotes or opportunities.

Experience Map
An experience map is like a journey map on a grander scale. Instead of focusing on a specific journey, it takes in the entire customer experience for a particular product or service. Think of it as a planning tool rather than a design tool, enabling your team to identify where changes are needed rather than how to implement them. 
Because they're high-level, holistic documents, experience maps have a long shelf life. They're often printed out on a wall-size piece of paper, and put in a prominent place. They're a great reference point for potential projects, because they can be related back to the most pressing customer needs within the overall experience, and used to track progress.
The downside of experience maps is that they're large, unwieldy and difficult to scan. They also don't give much direction on how to solve a problem, so you'll probably need to conduct further research to understand it better before you're ready to implement a solution. Compared with some of the other methods described in this chapter, experience maps are a pro-level skill, and you should expect to put in a lot of time and effort to create them.

Example experience map
To create an experience map, follow these steps:

Stick a piece of brown paper along the largest wall you can find.
Use a Post-It note to record each need, activity, pain point and delights you've heard about from users. Generally it's a good idea to phrase your Post-It notes in the first person - for example:
Needs are statements about what the user requires at this stage in the process: "I need to be certain that the shoes will arrive in time."
Activities are actions that users may take within this phase: "Check the confirmation email."
Pain points are problems, barriers or frustrations that arise, such as: "I can't find the delivery time guarantee anywhere."
Delights are the positives that users experience, such as: "Customer service gave me a $20 voucher to apologize for the delay." 


Once you've generated your Post-It notes, group them into columns to represent broad phases of the experience. Don't worry about the precise sequence of actions: that's a job for a journey map. Use one row for the names of phases, the next for tasks, then additional rows for actions, needs and pain points.
If you like, you can keep adding rows for further information. In the past, we've added layers to record relevant product attributes, competitor offerings, KPIs and solutions - it's actually a very flexible format.
You should involve your team in all of this activity, if possible, but if you can't, then you should now hold a show and tell of the experience map. Walk your colleagues through it, and ask them to call out any surprises or missing information.
Once you've sense-checked the rough experience map, you may want to hand it over to a visual designer for a makeover before you print it and put it on the wall in a prominent position. 

Personas
A persona is an abstracted set of user needs, normally presented in the form of an imaginary person. 

Example persona
Personas can be a great way to build empathy, especially if your team live very different lives from your users. They're also a powerful tool for making decisions, because in the process of creating them you deal with a lot of the difficult discussions about prioritizing one set of user needs above another. That's helpful later on, because you may not have time for further research, and you don't want to keep derailing your product development process with repetitive arguments about priorities.
Personas have several downsides, too:

They polarize. Some of your colleagues may be skeptical about using them based on bad experiences of personas they've had in the past.
If they use invented biographical detail, they run the risk of triggering people's prejudices (positive or negative), which can get in the way. 
It can be hard to get the level of fake biography right. Personas that talk about how many cats someone owns aren't helpful for design decisions, but a pure list of user needs can feel a little dry.
It's easy to confuse them with marketing segments, which look similar, but do a very different job. 

The trick to producing effective personas is in their creation. If the people who are going to be using them aren't involved in generating them, they'll flop. But if they are involved, personas can be really effective. Here's how to create them:

Start by reviewing any existing reports, and conducting qualitative research to profile users. 
In the analysis process, focus on producing conceptual diagrams, particularly spectrums. These allow you to categorize participants by their similarities or differences in terms of user need, which you can then use as the basis for personas. Give each of these a name (a real name, like Adil, or a descriptive name, like 'cyclist').
Using this approach, you can create a longlist of personas (anywhere from five to as many as 20).
Now you need to combine and prioritize your longlist of personas to arrive at a smaller final set. Two or three primary personas is a great target, but you can include some secondary personas too, if you like. The way to do this is by debate with your project team, not on your own, because the discussion about which to prioritize is right at the heart of the process.  Here's an example: let's say we wanted to design an underground train station. In the process of reducing the longlist to a shortlist, we identify shoppers and parents of young children as two separate groups. But in design terms, their needs are identical. They both struggle to get up escalators, whether it's with shopping bags or buggies. So we'll condense them into a single persona, we don't need both. We also agree that we're going to deliberately prioritize the needs of commuters over tourists. So we'll have a commuter persona, but not a tourist persona. Later on, when we have to make tradeoffs, that's our decision. 
Finally, create the personas you've chosen as A3 posters, and add as much biographical color (photos, names, background) as you feel is appropriate. More biography helps with creating empathy, whereas if your objective is primarily about guiding decision-making then it's best to keep it light.
You may also want to consider other formats to get your personas across, such as mood boards, video reels, stories, role-playing or even mannequins!
Like a house plant, you should keep your personas alive with regular attention, updating them based on any new research you do. As you find out more about your users, stick Post-Its expressing new learnings about that persona onto your poster.  

Personas discriminate. In fact, they're a tool for making difficult prioritization decisions. They deliberately don't cover everybody. The point of the exercise is the prioritization and debate. By getting it out of the way early, you can avoid continually revisiting arguments about who takes priority. That means your team can make better decisions, move faster and have fewer arguments along the way. You should make sure you update personas when you do additional research, too.
Showreel
Showreels are compilations of video clips. They're great for providing your audience with direct exposure to your users, and it highlights their experiences like no other format can. The downside is that they're time-consuming to produce. Also, on their own they can give a skewed view of the findings, so they're best used alongside another form of documentation like a report, experience map or personas.
Although showreels are the most common format for sharing the evidence directly, there are others. For instance, you might choose to create a scrapbook or website of photographs.
How to make a showreel:

Ensure your note-taker includes time stamps for key examples and quotes: this will make it easier for you to find the right clips later on.
Ask participants to give their final feedback direct to the camera. This is often the best footage to use for a showreel, as it's more likely to be concise, articulate and focused on the main points.
Without context, it's sometimes hard for your audience to spot the point the clip is trying to demonstrate, so it's a good idea to add an interstitial or title that summarizes it for them. For example, "Joey struggles to find the correct shoe size on the product page".
Add subtitles if there's time. This helps to make up for poor audio quality.
If it's really important to get good quality video, bring a tripod and microphone, and work with a colleague or professional videographer to set up and monitor the recording.
Although there are no definite rules for duration, it's a good idea to keep it under five minutes in total, and keep individual clips to less than a minute. Several short clips that reinforce the same point are more powerful than a single longer clip.

It's worth mentioning that this is a very short summary of these deliverables: there's a lot more information out there in books and blogs on each one, so keep exploring if you want to know more. 
Debrief Session
In most research projects, you'll want to mark the end of the cycle with a face-to-face debrief session. There are a number of benefits to doing this:

You can ensure everyone's heard the message.
It gives everyone in the team an opportunity to ask and answer questions.
You can collectively agree actions and next steps.
A face-to-face session is more interactive and engaging, not a one-way communication that's easy to switch off from.
Finally, it provides a sense of closure for the project team, and an opportunity to review what worked and what didn't.

If you created a project area, then that's the best place to hold the session. Allow at least an hour, to enable you to cover a mix of activities. For a larger scale discovery project, you might need as many as three hours for a workshop. The first part of the session is a playback of findings: this could be a show and tell, or a more formal presentation. The second part of the session is about agreeing actions.
Presenting Findings
Firstly, present back the findings. If everyone in the room was present throughout the project, and took part in the analysis, then this could be very brief: just a quick recap to confirm you're all agreed on the same interpretation. Usually, though, you'll need to spend the first part of the session playing back the findings to the team. To do this, use a combination of the pyramid story you generated during the analysis process (see Chapter 8,), documentation such as a report deck or experience map, and any additional pieces of evidence like photos or videos.
Tailor your presentation to your audience. It's normal to encounter a lack of knowledge, as well as resistance and blinkered expectations when you feed back, so you need to think of the best way to counteract this. As you can see from the diagram below, you can deploy the different elements of your research project to increase buy-in. Encourage questions and discussion through the presentation too.

Feedback model
Agreeing Actions
The whole purpose of your project is to generate action. As we've mentioned already, the best way to do this is by continually engaging and making the research relevant to your stakeholders. Now, though, you can use collaborative activities to shape and assign actions. There are many techniques on offer, but these are some of the most useful:
Empathy Mapping
Complete a different empathy map for each set of users. Ask your audience to work in groups to a worksheet like the one below, reflecting what they've seen and heard about user needs.

Empathy map example
Prioritization Grid
Create a 2x2 framework like the one below. One axis should be labelled 'effort', while the other should be called 'impact'. Map possible solutions onto the framework. When you've finished, focus your efforts on the solutions that are in the low effort / high impact quadrant.

A prioritization grid
Agree Backlog
If you're already managing a backlog of product changes, you can add the actions from the research onto your existing list. If you're starting from scratch, then work as a group to create recommendations in a list report (see above).
Roadmapping
This is a particularly good activity if you've created an experience map. Looking at the experience map, identify user problems you could address with new initiatives and add them as Post-It notes in a different color. Or if you've got an existing roadmap, add the activities to the experience map to double-check you're targeting relevant areas.
Top Priorities
Ask each participant to complete Post-It notes capturing recommendations for action during your presentation, or generate them in small groups afterwards. Group these together on a wall to remove duplicates, then get the whole team to vote with sticky dots on the ones that should be top priority.
Summary

The more engaged you get your team, the more likely your research will be acted on. Make plans to involve them throughout the project.
Choose the right format(s) to document your research, but don't overdo it. Speed is normally more important than detail.
Use a pyramid story structure, allowing you to get your message across both as a 60-second summary and as an in-depth account.
Tailor your delivery to your audience, using the right mix of insight, evidence and ideas to engage and persuade them.
Host an interactive debrief workshop. Use interactive exercises to get the team to generate and own an action plan so your research has an impact.










