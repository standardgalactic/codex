



Part IGeometry of Divergence Functions: Dually Flat Riemannian Structure










Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_1




1. Manifold, Divergence and Dually Flat Structure




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp






The present chapter begins with a manifold and a coordinate system within it. Then, a divergence between two points is defined. We use an intuitive style of explanation for manifolds, followed by typical examples. A divergence represents a degree of separation of two points, but it is not a distance since it is not symmetric with respect to the two points. Here is the origin of dually coupled asymmetry, leading us to a dual world. When a divergence is derived from a convex function in the form of the Bregman divergence, two affine structures are induced in the manifold. They are dually coupled via the Legendre transformation. Thus, a convex function provides a manifold with a dually flat affine structure in addition to a Riemannian metric derived from it. The dually flat structure plays a pivotal role in information geometry, as is shown in the generalized Pythagorean theorem. The dually flat structure is a special case of Riemannian geometry equipped with non-flat dual affine connections, which will be studied in Part II.

1.1 Manifolds

1.1.1 Manifold and Coordinate Systems
An 
            n-dimensional
           manifold M is a set of points such that each point has n-dimensional extensions in its neighborhood. That is, such a neighborhood is topologically equivalent to an n-dimensional Euclidean space. Intuitively speaking, a manifold is a deformed Euclidean space, like a curved surface in the two-dimensional case. But it may have a different global topology. A sphere is an example which is locally equivalent to a two-dimensional Euclidean space, but is curved and has a different global topology because it is compact (bounded and closed).
Since a manifold M is locally equivalent to an n-dimensional Euclidean space , we can introduce a local
           coordinate system (1.1)composed of n components  such that each point is uniquely specified by its coordinates  in a neighborhood. See Fig. 1.1 for the two-dimensional case. Since a manifold may have a topology different from a Euclidean space, in general we need more than one coordinate neighborhood and coordinate system to cover all the points of a manifold.Fig. 1.1Manifold M and coordinate system .  is a two-dimensional Euclidean space

The coordinate system is not unique even in a coordinate neighborhood, and there are many coordinate systems. Let  be another coordinate system. When a point  is represented in two coordinate systems  and , there is a one-to-one correspondence between them and we have relations (1.2)
 (1.3)where  and  are mutually inverse vector-valued functions. They are a
           coordinate transformation and its inverse transformation. We usually assume that (1.2) and (1.3) are differentiable functions of n coordinate variables.1
Fig. 1.2Cartesian coordinate system  and polar coordinate system  in 




1.1.2 Examples of Manifolds

A. Euclidean Space

Consider a two-dimensional Euclidean space, which is a flat plane. It is convenient to use an orthonormal Cartesian coordinate system . A polar coordinate system  is sometimes used, where r is the radius and  is the angle of a point from one axis (see Fig. 1.2). The coordinate transformation between them is given by (1.4)
 (1.5)The transformation is analytic except for the origin.

B. Sphere

A sphere is the surface of a three-dimensional ball. The surface of the earth is regarded as a sphere, where each point has a two-dimensional neighborhood, so that we can draw a local geographic map on a flat sheet. The pair of latitude and longitude gives a local coordinate system. However, a sphere is topologically different from a Euclidean space and it cannot be covered by one coordinate system. At least two coordinate systems are required to cover it. If we delete one point, say the north pole of the earth, it is topologically equivalent to a Euclidean space. Hence, at least two overlapping coordinate neighborhoods, one including the north pole and the other including the south pole, for example, are necessary and they are sufficient to cover the entire sphere.

C. Manifold of Probability Distributions

C1. Gaussian Distributions
The probability density function of Gaussian random variable x is given by (1.6)where  is the mean and  is the variance. Hence, the set of all the Gaussian distributions is a two-dimensional manifold, where a point denotes a probability density function and (1.7)is a coordinate system. This is topologically equivalent to the upper half of a two-dimensional Euclidean space. The manifold of Gaussian distributions is covered by one coordinate system .
There are other coordinate systems. For example, let  and  be the first and second moments of x, given by (1.8)where  denotes the expectation of a random variable. Then, (1.9)is a coordinate system (the moment coordinate system).
It will be shown later that the coordinate system defined by , (1.10)is referred to as the natural parameters, and is convenient for studying properties of Gaussian distributions.
C2. Discrete Distributions
Let x be a discrete random variable taking values on . A probability distribution p(x) is specified by  probabilities (1.11)so that p(x) is represented by a probability vector (1.12)Because of the restriction (1.13)the set of all probability distributions  forms an n-dimensional manifold. Its coordinate system is given, for example, by (1.14)and  is not free but is a function of the coordinates, (1.15)The manifold is an n-dimensional simplex, called the probability simplex, and is denoted by . When ,  is the interior of a triangle and when , it is the interior of a 3-simplex, as is shown in Fig. 1.3.Fig. 1.3Probability simplex:  and 


Let us introduce  random variables , such that (1.16)Then, a probability distribution of x is denoted by (1.17)in terms of coordinates .
We shall use another coordinate system  later, given by (1.18)which is also very useful.
C3. Regular Statistical Model
Let x be a random variable which may take discrete, scalar or vector continuous values. A statistical model is a family of probability distributions  specified by a vector parameter . When it satisfies certain regularity conditions, it is called a regular statistical model. Such an M is a manifold, where  plays the role of a coordinate system. The family of Gaussian distributions and the family of discrete probability distributions are examples of the regular statistical model. Information geometry has emerged from a study of invariant geometrical structures of regular statistical models.

D. Manifold of Positive Measures

Let x be a variable taking values in set . We assign a positive measure (or a weight)  to element . Then (1.19)defines a distribution of measures over N. The set of all such measures sits in the first quadrant  of an n-dimensional Euclidean space. The sum (1.20)is called the total mass of .
When  satisfies the constraint that the total mass is equal to 1, (1.21)it is a probability distribution belonging to . Hence,  is included in  as its submanifold.
A positive measure (unnormalized probability distribution) appears in many engineering problems. For example, image s(x, y) drawn on the x-y plane is a positive measure when the brightness is positive, (1.22)When we discretize the x-y plane into  pixels (i, j), the discretized pictures  form a positive measure belonging to . Similarly, when we consider a discretized power spectrum of a sound, it is a positive measure. The histogram of observed data defines a positive measure, too.

E. Positive-Definite Matrices

Let A be an  matrix. All such matrices form an -dimensional manifold. When A is symmetric and positive-definite, they form a -dimensional manifold. This is a submanifold embedded in the manifold of all the matrices. We may use the upper right elements of A as a coordinate system. Positive-definite matrices appear in statistics, physics, operations research, control theory, etc.

F. Neural Manifold

A neural network is composed of a large number of neurons connected with each other, where the dynamics of information processing takes place. A network is specified by connection weights  connecting neuron i with neuron j. The set of all such networks forms a manifold, where matrix  is a coordinate system. We will later analyze behaviors of such networks from the information geometry point of view.



1.2 Divergence Between Two Points

1.2.1 Divergence
Let us consider two points P and Q in a manifold M, of which coordinates are  and 
            . A
           divergence D[P : Q] is a function of  and  which satisfies certain criteria. See Basseville (2013) for a detailed bibliography. We may write it as (1.23)We assume that it is a differentiable function of  and .


Definition 1.1


D[P : Q] is called a divergence when it satisfies the following criteria:(1)
. (2)
, when and only when . (3)When P and Q are sufficiently close, by denoting their coordinates by  and , the Taylor expansion of D is written as  (1.24) and matrix  is positive-definite, depending on . 


A divergence represents a degree of separation of two points P and Q, but it or its square root is not a distance. It does not necessarily satisfy the symmetry condition, so that in general (1.25)We may call D[P : Q] divergence from P to Q. Moreover, the triangular inequality does not hold. It has the dimension of the square of distance, as is suggested by (1.24). It is possible to symmetrize a divergence by (1.26)However, the asymmetry of divergence plays an important role in information geometry, as will be seen later.
When P and Q are sufficiently close, we define the square of an infinitesimal distance ds between them by using (1.24) as (1.27)A manifold M is said to be Riemannian when a positive-definite matrix  is defined on M and the square of the local distance between two nearby points  and  is given by (1.27). A divergence D provides M with a
           Riemannian structure.


1.2.2 Examples of Divergence

A. Euclidean Divergence

When we use an orthonormal Cartesian coordinate system in a Euclidean space, we define a divergence by a half of the square of the Euclidean distance, (1.28)The matrix  is the identity matrix in this case, so that (1.29)
B. Kullback-Leibler Divergence

Let p(x) and q(x) be two probability distributions of random variable x in a manifold of probability distributions. The following is called the
           Kullback-Leibler (KL) divergence: (1.30)When x is discrete, integration is replaced by summation. We can easily check that it satisfies the criteria of divergence. It is asymmetric in general and is useful in statistics, information theory, physics, etc. Many other divergences will be introduced later in a manifold of probability distributions.

C. KL-Divergence for Positive Measures

A manifold of positive measures  is a subset of a Euclidean space. Hence, we can introduce the Euclidean divergence (1.28) in it. However, we can extend the KL-divergence to give (1.31)When the total masses of two measures  and  are 1, they are probability distributions and  reduces to the KL-divergence  in (1.30).

D. Divergences for Positive-Definite Matrices

There is a family of useful divergences introduced in the manifold of positive-definite matrices. Let P and Q be two positive-definite matrices. The following are typical examples of divergence: (1.32)which is related to the Von Neumann entropy of quantum mechanics, (1.33)which is due to the KL-divergence of multivariate Gaussian distribution, and (1.34)which is called the -divergence, where  is a real parameter. Here, tr  denotes the trace of matrix  and  is the determinant of .



1.3 Convex Function and Bregman Divergence

1.3.1 Convex Function
A nonlinear
           function  of coordinates  is said to be convex when the inequality (1.35)is satisfied for any ,  and scalar . We consider a differentiable convex function. Then, a function is convex if and only if its Hessian (1.36)is positive-definite.
There are many convex functions appearing in physics, optimization and engineering problems. One simple example is (1.37)which is a half of the square of the Euclidean distance from the origin to point . Let  be a probability distribution belonging to . Then, its entropy (1.38)is a concave function, so that its negative, , is a convex function.
We give one more example from a probability model. An exponential family of probability distributions is written as (1.39)where  is the probability density function of vector random variable  specified by vector parameter  and  is a function of . The term  is the normalization factor with which (1.40)is satisfied. Therefore,  is given by (1.41)
 is regarded as a manifold, where  is a coordinate system. By differentiating (1.41), we can prove that its Hessian is positive-definite (see the next subsection). Hence,  is a convex function. It is known as the cumulant generating function in statistics and free energy in statistical physics. The exponential
           family plays a fundamental role in information geometry.


1.3.2 Bregman Divergence
A graph of a convex function is shown in Fig. 1.4. We draw a tangent hyperplane touching it at point  (Fig. 1.4). It is given by the equation (1.42)where z is the vertical axis of the graph. Here,  is the gradient operator such that  is the gradient vector defined by (1.43)in the component form. Since  is convex, the graph of  is always above the hyperplane, touching it at . Hence, it is a supporting hyperplane of  at  (Fig. 1.4).Fig. 1.4Convex function , its supporting hyperplane with normal vector  and divergence 


We evaluate how high the function  is at  from the hyperplane (1.42). This depends on the point  at which the supporting hyperplane is defined. The difference from (1.42) is written as (1.44)Considering it as a function of two points  and , we can easily prove that it satisfies the criteria of divergence. This is called the Bregman divergence [Bregman (1967)] derived from a convex function .
We show examples of Bregman divergence.


Example 1.1

(Euclidean divergence) For  defined by (1.37) in a Euclidean space, we easily see that the divergence is (1.45)that is, the same as a half of the square of the Euclidean distance. It is symmetric.



Example 1.2

(Logarithmic divergence) We consider a convex function (1.46)in the manifold  of positive measures. Its gradient is (1.47)Hence, the Bregman divergence is (1.48)For another convex function (1.49)the Bregman divergence is the same as the KL-divergence (1.31), given by (1.50)When , this is the KL-divergence from probability vector  to another .



Example 1.3

(Free energy of exponential family) We calculate the divergence given by the normalization factor  (1.41) of an exponential family. To this end, we differentiate the identity (1.51)with respect to . We then have (1.52)or (1.53)
 (1.54)where  denotes the expectation with respect to  and  is the expectation of . We then differentiate (2.â12) again with respect to  and, after some calculations, obtain (1.55)or (1.56)where  is the transpose of column vector  and  is the covariance matrix of , which is positive-definite. This shows that  is a convex function. It is useful to see that the expectation and covariance of  are derived from  by differentiation.
The Bregman divergence from  to  derived from  of an exponential family is calculated from (1.57)proving that it is equal to the KL-divergence from  to  after careful calculations, (1.58)





1.4 Legendre Transformation
The gradient of 
 (1.59)is equal to the
         normal vector  of the supporting tangent hyperplane at , as is easily seen from Fig. 1.4. Different points have different normal vectors. Hence, it is possible to specify a point of M by its normal vector. In other words, the transformation between  and  is one-to-one and differentiable. This shows that  is used as another coordinate system of M, which is connected with  by (1.59).
The transformation (1.59) is known as the Legendre transformation. The Legendre transformation has a dualistic structure concerning the two coupled coordinate systems  and . To show this, we define a new function of  by (1.60)where (1.61)and  is not free but is a function of , (1.62)which is the inverse function of . By differentiating (1.60) with respect to , we have (1.63)Since the last two terms of (1.63) cancel out because of (1.59), we have a dualistic structure (1.64)
 is called the Legendre dual of . The dual function  satisfies (1.65)which is usually used as the definition of . Our definition (1.60) is direct. We need to show  is a convex function. The Hessian of  is written as (1.66)which is the Jacobian matrix of the inverse transformation from  to . This is the inverse of the Hessian , since it is the Jacobian matrix of the transformation from  to . Hence, it is a positive-definite matrix. This shows that  is a convex function of .
A new Bregman divergence is derived from the
         dual convex function , (1.67)which we call the dual divergence. However, by calculating carefully, one can easily derive (1.68)Hence, the dual divergence is equal to the primal one if the order of two points is exchanged. Therefore, the divergences derived from the two convex functions are substantially the same, except for the order.
It is convenient to use a self-dual expression of divergence by using the two coordinate systems.


Theorem 1.1

The divergence from P to Q derived from a convex  is written as (1.69)where  is the coordinates of P in  coordinate system and  is the coordinates of Q in  coordinate system.



Proof

From (1.57), we have (1.70)Substituting (1.70) in (1.69) and using , we have the theorem.
We give examples of dual convex functions. For convex function (1.37) in Example 1.1, we easily have (1.71)and (1.72)Hence, the dual convex function is the same as the primal one, implying that the structure is self-dual.


In the case of Example 1.2, the duals of  and  in (1.46) and (1.49) are (1.73)
 (1.74)by which (1.75)hold, respectively.
In the case of the free energy  in Example 1.3, its Legendre transformation is (1.76)where  is the expectation with respect to . Because of this,  is called the expectation parameter in statistics. The dual convex function  derived from (1.65) is calculated from (1.77)where  is a function of  given by . This proves that  is the negative entropy, (1.78)The dual divergence derived from  is the KL-divergence (1.79)where  and .


1.5 Dually Flat Riemannian Structure Derived from Convex Function

1.5.1 Affine and Dual Affine Coordinate Systems
When a function  is convex in a coordinate system , the same function expressed in another coordinate system , (1.80)is not necessarily convex as a function of . Hence, the convexity of a function depends on the coordinate system of M. But a convex function remains convex under affine transformations (1.81)where  is a non-singular constant matrix and  is a constant vector.
We fix a coordinate system  in which  is convex and introduce geometric structures to M based on it. We consider  as an
           affine coordinate system, which provides M with an
           affine flat structure: M is a flat manifold and each coordinate axis of  is a straight line. Any curve  of M written in the linear form of parameter t, (1.82)is a straight line, where and  and  are constant vectors. We call it a
           geodesic of an affine manifold. Here, the term "geodesic" is used to represent a straight line and does not mean the shortest path connecting two points. A geodesic is invariant under affine transformations (1.81), but this is not true under nonlinear coordinate transformations.
Dually, we can define another coordinate system  by the Legendre transformation, (1.83)and consider it as another type of affine coordinates. This defines another affine structure. Each coordinate axis of  is a dual straight line or
           dual geodesic. A dual straight line is written as (1.84)This is the
           dual affine structure derived from the convex function . Since the coordinate transformation between the two affine coordinate systems  and  is not linear in general, a geodesic is not a dual geodesic and vice versa. This implies that we have introduced two different criteria of straightness or flatness in M, namely primal and dual flatness. M is dually flat and the two flat coordinates are connected by the Legendre transformation.


1.5.2 Tangent Space, Basis Vectors and Riemannian Metric
When  is an (infinitesimally) small line element, the square of its length ds is given by (1.85)Here, we use the upper indices i, j to represent components of . It is easy to see that the
           Riemannian metric  is given by the Hessian of 
 (1.86)Let  be the set of tangent vectors along the coordinate curves of  (Fig. 1.5). The vector space spanned by  is the
           tangent space of M at each point. Since  is an affine coordinate system,  looks the same at any point. A tangent vector  is represented asFig. 1.5Basis vectors  and small line element 

 (1.87)where  are the components of  with respect to the
           basis vectors . The small line element  is a tangent vector expressed as (1.88)Dually, we introduce a set of basis vectors  which are tangent vectors of the dual affine coordinate curves of  (Fig. 1.6). The small line element  is expressed as (1.89)in this basis. A vector  is represented in this basis as (1.90)In order to distinguish affine and dual affine bases, we use the lower index as in  for the affine basis and the upper index as in  for the dual affine basis. Then, by using the lower and upper indices as in  and  in the two bases, the components of a vector are naturally expressed without changing the letter A but by changing the position of the index to upper or lower. Since they are the same vector expressed in different bases, (1.91)and  in general.Fig. 1.6Two dual bases  and 


It is cumbersome to use the summation symbol in Eqs. (1.87)-(1.91) and others. Even if the summation symbol is discarded, the reader may consider from the context that it has been omitted by mistake. In most cases, index i appearing twice in one term, once as an upper index and the other time as a lower index, is summed over from 1 to n. A. Einstein introduced the following summation
           convention:

Einstein Summation Convention: When the same index appears twice in one term, once as an upper index and the other time as a lower index, summation is automatically taken over this index even without the summation symbol.
We use this convention throughout the monograph, unless specified otherwise. Then, (1.91) is rewritten as (1.92)Since the square of the length ds of a small line element  is given by the inner product of , we have (1.93)which is rewritten as (1.94)Therefore, we have (1.95)This is the inner product of basis vectors  and , which depends on position .
A manifold equipped with , by which the length of a small line element  is given by (1.93), is a Riemannian manifold. In the case of a Euclidean space with an orthonormal coordinate system,  is given by (1.96)where  is the Kronecker delta, which is equal to 1 for  and 0 otherwise. This is derived from convex function (1.37). A Euclidean space is a special case of the Riemannian manifold in which there is a coordinate system such that  does not depend on position, in particular, written as (1.96). A manifold induced from a convex function is not Euclidean in general.
The Riemannian metric can also be represented in the dual affine coordinate system . From the representation of a small line element  as (1.97)we have (1.98)where  is given by (1.99)From (1.66), we see that the components of the small line elements  and  are related as (1.100)
 (1.101)where . So the two Riemannian metric tensors are mutually inverse.
This also implies that the two bases are related as (1.102)Hence, the inner product of two basis vectors  and  satisfies (1.103)because . So the two bases  and  are mutually dual or reciprocal (Fig. 1.6). Neither of the bases is orthonormal by itself in general, but the two together are complementarily orthogonal. Such a set of bases is useful, because the components of a vector  are given by the inner product, (1.104)The two components are connected by (1.105)



1.5.3 Parallel Transport of Vector
A tangent vector  defined at a point  is transported to another point  without changing the components , because  are the same everywhere in a dually flat manifold. This is a special case of
           parallel transport of a vector in a general non-flat manifold. As will be seen in Part II, the parallel transport of a vector needs to use an affine connection in the general case. But in our case of a dually flat manifold derived from a convex function , the parallel transport is very simple.
The dual parallel transport of  is different from the parallel transport of . When  is represented in the dual basis as (1.106)the dual transport does not change the components . However, it changes the components , because the relation between  and  depends on position  or , as is seen from (1.105), where  and  depend on  and .
Since M is Riemannian and is not Euclidean in general, even though the parallel transport is defined easily, the length of a vector changes by the parallel transport and the dual parallel transport. The square of the magnitude of  is written as (1.107)Therefore, it depends on the position , even though the components of  do not change by parallel transport. The
           inner product of vectors  and  is represented by various forms, (1.108)Two vectors  and  are orthogonal when . However, when both  and  are parallelly transported from  to , the orthogonality does not hold in general at  even when it holds at . However, when  is transported in parallel and  is transported in dual parallel, the orthogonality is kept invariant, because  is invariant. This is an important property of two dually coupled parallel transports.



1.6 Generalized Pythagorean Theorem and Projection Theorem

1.6.1 Generalized Pythagorean Theorem
Two curves  and  intersect orthogonally when their tangent vectors (1.109)
 (1.110)are orthogonal, that is, (1.111)at the intersection point ,  and  denotes d / dt.
Even though a manifold is flat from the point of view of affine structures, it is different from a Euclidean space. A dually flat manifold is a generalization of the Euclidean space. A
           generalized Pythagorean theorem holds in a dually flat manifold M.
Let us consider three points P, Q, R in a dually flat manifold M, which form a triangle. We call it an orthogonal triangle when the dual geodesic connecting P and Q is orthogonal to the geodesic connecting Q and R (Fig. 1.7).Fig. 1.7Generalized orthogonal triangle  and Pythagorean theorem



Theorem 1.2

(Generalized Pythagorean Theorem) When triangle PQR is orthogonal such that the dual geodesic connecting P and Q is orthogonal to the geodesic connecting Q and R, the following generalized Pythagorean relation holds: (1.112)




Proof

By using the relation (1.113)we have (1.114)after some calculations. The dual geodesic connecting P and Q is written as (1.115)in the parametric form. Its tangent vector is given by (1.116)Dually, the geodesic connecting Q and R is (1.117)and its tangent vector is (1.118)Since the two tangent vectors are orthogonal, we have (1.119)The Pythagorean relation is proved from (1.114). 


Since the divergence is asymmetric, we have the dual statement.


Theorem 1.3

(Dual Pythagorean Theorem) When triangle PQR is orthogonal such that the geodesic connecting P and Q is orthogonal to the dual geodesic connecting Q and R, the dual of the generalized Pythagorean relation holds, (1.120)


In the special case of convex function (1.37), the divergence is exactly a half of the square of the Euclidean distance. Moreover, the affine coordinate system is exactly the same as the dual affine coordinate system, because the affine structure is self-dual. Hence, a geodesic is a dual geodesic at the same time. In this case, the generalized Pythagorean relation reduces to the Pythagorean relation in a Euclidean space. The theorems are indeed a generalization of the Pythagorean theorem of a
           Euclidean space to a dually flat manifold.


1.6.2 Projection Theorem
Consider a point P and a smooth submanifold S in a dually flat manifold M. Then, the divergence from a point P to submanifold S is defined by (1.121)We study the problem of finding the point in S that is closest to P in the sense of divergence. This gives an approximation of P by using a point inside S. The Pythagorean theorem is useful for solving various approximation problems.
We define the geodesic projection and the dual geodesic projection of P to . A curve  is said to be orthogonal to S when its tangent vector  is orthogonal to any tangent vectors of S at the intersection (Fig. 1.8).Fig. 1.8Geodesic projection of P to S




Definition 1.2


 is the geodesic projection of P to S when the geodesic connecting P and  is orthogonal to S. Dually,  is the dual geodesic projection of P to S, when the dual geodesic connecting P and  is orthogonal to S. See Fig. 1.8.

We then have the projection theorem:


Theorem 1.4

(Projection Theorem) Given  and a smooth submanifold , the point  that minimizes the divergence , is the dual geodesic projection of P to S. The point  that minimizes the dual divergence , is the geodesic projection of P to S.



Proof

Let  be the dual geodesic projection of P to S. Consider a point  which is (infinitesimally) close to . Then, three points P,  and Q form an orthogonal triangle, because the small line element connecting  and Q is orthogonal to the the dual geodesic connecting P and . Hence, the Pythagorean theorem shows (1.122)for any neighboring Q. This shows that  is a critical point of , , proving the theorem. The dual part is proved similarly.


It should be noted that the projection theorem gives a necessary condition for the point  to minimize the divergence, but is not sufficient. The projection or dual projection can give the maximum or saddle point of the divergence. The following theorem gives a sufficient condition for the minimality of the projection and its uniqueness.


Theorem 1.5

When S is a flat submanifold of a dually flat manifold M, the dual projection of P to S is unique and minimizes the divergence. Dually, when S is a dual flat submanifold of a dually flat manifold M, the projection of P to S is unique and minimizes the dual divergence.



Proof

The Pythagorean relations (1.112), (1.120) hold for any . Hence the projection (dual projection) is unique and minimizes the dual divergence (divergence). 




1.6.3 Divergence Between Submanifolds: Alternating Minimization Algorithm
When there are two submanifolds K and S in a dually flat M, we define a divergence between K and S by (1.123)The two points  and  are the closest pair between K and S. In order to obtain the closest pair, the following iterative algorithm, the
           alternating minimization algorithm, is proposed. See Fig. 1.9.Fig. 1.9Iterated dual geodesic projections (em algorithm)

Begin with an arbitrary , , and search for  that minimizes . This is given by the geodesic projection of  to K. Let it be . Then search for the point in S that minimizes . Let it be . This is given by the dual geodesic projection of  to S. Since we have (1.124)the procedure converges. It is unique when S is flat and K is dual flat. Otherwise, the converging point is not necessarily unique.
In later sections, the geodesic projection is called the e-projection, signifying the exponential projection, and the dual geodesic projection is called the m-projection, signifying the mixture projection. By this reason, this alternating primal and dual geodesic projection algorithm is called the
           em algorithm.


Remarks

A dually flat Riemannian structure is derived from the Bregman divergence by using a convex function. It has a dualistic structure. However, not all divergences are Bregman divergences, that is, not necessarily derived from convex functions. An interesting question is what type of geometry is induced from such a general divergence. This question will be studied in Part II. Briefly speaking, it gives a Riemannian manifold with a dual pair of affine connections which are not flat. There are no affine coordinate systems in such cases.
A dually flat manifold is a generalization of a Euclidean space, inheriting useful properties from it. A general non-flat manifold is regarded as a curved submanifold of a dually flat manifold, as a Riemannian manifold is a curved submanifold of a Euclidean space with higher dimensions. Therefore, it is important to study the properties of a dually flat manifold.
The Pythagorean theorem and related projection theorem are highlights of a dually flat manifold, proposed in Nagaoka and Amari (1982). However, this work was not published in a journal, because, unfortunately, it was rejected by major journals. These theorems play important roles in most applications of information geometry. The Pythagorean theorem has been known for many years in the case of the KL-divergence. It is information geometry that has generalized the Pythagorean relation applicable to any Bregman divergence. Conversely, when a manifold is dually flat from the geometrical point of view, we can prove that there is a convex function from which the dually flat structure is derived. This will be explained later.
We add a comment on the notation. There are many coordinate systems in a coordinate neighborhood of a manifold, because when  is a coordinate system, its transform , (1.125)is another coordinate system, provided  is differentiable and invertible. The Jacobian matrix  of the coordinate transformation (1.126)is non-degenerate, that is, matrix  is invertible.
Here we use indices  to represent components in the coordinate system  and Greek indices  for the coordinate system . This is a convenient way of distinguishing coordinate systems. For example, a small line element connecting P and  is  in coordinate system  and  in coordinate system , and they are linearly connected by (1.127)When ds is a local distance written as (1.128)in the coordinate system , it can be written as (1.129)in coordinate system . Here,  and  are different matrices connected by (1.130)Such a quantity is called a tensor. We use the same letter g for the Riemannian metric tensor, but indices i, j or ,  distinguish the coordinate system in which it is represented. In general, we may use the same letter for a quantity even if it is represented in different coordinate systems, distinguishing them by the letter types of indices. This is convenient for the index notation, introduced by Schouten (1954). We mainly follow this idea.
We may choose any coordinate system. The geometry should be the same whichever coordinate system we use. Mathematicians often do not like to use a coordinate system, because geometry should not depend on it. They say that the index notation is an ugly classic method of differential geometry, where tensors are represented by quantities having indices. So they use the coordinate-free method of abstract description. This is sometimes elegant. However, it is wiser to choose an adequate coordinate system, because the geometry is the same in whichever coordinate system it is analyzed. For Euclidean geometry, an orthonormal coordinate system is usually preferable. However, when we analyze a boundary value problem of the heat equation in a Euclidean space, if the boundary is a circle, the polar coordinate system makes the boundary condition very simple. So in such a case, we use this.
Any coordinate system is permissible, but it is advisable to use a convenient one, instead of rejecting the usage of a coordinate system. This is the way in which engineers and physicists work.




Footnotes


1


Mathematically trained readers may know the rigorous definition of a manifold: A manifold M is a Hausdorff space which is covered by a number of open sets called coordinate neighborhoods, such that there exists an isomorphism between a coordinate neighborhood and a Euclidean space. The isomorphism defines a local coordinate system in the neighborhood. M is called a differentiable manifold when the coordinate transformations are differentiable. See textbooks on modern differential geometry. Our definition is intuitive, not mathematically rigorous, but is sufficient for understanding information geometry and its applications.

 













Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_2




2. Exponential Families and Mixture Families of Probability Distributions




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp






The present chapter studies the geometry of the exponential family of probability distributions. It is not only a typical statistical model, including many well-known families of probability distributions such as discrete probability distributions , Gaussian distributions, multinomial distributions, gamma distributions, etc., but is associated with a convex function known as the cumulant generating function or free energy. The induced Bregman divergence is the KL-divergence. It defines a dually flat Riemannian structure. The derived Riemannian metric is the Fisher information matrix and the two affine coordinate systems are the natural (canonical) parameters and expectation parameters, well-known in statistics. An exponential family is a universal model of dually flat manifolds, because any Bregman divergence has a corresponding exponential family of probability distributions (Banerjee et al. 2005).
We also study the mixture family of probability distributions, which is the dual of the exponential family. Applications of the generalized Pythagorean theorem demonstrate how useful this is.

2.1 Exponential Family of Probability Distributions
The standard form of an
         exponential family is given by the probability density function (2.1)where x is a random variable,  is an n-dimensional vector parameter to specify a distribution,  are n functions of x which are linearly independent, k(x) is a function of x,  corresponds to the normalization factor and the Einstein summation convention is working. We introduce a new vector random variable  by (2.2)We further introduce a measure in the sample space  by (2.3)Then, (2.1) is rewritten as (2.4)Hence, we may put (2.5)which is a probability density function of  with respect to measure .
The family of distributions (2.6)forms an n-dimensional manifold, where  is a coordinate system. From the normalization condition (2.7)
 is written as (2.8)We proved in Chap. 1 that  is a convex function of , known as the
         cumulant generating function in statistics and
         free energy in physics. A dually flat Riemannian structure is introduced in M by using . The affine coordinate system is , which is called the
          or canonical parameter of an exponential family. The dual affine parameter is given by the Legendre transformation, (2.9)which is the expectation of  denoted by , (2.10)This  is called the expectation parameter in statistics. Since the dual affine parameter  is nothing other than , we hereafter use , instead of , to represent the dual affine parameter in an exponential family. This is a conventional notation used in Amari and Nagaoka (2000), avoiding the cumbersome  notation. So we have (2.11)Hence,  and  are two affine coordinate systems connected by the Legendre transformation.
We use  to denote the dual convex function , the Legendre dual of , which is defined by (2.12)In order to obtain , we calculate the
         negative entropy of , obtaining (2.13)Given , the  that maximizes the right-hand side of (2.12) is given by the solution of . Hence, the dual convex function  of , which we hereafter denote as , is given by the negative entropy, (2.14)where  is regarded as a function of  through . The inverse transformation is given by (2.15)The divergence from  to  is written as (2.16)The Riemannian metric is given by (2.17)
 (2.18)for which we hereafter use the abbreviation (2.19)Here, the position of the index i is important. If it is lower, as in , the differentiation is with respect to , whereas, if it is upper as in , the differentiation is with respect to .
The Fisher information matrix plays a fundamental role in statistics. We prove the following theorem which connects geometry and statistics.


Theorem 2.1

The Riemannian metric in an exponential family is the
           Fisher information matrix defined by (2.20)




Proof

From (2.21)we have (2.22)which is equal to . This is the Riemannian metric derived from , as is shown in (1.â56).




2.2 Examples of Exponential Family: Gaussian and Discrete Distributions
There are many statistical models belonging to the exponential family. Here, we show only two well-known, important distributions.

2.2.1 Gaussian Distribution
The Gaussian distribution with mean  and variance  has the probability density function (2.23)We introduce a new vector random variable , (2.24)
 (2.25)Note that x and  are dependent, but are linearly independent. We further introduce new parameters (2.26)
 (2.27)Then, (2.23) is written in the standard form, (2.28)The convex function  is given by (2.29)Since  and  are not independent but satisfy the relation (2.30)we use the dominating measure of (2.31)where  is the delta function.
The dual affine coordinates  are given from (2.10) as (2.32)



2.2.2 Discrete Distribution
Distributions of discrete random variable x over  form a probability simplex . A distribution  is represented by (2.33)We show that  is an exponential family. We have (2.34)because of (2.35)We introduce new random variables , (2.36)and new parameters (2.37)Then, a discrete distribution  is written from (2.34) as (2.38)where the cumulant generating function is (2.39)The dual affine coordinates  are (2.40)The dual convex function is the negative entropy, (2.41)By differentiating it, we have . (2.42)




2.3 Mixture Family of Probability Distributions
A mixture family is in general different from an exponential family, but family  of discrete distributions is an exponential family and a mixture family at the same time. We show that the two families play a dual role.
Given  probability distributions  which are linearly independent, we compose a family of probability distributions given by (2.43)where (2.44)This is a statistical model called a
         mixture family, where  is a coordinate system and . (We sometimes consider the closure of the above family, where .)
As is easily seen from (2.33), a discrete distribution  is a mixture family, where (2.45)Hence,  is a dual affine coordinate system of the exponential family . We consider a general mixture family (2.43) which is not an exponential family. Even in this case, the negative entropy (2.46)is a convex function of . Therefore, we regard it as a dual convex function and introduce the dually flat structure to , having  as the dual affine coordinate system. Then, the primary affine coordinates are given by the gradient, (2.47)It defines the primal affine structure dually coupled with , although  is not the natural parameter of an exponential family, except for the case of  where  is the natural parameter.
The divergence given by  is the KL-divergence (2.48)



2.4 Flat Structure: e-flat and m-flat
The manifold M of exponential family is dually flat. The primal affine coordinates which define straightness or flatness are the natural parameter  in an exponential family. Let us consider the straight line, that is a geodesic, connecting two distributions  and . This is written in the  coordinate system as (2.49)where t is the parameter. The probability distributions on the geodesic are (2.50)Hence, a geodesic itself is a one-dimensional exponential family, where t is the natural parameter.
By taking the logarithm, we have (2.51)Therefore, a geodesic consists of a linear interpolation of the two distributions in the logarithmic scale. Since (2.51) is an exponential family, we call it an e
        -geodesic, e standing for "exponential". More generally, a submanifold which is defined by linear constraints in  is said to be
         e-flat. The affine parameter  is called the
         e-affine parameter.
The dual affine coordinates are , and define the dual flat structure. The dual geodesic connecting two distributions specified by  and  is given by (2.52)in terms of the dual coordinate system. Along the dual geodesic, the expectation of  is linearly interpolated, (2.53)In the case of discrete probability distributions , the dual geodesic connecting  and  is (2.54)which is a mixture of two distributions  and . Hence, a dual geodesic is a mixture of two probability distributions. We call a dual geodesic an
         m-geodesic and, by this reasoning,  is called the
         m-affine parameter, where m stands for "mixture". A submanifold which is defined by linear constraints in  is said to be
         m-flat. The linear mixture (2.55)is not included in M in general, but  is in M, where we used the abuse of notation  to specify the distribution of M of which dual coordinates are .


Remark

An m-geodesic (2.52) is not a linear mixture of two distributions specified by  and  in the case of a general exponential family. However, we use the term m-geodesic even in this case.



2.5 On Infinite-Dimensional Manifold of Probability Distributions
We have shown that  of discrete probability distributions is an exponential family and a mixture family at the same time. It is a super-manifold, in which any statistical model of a discrete random variable is embedded as a submanifold. When x is a continuous random variable, we are apt to consider the geometry of the manifold F of all probability density functions p(x) in a similar way. It is a super-manifold including all statistical models of a continuous random variable. It is considered to be an exponential family and a mixture family at the same time. However, the problem is not mathematically easy, since it is a function space of infinite dimensions. We show a naive idea of studying the geometry of F. This is not mathematically justified, although it works well in most cases, except for "pathological" situations.
Let p(x) be a probability density function of real random variable , which is mutually absolutely continuous with respect to the Lebesgue measure.1 We put (2.56)Then, F is a function space consisting of  functions. For two distributions  and , the exponential family connecting them is written as (2.57)provided it exists in F. Also the mixture family connecting them (2.58)is assumed to belong to F. Then, F is regarded as an exponential and a mixture family at the same time as  is. Mathematically, there is a delicate problem concerning the topology of F. The -topology and -topology of the function space F are different. Also the topology induced by p(x) is different from that induced by .
Disregarding such mathematical problems, we discretize the real line  into  intervals, . Then, the discretized version of p(x) is given by the discrete probability distribution , (2.59)This gives a mapping from F to , which approximates p(x) by . When the discretization is done in such a way that  in each interval converges to 0 as n tends to infinity, the approximation looks fine. Then, the geometry of F would be defined by the limit of  consisting of discretized . However, we have difficulty in this approach. The limit  of the geometry of  might not be unique, depending on the method of discretization. Moreover, an admissible discretization would be different for different .
Forgetting about the difficulty, by using the delta function , let us introduce a family of random variables  indexed by a real parameter s, which plays the role of index i in  of . Then, we have (2.60)which shows that F is a mixture family generated by the delta distributions , . Here, p(s) are mixing coefficients. Similarly, we have (2.61)where (2.62)and  is a functional of  formally given by (2.63)Hence, F is an exponential family where  is the  affine coordinates and  is the dual affine coordinates . The dual convex function is (2.64)Indeed the dual coordinates are given by (2.65)and we have (2.66)where  is the FrÃ©chet-derivative with respect to function . The e-geodesic connecting p(x) and q(x) is (2.57) and the m-geodesic (2.58). The tangent vector of an e-geodesic is (2.67)in the e-coordinates, and that of an m-geodesic is (2.68)in the m-coordinates.
The KL-divergence is (2.69)which is the Bregman divergence derived from  and it gives F a dually flat structure. The Pythagorean theorem is written, for three distributions p(x), q(x) and r(x), as (2.70)when the mixture geodesic connecting p and q is orthogonal to the exponential-geodesic connecting q and r, that is, when (2.71)It is easy to prove this directly. The projection theorem follows similarly.
The KL-divergence between two nearby distributions p(x) and  is expanded as (2.72)Hence, the squared distance of an infinitesimal deviation  is (2.73)which defines the Riemannian metric given by the Fisher information.
Indeed, the Riemannian metric in -coordinates are given by (2.74)and its inverse is (2.75)in -coordinates.
It appears that most of the results we have studied in  hold well even in the function space F with naive treatment. They are practically useful even though no mathematical justification is given. Unfortunately, we are not free from mathematical difficulties. We show some examples.
The pathological nature in the continuous case has long been known. The following fact was pointed out by CsiszÃ¡r (1967). We define a quasi--neighborhood of p(x) based on the KL-divergence, (2.76)However, the set of the quasi--neighborhoods does not satisfy the axiom of the topological subbase. Hence, we cannot use the KL-divergence to define the topology. More simply, it is demonstrated that the entropy functional (2.77)is not continuous in F, whereas it is continuous and differentiable in  (Ho and Yeung 2009).
G. Pistone and his co-workers studied the geometrical properties of F based on the theory of Orlicz space, where F is not a Hilbert space but a Banach space. See Pistone and Sempi (1995), Gibilisco and Pistone (1998), Pistone and Rogathin (1999), Cena and Pistone (2007). This was further developed by Grasselli (2010). See recent works by Pistone (2013) and Newton (2012), where trials for mathematical justification using innocent ideas have been developed.


2.6 Kernel Exponential Family
Fukumizu (2009) proposed a
         kernel exponential family, which is a model of probability distributions of function degrees of freedom. Let k(x, y) be a kernel function satisfying positivity, (2.78)for any f(x) not equal to 0. A typical example is the Gaussian kernel (2.79)where  is a free parameter.
A kernel exponential family is defined by (2.80)with respect to suitable measure , e.g., (2.81)The natural or canonical parameter is a function  indexed by y instead of  and the dual parameter is (2.82)where expectation is taken by using .  is a convex functional of . This exponential family does not cover all p(x) of probability density functions. So there are many such models, depending on k(x, y) and . The naive treatment in Sect. 2.5 may be regarded as the special case where the kernel k(x, y) is put equal to the delta function .


2.7 Bregman Divergence and Exponential Family
An exponential family induces a Bregman divergence  given in (2.16). Conversely, when a Bregman divergence  is given, is it possible to find a corresponding exponential family ? The problem is solved positively by Banerjee et al. (2005). Consider a random variable . It specifies a point  in the -coordinates of a dually flat manifold given by . Let  be its -coordinates. The -divergence from  to , the latter of which is the -coordinates of , is written as (2.83)Using this, we define a probability density function written in terms of the divergence as (2.84)where  is determined from  as the -coordinates of . Thus, we have an exponential family derived from .
The problem is restated as follows: Given a convex function , find a measure  such that (2.8), or equivalently (2.85)is satisfied. This is the inverse of the Laplace transform. A mathematical theory concerning the one-to-one correspondence between (regular) exponential families and (regular) Bregman divergences is established in Banerjee et al. (2005).


Theorem 2.2

There is a bijection between regular exponential families and regular Bregman divergences.

The theorem shows that a Bregman divergence has a probabilistic expression given by an exponential family of probability distributions. A Bregman divergence is always written in the form of the KL-divergence of the corresponding exponential family.


Remark

A mixture family  has a dually flat structure, where the negative entropy  is a convex function. We can define an exponential family of which the convex function is . However, this is different from the original M. Hence, Theorem 2.2 does not imply that a mixture family is an exponential family, even though it is dually flat.



2.8 Applications of Pythagorean Theorem
A few applications of the generalized Pythagorean Theorem are shown here to illustrate its usefulness.

2.8.1 Maximum Entropy Principle
Let us consider discrete probability distributions , although the following arguments hold even when x is a continuous vector random variable. Let  be k random variables, that is, k functions of x. Their expectations are (2.86)We consider a probability distribution p(x) for which the expectations of  take prescribed values , (2.87)There are many such distributions and they form an -dimensional submanifold  specified by , because k restrictions given by (2.87) are imposed. This  is m-flat, because any mixtures of distributions in  belong to the same .
When one needs to choose a distribution from , if there are no other considerations, one would choose the distribution that maximizes the entropy. This is called the
           maximum entropy principle.
Let  be the uniform distribution that maximizes the entropy in . The dual divergence between  and  is written as (2.88)where the e-coordinates of  are given by ,  is the m-coordinates of P and  is the negative entropy. This is the KL-divergence  from P to . Since  is the uniform distribution, . Hence, maximizing the entropy  is equivalent to minimizing the divergence. Let  be the point that maximizes the entropy. Then, triangle  is orthogonal and the Pythagorean relation (2.89)holds (Fig. 2.1). This implies that the entropy maximizer  is given by the e-projection of  to .Fig. 2.1The family maximizing entropy under linear constraints is an exponential family

Each  includes the entropy maximizer . By changing , all of these  form a k-dimensional submanifold  which is an exponential family, where the natural coordinates are specified by  (Fig. 2.1), (2.90)It is easy to obtain this result by the variational method that maximizes the entropy  under constraints (2.87).


2.8.2 Mutual Information
Let us consider two random variables x and y and the manifold M consisting of all p(x, y). When x and y are independent, the probability can be written in the product form as (2.91)where  and  are respective marginal distributions.
Let the family of all the independent distributions be . Since the exponential family connecting two independent distributions is again independent, the e-geodesic connecting them consists of independent distributions. Therefore,  is an e-flat submanifold.
Given a non-independent distribution p(x, y), we search for the independent distribution which is closest to p(x, y) in the sense of KL-divergence. This is given by the
           m-projection of p(x, y) to  (Fig. 2.2). The projection is unique and given by the product of the marginal distributions (2.92)The divergence between p(x, y) and its projection is (2.93)which is the mutual information of two random variables x and y. Hence, the mutual information is a measure of discrepancy of p(x, y) from independence.Fig. 2.2Projection of p(x, y) to the family  of independent distributions is the m-projection. The mutual information  is the KL-divergence 


The reverse problem is also interesting. Given an independent distribution (2.92), find the distribution p(x, y) that maximizes  in the class of distributions having the same marginal distributions as . These distributions are the inverse image of the m-projection. This problem is studied by Ay and Knauf (2006) and Rauh (2011). See Ay (2002), Ay et al. (2011) for applications of information geometry to complex systems.


2.8.3 Repeated Observations and Maximum Likelihood Estimator
Statisticians use a number of independently observed data  from the same probability distribution  in an exponential family M for estimating . The joint probability density of  is given by (2.94)having the same parameter . We see how the geometry of M changes by multiple observations.
Let the arithmetic average of  be (2.95)Then, (2.94) is rewritten as (2.96)Therefore, the probability density of  has the same form as , except that  is replaced by  and the term  becomes N times larger.
This implies that the convex function becomes N times larger and hence the KL-divergence and Riemannian metric (Fisher information matrix) also become N times larger. The dual affine structure of M does not change. Hence, we may use the original M and the same coordinates  even when multiple observations take place for statistical inference. The binomial distributions and multinomial distributions are exponential families derived from  and  by multiple observations.
Let M be an exponential family and consider a statistical model  included in it as a submanifold, where S is specified by parameter , . Since it is included in M, the e-coordinates of  in M are determined by  in the form of . Given N independent observations , we estimate the parameter  based on them.
The observed data specifies a distribution in the entire M, such that its m-coordinates are (2.97)This is called an
           observed point. The KL-divergence from the observed  to a distribution  in S is written as , where  is the -coordinates of the observed point . We consider a simple case of , where the observed point is given by the histogram (2.98)Then, except for a constant term, minimizing  is equivalent to maximizing the -likelihood (2.99)
Fig. 2.3The maximum likelihood estimator is the m-projection of observed point to S


Hence, the
           maximum likelihood estimator that minimizes the divergence is given by the m-projection of  to S. See Fig. 2.3. In other words, the maximum likelihood estimator is characterized by the m-projection.


Remarks

An exponential family is an ideal model to study the dually flat structure and also statistical inference. The Legendre duality between the natural and expectation parameter was pointed out by Barndorff-Nielsen (1978). It is good news that the family  of discrete distributions is an exponential family, because any statistical model having a discrete random variable is regarded as a submanifold of an exponential family. Therefore, it is wise to study the properties of the exponential family first and then see how they are transferred to curved subfamilies.
Unfortunately, this is not the case with continuous random variable x. There are many statistical models which are not subfamilies of exponential families, even though many are curved-exponential families, that is, submanifolds of exponential families. Again, the study of the exponential family is useful. In the case of a truly non-exponential model, we use its local approximation by using a larger exponential family. This gives an exponential fibre-bundle-like structure to statistical models. This is useful for studying the asymptotic theory of statistical inference. See Amari (1985).
It should be remarked that a generalized linear model provides a dually flat structure, although it is not an exponential family. See Vos (1991). A mixture model also has remarkable characteristics from the point of view of geometry. See Marriott (2002), Critchley et al. (1993).




Footnotes


1


It would be better to use density function p(x) with respect to the Gaussian measurerather than the Lebsesque measure dx.

 













Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_3




3. Invariant Geometry of Manifold of Probability Distributions




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp






We have introduced a dually flat Riemannian structure in the manifolds of the exponential family and the mixture family based on the convexity of the cumulant generating function (free energy) and the negative entropy, respectively. The KL-divergence is derived from these convex functions. However, we need justification for this selection of convex function and divergence. Moreover, such a convex function does not exist for a general statistical model. Therefore, a reasonable criterion is needed for introducing a geometrical structure to a manifold of probability distributions. It is invariance that justifies the above selection.
Invariance requires that a geometrical structure should be invariant when random variable  is represented in a different form , provided  is invertible. This is an idea introduced by Chentsov (1972). We begin with a simpler idea of information monotonicity by coarse graining, due to CsiszÃ¡r (1974), a simplified version of Chentsov's invariance. There exists a unique class of decomposable invariant
       divergences, known as f-divergences.

3.1 Invariance Criterion
We treat a statistical model (3.1)parameterized by , which forms a manifold with coordinate system . Here, x may take discrete, continuous and vector values. What is a natural divergence  between two probability distributions  and ? In answering this question, we consider the invariance criterion, which states that the geometry is the same when random variable x is transformed into y without losing information. We consider a mapping of x to y
 (3.2)which is in general many-to-one, so we cannot recover x from y. Then, information is lost by this mapping. Let the probability distribution of y be , (3.3)in the discrete case, which is induced from  by the mapping . In the continuous case, the probability density  is given by integration. The divergence  between  and  changes to  between  and . Since divergence  represents the dissimilarity of two distributions  and , it is postulated that it decreases in general by this mapping, (3.4)We call this relation
         information monotonicity.
Obviously, when k is one-to-one, that is invertible, there is no loss of information and the equality is required to hold in (3.4). However, there is a case when information is not lost even when k is not invertible. This is the case when x includes a redundant part, the distribution of which does not depend on . We may abandon this part without losing information concerning . The remaining part retains full information. Statisticians call such a part a
         sufficient statistic. Its definition is given below.
A function (3.5)is called a sufficient statistic when the probability density function  is decomposed as (3.6)This implies that the probability  is written as a function of s, except for a multiplicative term r(x) which does not depend on . The equality is required to hold in (3.4) when and only when y is a sufficient statistic.
We formally state the invariance criterion, for which the basic idea was originally due to Chentsov (1972) and which was formulated in this way by Amari and Nagaoka (2000).

Invariance Criterion: A geometrical structure of M is invariant when it satisfies the monotonicity (3.4), where the equality holds if and only if  is a sufficient statistic.
We study the class of
         invariant divergences and
         invariant Riemannian metrics. The invariant metric is unique, given by the Fisher information matrix except for a scale constant (Chentsov 1972).


3.2 Information Monotonicity Under Coarse Graining

3.2.1 Coarse Graining and Sufficient Statistics in 

We consider a family  of discrete probability distributions, where random variable x takes on values . Let us denote a probability distribution by an -dimensional probability vector . We divide X into  subsets  such that (3.7)where  is the empty set. This is a partition of X (Fig. 3.1).Fig. 3.1Partition of X into  subsets

Assume that we cannot observe x directly, but know the subset to which x belongs. This is the case when X is coarse-grained. We then introduce a coarse-grained random variable y, taking on values , where  implies that x belongs to . Let its distribution be denoted by -dimensional probability vector 
            .
           Coarse graining leads to a new distribution  in  given by (3.8)Let  be a divergence between two distributions  and . It is said to be additive or decomposable when it is written in an additive form of componentwise divergences, (3.9)for some function d(p, q). The divergence  changes to  by coarse graining, (3.10)The information monotonicity criterion requires (3.11)When does the equality hold in (3.11)? This occurs in the case when there is no loss of information by coarse graining. Since y is a function of x, we have the following decomposition: (3.12)where  is a coordinate system of . We see that y is a sufficient statistic when  does not depend on . In this case, the conditional distributions of  and  are equal for two distributions  and , that is, (3.13)



3.2.2 Invariant Divergence
When a divergence is written in the form (3.14)where f is a differentiable convex function satisfying (3.15)it is called an
           f-divergence. The f-divergence was introduced by Morimoto (1963), Ali and Silvey (1966) and CsiszÃ¡r (1967). It is easy to prove that this satisfies the criteria of divergence, by expanding  in the Taylor series, although it is not a Bregman divergence in general.


Theorem 3.1

An f-divergence is invariant and decomposable. Conversely an invariant and decomposable divergence is an f-divergence, except for the case of .



Proof

We first prove that an f-divergence satisfies the criterion of information monotonicity. Consider a simple partition where  and all the other  are singleton sets. That is,  are put in a subset  but all the other x remain as they are. We prove only this case, but other cases can be proved similarly. We need to prove (3.16)By introducing (3.17)the right-hand side of (3.16) is written as (3.18)Since f is convex, (3.19)which proves the information monotonicity.
Conversely, assume that the information monotonicity holds for a
             decomposable divergence (3.9). Then, the equality holds when (3.13) is satisfied, that is,  in the present case. The equality is written as (3.20)By putting (3.21)we have (3.22)for , and hence k(p, u) is linear in p. So we have (3.23)implying (3.24)This proves the theorem.




Remark 1

The above proof is not valid when , because coarse graining causes . The following is shown by Jiao et al. (2015): There exists a class of invariant divergences which are not necessarily f-divergences when . So the case with  is special and Jiao et al. (2015) derived a general class of invariant divergences when .



Remark 2

When we treat non-decomposable divergences, there are invariant divergences which are not f-divergences. A function of f-divergence is invariant but is not decomposable in general. A simple example is (3.25)Further, an adequate nonlinear function of two f-divergences  and  is invariant but is not an f-divergence.

We will show in Part II that any invariant divergence gives the same geometry called the -structure.
When a linear term is added to a convex function f, (3.26)where c is a constant,  is also convex. It is easy to see (3.27)so (3.26) does not change the divergence. Hence, without loss of generality, we can always use a convex function satisfying (3.28)Moreover, since (3.29)holds for another constant , the constant c determines the scale of divergence. To fix the scale, we use f that satisfies (3.30)



Definition 3.1

A convex function f satisfying (3.28) and (3.30) is said to be standard. An f-divergence derived from a standard f is a
             standard f-divergence.

When  is a standard f-divergence, its dual  is also a standard f-divergence. To show this, define (3.31)Then,  is a standard convex function when f is, and we have (3.32)




3.3 Examples of f-Divergence in 


3.3.1 KL-Divergence
For (3.33)the derived divergence is the KL-divergence (3.34)The dual of f is (3.35)The derived divergence is the dual of the KL-divergence (3.36)which coincides with the divergence derived from the cumulant generating function .


3.3.2 
-Divergence
For (3.37)This is known as the Pearson -divergence.


3.3.3 
-Divergence
Let  be a real parameter. We define the 
          
          -function by (3.38)The derived divergence is the 
          
          -divergence (Amari 1985; Amari and Nagaoka 2000) given by (3.39)The dual of the -function is the -function. Hence, the dual of the -divergence is the -divergence, (3.40)When , we have (3.41)which is known as the square of the Hellinger distance.
We extend the -function (3.38) to the case of , by taking the limit . Then, (3.42)The derived divergences are (3.43)Hence, the KL-divergence is -divergence and its dual is 1-divergence.
For (3.44)which is not differentiable, and hence  is not a divergence by our definition,  is a symmetric function of  and , (3.45)known as the variational distance.
The square of the Euclidean distance, (3.46)is a divergence. But it is not an f-divergence and is not invariant.



3.4 General Properties of f-Divergence and KL-Divergence

3.4.1 Properties of f-Divergence
The following properties hold in .

(1)An f-divergence  is convex with respect to both  and . (2)It is bounded from above as  (3.47)
 (3.48)
 (3)For ,  (3.49) when  and  hold for some x. (4)For ,  (3.50) when  and  hold for some x. 

Properties (3) and (4) hold for the KL-divergence and its dual, because they are -divergences. They lead to the following results of approximation of a probability distribution by using the -divergence. Given , we search for the distribution  that minimizes the divergence from  to a smooth submanifold , (3.51)Then, the following holds:(5)Zero-forcing: When , the best approximation  in the closure of S satisfies  (3.52) for x at which . (6)Zero-avoidance: When , the best approximation  in the closure of S satisfies  (3.53) for x at which . 



3.4.2 Properties of KL-Divergence

A. Large deviation

Let  be a distribution in  from which N independent data  are generated. The empirical distribution of the observed data is given by , (3.54)where  is the number that  is observed among N data. This is the maximum likelihood estimator. How far is  from the true ? The probability distribution of  is evaluated by the KL-divergence asymptotically when N is large.

Sanov Lemma. The probability of  is asymptotically given by (3.55)that is, the probability decays exponentially as N increases where the exponent of decay is .
The proof is given by evaluating the distribution of , a multinomial distribution, when N is large, which we omit. When  is close to , by putting (3.56)and expanding , we have the central limit theorem
          .

Central Limit Theorem The distribution of  is asymptotically Gaussian with mean  and covariance (3.57)Let A be a region in . Then, we have the theorem of large deviation, which is useful in information theory and statistics (Fig. 3.2).Fig. 3.2
e-projection of  to A



Large Deviation Theorem The probability that  is included in A is given asymptotically by (3.58)where (3.59)When A is a closed set having a boundary,  is given by e-projecting  to the boundary of A.

B. Symmetrized KL-divergence and Fisher information

The Riemannian distance between two points  and  is given by the minimum of the distance along all curves  connecting  and  such that , , that is, (3.60)Since the KL-divergence is (3.61)there would be some relation between the KL-divergence and the integration of the Fisher information along a curve. Let us consider the e-geodesic and the m-geodesic connecting two points  and , (3.62)
 (3.63)They are exponential and mixture families, respectively. Let  and  be the Fisher information along the curves, (3.64)
 (3.65)Then, we have the following theorem.


Theorem 3.2

The symmetrized KL-divergence is given by the integration of the Fisher information along the e-geodesic and the m-geodesic, (3.66)


The proof is technical and is omitted.



3.5 Fisher Information: The Unique Invariant Metric
Since an f-divergence is invariant, the Riemannian metric derived from it is invariant. We can easily calculate the metric  from an f-divergence by the Taylor expansion, (3.67)A simple calculation gives the following lemma.


Lemma

Any standard f-divergence gives the same Riemannian metric which is the Fisher information matrix (3.68)where (3.69)


Chentsov (1972) proved a stronger theorem that the Fisher information matrix is the unique invariant metric of . He used the framework of category theory. We show a simpler proof due to Campbell (1986).
Consider a series of , and reformulate the invariance criterion. We consider coarse graining of  by a partition of  to , where . Random variable x taking on values  is reduced to random variable y taking on values , such that  when x is included in . Obviously, probability distribution  is mapped to  by this coarse graining. It defines a mapping f from  to 
 (3.70)Conversely, we consider a mapping h from  to , which is determined by an arbitrary conditional probability distribution, (3.71)Given , it generates  stochastically based on . We define a mapping by (3.72)Given y of which the probability is , the probability distribution  of x is given by (3.72). The mapping h which depends on  embeds  in  and it satisfies (3.73)where Id is the identity mapping (see Fig. 3.3).Fig. 3.3Embedding of  in  (m = 2, n = 3)

Consider a problem of estimation of  by observing random variable y. When  is embedded in a larger manifold  by (3.72), the random variable is x. However, x includes a redundant part for estimating . y is a sufficient statistic for estimating .
The invariance criterion claims that the geometry of  is the same as the geometry of embedded  in the larger manifold . In particular, the inner product of two basis vectors in  should be the same as that in the embedded image. Now we state the theorem of Chentsov.


Theorem 3.3

The invariant metric is unique, given by the Fisher information to within a constant factor.



Proof

We use  to prove the theorem, considering  as its subspace constrained by . When , the mapping f is only a permutation of indices. We consider the center of , (3.74)It is invariant under the permutation group of index i. So the inner product of two basis vectors  and  in  is invariant under the permutation of indices. Hence, we put (3.75)
 (3.76)or (3.77)When  is in , its small deviation  inside  satisfies (3.78)Since  is a tangent vector of , (3.79)holds for any tangent vector  of .
Therefore, we may put  when calculating the inner product of two tangent vectors of . B(n) is responsible only for the normal direction to . So, we put (3.80)Let us consider a point (3.81)where  are integers, satisfying . We then consider the following embedding of  in  given by the conditional distributions (3.82)where  is a partition of  such that  includes  elements. Then,  is mapped to the center of , (3.83)The basis vector  is mapped to (3.84)in  by this embedding. Similar equations hold for other , . The inner product is equal to (3.85)Hence, we have (3.86)Since the constant c is used only to determine the scale of the Fisher information, we may put . Similarly, (3.87)This holds only at the points where  are rational numbers, but because of the continuity, it holds for any . This proves the theorem.




Remark

We can prove the uniqueness of the cubic tensor  defined by (3.88)under the invariance criterion in a similar way. This will be used to study the uniqueness of the -connection in Part II.



3.6 
f-Divergence in Manifold of Positive Measures
We extend the notion of invariance from  to  by using the information monotonicity under coarse graining. We can prove that the only invariant decomposable divergence is an f-divergence, since the proof of Theorem 4.â1 is also valid for . An f-divergence is (3.89)
, for a manifold of positive measures , where f is a standard convex function satisfying (3.28) and (3.30). We need to use a standard convex function to define a divergence in , because (3.89) does not satisfy the criteria of divergence for a general convex f. The criteria are satisfied when a standard convex function f is used.
We can calculate the invariant Riemannian metric induced in  by an f-divergence.


Theorem 3.4

The Riemannian metric in  induced by an invariant divergence is the Euclidean metric (3.90)




Proof

It is easy to derive (3.90) by the Taylor expansion of (3.89) (3.91)where . By using a new coordinate system given by (3.92)the square of an infinitesimal distance is given as (3.93)showing that the manifold is Euclidean and the coordinate system is orthonormal.


It should be noted that manifold  is a submanifold of . The constraint  becomes (3.94)in the new coordinate system. Hence,  is a sphere in a Euclidean space, so it is curved.
As an important special case of f-divergence, we introduce the -divergence, which is previously defined in , to . It is defined by using the standard -function, (3.95)



Definition


          The 
            
          -divergence is defined in  by (3.96)


When both  and  satisfy the normalization condition, (3.97)they are probability distributions and the -divergence is equal to that in a manifold of probability distributions.


Remarks

There is a long history of studies on geometry of manifolds of probability distributions. C.R. Rao is believed to have been the first who introduced a Riemannian metric by using the Fisher information matrix (Rao 1945). This was work he did at the age of twenty-four, and the famous CrÃ¡mer-Rao theorem was presented in the same seminal paper. It is a monumental work from which Information Geometry has emerged. Jeffreys (1946) used the square root of the determinant of the Fisher metric, which is the Riemannian volume element, as an invariant prior distribution over the manifold in Bayesian statistics. However, there was no such concept in the first edition of his famous book, "Probability Theory", published in 1939 (Jeffreys 1939). It appeared in the second edition (Jeffreys 1948; see also Jeffreys 1946).
It was a big surprise that a hidden prehistory was uncovered by Stigler (2007) (Frank Nielsen kindly let me know of this paper). In 1929, Harold Hotelling spent nearly half a year at Rothamsted working with R.A. Fisher on establishing a foundation for mathematical statistics. He submitted a paper entitled "Spaces of statistical parameters" to the American Mathematical Society Meeting in 1929 (which, in his absence, was read by O. Ore). The paper has never been published, so his idea has become entombed and remains unknown. He stated in the paper that the Riemannian metric is given by the Fisher information matrix in a statistical manifold. Moreover, he remarked that the manifold of a location-scale statistical model has a constant negative curvature. Incidentally, I discovered this fact in 1958 when I was a master's student, and this was the origin of my study of information geometry.
After Rao, there appeared a number of works using the Riemannian structure, e.g., James (1973). It was Chentsov (1972) who introduced the invariance criterion for defining the geometry of a statistical manifold. He proved that the Fisher information matrix is the only invariant metric in . Moreover, he obtained the class of invariant affine connections (-connections studied in Part II). Unfortunately, his work was published only in Russian, so his contributions did not become popular in the western world until an English translation appeared in 1982. Later, Efron (1975) investigated old unpublished calculations by R.A. Fisher and elucidated the results by defining the statistical curvature of a statistical model. He showed that the higher-order efficiency of statistical estimation is given by the statistical curvature which is the e-curvature defined in Part II. This work was commented on by A.P. Dawid in discussions of Efron's paper, where the e- and m-connections were suggested.
Following Efron's and Dawid's works, Amari (1982) further developed the differential geometry of statistical models and elucidated its dualistic nature. It was applied to statistical inference to establish a higher-order statistical theory (Amari 1982, 1985; Kumon and Amari 1983). The formal theory of a dually flat manifold was first proposed by Nagaoka and Amari (1982), which included the Pythagorean theorem and projection theorem. However, it was not published as a journal paper, because it was rejected by major journals. The editor of the Annals of Probability asked me to withdraw the paper, because he had approached seven reviewers but none reviewed it seriously. So he concluded that most probabilists would not have any interest in the direction of this research. A reviewer for the Zeitschrift fÃ¼r Wahrsceinlichkeitstheorie und Verwandte Gebiete (Theory of Probability and its Applications) sent me a letter stating that the paper was useless, because no essential relation exists between statistics and differential geometry. He also pointed out that the differential geometry of this paper is different from that in textbooks so it would be dubious. (We proposed a new framework of duality in differential geometry.) So it was rejected. Several years passed and thirdly a reviewer in IEEE Transactions on Information Theory wrote that the theory was now well known around the world and the paper submitted included few new ideas. This was because a workshop on this subject was organized in London in 1984 by Sir D. Cox, and my "Springer Lecture Notes" (Amari 1985) were published. Since then, information geometry has become widely known and a number of competent researchers have joined from the fields of statistics, vision, optimization, machine learning, etc. Many international conferences have been organized on this subject.
However, a mathematically rigorous foundation involves difficulty in the case of the function space of probability density functions. This is because the topology of the space of p(x) is different from that of the space of . There is a series of studies given by Pistone and his coworkers (Pistone and Sempi 1995; Pistone and Rogatin 1999; Cena and Pistone 2007; Pistone 2013). See also Grasselli (2010). Newton (2012) gave a theory based on a Hilbert space, in the framework that p(x) has finite entropy. Here, p(x), a probability density function with respect to measure , is mapped onto a Hilbert space by using the following representation of p(x): (3.98)where (3.99)are presumed. J. Jost and his coworkers are developing a rigorous theory in Leipzig, preparing a monograph. See Ay et al. (2013).
Information geometry uses the e- and m-geodesic connecting two distributions p(x) and q(x), KL-divergence , the Pythagorean and projection theorems and the orthogonality of two curves. Therefore, we want to have a framework in which the above structures are guaranteed. We need to search for mild regularity conditions which give such a framework (cf. Pistone 2013; Newton 2012). Fukumizu (2009) proposed a novel idea of the kernel exponential family for treating statistical manifolds with function degrees of freedom.













Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_4




4. 
      -Geometry, Tsallis q-Entropy and Positive-Definite Matrices




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp






An f-divergence is not necessarily of the Bregman type. Hence, the invariant geometry induced from an f-divergence does not necessarily give a dually flat structure. It is proved that the KL-divergence, which is an f-divergence, is the unique class of decomposable divergences that are invariant and flat in . However, when we study a manifold  of positive measures, there are other invariant, flat and decomposable divergences. They are -divergences, including the KL-divergence as a special case. The present chapter studies the invariant -structure originating from the -divergence. It includes the -geodesic, -mean, -projection, -optimization and -family of probability distributions.
We also remark that the geometry originating from Tsallis q-entropy (Tsallis 1988, 2009; Naudts 2011) is nothing other than the -geometry, where . We show another type of flat structure, called conformal flattening, induced from the Tsallis q-entropy. It is related to the escort probability distribution. Extending it, we identify a universal class of dually flat divergences in . We further study a general invariant flat structure of the manifold of positive-definite matrices, which is important in its own right.

4.1 Invariant and Flat Divergence

4.1.1 KL-Divergence Is Unique
A divergence is flat
           when it induces a flat structure in the underlying manifold. A Bregman divergence is flat. We begin with the following well-known result in . See CsiszÃ¡r (1991) for the characterization of the KL-divergence.


Theorem 4.1

The KL-divergence and its dual are the only decomposable, flat and invariant divergences, except for the special case of .

A proof of the present theorem is given as a corollary of Theorem 4.2 in the next subsection. It will be shown in Part II without assuming the decomposability that the KL-divergence is the unique canonical divergence in a dually flat manifold of
           probability distributions.


4.1.2 
-Divergence Is Unique in  
We begin with a theorem due to Amari (2009).


Theorem 4.2

The -divergences form the unique class of decomposable, flat and invariant divergences of .



Proof

We first prove that an -divergence is a Bregman divergence in the manifold . This does not imply that its affine coordinate system is the measure vector  itself. We define a new coordinate system  by (4.1)and call  the -representation of a positive measure . Then, (4.2)is a convex function of  when . Therefore, (4.3)is a convex function of  for  and the accompanying affine coordinate system is . The dual affine coordinate system  is given by  as (4.4)Hence, it is the -representation of . The dual convex function is (4.5)Calculations show that the Bregman divergence (4.6)is the -divergence defined in (3.â96).
Conversely, assume that an f-divergence (4.7)is a Bregman divergence and further that its affine coordinate system  is connected with  componentwise as (4.8)The dual affine coordinates are (4.9)for some function . Since the cross term of  and  in the divergence is included only in the last term of (4.6), the relation (4.10)must hold for each i. By differentiating it with respect to  and omitting suffix i for brevity, we have (4.11)By putting  and , we have (4.12)Further, by putting (4.13)the logarithm of (4.12) is written in the form (4.14)for some functions s and t. By differentiating both sides with respect to x, we have (4.15)where c is a constant. From this, we see that f is of the form (4.16)except for a scale factor and a constant. This is a convex function for  but is not a standard f-function. By transforming it to the standard form, we have (4.17)and the theorem is proved.


We did not mention the case of . If we modify the definition (4.1) of the -representation as (4.18)
 is given by the limit . By using this, the proof holds even in the limiting case of .

 is a submanifold of , where the constraint (4.19)is imposed. The constraint is rewritten in the -coordinate system as (4.20)This is a nonlinear constraint for . So  is not dually flat but curved for general , except for the linear constraint case of . When , it is linear in the dual coordinate system. Hence, the -divergence gives a flat structure to  only when , that is the KL-divergence and its dual. Therefore, the KL-divergence is the only invariant, flat and decomposable divergence in , proving Theorem 4.1.


Remark

Jiao et al. (2015) proved that the KL-divergence is the only invariant divergence of the Bregman type in  without assuming the decomposability. It is also proved in the geometrical framework that the canonical divergence of  is the KL-divergence in Part II. The case of  is fully studied in Jiao et al. (2015), characterizing the class of invariant Bregman-type divergences in . The following is proved:(1)An invariant decomposable divergence is an f-divergence when , but there is a new class of divergences which are not necessarily f-divergences when . (2)An invariant Bregman divergence is the KL-divergence for any n. 

From the point of view of geometry, a one-dimensional manifold  is a curve so its curvature always vanishes. The case with  is special in this sense.




4.2 
-Geometry in  and 


4.2.1 
-Geodesic and -Pythagorean Theorem in 

The affine and dual affine coordinates of  due to the -divergence are given by (4.1) and (4.4), respectively. An
           -geodesic passing through  is linear in the -representation  of (4.1), written as (4.21)where t is the parameter of the geodesic and  is a constant vector, representing the tangent direction of the geodesic. In particular, the -geodesic connecting two measures  and  is (4.22)Dually, a -geodesic is linear in the -representation  of (4.4), (4.23)The -geodesic connecting  and  is (4.24)We have the -version of the Pythagorean theorem and projection theorem.


Theorem 4.3

Given three positive measures , when the -geodesic connecting  and  is orthogonal to the -geodesic connecting  and , (4.25)




Theorem 4.4

Given  and a submanifold S in , the point  in S that minimizes the -divergence (4.26)is the -projection of  to S. When S is an -flat submanifold, the projection is unique.



Remark

When ,  is the KL-divergence and the theorems are the Pythagorean and projection theorems given in Chap. 1.



4.2.2 
-Geodesic in 

Although the -divergence is a Bregman divergence in , it is not a flat divergence in  for . The -geodesic connecting two probability vectors  and  in , given by (4.22) with  and , is not included in . However, we can normalize (4.22) to obtain the probability vector , (4.27)where c(t) is determined from (4.28)This is included in . We call it the -geodesic of . We can define
           the -projection in  by using the -geodesic.


4.2.3 
-Pythagorean Theorem and -Projection Theorem in 

Since  is -flat, its submanifold  enjoys an extended version of the Pythagorean
           theorem. The following theorem is due to Kurose (1994) and it holds for a general dual manifold having a constant curvature.


Theorem 4.5

Let  and  be three points in . When the -geodesic connecting  and  is orthogonal to the -geodesic connecting  and , (4.29)


We omit the proof. This is a generalization of a theorem in the spherical geometry, which has a constant curvature.
The projection theorem follows from it.


Theorem 4.6

Let M be a submanifold of . Given , the point in M that minimizes the -divergence from  to M is given by the -geodesic projection of  to M.

We can easily see from (4.29) that the -projection gives the critical point of the -divergence. See Matsuyama (2003) for the minimization of -divergence and -projection in ICA (independent component analysis).


4.2.4 Apportionment Due to -Divergence
We show an interesting application of -divergence in social science. There are many methods of deciding the numbers of seats proportionately to the populations in states, since the number of seats in a state must be an integer, whereas the ratios of populations are rational numbers. Let  be the population quotient vector (4.30)where  is the populations of state i and . Let  be the apportionment quotient vector and n be the total number of seats such that  is the number of seats assigned to state i.
We cannot simply put , because  should be an integer. Hence, we search for a  that is a rational vector of the form  closest to . We can use the -divergence  to show the closeness of  and  and search for a rational vector  that minimizes . There have been proposed many algorithms to decide . Ichimori (2011) and Wada (2012) showed that most existing methods are interpreted as minimization of some -divergence and their differences are only in the values of .


4.2.5 
-Mean
By using the -representation, we define the
           -mean. Let us consider two positive numbers x and y. We rescale them by (4.31)where h(x) is a monotonically increasing differentiable function satisfying . We may call h(x) the h-representation of x. The -representation is the case of .
The quantity called the h-mean of x and y, (4.32)is obtained by using the h-representations of x and y, taking their arithmetic mean, and then rescaling it back by using . The -mean of x and y is (4.33)We further require that the h-mean is scale-free, implying that, for , the h-mean of cx and cy is c times their h-mean, (4.34)The following theorem characterizes the -mean.


Theorem 4.7

(Hardy et al. 1952) The -mean using (4.35)is the only scale-free means among h-means.



Proof

We show the proof given by Amari (2007). Let h be a monotonically increasing differentiable function such that the h-mean is scale-free, (4.36)By differentiating Eq. (4.36) with respect to x, we derive (4.37)where (4.38)By putting , we have (4.39)Hence, we derive from (4.37) and (4.39), (4.40)Since m takes an arbitrary value as y varies, we have (4.41)for a function g(c) of c. By putting (4.42)we have (4.43)Hence, we have (4.44)By putting , (4.45)for constant . We finally derive (4.46)neglecting a constant of proportionality. In the case of , we have . 


One sees that the family of -means includes various known means:The last two cases show that fuzzy logic is naturally included in the -mean.
The -mean is inversely monotone with respect to , (4.47)This is a generalization of the well-known inequalities (4.48)As  increases, the -mean relies more on the smaller element of , while, as  decreases, the larger one is more emphasized. We may say that the -mean with smaller  is pessimistic, and with larger  is more optimistic. See Fig. 4.1.Fig. 4.1
-mean of 1 and 4 for various 


We can further define the weighted -mean of  with weights  by (4.49)where  and . This leads us to the -family of probability distributions in the next subsection.


4.2.6 
-Families of Probability Distributions
Given k probability distributions , we can define their -mixture by using the -mean.
The -representation of probability density function p(x) is given (Amari and Nagaoka 2000) by (4.50)Their -mixture is defined by (4.51)where normalization constant c is necessary to make it a probability distribution. It is given by (4.52)The  mixture is the ordinary mixture and the  mixture is the exponential mixture. The  mixture, (4.53)is the optimistic integration of component distributions in the sense that, for each x, it takes the largest values of the component probabilities. On the contrary, the  mixture is pessimistic, taking the minimum of the component probabilities, (4.54)The exponential mixture is more pessimistic than the ordinary mixture in the sense that the resulting probability density is close to 0 at x where some of the components are close to 0.
Let us next consider weighted mixtures. The weighted -mixture with weights  satisfying  is given by (4.55)This is called the -integration of  with weights . It connects k component distributions  continuously by using the parameter . It is called the
           -family of probability distributions where  plays the role of its coordinate system. When , this is an ordinary mixture family, (4.56)where  is imposed. When , this is an exponential family, (4.57)where the normalization constant is given by (4.58)The probability simplex  (and the function space F of probability distributions) are special, satisfying the following theorem.


Theorem 4.8

The probability simplex  is an -family for any .



Proof


 is a mixture of , (4.59)The -mixture family of  is (4.60)where (4.61)They cover the entire  so that  is an -family. 


We can also show that an -geodesic connecting  and  in  is a one-dimensional -family.


4.2.7 Optimality of -Integration
When a cluster of k distributions  is given, we search for q(x) that is close to all of . It is regarded as the center of the cluster. Let  be weights assigned to , and we use the weighted average of divergences from 's to q(x), (4.62)as a risk function. We search for the distribution q(x) that minimizes . The minimizer of  is called the D-optimal integration of  with weights . The following theorem characterizes the
           -integration (Amari 2007).


Theorem 4.9

(Optimality of -integration) The -integration of probability distributions  with weights  is optimal under the -risk, (4.63)where  is the -divergence.



Proof

Let us first prove the case of . By taking the variation of  under the normalizing constraint (4.64)we derive (4.65)where  is the Lagrange multiplier. This gives (4.66)and hence, the optimal q(x) is (4.67)When , we obtain (4.68)
 (4.69)respectively. Hence, the optimal q is proved to be the -integration for any .


The case with unnormalized probabilities, i.e., positive measures, is similar. The optimal integration  of  under the -divergence criterion is (4.70)where the normalization constant is not necessary.
There are interesting papers concerning applications of the -integration of stochastic evidences, see e.g., Wu (2009), Choi et al. (2013) and Soriano and Vergara (2015).


4.2.8 Application to -Integration of Experts
Let us consider a system composed of k experts , each of which processes input signal  and emits its own answer. The answer of  is a response y corresponding to . More generally, consider the case that the output of  is a probability distribution of y, , or a positive measure, . The entire system integrates these answers and provides an integrated answer concerning the distribution of y given  (Fig. 4.2).Fig. 4.2Integration of answers of expert machines

Let us assume that  is given as the weight or reliability of  for input . The -risk of an integrated answer  is given by (4.71)



Theorem 4.10


            The
             -expert machine (4.72)is optimal under the -risk .

Similar assertions hold for the case of positive measures.
The  machine is the mixture of experts (Jacobs et al. 1991) and the  machine is the product of experts (Hinton 2002).
It is important to determine the weights or reliability functions . When a teacher output  is available, one may use the soft-max function (4.73)as the weight of , where c is the normalization constant and  is the "inverse temperature", indicating the effectiveness of the weights.



4.3 Geometry of Tsallis q-Entropy
The Boltzmann-Gibbs distribution in statistical physics is an exponential family, such that an invariant flat structure is given to the underlying manifold. Its convex function is free energy and its dual convex function is the negative of the Shannon entropy. C. Tsallis proposed a generalized entropy called the q-entropy for studying various phenomena not included in the conventional Boltzmann-Gibbs framework (Tsallis 1988, 2009). The induced probability distributions are not exponential families which are subject to exponential decay of tail probabilities. This has opened the door to a new world of physics and beyond. The q-logarithm and q-exponential are introduced to this end. However, the q-logarithm is essentially the same as the -representation, where q and  are connected by . Therefore, the -geometry covers the geometry of
         q-entropy physics (Ohara 2007). We treat the discrete case of  mostly, but the results hold in the continuous case, too.
We further extend the q-framework by using the q-escort distribution. This gives a new dually flat structure to , although it is not invariant (Amari and Ohara 2011). It is conformally related to the invariant geometry (Amari et al. 2012). This framework is extended further to deformed exponential families proposed by Naudts (2011).

4.3.1 
q-Logarithm and q-Exponential Function
Tsallis introduced a generalized logarithm, called the
           q-logarithm, by (4.74)which gives  in the limit . The inverse of the 
            q logarithm
           is the q-exponential, (4.75)which gives the ordinary exponential function in the limit . These functions are the same as the -representation  and its inverse, where , except for a scaling factor and a constant. However, we keep the original q-notation rather than the -notation in this section, respecting the original q-terminology by C. Tsallis.
The Tsallis q-entropy is defined by (4.76)by replacing  by , which is concave for  and is the Shannon entropy when . This is closely related to the RÃ©nyi entropy (RÃ©nyi 1961). Similarly, the q-divergence is defined by (4.77)where  is the expectation with respect to . This is the same as the -divergence (3.â39) with .
The geometry derived from the
           q-divergence satisfies the invariance criterion, since it belongs to the class of f-divergence. So the Riemannian metric is given by the Fisher information matrix. Further, it is not dually flat except for the limiting cases of  and . However, if we extend it to the manifold of positive measures, it is both invariant and dually flat.


4.3.2 
q-Exponential Family (-Family) of Probability Distributions
We define the
           q-exponential family by (4.78)or equivalently by (4.79)where  and  are used instead of  and  in the ordinary exponential family. This is an -family (4.60) of , in which  is used instead of ,  and . Here,  is determined from the normalization constraint (4.80)Another example is the q-Gaussian distribution, given by (4.81)
 (4.82)where random variable x takes continuous values. Different from a Gaussian distribution, the values of x are limited within a finite range. Another important q-family is . We rewrite Theorem 4.8 in the following form.


Theorem 4.11

The family  of all the discrete distributions is a q-family for any q, that is an -family for any .



Proof

By introducing random variables  and putting , a probability  is written, using parameter , in the form (4.83)where the coordinate system  is (4.84)Hence, it is a q-family (-family). The function corresponding to the free energy is (4.85)where  is a function of . We call it the q-free energy. 




4.3.3 
q-Escort Geometry
The q-geometry (-geometry) is induced in a q-exponential family from the q-divergence. It consists of the Fisher information metric (3.â68) and cubic tensor defined in (3.â88). It is invariant but not flat in general. This is because the q-divergence (-divergence) is not a Bregman divergence in general. However, it is possible to modify it conformally to obtain a new dually flat structure. To begin with, we show that the
           q-free energy  defined by (4.80) is a convex function of .


Lemma 4.1

The q-free energy is convex.



Proof

By differentiating (4.79) with respect to , we have (4.86)


Its second derivatives are (4.87)We introduce a functional (4.88)which is the Tsallis q-entropy except for a scale and constant. Then, from (4.86) and (4.87) and by using the identities (4.89)we have (4.90)
 (4.91)the latter of which shows that the Hessian of  is positive-definite. This is called the
           q-metric (4.92)which is different from the invariant Fisher metric.
A new dually flat structure is introduced in  by the q-free-energy, which is different from the free energy. The affine coordinates are  given by (4.84). The dual affine coordinate system  is given by (4.93)The dual convex function is the inverse of the q-entropy (4.94)except for a scale and constant.
The Bregman divergence derived by  is (4.95)which is different from the q-divergence .  gives another dually flat Riemannian structure to .
By putting (4.96)
 (4.97)
 (4.98)holds. So  gives another probability distribution  of . We call it the
           escort probability distribution of . The escort distribution is obtained by changing  to  which shifts  toward the center (the uniform distribution ) as q decreases from .
We can define the q-escort geodesic and dual q-escort geodesic in . By using these geodesics, the q-Pythagorean theorem holds with respect to the q-escort divergence. One of the important consequences is the q-max entropy theorem. To this end, we define the q-escort expectation by (4.99)



Theorem 4.12

( q-Max-Entropy Theorem) Let  be a submanifold of  consisting of probability distributions of which the q-escort expectations of random variables  take fixed values, (4.100)where . The probability distribution  in  that maximizes the q-entropy is given by the q-geodesic projection of the uniform distribution  to . The family of such distributions for various  is a
             q-exponential family of distributions, (4.101)




Proof

This is clear from the fact that  is flat in the dual sense and (4.101) is a flat submanifold in the primal sense. See Fig. 4.3. 



Fig. 4.3
q-max entropy theorem



4.3.4 Deformed Exponential Family: -Escort Geometry
We used the q-logarithm to define the q-structure in . However, we may use a more general representation to study various dually flat structures of . See, for example, a
           deformed exponential family called the
           -exponential family (Kaniadakis and Scarfone 2002). Following Naudts (2011), we introduce the -logarithm defined by (4.102)where  is a positive non-decreasing function. We simply put (4.103)When  is a power function (4.104)it gives the q-logarithm. We use the inverse of u as the v-representation, (4.105)The -deformed exponential family is defined by using (4.105) as (4.106)where  is the free-energy corresponding to the normalization factor.


Theorem 4.13


 is a
             -exponential family for any  function.



Proof

We can prove the theorem in the same way as Theorem 4.11, by replacing  by . The affine coordinates are (4.107)and the -free-energy is (4.108)The -free-energy is a convex function of , so we can introduce a new dually flat affine structure together with a Riemannian metric. The Riemannian metric is written anew as (4.109)where  is the -escort entropy defined by (4.110)The dual affine coordinates are given by (4.111)where (4.112)is used. The dual  in (4.111) defines a probability distribution  called the
             -escort distribution. The dual convex function is (4.113)
            The
             -divergence is (4.114)The generalized Pythagorean theorem holds as well. 




Remark

The  is a convex function. Vigelis and Cavalcante (2013) introduced a -family of probability distributions by using a convex function . A new representation f(x) of a probability density function p(x) is given by (4.115)This is closely related to the -representation. A -family of probability distributions and -divergence are defined in this framework, giving a dually flat structure. It is possible to extend to the non-parametric case.



4.3.5 Conformal Character of q-Escort Geometry
The q-divergence is an invariant divergence, leading to the Fisher information metric. The q-escort divergence (4.95) is not invariant and the derived metric is not the Fisher information metric. However, we see that the q-metric is connected to the Fisher metric  by (4.116)where (4.117)This implies that the metric is changed pointwise isotropically, implying that the magnitude of a vector is enlarged or shrunken by a factor  but the angle of two vectors never changes, keeping the orthogonality invariant. Such a transformation of metric is called a
           conformal transformation. Hence, the q-escort structure is given by a conformal transformation from the invariant geometry. However, this property does not hold in the general -structure. We show the following theorem without proof. See Amari et al. (2012) and Ohara et al. (2012).


Theorem 4.14


            The
             q-escort geometry is unique among the -escort geometries in the sense that its Riemannian metric is derived by a conformal transformation of the invariant Fisher metric.



Remark

Conformal transformations are used in asymptotic theory of statistical inference (Okamoto et al. 1991; Kumon et al. 2011). They are also used in improving a kernel function in support vector machines, which will be shown later in Chap. 11.




4.4 (u, v)-Divergence: Dually Flat Divergence in Manifold of Positive Measures
We have used p and  representations of probability, which play the role of two dual coordinate systems in the invariant geometry. We have further used the - or q-representations, which lead us to the -geometry. The generalized deformed exponential family uses the -representation. A representation of probability defines the geometry. The importance of representation was emphasized by Zhang (2004). Eguchi et al. (2014) uses a U-representation to define the U structure which is dually flat.
The present section considers  and introduces a dually flat structure by using a pair of representations. We extend the idea given by Zhang (2011, 2013) and establish a general dually flat structure in . The present section mostly follows Amari (2014) to define general decomposable and non-decomposable Bregman divergences in a manifold of positive measures. In the next section, they are extended to
         invariant Bregman divergences of a manifold of positive-definite matrices.

4.4.1 Decomposable (u, v)-Divergence
Let us use two monotonically increasing and differentiable functions u(m) and v(m) and define (4.118)They are called the u- and v-representations of positive measure m, respectively.
Given , we call  and  defined by (4.119)the u- and v-representations of , respectively. The  and  are coordinate systems in . We search for a dually flat structure such that the u- and v-representations of  become two affine coordinates. To this end, we define a pair of convex functions  and  from which a Bregman divergence  is derived.
We define two scalar functions of  and  by (4.120)
 (4.121)By differentiation, we have (4.122)
 (4.123)Since , , . Hence,  is a convex function. So is . Moreover, they are the Legendre duals, because (4.124)We now define decomposable convex functions of  and  by (4.125)
 (4.126)



Definition 4.1

The (u, v)-divergence between two points  is defined by (4.127)where  and  are u- and v-representations of  and , respectively.

The (u, v)-divergence gives a dually flat structure, where  and  are affine and dual affine coordinate systems. The transformation between  and  is simple in the (u, v)-structure, because it can be done componentwise, (4.128)
 (4.129)This is a merit of the (u, v)-divergence. The Riemannian metric is given by (4.130)It is easy to see that this is a Euclidean metric. We have a new coordinate system 
 (4.131)in which the Riemannian metric is . The following theorem follows immediately.


Theorem 4.15

A decomposable and dually flat divergence in  is a (u, v)-divergence when it is invariant under the permutation of indices.

Many divergences are written in
           the form of (u, v)-divergence.

1.

-divergence

From the following power functions, (4.132)
 (4.133)is derived. This was introduced by Cichocki and Amari (2010) and Cichocki et al. (2011). The affine and dual affine coordinates are (4.134)and the convex functions are (4.135)where (4.136)
2. 
-divergence

By putting (4.137)we have (4.138)This is a special case of
           the -divergence.

3.

-divergence

From (4.139)we have (4.140)This is the -divergence (Minami and Eguchi 2004). It gives a dually flat structure
           even in . This is because u(m) is linear in m.

4.

-divergence

From (4.141)where U(m) is a convex function, we have the U-divergence (Eguchi et al. 2014).


4.4.2 General (u, v) Flat Structure in 

We consider a general dually flat structure of  which is not necessarily decomposable. Let us introduce a new coordinate system (4.142)in , where  is an arbitrary differentiable bijective vector function. We can define a dually flat structure in  by using an arbitrary convex function .  is the associated affine coordinate system and the dual affine coordinates are (4.143)We put (4.144)This structure is used in Nock et al. (2015).
An arbitrary pair  of coordinate systems do not necessarily give a dually flat structure. They give dually flat structure when and only when there exists a convex function  such that (4.145)is its gradient. In the case of a decomposable pair (u, v), the condition is always satisfied and the pair always defines a dually flat structure.
The Riemannian metric induced from a -structure is , which is not Euclidean in general.



4.5 Invariant Flat Divergence in Manifold of Positive-Definite Matrices
The present section studies information geometry of the manifold of positive-definite matrices, following Amari (2014). See also Ohara and Eguchi (2013). An extensive review is found in Cichocki et al. (2015). A positive definite matrix  is decomposed as (4.146)where  is a diagonal matrix consisting of positive entries (eigenvalues of ) and  is an orthogonal matrix. A positive-definite diagonal matrix is compared with a positive measure distribution. When its trace is 1, it is compared with a probability distribution. So a positive-definite matrix is an extension of a positive measure. Therefore, one can introduce a dually flat structure to the manifold of positive-definite matrices with the help of the (u, v)-structure. The manifold of positive-definite Hermitian matrices, in particular those with a trace equal to 1, are important in quantum information theory, but we do not study them, treating only the real case.

4.5.1 Bregman Divergence and Invariance Under Gl(n)
Let  be a
           positive-definite symmetric matrix and  be a convex function. A Bregman divergence is defined between two positive-definite matrices  and  by (4.147)where  is the gradient operator with respect to matrix  and hence  is a matrix, and the inner product of two matrices is defined by (4.148)It induces a dually flat structure in the manifold of positive-definite matrices, where the affine coordinate system is  itself and the dual affine coordinate system is (4.149)There is a one-to-one correspondence between positive-definite matrices and zero-mean multivariate Gaussian distributions. Indeed, a zero-mean multivariate Gaussian distribution is given by using a positive-definite matrix  as (4.150)which is an exponential family. Its e-affine coordinates are . The flat geometry is, therefore, given by the KL-divergence, (4.151)which is obtained from the potential function (4.152)Let us consider a linear transformation of  by , which is the set of all non-degenerate  matrices, given by (4.153)This corresponds to the transformation of random variable  to (4.154)A divergence is said to be invariant under Gl(n) when it satisfies (4.155)Since the KL-divergence is invariant under any transformation of , it is invariant under Gl(n).


Theorem 4.16

The KL-divergence is a flat divergence which is invariant under Gl(n) in the manifold of positive-definite matrices.



4.5.2 Invariant Flat Decomposable Divergences Under O(n)
The eigenvalues of a positive-definite matrix do not change under an orthogonal transformation , the group of orthogonal matrices. It is natural to consider a dually flat structure which is invariant under O(n).

4.5.2.1 The Case When  is e-Affine
We have a convex function  of  in this case. It is invariant under O(n) when (4.156)An invariant function is a symmetric function of n eigenvalues  of  (Dhillon and Tropp 2007). An invariant convex function of  is written using a convex function f of one variable satisfying  as (4.157)when it is decomposable in the additive form of . We study this case. We can prove the following lemma.


Lemma


 (4.158)



Outline of the proof. We assume that f is an analytic function. Then,  is expanded in a power series of . Therefore, we prove the lemma in the case of , which is easy. Hence, we have the lemma. 

Let g(u) be a function such that  is the inverse function of , satisfying . Then, the inverse transformation from  to  is given by (4.159)Hence, the dual potential function is (4.160)



Theorem 4.17

An e-flat decomposable O(n)-invariant divergence is given by (4.161)where  is the Legendre dual of .

We give well-known examples of invariant symmetric convex functions and dually flat divergences.
(1)    For , we have (4.162)
 (4.163)where  is the Frobenius norm (4.164)This gives a Euclidean structure.
(2)    For , we have (4.152) and (4.151), which are invariant under Gl(n).
(3)    For , (4.165)
 (4.166)This divergence is used in quantum information theory. The affine coordinate system is , the dual affine coordinate system is  and  is related to the von Neumann entropy.


4.5.2.2 General Dually Flat Decomposable Case: (u, v)-Divergence
We use the
             (u, v)-structure to introduce a general dually flat invariant decomposable divergence. Let (4.167)be u- and v-representations of matrices. We use two functions  and  defined by (4.120) and (4.121) for defining a pair of dually coupled invariant convex functions, (4.168)
 (4.169)They are not convex with respect to , but convex with respect to  and , respectively. The derived Bregman divergence is (4.170)It induces a dually flat structure to the manifold of positive-definite matrices.


Theorem 4.18

A dually flat, invariant and decomposable divergence is a (u, v)-divergence in the manifold of positive-definite matrices.

The Euclidean, Gaussian and von Neumann divergences given in (4.163), (4.151) and (4.166) are special examples of (u, v)-divergences. They are given by (4.171)
 (4.172)
 (4.173)When u and v are power functions, we have the -structure in the manifold
             of positive-definite matrices.
(4)    --divergence
By using the -structure given by (4.132), we have (4.174)
 (4.175)and the -divergence of matrices, (4.176)This is a Bregman divergence, where the affine coordinate system is  and its dual is .
(5)    The -divergence is derived as (4.177)
 (4.178)
 (4.179)The affine coordinate system is  and its dual is .
(6)    The -divergence is derived from (4.139) as (4.180)




4.5.3 Non-flat Invariant Divergences
We have so far studied invariant flat divergences. There are other types of invariant divergences which are not necessarily flat. We remark that the eigenvalues of  are invariant under Gl(n), because, for  and , (4.181)holds. So a divergence  is invariant when it is written as a function of , where  are the eigenvalues of .
Cichocki et al. (2015) introduced the following
           (-)-- divergence: (4.182)which can be written in terms of  as (4.183)It is extended to the case of  and/or  by taking the limit . For example, (4.184)
 (4.185)When ,  is symmetric with respect to  and  and hence the geometry is self-dual and Riemannian.
It is interesting to see that  generates the same Riemannian metric not depending on  and , although the dual affine connections do depend on  and .


Theorem 4.19

The Riemannian metric induced from the -- divergence is (4.186)


We omit the proof.



4.6 Miscellaneous Divergences
Many divergences have been defined in the literature. We show some of them. They are not invariant and not flat in general, but have their own characteristics. An extensive survey on divergence is found in Basseville (2013). See also Cichocki et al. (2009, 2011), for example. Only a Bregman divergence generates a dually flat structure. However, any divergence generates a dual pair of affine connections together with a Riemannian metric, as will be shown in Part II.

4.6.1 
-Divergence
The -divergence was proposed by Fujisawa and Eguchi (2008). See also Cichocki and Amari (2010). Let  be a real parameter. The
           -divergence between two probability distributions  and  is defined by (4.187)It is projectively invariant in the sense that, for any positive constants  and , (4.188)holds.
The -divergence has a super-robust property when we use it in statistical estimation. It is extremely robust even when outliers are mixed in observed data. It is possible to define the -divergence between positive-definite matrices  and  as (4.189)



4.6.2 Other Types of -Divergences
Zhang (2004) introduced the following -divergence, (4.190)which is different from that in the previous subsection. The geometry induced from (4.190) is exactly the same as the -geometry.
Zhang (2011) presented another -divergence when a convex function  exists. It is given by (4.191)Furuichi (2010) also introduced another --divergence, (4.192)



4.6.3 Burbea-Rao Divergence and Jensen-Shannon Divergence
For a convex function , one can construct a symmetric divergence by (4.193)This is called the Burbea-Rao divergence (Burbea and Rao 1982). When we use the negative of entropy as a convex function, we have (4.194)This is called the Jensen-Shannon divergence. It can be rewritten using the KL-divergence as (4.195)These are not flat in general.
We have the -version of the Burbea-Rao divergence (4.196)This is asymmetric divergence.


4.6.4 
-Structure and (F, G, H)-Structure
Zhang (2004) considered two representations of probabilities  in  by generalizing -representations. Let  be a positive increasing function, and call (4.197)the -representation of probability . In the continuous case,  is the -representation. For a differentiable convex function , we define a positive increasing function (4.198)which is another representation, -representation, of probability, (4.199)This was proposed earlier and is the same as the (u, v)-structure of Sect. 4.4.1 defined in .
Harsha and Moosath (2014) introduced a non-invariant dual structure called the
           (F, G, H)-structure to a manifold of probability distributions. However, it is proved to be equivalent to the
           -structure, Zhang (2015). Let G(u) be a smooth positive function. The G-metric is defined by (4.200)which reduces to the invariant Fisher metric when . Let F and H be two differentiable monotonically increasing positive functions. We call  and  the F- and H-representations of probability, respectively.
We define the (F, G)-connection by (4.201)where  denotes the inner product by using the G-metric. It is represented in the component form as (4.202)Similarly, we define the (H, G)-connection.


Theorem 4.20

The (F, G)-connection and (H, G)-connection are dual with respect to the G-metric when the following relation holds: (4.203)


The proof is omitted.
The - divergence is defined by (4.204)This is neither a Bregman divergence nor an invariant divergence in general, but covers a wide range of divergences in .


Remarks

We have seen that a dually flat structure is derived from a Bregman divergence. There are many divergences of the Bregman type which lead to different dually flat Riemannian structures. The invariance is a criterion which specifies a reasonable divergence in a manifold of probability distributions. We have searched for the divergence that is invariant and, at the same time, dually flat in the manifold  of probability distributions. The KL-divergence is the unique divergence of the Bregman type that is invariant.
If we consider the extended manifold of , the -divergences are derived as a unique class of invariant divergences of the Bregman type. This introduces the -geometry to the manifold of probability distributions. It is invariant geometry but is not necessarily dually flat except for the case of , which gives the KL-divergence. The -geometry is interesting. We have shown the -Pythagorean theorem and -projection theorem in an -family despite the fact that the manifold is not dually flat. More generally, given a general divergence and a point P in a submanifold , the set of point Q that minimizes D[Q : M] at  does not form a geodesic submanifold orthogonal to M at P. That is, the minimizer P is not the geodesic projection of Q to M. However, in the case of an -family, this is given by the -geodesic projection for the -divergence. The -projection is useful in applications. See, e.g., Matsuyama (2003).
It is a happy coincidence that the Tsallis q-geometry of the q-entropy is exactly the same as the geometry where . Furthermore, the q-geometry introduced the escort probability distributions, which lead us to the conformal flattening of the non-flat q-geometry. This gives a new q-divergence of the Bregman type, from which flat (but non-invariant) geometry is derived. This idea has been generalized to a general deformed exponential family.
Apart from the framework of invariance, we introduced a general class of decomposable and non-decomposable divergences of the Bregman type in . They are the (u, v)- and -divergence. This is extended to give an invariant dually flat geometry to the manifold of positive-definite matrices. Quantum information geometry deals with a manifold of positive-definite Hermite matrices (which is a complex version of positive-definite real matrices). Therefore, the invariant (u, v)-structure would be useful in studying quantum information geometry, although we cannot explore it in the present monograph.
Divergences are used in various applications. The choice of a divergence function depends on the purpose of the application. An invariant divergence gives a Fisher efficient estimator but is not robust. There are robust divergences like the -divergence. A decomposable divergence is used in many applications, because they are simple and the coordinate transformation between  and  is tractable.











Part IIIntroduction to Dual Differential Geometry










Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_5




5. Elements of Differential Geometry




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp






Here is an introduction to
       Riemannian geometry. The reader does not need to understand the detailed derivations of equations. More important are ideas and concepts of differential geometry. They can be understood "intuitively" without tears.

5.1 Manifold and Tangent Space
Let us consider an n-dimensional manifold M having a (local) coordinate system . It is in general curved. The
         tangent space  at point  is a vector space spanned by n tangent vectors along the coordinate curves of . We denote them as , which is a basis of the tangent space (Fig. 5.1). Tangent space  is regarded as a linearization of M in a neighborhood of , since a small line element  of M connecting two nearby points  and  is approximated by an (infinitesimally small) tangent vector (5.1)See Fig. 5.2.
Mathematicians are not satisfied with this intuitive definition. They ask what the tangent vector along the coordinate curve  is. They define a tangent vector in terms of a differential operator on a function  in that direction. That is, they identify tangent vector  with the well-established partial derivative operator (5.2)It operates on a differentiable function  and gives its derivative in the direction of coordinate curve , that is, the partial derivative. Hence, one may write (5.3)A vector (5.4)is the directional derivative operator which operates on f as (5.5)
Fig. 5.1Tangent space  and basis vectors 

Fig. 5.2Infinitesimal vector  in 


When the coordinate system is changed from  to , the partial derivatives change as follows: (5.6)where (5.7)Therefore, we have the law of transformation for the tangent vectors, (5.8)
 (5.9)For a manifold of probability distributions, we have another expression of a tangent vector. We identify  with the
         score function (5.10)which is a random variable because it is a function of x. Then, the tangent space  is a linear space spanned by n random variables .
A tangent vector is a geometrical quantity, but it has various representations such as a differentiation operator and a random variable.


5.2 Riemannian Metric
When an inner product is defined in the tangent space , we have a matrix  consisting of the inner products of basis vectors (5.11)It is a positive-definite matrix depending on . It is called the metric tensor and its components change to (5.12)by a coordinate transformation. (See Sect. 5.4 for the definition of a tensor.) A manifold is Riemannian when a metric tensor is defined.
For the manifold of probability distributions, we define an inner product by using the stochastic expression (5.13)This is the Fisher information matrix which is invariant.
The inner product of two vectors  and  is given by (5.14)A Riemannian manifold is Euclidean when there exists a coordinate system in which the metric tensor becomes (5.15)A Riemannian manifold is curved from the metric point of view when it does not have a coordinate system satisfying (5.15). We will see later that a manifold is (locally) flat when and only when the Riemann-Christoffel curvature tensor vanishes. We need an affine connection to define the curvature tensor.


5.3 Affine Connection
Tangent space  is a local approximation of M at . However, a collection of 's at all  does not recover the entire figure of M without specifying how  and   are related. It is the role of an affine connection to establish a one-to-one mapping between  and , in particular when  and  are infinitesimally close. The entire figure of M will be recovered from the aggregate of 's by using an affine connection.
Let us consider two nearby tangent spaces  and . Let (5.16)
 (5.17)be two tangent vectors belonging to  and , respectively. How different are they? We cannot compare them directly, because they belong to different tangent spaces. The basis vectors  and  are different, so even when the components of  and  are the same, we cannot say they are equal.
A manifold is a continuum, so  and  would be very similar, almost the same intuitively speaking, because the two tangent spaces become identical as  tends to 0. We define a one-to-one affine correspondence between two nearby tangent spaces such that it becomes identical as  tends to 0. As an example, consider a curved surface embedded in a three-dimensional Euclidean space. The tangent spaces at  and at  are slightly different in the three-dimensional space. We shift  in parallel such that the origins of  and  coincide in the three-dimensional space. However, the directions of  and  are slightly different when the surface is curved. We project the shifted  to  (Fig. 5.3) and let it be . The projected  is the counterpart of  in , so a correspondence between  and  is established by this projection. This is an example of
         affine connection.Fig. 5.3Shift  to P. The shifted  does not belong to . Project it to , obtaining  which is slightly different from 


We begin with technical expressions of an affine connection. Let us map the basis vector  of  to , by which an affine correspondence is established. It is the projection in the ambient Euclidean space in the previous example, but we consider a more general situation. The map  of  is close to , so it is represented as (5.18)The difference  is a vector of  written in the component form as (5.19)The components  become 0 as . So they are linear in  and we put (5.20)as the first-order approximation, where the coefficient  is a quantity having three indices.
A linear correspondence between  and  is established by giving a quantity  having three indices. They are called the
         coefficients of an affine connection which is to be established. The coefficients are given by the inner products of  and  as (5.21)where (5.22)is the covariant expression (lower indices expression) of .
There still remains the problem of determining . The traditional way is to use the Riemannian metric . It is the
         Levi-Civita connection
         (Riemannian connection) introduced in Sect. 5.9. Another way is to use a divergence  defined in M. This leads us to dually coupled affine connections, which we will see in the next chapter.


5.4 Tensors

        A
         tensor is a quantity having a number of components such as ,  and . A vector is a tensor having only one index. More precisely, a tensor is a quantity associated with tangent space  spanned by n tangent vectors . A vector A is represented in this basis as (5.23)in the component form, where the Einstein summation convention is working.
Let  be the dual basis, which is given by (5.24)by using the metric tensor  and its inverse . Note that the dual basis was denoted previously as , but we hereafter omit , because the upper index i of  shows that it is a dual basis vector. Vector A is represented in the dual basis as (5.25)so that we have (5.26)A tensor , for example, is a quantity represented, as (5.27)in the linear form of the product  of basis vectors. The product is formal and is just a concatenation of basis vectors. When an index is in the upper position, as in , it is said to be contravariant, and when it is in the lower position, as in , it is said to be covariant. A tensor may have contravariant and covariant components at the same time, as in .
When another coordinate system  is adopted, the basis vectors change by the coordinate transformation as in (5.8). Therefore, the component of a vector changes, as in (5.28)for a contravariant (upper index) vector and (5.29)for a covariant vector. Similarly, for a tensor like , the components change as in (5.30)For a scalar function , its gradient (5.31)is a covariant vector, because of (5.32)The Fisher information matrix (5.13) is a tensor. We define a quantity (5.33)It is a covariant tensor having three indices and is symmetric. We call it a (statistical)
         cubic tensor for short. Two tensors G and T will play a fundamental role in the manifold of probability distributions.
Not all indexed quantities are tensors. For example, the second derivative of a scalar function f
 (5.34)gives a quantity having two indices, but it is not a tensor. By changing the coordinate system from  to , we have (5.35)This shows that it is not a tensor. (It is a tensor at the critical point where  holds.)
It should be noted that  is not a tensor. By changing the coordinate system from  to ,  changes as in (5.36)in the new coordinate system. By using this relation, after some calculations, we have (5.37)So it is not a tensor. Note that, even if (5.38)holds in one coordinate system, it does not mean that (5.39)in another coordinate system. Although it is not a tensor, it has its own meaning, representing the nature of the coordinate system. In a Euclidean space, (5.40)in an orthonormal coordinate system , but if we use the polar coordinate system 
 (5.41)because the tangent vector  in the radial direction changes depending on the position in the polar coordinate system.
When an equation is written in a tensor form such as (5.42)depending on physical quantities , it has the same form in other coordinate systems (5.43)In this sense, a tensorial equation is invariant. A. Einstein obtained the equation of gravity in terms of tensors, because he believed that the law of nature should have the same form whichever coordinate system we use, and hence it should be written in a tensorial form.


5.5 Covariant Derivative
A vector field X is a vector-valued function on M, the value of which at  is given by a vector (5.44)When a vector field is given, it is possible to evaluate the intrinsic change of the vector as position  changes, by using the affine connection.
In order to see the intrinsic change between  and , since they belong to different tangent spaces, we need to map  to  for comparison. Since the basis vector  is mapped to  by (5.45)vector  is mapped to  as (5.46)where the Taylor expansion of  is used. Hence, their difference is evaluated as (5.47)This shows the intrinsic change of  as  changes by . The rate of intrinsic change along the coordinate curve  is denoted as (5.48)This is called the
         covariant derivative of  and  is a tensor.
Let  be another vector field. Then, the directional covariant derivative of X along Y is denoted as (5.49)This is the covariant derivative of X along Y. It is again a vector field.
We can define the covariant derivative of a tensor, e.g., (5.50)in a similar way, since it is spanned by multilinear vector products of the basis vectors .
For a scalar function , its change is measured by ordinary differentiation. Hence, vector field  gives its directional derivative (5.51)Note that, for a vector field X, the partial derivatives of its components  are not a tensor. We should use the covariant derivative for evaluating its intrinsic change.


5.6 Geodesic
A curve  is called a
         geodesic when its direction does not change. So it is a generalization of the straight line. Here, a change in direction is measured by the covariant derivative derived from an affine connection. Note that this does not necessarily mean that it is a curve of minimal distance connecting two points, although this is the literal definition of a geodesic. The minimality and straightness can be different in a general manifold. It is possible to define an affine connection by using the metric such that a straight line (geodesic) has the minimality of distance, as is given in Theorem 5.2. But a divergence function gives a more general affine connection.
The tangent vector of curve  at t is given by (5.52)where  and  denotes the derivative d / dt. When  is a geodesic, the tangent vector  corresponds to  by the affine connection. See Fig. 5.4. Since the change of the tangent direction of a curve is measured by the covariant derivative of  along itself, the equation of the geodesic isFig. 5.4Geodesic:  corresponds to 

 (5.53)This is given in the component form as (5.54)If we consider the equation (5.55)
 does not change the direction  of the curve, too, but its magnitude may change. However, by choosing the parameter t adequately, it is possible to reduce (5.55) to (5.54). Hence we consider only the case of (5.54).Fig. 5.5Parallel transport of A(0) at  to A(1) at  along curve 




5.7 Parallel Transport of Vector
We can transport a vector  at  to  at  without changing it "intrinsically". The affine connection determines this
         parallel transport. For two distant points  and , we continue the process of parallel transport of a vector along a curve  connecting  and .
Define a vector field (5.56)along curve  connecting P and Q (see Fig. 5.5). When its covariant derivative along the curve vanishes, (5.57)
A(t) is intrinsically the same at any . This is written in the component form as (5.58)When A(t) satisfies (5.57) or (5.58), we say that A(0) at  is transported parallelly to A(1) at . The parallel transport depends in general on the path along which it is transported. So we denote the parallel transport of a vector A from  to  along curve  by (5.59)



5.8 Riemann-Christoffel Curvature
A manifold is curved in general. When a vector is transported in parallel from one point to another, the resultant vector depends on the path along which it is transported. This never happens in a flat manifold. In order to show how curved a manifold is, we define the
         Riemann-Christoffel (RC) curvature tensor determined from the affine connection. One may skip this section, since we do not use
         RC curvature in applications in this monograph. When the RC curvature tensor vanishes, that is, when it is identically equal to 0, the manifold is (locally) flat. When it is flat, there exists an affine coordinate system such that each coordinate curve is a geodesic and its tangent vector coincides at any point by parallel transport.

5.8.1 Round-the-World Transport of Vector
Let us consider two curves  and , , both connecting the same two points  and . When a vector A at  is transported to  in parallel along curve , it becomes . If we transport  back to  along the same curve  in reverse, it is A. Now we transport A in parallel along the two curves  and . The resultant vectors,  and , are different in general (Fig. 5.6). This implies that when we transport a vector from  to  along path  and then transport it back to the original point  along the other path  in reverse, the resultant vector is different from A. So a vector changes when it is transported along a loop (consisting of path  and reverse path of ). In other words, a vector is changed by a round-the-world trip.Fig. 5.6Parallel transport of A via  is different from that via 


The change may be used to measure how curved M is. To evaluate the change, we consider an infinitesimally small quadrangle connecting four points P, Q, R and S, where their coordinates are (5.60)(See Fig. 5.7.) We transport A in parallel first from P to Q by . Then, A becomes , the components of which are (5.61)We further transport  from Q to R along the path . Then, the transported vector at R is , where the components of additional change  are (5.62)Since  is evaluated at , the Taylor expansion gives (5.63)
Fig. 5.7Parallel transports of A along PQR and PSR


Now, we transport A along the different route, first along the path  to S and then to R along . The resultant change is given by exchanging  and  in (5.63). The result is (5.64)How different are the resultant vectors? By subtracting  from  where (5.63) and (5.64) are used, the result is written as (5.65)where we put (5.66)We can prove that  is a tensor. It is called the Riemann-Christoffel (RC) curvature tensor. This shows how a vector changes by the round-the-world trip along an infinitesimal loop. We denote the infinitesimal loop encircling P, Q, R, S and P by a tensor (5.67)which is antisymmetric with respect to the two indices i and j, (5.68)This is a small surface element, representing a surface spanned by  and  (Fig. 5.8). Equation (5.65) is written as (5.69)
Fig. 5.8Small surface element, loop and membrane

When vector A is transported in parallel along a general loop , , we span a membrane encircled by the loop (see Fig. 5.8). Then, the changed  due to the round-the-world parallel transportation is given by the surface integral (5.70)This does not depend on the way of spanning the membrane, as is clear from the Stokes' Theorem.


5.8.2 Covariant Derivative and RC Curvature
The partial derivative is always commutative, (5.71)However, this does not in general hold for the covariant derivative, (5.72)The covariant derivative of  in the direction of basis vector  is (5.73)By using this, we have (5.74)We omit the proof, but we see that the RC curvature shows the degree of non-commutativity of the covariant derivative.
In general, we can define the RC curvature by (5.75)where (5.76)This is a sophisticated definition of the RC curvature tensor which one sees in modern textbooks on differential geometry. However, it is difficult to understand the meaning of the RC curvature from it.


5.8.3 Flat Manifold
When the RC curvature vanishes, M is said to be flat. The parallel transport of a vector does not depend on the path in this case. Let us consider a set of basis vectors  in the tangent space at a point. We construct n geodesics passing through the point in the directions of . We then have n coordinate curves , of which tangent vectors  are the same everywhere. This generates a flat coordinate system . Indeed, we transport the tangent vectors  to any point and compose the geodesics the directions of which are . Vectors  are parallel at any point and we have a net of coordinate curves .
Since the tangent vectors of a coordinate curve  are all in parallel, we have (5.77)Therefore, from (5.73) we have (5.78)Hence, when M is flat, we have an affine coordinate system consisting of geodesics in which (5.78) holds at any .



5.9 Levi-Civita (Riemannian) Connection
We have so far treated the metric and affine connection separately. However, it is possible to define an affine connection such that it is essentially related to the metric, giving a unified picture. This is Riemannian geometry. It requires that the magnitude of a vector does not change by the parallel transport. This establishes a relation between the metric and the affine connection (see Fig. 5.9).Fig. 5.9The magnitude of A is equal to the magnitude of 


It is easy to see the equivalence of the following two propositions of parallel transportation: (1) The magnitude of a vector does not change by parallel transportation, (5.79)(2) The inner product of two vectors does not change by parallel transportation, (5.80)We consider an infinitesimal parallel transport of two basis vectors along the coordinate curve . Then, when the length of a vector does not change, we have (5.81)Because , this condition is written as (5.82)More generally, this condition is equivalent to (5.83)for three vector fields X, Y and Z. When an affine connection satisfies this condition, it is said to be metric. The
         metric affine connection is uniquely determined from metric , provided the symmetric condition (5.84)holds.


Theorem 5.1

When the parallel transport does not change the magnitude of a vector, there is a unique symmetric affine connection given by (5.85)


It is an interesting exercise to prove this from (5.82). It is called the Levi-Civita connection or Riemannian connection. Many conventional textbooks on differential geometry study only the
         Levi-Civita connection. By using the Levi-Civita connection, we have the following convenient property.


Theorem 5.2

A curve that connects two points by a minimal distance is a geodesic under the Levi-Civita connection, where the length of a curve  connecting  and  is given by (5.86)


It is possible to obtain (5.54) and (5.85) by the variational method, , of minimizing (5.86) with respect to curve . This is also a good exercise. See Fig. 5.10.Fig. 5.10A Riemannian geodesic  is a curve which does not change the direction , and also the distance s is minimized along it



5.10 Submanifold and Embedding Curvature
We consider a
         submanifold embedded in a larger manifold. It has embedding curvature when it is curved in the ambient manifold. This is different from the RC curvature. It is useful to embed a manifold in a simple (e.g. flat) higher-dimensional ambient manifold and study its properties in the ambient manifold. Geometrical quantities are transferred from a simple ambient manifold to the submanifold by embedding.

5.10.1 Submanifold
Let S be a submanifold embedded in M (Fig. 5.11). Let  be a coordinate system of  and  be a coordinate system of , where we assume . Since a point  in S is also a point in the ambient M, its coordinates in M are specified by  as (5.87)We consider the case that  is differentiable with respect to .Fig. 5.11Submanifold S embedded in M

Fig. 5.12Tangent vectors  of submanifold

The tangent vector  along the coordinate curve  of S is (5.88)and the tangent space  of S is spanned by them (Fig. 5.12). However, they are regarded as tangent vectors at point  of M by embedding. They are represented in M as (5.89)in terms of the basis vectors  of M. Defining (5.90)we have (5.91)A vector  is a vector  and (5.92)Submanifold S inherits the geometrical structures of M. The magnitude of a tangent vector A in  is given by its magnitude in M. Hence, the metric (5.93)in S is given by (5.94)



5.10.2 Embedding Curvature
An affine connection is naturally transferred to S from M. Let  be a basis vector at  of S and we map it in parallel to . We first transport it in M from  to  in parallel. The resultant vector is denoted as , where  is given by the covariant derivative of  in the direction of  in M, (5.95)We calculate  in M, (5.96)where we put (5.97)Here, the vector  is not necessarily included in the tangent space of S (Fig. 5.13). So we decompose it in the tangent direction of S and its orthogonal direction, (5.98)where  and  is orthogonal to S. We define the parallel transport of  within S by the change , neglecting the change in the orthogonal direction: (5.99)Rewriting  in terms of basis vectors , the induced affine connection of S is given as (5.100)
Fig. 5.13Decomposition of  in the orthogonal part  and parallel part  with respect to 


The orthogonal direction of  represents how S is curved in M. To show the orthogonal component, we supplement  with  orthogonal vectors , such that the entire vectors  span the tangent space of M. Then, the orthogonal part is given by (5.101)where we use the covariant derivative in M to define (5.102)This is the
           embedding curvature of S, sometimes called the
           Euler-Schouten curvature tensor.
The embedding curvature is different from the RC curvature, which is derived from the affine connection . The RC curvature is the intrinsic curvature considering only inside S. As a simple example, let us consider a cylinder S embedded in a three-dimensional Euclidean manifold M. It is curved in M, so it has non-zero embedding curvature. But its RC curvature vanishes and Euclidean geometry holds inside S. If we live in S and do not know the outer world of three dimensions, we enjoy Euclidean geometry in S where the RC curvature is 0. But S has non-zero embedding curvature.


Remarks

Differential geometry studies properties of a manifold by its local structure. A Riemannian manifold is a typical example, where a manifold is equipped with a metric tensor  by which the distance of two nearby points is measured. It is locally approximated by a Euclidean space but is curved in general. Modern differential geometry further studies the global topological structure of a manifold. It is interesting to see how the global structure is restricted by the local structure such as the curvature. This is an important perspective. However, we have not mentioned the global properties, because most (though not all) applications use only local structure.
Since differential geometry has been developed as pure mathematics, mathematicians have constructed a rigorous, sophisticated theory, excluding intuitive definitions of geometrical concepts. However, once such a rigorous theory is established, we may use intuitive understanding for applications. Part II is an attempt to introduce the modern concepts of differential geometry without tears to beginners.
After non-Euclidean geometry was developed in the 19th century, people came to know that there existed non-Euclidean spaces. B. Riemann, in his professorship lecture, proposed the concept of Riemannian geometry, which is non-Euclidean and curved. He conjectured that the real world might be Riemannian on a cosmological scale or on an atomic scale. His view was proved true in the 20th century in relativity theory and elementary particle theory.
There are many of applications of differential geometry. Relativity theory is one of them, in which Einstein introduced the concept of a torsion tensor to establish a unified theory (unification of gravity and electromagnetism). Unfortunately, this interesting idea failed. But the torsion tensor survived in mathematics. The torsion tensor is a third-order tensor of which the first two indices are anti-symmetric. This is a new quantity to supplement the Riemannian structure of , although we have not mentioned it here.
A Riemannian manifold with torsion plays a fundamental role in continuum mechanics including dislocations. A dislocation field in a continuum is identified with a torsion field, and a rich theory has been established. See, e.g., Amari [1962, 1968]. Another application is the dynamics of electro-mechanical systems, such as motors and generators, by Gabriel Kron. Here, non-holonomic constraints play a role, and are converted to torsion. Recent robotics also uses non-holonomic constraints. Differential geometry plays important roles in various areas.
Information geometry also uses differential geometry, where the invariance criterion plays a fundamental role in defining the geometrical structure of a manifold of probability distributions. However, the conventional edifice of differential geometry in textbooks is not enough to explore its structure. We need a new concept of duality of affine connections with respect to the Riemannian metric. In the next chapter, we study a Riemannian manifold equipped with dually coupled affine connections.














Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_6




6. Dual Affine Connections and Dually Flat Manifold




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp






We have considered one affine connection, namely the Levi-Civita connection, in a Riemannian manifold M. However, we can establish a new edifice of differential geometry, by treating a pair of affine connections which are dually coupled with respect to the Riemannian metric. Such a structure has not been described in conventional textbooks, but is the heart of information geometry. Mathematically speaking, in addition to the Riemannian structure , we study the structure , which has a third-order symmetric tensor T in addition to G. As an important special case, we study a dually flat Riemannian manifold. It may be regarded as a dualistic extension of the Euclidean space. The generalized Pythagorean theorem and projection theorem hold in such a manifold. They are particularly
       useful in applications.

6.1 Dual Connections
The Levi-Civita connection is the only metric affine connection (without torsion) that preserves the metric by parallel transport. However, there is another way of preserving the metric by using two affine connections. We consider here two symmetric affine connections  and  and denote the associated parallel transports as  and , respectively. These affine connections are dually coupled when the parallel transports of vectors A and B, one by  and the other by , do not change their inner product, (6.1)
Fig. 6.1Conservation of inner product by dual parallel transports

See Fig. 6.1. Such a pair of affine connections are said to be dually coupled with respect to the Riemannian metric, which defines the inner product. A pair of connections collaborate to preserve the inner product by parallel transportation of vectors. When the two connections are identical, (6.1) reduces to the metric condition (5.â80), so that this is an extension of the metric connection.
We search for analytical expressions of dual connections. Consider two basis vectors  and  at point . We transport them to , one by using affine connection  and the other by dual connection . Then, their parallel transports are, respectively, (6.2)
 (6.3)where d and  denote the changes induced by the parallel transformations due to  and , respectively. From the conservation of the inner product (6.4)we have (6.5)where higher-order terms are neglected.
By the Taylor expansion, we have the componentwise expression (6.6)Compare this with the self-dual case (5.â82).
This is rewritten in terms of the covariant derivatives as (6.7)where X, Y and Z are three vector fields. This is confirmed by using three vector fields  and , as (6.8)which is the same as (6.6).
The average of two dual connections is given by (6.9)The related covariant derivative is (6.10)From (6.7), we see that  satisfies (5.â83) and  is the Levi-Civita connection. Let us define (6.11)Then, the dual connections are written as (6.12)



Theorem 6.1

When  and  are dual affine connections, T is a symmetric tensor given by (6.13)
 (6.14)




Proof

We calculate the covariant derivative of tensor . It is given by (6.15)Since  is the metric connection, (6.16)Hence, we have (6.17)Since  is symmetric with respect to j and k, we have (6.18)Moreover,  is a symmetric connection, so  is symmetric with respect to i and j. Hence  is symmetric with respect to three indices, i, j, and k.  is a tensor, because it is the covariant derivative of tensor . (6.14) is also derived similarly. 




Remark

S. Lauritzen called  the skewness tensor. However, it is symmetric, and so we hesitate to use the term "skewness", which often implies anti-symmetry. So we use the term cubic tensor. This is called the
           Amari-Chentsov tensor by some researchers (e.g., Ay et al. 2013), since Chentsov defined it and Amari has developed its theory. The triplet  is also called the
           Amari-Chentsov structure.

Dual affine connections are determined from  by (6.12), where  is a positive-definite symmetric matrix and  is a cubic tensor. When , the two affine connections are identical. Hence, the connection is self-dual and M reduces to the ordinary Riemannian manifold, having the Levi-Civita connection.


6.2 Metric and Cubic Tensor Derived from Divergence
When a divergence  is defined in M, we show that two tensors  and  are automatically induced from it. We consider a neighborhood of diagonal position  of D. Since D has two arguments, we introduce the following notation of differentiation at the diagonal: (6.19)
 (6.20)Similarly, for multiple differentiation, we use the notation (6.21)etc.
We define the following quantities by using the above notations: (6.22)
 (6.23)
 (6.24)We can prove that  and  define affine connections, by checking how they are transformed by coordinate transformations. We omit the calculations since they are technical and easy. Their difference (6.25)is a third-order symmetric tensor. Hence, we have two characteristic tensors  and  from a divergence D. The following is a key result connecting a divergence and dual geometry, derived by Eguchi (1983).


Theorem 6.2

The two affine connections  and  are dual with respect to the Riemannian metric .



Proof

By differentiating (6.26)with respect to , we have (6.27)This satisfies (6.6) so that  and  are dual affine connections. 


When a Legendre pair of convex functions  and  are given, where  and  are connected by the Legendre transformation, we have a Bregman divergence (6.28)where  is the Legendre dual of . The metric tensor derived from it is (6.29)in the -coordinates and (6.30)in the -coordinates. Moreover, by differentiating it, we have from (6.23) and (6.24), (6.31)in the two coordinate systems. This implies that the geometry derived from a convex function, or the related Bregman divergence, is dually flat and the affine coordinate systems are  and . The cubic tensor is written as (6.32)in the two coordinate systems. This justifies our former definition of the dually flat structure introduced in Part I without differential geometry.


6.3 Invariant Metric and Cubic Tensor
An f-divergence is an invariant divergence in the manifold of probability distributions. We calculate the two tensors  and  derived from an f-divergence, which are therefore invariant.


Theorem 6.3

Invariant tensors derived from a standard f-divergence in the manifold of probability distributions are given as (6.33)
 (6.34)where  is the Fisher information matrix and (6.35)
 (6.36)




Proof

By differentiating an arbitrary f-divergence (6.37)with respect to  and  and putting , we have (6.33) and (6.34). 




Remark

The uniqueness of the f-divergence under the invariance criterion is derived from the information monotonicity and decomposability. More strongly, the Chentsov theorem proves that  and  are the unique invariant second-order and third-order symmetric tensors in 
            .
          




6.4 
-Geometry
When  is a symmetric tensor, so is  for real . We call the two affine connections derived from , (6.38)the -connection and -connection, respectively.


Theorem 6.4


 and  are dually coupled and the  connection  is the Levi-Civita connection, which is self-dual.

The proof is easy from (6.12).
When  is derived from an f-divergence, it is  for  satisfying (6.36) and, moreover,  is derived from the dual of the f-divergence. The derived dual structure is the only invariant geometry in the case of a manifold of probability distributions. We call it the -geometry. The -geometry is derived from the -divergence defined in (3.â39). It is not dually flat in general. When , it reduces to the KL-divergence, giving a dually flat structure.
For any convex function , we can construct a related -divergence. In this case, the -geometry is induced from the -divergence defined by (6.39)This is a Jensen-type divergence introduced by Zhang (2004).



6.5 Dually Flat Manifold
We have the following theorem concerning dual curvatures.


Theorem 6.5

When the RC curvature R vanishes with respect to one affine connection, the RC curvature  with respect to the dual connection vanishes and vice versa.



Proof

When the RC curvature vanishes, , the round-the-world parallel transportation does not change any A: (6.40)For vector transportations, we always have (6.41)Hence, when (6.40) holds, we have (6.42)for any A and B. This implies (6.43)showing that the dual RC curvature vanishes, . 


A manifold is always dually flat when it is flat with respect to one connection. When M is dually flat, there exists an affine coordinate system  for which (6.44)Each coordinate curve  is a geodesic. The basis vectors  are transported in parallel to any position, not depending on a path of transportation.
Similarly, there exists a dual affine coordinate system  for which (6.45)holds. Each coordinate curve  is a dual geodesic. Let its direction be . Here, we use a lower index to denote the components of  and the related basis vectors are denoted by upper-indexed quantities such as . This notation fits our index notation of raising and lowering indices by using the metric tensors  and its inverse . The Jacobians of the coordinate transformations satisfy (6.46)Therefore, two bases  and  satisfy (6.47)



Theorem 6.6

In a dually flat manifold, there exists affine coordinate system  and dual affine coordinate system  such that their tangent vectors are reciprocally orthogonal, (6.48)




Proof

From (6.47), we have (6.49)We also have (6.50)at any point. Note that  and  depend on the position, but (6.47) holds at any point.



6.6 Canonical Divergence in Dually Flat Manifold
We have shown that a dual structure is constructed from a divergence function. In particular, a dually flat structure is induced from a Bregman divergence. However, many divergences give the same dual structure. This is because the differential geometry of the metric and connections is defined from the derivatives of divergence  at , given in (6.22)-(6.24). That is, it depends only on the values of  for infinitesimally close  and . There are no unique ways of extending an infinitesimally defined divergence to the entire M. That is,  gives the same geometry as  when a non-negative function  satisfies (6.51)
 (6.52)
 (6.53)
 (6.54)where  and .  given in (3.â25) is such an example. Interestingly, however, when a manifold is dually flat, we can obtain a unique canonical divergence, despite the fact that there are many locally equivalent divergences. To show this, we begin with the following lemma.


Lemma 6.1

When M is dually flat, there are a pair of dual affine coordinate systems  and  and of Legendre-dual convex functions  and  satisfying (6.55)such that the metric is given by (6.56)and the cubic tensor by (6.57)
 (6.58)




Proof

By using the affine coordinate system  for which , (6.6) reduces to (6.59)Because the connections are symmetric, we have (6.60)We fix index j and denote it by  . So we have (6.61)Then, there is a function  satisfying (6.62)or for each j, we have (6.63)Since  is symmetric, we have (6.64)This guarantees the existence of a scalar function  such that (6.65)Hence (6.66)where  is convex because  is positive-definite. Since  for the -coordinates,  is given from (6.18) by (6.67)By using the dual affine coordinate system, we have a convex function  that satisfies (6.56) and (6.58). It is easy to see that the two coordinate systems are connected by a Legendre transformation, so that the two functions are the Legendre duals. 




Theorem 6.7

When M is dually flat, there exists a Lengdre pair of convex functions ,  and a canonical divergence given by the Bregman divergence (6.68)


They are uniquely determined except for affine transformations. Conversely, the canonical divergence gives the original dually flat Riemannian structure.


Theorem 6.8

The KL-divergence is the canonical divergence of an exponential family of probability distributions which is invariant and dually flat.



Remark 1

Many studies begin with the KL-divergence given a priori without any justification. However, our theory shows that the KL-divergence is an outcome of dual flatness in the invariant geometry.



Remark 2

The KL-divergence is derived as the unique canonical divergence without assuming decomposability in the above theorem. See also another derivation by Jiao et al. (2015).

For a dually flat M, its affine coordinates  and  are not unique. Any affine transformation (6.69)where  is an invertible matrix and  are constants, gives a set of dually coupled coordinate systems. The convex functions  are not unique either, because we may add a linear term, as in (6.70)where  is a vector and d is a scalar. However, the canonical divergence (6.71)is uniquely determined, not depending on a specific choice of affine coordinate systems.


6.7 Canonical Divergence in General Manifold of Dual Connections
It is known that there always exists a divergence in a manifold having dual connections, such that the same dual structure is given by the divergence (Matumoto 1993). There are many such divergences. So it is an interesting problem to define a canonical divergence, if possible, in a manifold M having non-flat dual connections. When M is dually flat, we have a canonical divergence. Kurose (1994) showed that a canonical divergence called the geometrical divergence exists when M is 1-conformally flat. M is embedded in  in this case. Moreover, when it has constant curvature, the generalized Pythagorean theorem (Theorem 4.â5) holds. The -divergence is a canonical divergence of  in this sense. Taking these facts into account, we demonstrate an on-going trial by N. Ay and S. Amari to define a canonical divergence in the general case, briefly without proof (Ay and Amari 2015, Henmi and Kobayashi 2000).
Consider  of a Riemannian manifold with dual affine connections. Let  be a coordinate system. Given a point  and a tangent vector X belonging to the tangent space at , we have a geodesic curve , (6.72)passing through  and its tangent direction is X, (6.73)When the geodesic reaches point  as t increases from 0 to 1, (6.74)
 is called the exponential map of X, (6.75)Given  and , we have the inverse of the exponential map, (6.76)in a neighborhood of .
We now define a canonical divergence in a general manifold of dual connections. We first define a divergence between  and  by (6.77)where  is the primal geodesic connecting  and . It can be rewritten as (6.78)We then define another divergence by using the dual geodesic  connecting  and : (6.79)A canonical divergence is defined by the arithmetic mean of the above two.


Definition

A canonical divergence is given by (6.80)




Theorem 6.9

The geometrical structure derived from the canonical divergence (6.80) coincides with the original geometry. When M is dually flat, it gives the canonical divergence of the Bregman type. When M is Riemannian , it is a half of the squared Riemannian distance.

In a dually flat manifold, the projection theorem holds: Given  and a submanifold , the point  that minimizes , , is the geodesic projection of  to S such that the geodesic connecting  and  is orthogonal to S at 
          . The projection theorem does not hold in general, but we have the following theorem.


Theorem 6.10

The canonical divergence satisfies the projection theorem when (6.81)where  is the contravariant component of  and (6.82)




Proof

Consider a divergence ball centered at  and with radius , (6.83)Let S be a smooth submanifold of M. Let  be the minimizer of , . When c is increasing from 0, the ball  touches S at . The tangent hypersurfaces of S and  are the same at this point, and its normal vector is given by (6.84)The tangent direction of the geodesic connecting  and  is given by (6.85)So the projection theorem holds when the above two share the same direction. 


It is interesting to study when the geodesic projection theorem (6.81) holds. It holds in the dually flat case. It holds for the -divergence, and hence it is the canonical divergence of the -geometry.


6.8 Dual Foliations of Flat Manifold and Mixed Coordinates
A dually flat manifold admits two types of foliations, e-foliation and m-foliation, which are orthogonal to each other. This structure is useful for separating two quantities, one represented in the e-coordinates and the other in the m-coordinates. This fits particularly well for analyzing a hierarchical system (Amari 2001).

6.8.1 
k-cut of Dual Coordinate Systems: Mixed Coordinates and Foliation
Let M be a dually flat manifold with dually coupled affine coordinate systems  and . We partition the coordinates into two parts, one consisting of k components and the other consisting of  components. We rearrange the suffixes such that the first k components consist of  and the last  components consist of . The same rearrangement is done for the -coordinates. We call such a partition a k
          -cut.
Let us compose a new coordinate system  of which the first k components are the corresponding -coordinates and the last  components are -coordinates such as (6.86)This is a new coordinate system called a
           mixed coordinate system, since m-affine coordinates and e-affine coordinates are mixed in it. It is not an affine coordinate system by itself. The basis vectors of the tangent space in the mixed coordinates are composed of two parts, the first part consisting of (6.87)and the second part consisting of (6.88)They are orthogonal, because of (6.89)Therefore, the Riemannian metric in this coordinate system has a block-diagonal form, (6.90)Let us consider an -dimensional submanifold obtained by fixing the first k coordinates (-coordinates) to be equal to 
 (6.91)and denote it by , in which  run freely. It is an m-flat submanifold, because it is defined by linear constraints on -coordinates. For ,  and  do not intersect, (6.92)Moreover, the entire M is covered by the aggregate of all 's (6.93)Hence, 's give a partition of M. Such a partition is called a
           foliation.
Dually to the above, we fix the second part of the mixed coordinates (-coordinates), (6.94)where  and  run freely. We then have a k-dimensional e-flat submanifold denoted by . Moreover, 's form another foliation of M. We thus have two foliations. Moreover,  and  are orthogonal to each other for any  and . See Fig. 6.2.Fig. 6.2Dual orthogonal foliation of manifold



Theorem 6.11

A dually flat M admits a pair of orthogonal k-cut foliations for any k, one of which is m-flat and the other e-flat.



6.8.2 Decomposition of Canonical Divergence
By using the mixed coordinates, the canonical divergence between two points P and Q can be decomposed into a sum of two divergences, one representing the difference in the first part and the other in the second part. Let (6.95)be the mixed coordinates of the two points P and Q. P is located at the intersection of  and  and Q is at the intersection of  and . We m-project P to  and let the projected point be . We also e-project P to  and let the projected point be . See Fig. 6.3. Since the m-geodesic connecting P and  is orthogonal to the e-geodesic connecting  and  forms a right triangle so that the Pythagorean theorem is applicable. We can do the same thing for the triangle . Then, we have the decomposition theorem.Fig. 6.3Foliation and decomposition of KL-divergence



Theorem 6.12

The canonical divergence D[P : Q] is decomposed as (6.96)
 representing the difference in the first part and  representing the difference in the second part.



6.8.3 A Simple Illustrative Example: Neural Firing
We show the usefulness of the orthogonal foliation by a simple example. Let us consider a network consisting of two neurons which emit spikes stochastically. Let  and  be two binary random variables, taking values , when neuron i is excited (emitting a spike) and 0 otherwise. Joint probability  specifies the stochastic behavior of this network. The manifold of all joint probability distributions  forms a three-dimensional exponential family, because (6.97)This is a set of discrete distributions over four elements, and we can write it in the exponential form, (6.98)The affine coordinates are given by (6.99)The dual coordinates  are (6.100)showing the firing rate (probability of ) of neuron i and (6.101)showing the joint firing rate (the probability of the two neurons firing at the same time).
We construct mixture coordinates such that the first part consists of  and  and the second part consists of . Using the mixed coordinate system (6.102)we have a dually orthogonal foliation. The one-dimensional submanifold  consists of all the distributions in which the firing rates of the two neurons are fixed to . The coordinate  in  represents how firing of the two neurons is correlated. When  and  are independent, as is seen from (6.98). Given , the e-flat submanifold  represents distributions for which interaction of  and  is fixed to be equal to  but the firing rates of the neurons are arbitrary. Thus, the partition is done in such a way that the first part represents firing rates of neurons and the second part represents the interaction of two neurons (Fig. 6.4).Fig. 6.4Dual foliation of 


One may measure the degree of interaction by the covariance of  and , (6.103)It is 0 when the two neurons fire independently. If we use v as a coordinate in , we have another coordinate system  in M. However, the v-axis is not orthogonal to the marginal firing rates , while  is. Therefore, the mixed coordinates are successful in decomposing the firing rates and interaction orthogonally but v is not.
Given two distributions  and , we have the decomposition of their KL-divergence, as (6.104)where  is the distribution having the same marginal distributions as p and the same interaction as q. KL[p : r] represents the divergence due to the difference in mutual interaction and KL[r : q] represents that due to marginal firing rates.


6.8.4 Higher-Order Interactions of Neuronal Spikes
We can generalize the idea to a network of n neurons (Amari 2001; Nakahara and Amari 2002; Nakahara et al. 2006; Amari et al. 2003). Let us consider a network consisting of n neurons, which emit spikes stochastically. Let  be a binary random variable, representing emission of spikes. The state of the network is represented by . The set of all probability distributions  forms , where , since there are N states . This is an exponential family. By expanding  as (6.105)we have (6.106)This is called a log linear model. According to the degrees of variables in , we partition the entire  in a hierarchical form as (6.107)
 (6.108)such that each subvector  consists of coefficients of monomials  of degree k.
The dual affine coordinates are composed of (6.109)which are joint firing rates of k neurons, , and they are hierarchically partitioned as (6.110)where (6.111)The kth mixed coordinate system is composed of (6.112)Since (6.113)is composed of the joint firing rates up to k neurons, the other coordinates (6.114)represent the directions orthogonal to the joint firing rates up to k neurons. A change in  does not affect  but alters the joint firing rates of more than k neurons. Hence,  represents interactions of more than k neurons orthogonal to the firing rates up to k neurons.
Among n terms, , we can say that  represents the degree of mutual interactions among k neurons. 's  are called the
           higher-order correlations or interactions of neurons. Although  are not mutually orthogonal,  are orthogonal to .
We show a simple case of , consisting of three neurons. We have (6.115)which represents the third-order interactions of the three neurons. It is orthogonal to firing rates of neurons and joint firing rates of any pair of neurons. Similarly, (6.116)represents pairwise interactions of neurons 1 and 2, which are orthogonal to the firing rates of single neurons.


Remark

There are many other hierarchical stochastic systems. One is a Markov chain consisting of various orders. A lower-order system is included in a higher-order system. Hence, we can decompose them in a dually orthogonal way. The auto-regressive (AR) and moving-average (MA) models of time series also form hierarchical stochastic systems, where their degrees compose hierarchy. See Amari (1987, 2001).




6.9 System Complexity and Integrated Information
We consider a stochastic system which receives an input signal , processes it and emits output , and study its complexity by using a mixed coordinate system. We regard it a muliterminal stochastic channel having n input and n output terminals, see Fig. 6.5. Input  and output  are vectors. When a system is very simple, there is no interaction among different terminals. Hence, output  depends only on  and input  does not affect . A complex system has interaction among different terminals and information is integrated to give an integrated output . The degree of interaction is used to define a measure of complexity of the system (Ay 2002, 2015; Ay et al. 2011). Tononi (2008) initiated a new idea of IIT (integrated information theory) to elucidate consciousness. The degree of
        information integration distinguishes a conscious state from unconscious states in the brain (Balduzzi and Tononi 2008; Oizumi et al. 2014, etc.).
We propose a measure of complexity, or of information integration, by using a degree of stochastic interaction within a system from the information geometric point of view, based on part of on-going work with M. Oizumi and N. Tsuchiya. This is an extension of the work by Ay (2001, 2015), and is related to the Tononi information integration (Barrett and Seth 2011).Fig. 6.5Stochastic information transmission channel
Fig. 6.6
a Channel with two terminals and b its split version

We consider a  system for simplicity, where input is  and output is , having only two terminals (Fig. 6.6), although generalization is easy. We study the binary case where  and  take on values 0 and 1, and also the Gaussian case where  and  are Gaussian random variables with mean 0. The behavior of a system is described by joint probability distribution . When the components of  and  are binary, it belongs to an exponential family , called the full model, (6.117)described by e-coordinates . The higher-order terms are  and so on. We have the corresponding -coordinates. The full model is a graphical model shown in Fig. 6.6a, which is a complete graph, since intrinsic correlations between  and  and also between  and  may exist, as is denoted by the dotted branches in Fig. 6.6a. Refer to information geometry of a graphical model studied in Chap. 11.
The complexity of a system is measured by the degree to which it is different from split systems where no interaction exists between  and  (Ay 2002, 2015). So we consider a split system S where no mutual interaction exists, as is shown in Fig. 6.6b. Here, a split model is derived by deleting the branches connecting  and . Let the probability distribution of the split model be , the e-coordinates of which are . Since there are no branches connecting  and , we put . (This is because  and  are conditionally independent where the other variables are fixed.) The higher-order terms are also 0. (This is because no cliques exist connecting three or four nodes in the split model.) Hence, a split model has a probability distribution of the form, (6.118)Split models form an exponential family , which has ten degrees of freedom and is a submanifold of .
The split model family  defined in the above is slightly different from the one  defined by N. Ay. In a split model belonging to , no direct correlation between  and  exists, so  in addition to . That is,  is derived from  by deleting the branch connecting  and .  is an e-flat submanifold of . We do not assume  in , because  and  may be affected by correlated noises directly given from the environment. Since such correlations are given rise to by the environmental situation, even when  and  are independent and  does not affect ,  and  can be correlated in , but not in . To explain this situation, consider a Gaussian model, (6.119)where  is a  matrix and  is a noise term subject to , where  is the covariance matrix of . The components  and  can be correlated.
The degree of
         system complexity, or of
         integrated information, of  is measured by the KL-divergence from  to the split distribution  or  that is closest to  in  or  (Fig. 6.7), (6.120)
 (6.121)They are given by the m-projection of  to  and . Since we have two split models  and , we have two definitions of geometric measure of information integration or stochastic interactions.Fig. 6.7Split model and orthogonal projection


Definition Geometric measures of information integration, or system complexity, are defined by (6.122)
 (6.123)
 is the same as that of Ay (2002, 2015) and also that of Barrett and Seth (2011). GI is a new measure.
Before comparing these two, we show a criterion which such a measure should satisfy. Oizumi et al. (2015) postulated that a degree  of information integration should satisfy (6.124)where I[X : Y] is the mutual information between  and .  should be 0 when , that is, when no information is transmitted from X to Y. They argued that various measures of  so far proposed do not necessarily satisfy the postulate, and defined a new measure  based on the concept of mismatched decoding, which satisfies the postulate (Oizumi et al. 2015).
We study properties of GI and  and see if they satisfy the postulate. Since  is an e-flat submanifold constrained by (6.125)where we use  instead of , we define mixed coordinates (6.126)Then, the m-projection of  to , (6.127)keeps the -part of the mixed coordinates invariant. Therefore, the mixed coordinates  of  are given by (6.128)
 (6.129)where  etc. are those of . These results are directly obtained by minimizing , too. We have a similar result in the case of the m-projection to , where  is replaced by .
We see from (6.128) that the m-projection  is characterized by (6.130)where  etc. are the marginal distributions of , etc. This means that the marginal distributions of  concerning  and  are equal to those of , respectively. Moreover, the conditional distributions are equal: (6.131)The m-projection  to  satisfies (6.132)
 (6.133)
 (6.134)Note that  does not in general hold in .
Although  holds in , this does not mean that  and  are uncorrelated. When  and  are correlated,  and  are correlated even in the split model .
The measures GI and  are represented in terms of entropy and mutual information as follows. Due to the Pythagorean theorem, we have, in the binary case, (6.135)
 (6.136)where H[p] is the entropy of  and  is the uniform distribution of which entropy is put equal to c. Therefore, we have (6.137)This holds in general, including the Gaussian case, where an independent distribution  is used instead of the uniform . Similarly, (6.138)Since the entropy is decomposed as (6.139)we have the following theorem, which is useful for calculating GI and .


Theorem 6.13

The two geometrical measures GI and  are given, in terms of conditional entropy, as (6.140)
 (6.141)where X, and Y denote the random variables  and  subject to , and  and  denote the random variables  subject to  and , respectively.

Moreover, we have simpler representations.


Theorem 6.14


 (6.142)
 (6.143)where  is the conditional mutual information. This elucidates the relation between GI and  as follows: (6.144)
 (6.145)
 (6.146)




Theorem 6.15


GI satisfies the postulate (6.124) but  does not.



Proof

Since both GI and  are given by the KL-divergence, they satisfy (6.147)Let us next consider the independent distribution (6.148)derived from . The mutual information is (6.149)Since  satisfies , this is included in . So (6.150)since  is the minimizer of divergence in . However,  does not necessarily satisfy  and hence is not included in  in general. Hence, (6.151)is not guaranteed. Indeed, for  where X and Y are independent, , but if  and  are correlated (6.152)



We analyze the Gaussian system given in (6.119) for illustration.


Example 1

(Gaussian channel) The joint probability distribution of  in (6.119) is (6.153)when  is subject to . By putting (6.154)it is rewritten as (6.155)where  is the inverse of the covariance matrix (6.156)and they are given explicitly as functions of the system parameters  and .

A full model  belongs to an exponential family, where the -coordinates are  and -coordinates are . A split model is given by (6.157)which does not include terms . By using this expression, we obtain  from .
However, there is a serious problem concerning the optimal solution. The solution can be written as (6.158)but  is not diagonal. The solution is split in the sense that  is satisfied and its graph does not have diagonal branches, but not split in the sense that  is not diagonal. Hence,  depends on both  and . This does not happen in , since  holds.
In order to overcome this flaw, we introduce the third model of split systems, (6.159)This condition can be written as the Markov conditions (6.160)that is,  and  are conditionally independent when  is fixed, (6.161)Since  includes ,  satisfies the postulate (6.162)However,  is neither e-flat nor m-flat. It is curved, so we need to study its properties carefully. This remains as a problem for our future study (Oizumi et al. 2016).
Before finishing this subsection, we show an example in the binary case.


Example 2

(Binary channel) We consider two binary transmission channels. One is , in which  chooses  with probability  and chooses  with probability . Once  or  is chosen by , the transmission of  to  is through a binary symmetric channel with error probability . This means that, when , the probability of  is  and that of  is . The other cases are similarly defined. We further consider another channel  which generates , (1, 1) with probability 1 / 2 each, and its output is  irrespective of . So no information transmission takes place in . We study a combined binary channel C that chooses  with probability  and chooses  with probability . The split model  is defined by , and  is not necessarily 0.  plays the role of correlated  in the Gaussian case. The split model  is defined by  and .



Remark 1

We can introduce a hierarchy of split models in a general channel having n input terminals and n output terminals. We partition k inputs  into k subsets , (6.163)Similarly, we partition  into . The split model  with respect to this partition is obtained by deleting all the branches connecting terminals in  and . Since a refinement of a partition gives a finer partition, we have a hierarchical structure concerning partitions. Hence, GI forms a hierarchical structure with respect to partitions.



Remark 2

We can extend the above results to the dynamical systems of Markov chains, such that the state  at time  is determined stochastically by a conditional probability distribution  of a stochastic channel. The initial state distribution  is set equal to the stationary distribution of the Markov chain.



6.10 Input-Output Analysis in Economics
We show another example of the dual foliation from the field of economics, due to Morioka and Tsuda (2011). The
         input-output analysis uses a table , which is an  matrix, showing the quantities of products and amounts of consumption in n industries and how the products are transferred from one industry to another for consumption. Namely, each row and column of matrix  represent an industry and  is the amount of product that industry i sells to industry j.  are represented in the monetary basis.
Let (6.164)be the row sum of the table, which represents the quantity of gross product of industry i. Similarly, the column sum (6.165)represents the amount of gross consumption of industry j. They satisfy (6.166)We have an interest not merely in the gross product and consumption of each industry but more in their interactions, reflecting the structural relationship between industries.
To this end, let us consider the manifold M consisting of all input-output tables (6.167)where  form a coordinate system of M. We define another coordinate system by (6.168)and regard it as an e-flat coordinate system of M. The associated convex function is (6.169)Then, the dual m-coordinate system is given by  which is merely (6.170)and the dual convex function is (6.171)The canonical divergence between two input-output tables  and  is (6.172)In order to separate the distributions of gross products and consumptions from their interrelations, we treat  and  as a part of new m-affine coordinates, which are linear combinations of m-coordinates . We replace the last row  and last column  by  and , respectively. Then we have a modified table in which the last row and column are replaced. We denote the new coordinates by . This is given by an affine coordinate transformation from . The corresponding e-affine coordinates, denoted by  are calculated from the invariance relation (6.173)as (6.174)
 (6.175)We partition the coordinates and construct the mixed coordinates. The first part consists of . The second part consists of . The first m-coordinates represent the gross products and consumptions in industries, while the second part is orthogonal to the first part, representing the interrelations among industries. The divergence between two tables can be decomposed into a sum, the one due to the difference of gross products and consumptions and the second due to the difference in the interrelations.
The  are obtained by deleting industry n from the table. Hence, it is not symmetric with respect to all the industries. To overcome this difficulty, let  be the e-coordinates where industry k is replaced, instead of industry n, by the total sums. Then, their average defined by (6.176)would be a good measure of interactions among industries.
Instead of replacing one industry k by the gross distributions, we may add  to the input-output table as its th row and th column. Then, the interaction part based on the th row and column becomes (6.177)Morioka and Tsuda (2011) used this for analysis.
Observing the trend of yearly changes in the first part of , one can understand the developments of the gross products in industries. The yearly changes of the second part  represent how the industrial interrelationship changes. This reflects the structural change in the interrelations among industries.
One can try to alter the gross amounts of products of industries from  to (6.178)by using arbitrary coefficients . By using another set of coefficients , the gross consumptions are changed to (6.179)Such changes can be realized by transforming  into (6.180)This is called the
         RAS transformation, by which the interrelationship  does not change but the gross amounts of products and consumptions may change arbitrarily.
Annual statistics of gross amounts  and  are published every year, but  themselves are not, because construction of the entire  table is laborious. So, the entire table is published only every five years in Japan, for example. In such a case, we can interpolate the  part (or  part) in the unknown years by using the e-geodesic in the interaction part from the known S-parts. Morioka and Tsuda (2011) studied the change in the industrial structure of Japan after the War, finding remarkable changes occurring as the Japanese economy developed.
See Marriott and Salmon (2011) for other applications of geometry to economics.


Remarks

The concept of dual affine connections was introduced in a Riemannian manifold by Amari (1982) and Nagaoka and Amari (1982). See also Amari and Nagaoka (2000). The idea emerged from the invariant geometry of a manifold of probability distributions due to Chentsov (1972). However, the late professor K. Nomizu stated that such a concept exists in affine differential geometry (Nomizu and Sasaki 1994).
Affine differential geometry studies properties of n-dimensional hypersurfaces embedded in an -dimensional affine space. This was originally developed by W. Blaschke and also developed by J. L. Koszul (see Nomizu and Sasaki 1994). The Hessian manifold of Shima (2007) also deals with a dually flat manifold.
The concept of dual (conjugate) affine connections is naturally introduced in affine differential geometry but it has not played a central role. The concept of dual connections in information geometry is more general, since it deals with a manifold which might not be embedded in an -dimensional affine space. However, there is much overlap between these two fields and they have been developping through mutual interactions. The present monograph does not touch upon affine differential geometry, although there are many common interesting problems. Excellent work is found in Kurose (1990, 1994, 2002). See also Matsuzoe (1998, 1999), Matsuzoe et al. (2006), Uohashi (2002) and many others.
lnvariant geometry is due to Chentsov (1972), where the uniqueness of two tensors G and T is presented. The invariant geometry (-geometry) is constructed from these tensors. How is a general dual manifold related to a statistical manifold? Due to a theorem of Banerjee et al. (2005), we know that any dually flat manifold is realized as an exponential family. LÃª (2005) proved a stronger theorem that any dual manifold can be realized as a submanifold of an N-dimensional probability simplex  for a sufficiently large N. There is another interesting problem: Given a Riemannian manifold , on what condition does it become dually flat by supplementing an adequate T? Such a Riemannian manifold is said to be flattenable. It is interesting to know the characterization of flattenable Riemannian manifolds. When , this is always possible, but when , it is not. This problem was studied by Amari and Armstrong (2014).
The Chentsov invariance theorem was proved in the discrete case of . Amari and Nagaoka (2000) formulated the invariance in a general continuous case in terms of sufficient statistics. However, there is no rigorous proof due to difficulties in dealing with a function space. The Leipzig group, including J. Jost and H. V. LÃª, is tackling this problem (Ay et al. 2013).
The global topology of a statistical manifold is another interesting problem of differential geometry. It is interesting to see how a dual pair of local curvatures is related to the global topology of a manifold.
Finally, we give a list of monographs on information geometry. They each have the own characteristics: Amari (1985), Amari and Nagaoka (2000), Arwini and Dodson (2008), Calin and Udriste (2013), Chentsov (1972), Kass and Vos (1997), Murray and Rice (1993).










Part IIIInformation Geometry of Statistical Inference










Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_7




7. Asymptotic Theory of Statistical Inference




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp







7.1 Estimation
Let  be a statistical model specified by parameter , which is to be estimated. When we observe N independent data  generated from , we want to know the underlying parameter . This is a problem of estimation, and an
         estimator (7.1)is a function of D. The estimation error is given by (7.2)when  is the true value. The bias of the estimator is defined by (7.3)where the expectation is taken with respect to . An estimator is unbiased when .
The asymptotic theory studies the behavior of an estimator when N is large. When the bias satisfies (7.4)it is asymptotically unbiased.
It is expected that a good estimator converges to the true parameter as N tends to infinity. It is written as (7.5)When this holds, an estimator is consistent. The accuracy of an estimator is measured by the
         error covariance matrix, , (7.6)It decreases in general in proportion to 1 / N, so that the estimator  becomes sufficiently accurate as N increases. The well-known
         CramÃ©r-Rao Theorem gives a bound of accuracy.


Theorem 7.1

For an asymptotically unbiased estimator , the following inequality holds: (7.7)
 (7.8)where  is the Fisher information matrix,  is its inverse, and the matrix inequality implies that  is positive semi-definite.

The maximum likelihood estimator (MLE) is the maximizer of the likelihood, (7.9)It is known that the MLE is asymptotically unbiased and its error covariance satisfies (7.10)attaining the
         CramÃ©r-Rao bound (7.7) asymptotically. Such an estimator is said to be Fisher efficient (first-order efficient).


Remark

We do not mention Bayes estimators, where a prior distribution of parameters is used. However, when the prior distribution is uniform, the MLE is the maximum a posteriori Bayes estimator. Moreover, it has the same asymptotic properties for any regular Bayes prior. Information geometry of Bayes statistics will be touched upon in a later chapter.



7.2 Estimation in Exponential Family
An exponential family is a model having excellent properties such as dual flatness. We begin with an exponential family (7.11)to study the statistical theory of estimation, because it is simple and transparent.
Given data D, their joint probability distribution is written as (7.12)where  is the arithmetic mean of the observed examples, (7.13)It is a sufficient statistic. The MLE  is given by differentiating (7.12) and is the solution to (7.14)Using the -coordinates, this is written as (7.15)Observed data defines a point  in M of which the coordinates are (7.16)We call it the observed point determined from data D, which is nothing other than the MLE in the -coordinates. The following theorem is easy to prove.


Theorem 7.2

The MLE is unbiased and efficient: (7.17)
 (7.18)




Proof

We see from the central limit theorem that  is asymptotically subject to a Gaussian distribution with mean  and covariance matrix . Since the MLE attains the CramÃ©r-Rao bound, it is the best estimator in an exponential family. 




Remark

The MLE  expressed in the -coordinates is asymptotically unbiased and asymptotically efficient, but it is not exactly unbiased, nor does it attain the CramÃ©r-Rao bound exactly. This is because the bias and covariance matrix are not tensors so that the results are different in the -coordinate system.



7.3 Estimation in Curved Exponential Family
Estimation in an exponential family is too simple. We study estimation in a curved exponential family, which is a submanifold embedded in an exponential family. Many statistical models belong to this class. A curved exponential family of probability distributions with parameter  is written in the following form: (7.19)
 is a submanifold of an exponential family , where  is a coordinate system of S.
Observed data D specifies the observed point  in the ambient exponential family M, which is not included in S in general. An estimated value of  is derived by mapping the observed point  to S (Fig. 7.1). That is, an estimator  is derived from a mapping from M to S. Let it be (7.20)such that (7.21)
Fig. 7.1An estimator  defines auxiliary submanifold 


The observed point  converges to the true point as N goes to infinity, as is clear from the law of large numbers. Hence, a
         consistent estimator satisfies (7.22)Let us consider the set of points  in M which are mapped to  by the estimator . This is the inverse image of an estimator f, denoted by (7.23)It forms an -dimensional submanifold passing through  (Fig. 7.1). We call it an
         ancillary submanifold associated with estimator f.  is defined at each  and they give a foliation of M at least in a neighborhood of S, (7.24)
 (7.25)where U is a neighborhood of S. When , that is, when  passes through ,  gives a consistent estimator.
An estimator defines an ancillary family  associated with it and conversely an ancillary family  defines a consistent estimator when f satisfies (7.22). It is possible to study the performance of an estimator in terms of the geometry of an ancillary family. Let us define a coordinate system  inside each  such that the origin  is at  which is the intersection of  and S. We denote coordinates of S by (7.26)and coordinates in  by (7.27)Then, combining the two, we have a new coordinate system of M, (7.28)defined in a neighborhood  (Fig. 7.2).Fig. 7.2New coordinate system  of M


The -coordinates and -coordinates in M are written in terms of the new coordinates  as (7.29)
 (7.30)Any point in S satisfies , so that S is represented by (7.31)The Jacobian matrices of the coordinate transformations between  and  and  and  are expressed as (7.32)
 (7.33)and are decomposed as (7.34)
 (7.35)in terms of the  and  coordinates.
The Fisher information is given in the -coordinate system as (7.36)and is decomposed as (7.37)Given data D, the - and -coordinates  of the observed point  are determined from (7.38)The estimator associated with ancillary family  is given by (7.39)



7.4 First-Order Asymptotic Theory of Estimation
When the true distribution is  in S, by the law of large numbers, the observed point  converges to (7.40)as N tends to infinity. We define the error, that is the deviation of the observed point from the true distribution in the -coordinates, by (7.41)Since it is small, we normalize it as (7.42)Then, the moments of the error are easily calculated. They are summarized in the following theorem.


Theorem 7.3

The moments of the error (deviation)  in the -coordinates are given by (7.43)
 (7.44)
 (7.45)where (7.46)
 (7.47)


Let us also normalize the error in the -coordinates as (7.48)where  is the -coordinates of . By expanding (7.49)we have (7.50)where (7.51)By inverting (7.50), we have (7.52)where (7.53)We have, therefore, an asymptotic evaluation of the error in the -coordinates as (7.54)
 (7.55)Since  are asymptotically Gaussian, the error  in (7.48) expressed in the -coordinates is asymptotically (7.56)By integrating  with respect to , we have the asymptotic distribution of the estimation error (7.57)where (7.58)When  is orthogonal to M, (7.59)so that we have (7.60)In general (7.61)and  is maximized in the orthogonal case, where the CramÃ©r-Rao bound is asymptotically attained. An estimator is efficient in this case.
We summarize the results in the following.


Theorem 7.4

(1) An estimator  is consistent when its ancillary family  passes through  in M. (2) A consistent estimator is
           efficient when  is orthogonal to S.

The maximum likelihood estimator is given by the m-projection of  to S. Therefore, its  is orthogonal to S and it is efficient.


Remark


          The
           first-order asymptotic theory is a linear theory in a small neighborhood of the true distribution. Hence, it is enough to consider only the tangent space  instead of the entire M for evaluating the performance of an estimator. Therefore, the asymptotic theory is common for all regular statistical models. We may consider the case where the ancillary family  depends on N so that it is denoted as . Then, the theory holds when  passes through  and is orthogonal to S, as N tends to infinity. Such an ancillary family is important for studying the performance of testing
           hypotheses.



7.5 Higher-Order Asymptotic Theory of Estimation
The covariance matrix of an efficient estimator achieves the CR-bound  asymptotically when we ignore the term of order . The higher-order asymptotic theory evaluates this higher-order term. This makes it possible to compare the performances of various efficient estimators more accurately.
In order to compare the higher-order errors, we introduce asymptotic bias-correction of estimators. The asymptotic bias  of an estimator is given in (7.54), which is of the order 1 / N. If we modify the estimator by (7.62)the bias of the new estimator becomes (7.63)We call it a bias-corrected estimator. In order to compare the covariances of various efficient estimators, we use their bias-corrected versions. The idea of bias correction is due to Rao (1962), and is necessary in order to exclude estimators which are good at some specific points but not uniformly good. For example, the trivial estimator (7.64)which does not depend on data D, is the best estimator when the true distribution is  but very bad for other .
We evaluate the error terms from (7.52) by using the higher-order terms of the Taylor expansion, where we need higher-order moments of the error given in (7.43)-(7.45). We then have the following theorem. The calculations are technical and they are formidably complicated, so we neglect them and give only the results. See Amari (1985).


Theorem 7.5

The covariance matrix of a bias-corrected efficient estimator is given by (7.65)where (7.66)is the square of the e-embedding curvature of S, (7.67)is the square of the m-embedding curvature of the ancillary family  and (7.68)is the square of the m-connection of the coordinate system  in S.

Thus, the second-order terms of the covariance of error are decomposed into a sum of three non-negative terms. The e-curvature term  depends on the statistical model S, showing the degree of its deviation from an exponential family. This vanishes when S itself is an exponential family. This term was introduced by Efron (1975) and he named it statistical curvature. The term  depends on the method of parameterization  in S and is common to all estimators. The m-curvature term  depends on the m-embedding curvature of . It vanishes when the m-curvature of  vanishes. Note that the m-curvature of  vanishes for the MLE, since the MLE is given by the m-projection of the observed point to S. This is the only quantity which depends on the estimator.


Theorem 7.6

A bias-corrected efficient estimator is second-order efficient when the embedding m-curvature of the associated  vanishes at S. The bias-corrected MLE is second-order efficient.



Remark

It is intriguing to ask if the higher-order bias-corrected MLE is third-order efficient or not. Unfortunately, it is not. Kano (1997, 1998) disproved the conjecture, showing that the MLE is not third-order efficient. It was Fisher's belief that the MLE would be the best estimator, but the dream of Fisher was shattered in the third-order asymptotic theory.



7.6 Asymptotic Theory of Hypothesis Testing
        

When the number of observations is large, we have an asymptotic theory of hypothesis testing. A typical situation is to test a null hypothesis (7.69)against alternatives (7.70)in a one-dimensional curved exponential family . This is a one-sided test but we can treat a two-sided test similarly.
Since S is a curve in M, we design a test by defining a rejection region R in M such that hypothesis  is rejected when the observed point  is included in R and is not rejected (is accepted) otherwise. The observed point  converges to  as N increases when hypothesis  is true. Hence, the rejection region should not include , but its boundary  lies close to , approaching  as N tends to infinity. See Fig. 7.3. The boundary surface  of R depends on the null hypothesis . It is an -dimensional hypersurface crossing S at point  which converges to  as N increases. We denote it by . See Fig. 7.3.Fig. 7.3Rejection region R and associated auxiliary submanifold 


We consider  as a free scalar parameter, and form an ancillary family of , depending on N. This is a foliation of M consisting of the boundaries of the rejection regions for various . This is useful for analyzing the performance of a hypothesis testing. The first-order asymptotic theory is easy, since  converges to  under hypothesis .


Theorem 7.7

A test is (first-order) efficient when the associated ancillary surface  passing through  is orthogonal to S and  converges to , as N tends to infinity.

There are many first-order efficient tests, the Rao test, Wald test, likelihood-ratio test, locally most powerful test among others. How do these tests differ in their performance? The question is answered by studying the power functions of test T, the probabilities  of rejecting  when the true distribution is u, up to the higher order. There are no uniformly most powerful tests in the second order except for the case that S is an exponential family. Therefore, one test is powerful at a specific point, while another is good at a different point. Information geometry characterizes the performances of various tests by the geometry of the associated ancillary surfaces, in particular by the m-embedding curvatures of  and the asymptotic angle between  and S. The second-order power functions of various tests are analyzed in Kumon and Amari (1983), Amari (1985). See also Amari and Nagaoka (2000).


Remarks

Information geometry was developed for elucidating higher-order characteristics of statistical inference, in particular, estimation and hypothesis testing. The first-order theory was established by the CramÃ©r-Rao theory and the Neyman-Pearson fundamental lemma. Researchers tackled the second-order theories in the late 1970s and many results were obtained independently in Japan, Germany, India, Russia and the U.S.A. See Akahira and Takeuchi (1981). B. Efron was the first to point out the role of statistical curvature in the second-order asymptotic theory (Efron 1975).
Amari (1982) established the second-order theory of estimation by using differential geometry. Kumon and Amari (1983) extended it to the higher-order theory of hypothesis testing. Information geometry was developed further for this purpose, while the duality theory was established by Nagaoka and Amari (1982). See also Amari and Nagaoka (2000).
Sir David Cox, one of most influential statisticians, paid attention to differential geometrical theory when he visited Japan, and he organized a Workshop on Differential Geometry of Statistics in London in 1984. Numerous active statisticians, C.R. Rao, B. Efron, A.P. Dawid, R. Kass, N. Read, O.E. Barndorff-Nielsen, S. Lauritzen, D.V. Hinkley, S. Eguchi and many others, participated in the workshop. It was very fortunate for information geometry that the topic was discussed openly at this workshop in its period of early infancy. But it was unfortunate that N.N. Chentsov could not participate, because it was supported by NATO and the world was divided by the Iron Curtain at that time.
We have shown in this chapter the asymptotic theory of statistics in the framework of a curved exponential family. We have not described details, but shown only intuitive ideas and results. The details are shown in Amari (1985) and also in Amari and Nagaoka (2000) or related journal papers. Since not all regular statistical models are curved exponential families, one might wonder if the theory is valid in a more general regular statistical model. We can prove that most results of higher-order statistical theory hold in a general regular statistical model, by forming a fiber bundle-like structure attached to S, consisting of higher-order derivatives of the score function. This is called a local exponential family. See Amari (1985) for details of higher-order asymptotic theory.
How about non-regular statistical models, where the Fisher information matrix is degenerate or not defined (diverging to infinity)? In the former case, a statistical model includes singularities. There are many such models. Typical examples include the multilayer perceptron. We will study such models in Part IV.
A simple example of the latter type is the location model where x is uniformly distributed in the interval of  and u is the unknown parameter. The Fisher information matrix diverges to infinity. In such a statistical model, there is no inner product in the tangent space. The metric is given by a Minkowski metric in the tangent space, which is different from a Riemannian manifold. In this case, M is a Finsler space. An estimator is not asymptotically Gaussian in such a model but is subject to a stable distribution. It is interesting to see the relation between the Finsler metric, stable distribution, and associated fractal structure, comparing them with the Riemannian metric, the Gaussian distribution due to the Central Limit Theorem and the smooth structure of the regular case. However, such a theory has not yet been explored. See a preliminary study by Amari (1984, in Japanese).













Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_8




8. Estimation in the Presence of Hidden Variables




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp







8.1 EM Algorithm

8.1.1 Statistical Model with Hidden Variables
Let us consider a statistical model , where vector random variable  is divided into two parts  so that . When  is not fully observed but  is observed,  is called a
           hidden variable. In such a case, we estimate  from observed . These situations occur in many applications. One can eliminate the hidden variable  by marginalization such that (8.1)Then, we have a statistical model  which does not include hidden variables. However, in many cases, the form of  is simple and estimation is tractable in M, but  is complicated because of integration or summation over . Estimation in such a model is computationally intractable. Typically, M is an exponential family. The
           EM algorithm is a procedure to estimate  by using a large model M from which model  is derived.
Let us consider a larger model (8.2)consisting of all probability density functions of . When both  and  are binary variables, S is a probability simplex so that it is an exponential family. We study the continuous variable case similarly, without considering delicate mathematical problems. Model M is included in S as a submanifold. Observed data give an observed point (8.3)in S when examples  are fully observed. This is the empirical distribution. When S is an exponential family, it is given by the sufficient statistic (8.4)in the -coordinates. The MLE is given by m-projecting  to M.
We do not have a full observed point  in the hidden variable case. We observe only  so that we have an empirical distribution  of  only. In order to have a candidate of a joint distribution , we use an arbitrary conditional distribution  and put (8.5)Since  is arbitrary, we take all of them as possible candidates of observed points and consider a submanifold (8.6)This is the
           observed submanifold in S specified by the partially observed data . By using the empirical distribution, it is written as (8.7)The data submanifold D is m-flat, because it is linear with respect to .
Before analyzing the estimation procedure, we give two simple examples of the hidden variable model.

(1) Gaussian mixture model

Let  be a Gaussian distribution of y with mean  and variance 1. We can treat more general multivariate Gaussian models with unknown covariance matrices in a similar way, but this simple model is enough for the purpose of illustration. The
           Gaussian mixture model consists of the mixture of k Gaussian distributions having different means , (8.8)where , , are unknown parameters to be estimated. Estimation is easy if, for each , we know the Gaussian distribution from which this  is generated. So we introduce a hidden variable h, which takes value i when y is generated from the ith distribution . The h is a random variable, the distribution of which is multinomial, taking value i with probability . Hence, the entire joint distribution is (8.9)and (8.8) is the marginal distribution of (8.9), obtained by summing h from 1 to k.

(2) Boltzmann machine with hidden units


          The
           Boltzmann machine is a stochastic model having a binary vector random variable . It originates from a model of a spin system in physics and a model of associative memory in machine learning. Consider a Markov chain , where state  at time  is stochastically determined from . We do not describe here the stochastic dynamics of the state transition, but simply study its stable distribution given by (8.10)This is called a Boltzmann machine specified by parameter , where an element  of matrix  is regarded as the intensity of connection between units i and j. They are assumed to be symmetric  with . The linear term  in the exponent is called a bias term, which specifies the tendency of  to be 1 rather than 0.
We consider the case where  is divided into two parts,  and  is observable while  is hidden. For the sake of simplicity, we consider the restricted Boltzmann machine (RBM), which consists of two layers, an observable layer and a hidden layer (Fig. 8.1). Connections exist only between units in the observable layer and between units in the hidden layer. No connections exist between units within the observable layer, and no connections exist between units within the hidden layer. Then, the stable distribution is written as (8.11)where, for the sake of simplicity, we ignore the bias term  and let it be 0.Fig. 8.1Restricted Boltzmann machine

The marginal distribution of  is (8.12)which is a mixture of exponential family distributions. The conditional distribution of  given  is (8.13)when the parameters  are known. This model is used in deep learning and we discuss it in a later chapter from the viewpoint of Bayesian information geometry.


8.1.2 Minimizing Divergence Between Model Manifold and Data Manifold
The MLE is the minimizer of KL-divergence from the observed point  to the model manifold in the fully observed case. We have an observed data submanifold D in the hidden case instead of . We consider the minimizer of KL-divergence from the data manifold to the model manifold. The problem is then to minimize the divergence between two submanifolds D and M, (8.14)where the minimum between two sets D and M is taken with respect to . The alternating minimization algorithm (em algorithm) studied in Chap. 1 is useful for this purpose.


Theorem 8.1

The MLE is the minimizer of the KL-divergence from D to M.



Proof

The KL-divergence from a distribution  to a distribution  is written as (8.15)where c is a term not depending on  and . We minimize (8.15) with respect to both  and  alternately by the em algorithm, that is, the alternating use of the e-projection and m-projection. First, assume that  is given and we minimize (8.15) with respect to . We consider one observed  for simplicity, although we need to consider the expectation with respect to , which is the summation over all observed .
Our task is to maximize the second term of (8.15) (8.16)with respect to . By differentiating it, the solution is given in the equation (8.17)In order to minimize (8.15) with respect to , we use the following lemma.



Lemma 8.1

The e-projection from a point of M to D does not alter the conditional distribution  and hence the conditional expectation of .



Proof

Given  and observed data , we search for  that minimizes (8.15). This is to minimize (8.18)under the constraint (8.19)The minimizer is given by the e-projection of  to D and analytically by solving (8.20)where  is the Lagrange multiplier corresponding to (8.19). This proves (8.21)which is exactly the same as the conditional probability of  at . 


By substituting (8.21) in (8.17), the minimizer of the KL-divergence satisfies (8.22)proving that it is the MLE. 



8.1.3 EM Algorithm
The EM algorithm (expectation maximization algorithm) is an iterative algorithm for obtaining the MLE in a model including hidden variables. It was formulated by Dempster et al. (1977). We show its geometry due to CsiszÃ¡r and Tusnady (1984), also by Amari et al. (1992), Byrne (1992) and Amari (1995). It is an application of the em algorithm from the geometrical point of view. We begin with  as an initial parameter, and e-project it to D to obtain the conditional distribution . This determines a candidate for the observed distribution in D. We calculate the conditional expectation of  likelihood to evaluate the likelihood of a new candidate , given by (8.23)for observed data . This is called the E-step, because it calculates the conditional expectation. This is the e-projection of  to D.
We then m-project the new candidate in D to M, to obtain a new candidate  in M. This is obtained by maximizing (8.23). It is called the M-step, because it is the maximization of the  likelihood (8.23). This is the m-projection. We repeat the procedures. See Fig. 8.2 .Fig. 8.2EM algorithm

It is easy to prove the following theorem.


Theorem 8.2

The KL-divergence decreases monotonically by repeating the E-step and the M-step. Hence, the algorithm converges to an equilibrium.

It should be noted that the m-projection is not necessarily unique unless M is e-flat. Hence, there might exist local minima.


8.1.4 Example: Gaussian Mixture
The parameters to be estimated are the weights  and the means  of component Gaussian distributions, . We begin with initial , and let  be the candidate at t. The E-step is to e-project  to D to obtain . This is the same as that at , (8.24)The conditional expectation is (8.25)up to a constant not depending on the parameters.
The M-step is maximization (m-projection) searching for a new  that maximizes (8.25). By differentiating (8.25) and making it equal to 0, we easily obtain (8.26)




8.2 Loss of Information by Data Reduction
        

Given original data , assume that we summarize it to a statistic (8.27)and use it for estimation. Then, we consider an estimator , which is a function of . When  is a sufficient statistic, there is no loss of information. Otherwise, summarizing the data in  will cause loss of information, which is measured by using the Fisher information. When there is a hidden variable  and we use  for estimation,  is not sufficient in general.
We define the conditional Fisher information of the original data  conditioned on . When , the probability distribution of  is given by the conditional probability . Hence the Fisher information is given as (8.28)where  is the conditional expectation of . Taking the average over , we have the conditional Fisher information (8.29)From the equality (8.30)where , ,  are the Fisher information based on  and  conditionally on . The loss of Fisher information by summarizing data to statistics  is given by (8.31)Oizumi et al. (2011) studied the loss of information in the case of spikes of neurons. Let t firing patterns  of neurons be observed. These include firing rates of neurons, covariances of spikes of two neurons and higher-order correlations of a number of neurons. Since the brain reduces information in the process of decision making, it loses some information. Consider a curved exponential family (8.32)where  and  is a parameter to specify the probability distribution based on which  is generated. When a multiple observation is possible, we have the sufficient statistic (observed point) (8.33)It includes all the information concerning firing rates, pairwise and higher-order interactions. An efficient estimator is obtained by m-projecting it to model M of which the coordinates are .
When a part of  is lost, for example higher-order correlations of spikes are lost, we cannot identify the observed point. We have instead an observed data submanifold D. The optimum estimator is the minimizer of . The amount of loss of information is calculated when correlational information is lost (Oizumi et al. 2011).


8.3 Estimation Based on Misspecified Statistical Model
When the true statistical model  is very complicated, we are apt to use a simplified model  to estimate parameter . This is a misspecified model. What is the loss of information by using a
         misspecified model? We begin with a simple example for illustration of the problem. Assume that n neurons are arranged in a one-dimensional neural field. When a stimulus is applied at position u, , the neuron corresponding to that position and neighboring neurons are activated. When the ith neuron corresponds to position (8.34)it is excited strongly, and neighboring neurons are also excited. We assume that, for an arbitrary j, the response of neuron j is  when a stimulus is applied at u. The curve  is called the tuning curve of neuron j. See Fig. 8.3. We assume that  is the firing rate of neuron i subject to a Gaussian distribution of which the mean is  and the covariance matrix is . Then, the statistical model of excitation is (8.35)
Fig. 8.3Tuning curve of neural field

Consider a simpler model having the same tuning curves but no correlations, (8.36)Wu et al. (2002) showed that there is asymptotically no loss of information even if we use the simple misspecified model  of (8.36). This is good news for the brain.
We study a general case of a misspecified model to see its loss of information. We consider the case that both  and  are curved exponential families lying in a larger exponential family S. The observed point  is asymptotically subject to the Gaussian distribution with mean  in the true model M and covariance matrix  when the true distribution is . The maximum likelihood estimator using model  is called the q-MLE. The q-MLE is obtained by m-projecting the observed point to  by using the q-ancillary family , which is an m-flat submanifold of S passing through  and orthogonal to the tangent space of  at . Since the observed point converges to  as N tends to infinity, the q-MLE is consistent when the q-ancillary family passing through  passes through . See Fig. 8.4.Fig. 8.4q-auxiliary family and q-MLE



Theorem 8.3

The q-MLE is consistent when and only when (8.37)which holds when the q-ancillary family  passes through .



Proof

Let (8.38)be the m-geodesic connecting  and . Its tangent vector at  is (8.39)It is orthogonal to the tangent vectors (8.40)of , when , which is calculated as (8.41)This implies that (8.37) holds and vice versa. 


The q-MLE estimator is Fisher efficient when the m-geodesic connecting  and  is orthogonal to both M and , because the ancillary submanifold  and the true ancillary submanifold  of the true MLE coincide. Hence, the observed  is mapped to the same  in both M and  by the m-projection. When  is not orthogonal to M, there is information loss. This is easily evaluated from the angles of the q-ancillary submanifold  and M.


Theorem 8.4

The q-MLE estimator is Fisher efficient when the q-ancillary family is orthogonal to M. When it is not orthogonal, the loss of Fisher information is given by (8.42)where  is the transversal coordinate system in .



Proof

By using the q-ancillary family, we can map the observed point  to . This is efficient when and only when  is orthogonal to the tangent space of M. Otherwise, there is information loss. By using the -coordinates, where  and  are the coordinates along the ancillary family , the q-MLE is mapped through it, but this is a non-orthogonal mapping to M. Hence, loss of information occurs, as is given in (7.â58) or (8.42).



Remark

When the q-ancillary family  does not pass , the q-estimator is not consistent. However, when this does not hold, let  be the coordinates of M at which  intersects M. If we reparameterize  such that the new parameter of  is , then the consistency always holds.



Remarks

The present short chapter introduces statistical models which are different from a regular model. One is a model with hidden variables, in which some random variables are not observed. The EM algorithm is known in such a model. From the geometrical point of view, it is nothing other than the em algorithm, which minimizes the divergence between the model manifold M and data manifold D derived from observed data. This is now a standard method in machine learning. When it was proposed by CsiszÃ¡r and Tusnady (1984), the paper was rejected by a journal because the reviewer did not admit computationally heavy iterative procedures (I. CsiszÃ¡r, personal communication). So this remains a conference paper.
Another model is a misspecified model. Its performance is easily understood from geometry, so that it is a good example to show the power of information geometry. The brain might use a misspecified or unfaithful statistical model for decoding information, because the true model is often unknown or too complicated. Therefore, we need to know the performance of the misspecified model. Oizumi et al. (2015) use a misspecified model to evaluate the amount of integrated information to measure the degree of consciousness.













Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_9




9. Neyman-Scott Problem: Estimating Function and Semiparametric Statistical Model




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp






The present chapter studies the famous
       Neyman-Scott problem, where the number of unknown parameters increases in proportion to the number of observations. The problem gave a shock to the statistics community, because the MLE is not necessarily asymptotically consistent or efficient in this problem. We solve the problem by constructing information geometry of estimating functions. The problem is reformulated in the framework of a semiparametric statistical model, which includes a finite number of parameters of interest and a nuisance parameter of function degrees of freedom. The problem uses a function space but we apply an intuitive description, sacrifying mathematical justification. The results are useful for solving both the semiparametric and Neyman-Scott problems.

9.1 Statistical Model Including Nuisance Parameters
Let us consider a statistical model (9.1)which includes two types of parameters. One is a parameter which we want to estimate, denoted by . This is called the
         parameter of interest. The other, denoted by , is a parameter the value of which is of no concern to us. It is called a
         nuisance parameter. We give two examples.


1. Measurement under Gaussian noise:scale problem: Let us measure the weight of a specimen repeatedly by using a scale. The true weight is  but measurements  are independent random Gaussian variables with mean  and variance , where  represents the accuracy of the scale. When we have interest in estimating  but do not care about ,  is the parameter of interest and  is the nuisance parameter. When we are interested in knowing the accuracy  of the scale but do not care about ,  is the parameter of interest and  the nuisance parameter.


2. Coefficient of proportionality: We consider a pair (x, y) of Gaussian random variables, where x and y represent the volume and the weight of a specimen, respectively. Here, x is a noisy observation of the volume v of the specimen and y is the noisy observation of its weight uv, where u is the specific gravity of the specimen. We assume that the noises are independent and Gaussian with mean 0 and variance 1. Then, their joint distribution is specified by (9.2)When we are interested only in specific gravity u, i.e., the coefficient of proportionality, but do not care about v, u is the parameter of interest and v is the nuisance parameter. The joint probability is written as (9.3)The problem is easy, because given observed data , we can use the MLE to estimate u and v and simply discard the estimator  of the nuisance parameter. Since MLE  is efficient, the estimator  is efficient.
Let the Fisher information matrix in the model (9.1) of all the parameters  be , where we use suffixes  for the entire  for the parameter  of interest and  for the nuisance parameter . The Fisher information matrix is partitioned as (9.4)where, by putting , (9.5)
 (9.6)
 (9.7)The asymptotic error covariance of the entire estimator  is given by using its inverse as (9.8)The inverse of the Fisher information matrix is also partitioned as (9.9)where its (a, b)-part  is not the inverse of the (a, b)-part  of . It is the (a, b)-part of the inverse  of . The two are different and  is given by the inverse of (9.10)as is clear from the inversion of a partitioned matrix.
We have (9.11)in the sense of a positive-definite matrix, which means that information is lost in the presence of unknown nuisance parameter . This is because, when  is known, the Fisher information is . Since the covariance of the estimation error, when  is unknown, is asymptotically (9.12)
 is called the efficient Fisher information matrix. The tangent vectors  and  along the  and  coordinate axes are represented by score functions (9.13)
Fig. 9.1Efficient score  in the presence of nuisance parameter

Let us project  to the space orthogonal to the subspace spanned by  (Fig. 9.1). Then, the projected vector is given by (9.14)or, in terms of the score functions, (9.15)This is called the efficient score, because the efficient Fisher information matrix is (9.16)This shows that only the part orthogonal to the nuisance direction is effective, keeping information for estimating , and the part in the nuisance direction is useless, because  is unknown.
When the subspace spanned by the scores of the parameter of interest is orthogonal to the nuisance parameters, we have . In this case, (9.17)holds, so there is asymptotically no loss of information. Therefore, it is desirable to choose the nuisance parameters such that the orthogonality holds. Given a statistical model , we consider the problem of reparameterizing  depending on  as (9.18)such that (9.19)This is in general impossible (see p. 254 in Amari 1985). However, when  is a scalar parameter, it is always possible.


9.2 Neyman-Scott Problem and Semiparametrics
Neyman and Scott (1948) presented a class of statistical problems and questioned the validity of the MLE, by showing that the asymptotic consistency and efficiency of the MLE are not guaranteed in some of their models. Let  be a statistical model and let  be N independent observations. The value of  (the parameter of interest) is kept the same (unknown) throughout the observations, but  changes each time. Hence,  is subject to . This is the Neyman-Scott problem and there are many examples of this type.
The estimation of the radius of the stone circle, Stonehenge in England, is a well-known romantic problem of this type. The stones are supposed to have been arranged in a circle to start with, but their positions have been disturbed in their long history. See Fig. 9.2. The radius u of the stone circle is the parameter of interest, and the declination angle of the ith stones  is the nuisance parameter. We show later another problem of estimating the shape parameter from neural spikes under changing firing rates. Independent component analysis, treated in Chap. 13, is also of this type. There are similar problems in computer vision (Kanatani 1998; Okatani and Deguchi 2009).Fig. 9.2Location of the ith stone

We use the problem of the coefficient of proportionality as a working example. It consists of N independent observations , subject to (9.20)where  and  are independent noises subject to Gaussian distributions with mean 0 and common variance . We assume that  is known. The joint probability distribution of  is (9.21)Here, u and , are scalar parameters.
Figure 9.3a shows an example of observed data and the problem is to draw a regression line to fit the data. The problem looks very simple, but is not. We show a number of intuitive solutions to this problem.Fig. 9.3Coefficient of proportionality: a Observed data; b least squares; c total least squares


1. Least squares solution

The least squares solution is the minimizer of (9.22)which is the sum of the squares of vertical errors to the regression line (Fig. 9.3b). The solution is (9.23)However, this is a bad solution. It is not consistent even asymptotically and it does not converge to the correct u even when N increases to become infinitely large.

2. Averaging method

Let  be the ratio obtained from one specimen. Their average (9.24)gives a consistent estimator. This is better than the least squares solution but is not so good in general.

3. Gross average method

Let us sum up all  and all  separately. Then calculate their ratio, (9.25)This is a good consistent estimator. It is of interest to know how good it is.

4. Total least square solution

Instead of minimizing the vertical errors in the least squares solution, we minimize the square of the lengths of orthogonal projection to the regression line (Fig. 9.3c). This is called the
         total least squares (TLS) solution. It is given by solving (9.26)
5. MLE

We estimate all the parameters , jointly by maximizing the likelihood, and we disregard all , keeping  only. This is the MLE. We can prove that this is identical with the TLS solution.
We use a semiparametric formulation of the Neyman-Scott problem. Since the sequence  is arbitrary and unknown, we assume that it is generated from an unknown probability distribution . In order to generate the ith example  ( in the above example), Nature chooses  from distribution . Then,  is chosen from . Thus, each  is subject to one and the same probability distribution (9.27)We treat an extended statistical model (9.28)which includes two parameters: One is , the parameter of interest, and the other is a function . Each observation is independently and identically distributed (iid) in this setting, but the underlying model includes the nuisance parameter k of function degrees of freedom. Such a model is called a semiparametric statistical model (Begun et al. 1983). We study the problem under this formulation.


9.3 Estimating Function
An estimating function is a generalization of the score function which is the derivative of the  likelihood and is used to obtain the ML estimator. It is particularly convenient for a model having a nuisance parameter. For a statistical model , we consider a differentiable function  which does not depend on . Here, we treat the case where  and  are scalar parameters for simplicity, but it is easy to generalize it to the case with vector  and vector .
A function  is called an
         estimating function, or more precisely an unbiased estimating function, when (9.29)
 (9.30)hold for any v, where  is the expectation with respect to . See Godambe (1991). We further assume (9.31)where  is the derivative with respect to u. An estimating function of M satisfies (9.32)for an arbitrary function k(v), when a statistical model M is extended to a semiparametric model  in (9.28). This is because  is a linear mixture of  with mixing distribution k(v).
The law of large numbers guarantees that the arithmetic mean of  over the observed data converges to its expectation. Hence, because of (9.29), the solution of (9.33)will give a good estimator; (9.33) is called an estimating equation. In the case of a statistical model without a nuisance parameter, the score function (9.34)satisfies (9.29), so it is an estimating function. In this case, (9.33) is the likelihood equation and the derived estimator is the MLE.
We analyze the asymptotic behavior of the estimator derived from an estimating function.


Theorem 9.1

The estimator  derived from an estimating function  is asymptotically unbiased and its error covariance is given asymptotically by (9.35)when  is the true parameter.



Proof

The proof is given by a similar method as the asymptotic analysis of MLE. We expand the left-hand side of (9.33) at , (9.36)The first term in the right-hand side converges, due to the central limit theorem, to a Gaussian random variable  with mean 0 and variance (9.37)The last term of (9.36) converges, due to the law of large numbers, to , where (9.38)Hence, we have (9.39)from which we have (9.35). 


An estimating function gives an unbiased estimator of which the error covariance converges to 0 in the order of 1 / N. However, there is no guarantee that an estimating function really exists. When does it exist? If there are many estimating functions, how should we choose a good one? These are questions we should address. We use information geometry in answering these questions.
Although we explain the scalar parameter case, our method holds in the vector case. When the parameter  of interest is vector-valued, an estimating function  is vector-valued, having the same dimensions as . An  is an (unbiased) estimating function when it satisfies (9.40)and also the matrix (9.41)is non-degenerate. The estimating equation is a vector equation (9.42)The resulting estimator is asymptotically unbiased and Gaussian, having the asymptotic error covariance matrix (9.43)



9.4 Information Geometry of Estimating Function
The statistical model  is parameterized by u and k(v), the latter of which has function-degrees of freedom. So we are obliged to use intuitive treatment, not mathematically rigorously justified, but the results are useful. In the function space , let us consider a submanifold  obtained by fixing the mixing function k(v). It is one-dimensional, that is, it is a curve, having a scalar parameter u. It is denoted by (9.44)We then consider an infinite-dimensional submanifold (9.45)where u is fixed but the mixing k(v) is free. One may consider that, for each u, an infinite-dimensional  is attached as a fiber. See Fig. 9.4.Fig. 9.4Two submanifolds  and  and their tangent vectors

The tangent space at a point (u, k) of  is spanned by infinitesimally small deviations  of probability density . By using the logarithmic expression, , we have (9.46)where (9.47)
 being the expectation with respect to . This shows that the tangent space  at  is composed of random variables  satisfying (9.48)We assume (9.49)and the inner product of two tangent vectors  and  are defined by (9.50)So the tangent space  is a Hilbert space. An estimating function  satisfies (9.48) at any (u, k), so it is a vector belonging to  for any k.
The tangent vector along the u-coordinate axis (9.51)satisfies (9.48). The one-dimensional subspace (9.52)composed of the u-score vector  is called the
         tangent subspace of interest at (u, k). In order to define tangent vectors along the nuisance parameter k(v), we consider a curve in the function space of k(v), written as (9.53)where (9.54)because (9.55)There are infinitely many curves, each specified by b(v). The tangent vector along a curve (9.53) is defined by (9.56)Let us denote by  the space spanned by the tangent vectors of all such curves, called the
         nuisance tangent subspace at (u, k).
Note that there are tangent vectors not belonging to  and , which are not included in the directions of change in u or k. We denote the subspace orthogonal to both of  and  by , which we call an
         ancillary tangent subspace (Fig. 9.5). Then, the tangent space is decomposed as (9.57)at each point (u, k), where  implies the direct sum.  is orthogonal to , but  and  are not orthogonal in general.Fig. 9.5Decomposition of tangent space 


We define e-parallel transport and m-parallel transport of a tangent vector  along the nuisance submanifold . We consider a small change of  in the direction , (9.58)where  is small. Since the e-representation of  is , it is natural to consider that  is e-parallelly transported from k to  without any change. But when , it does not belong to , because (9.59)in general. We subtract the average and define the e
        -parallel transport of  from  to  by (9.60)where  is the operator of the e-parallel transport from k(v) to  in . Obviously, (9.61)We next define the m-parallel transport. Since the m-representation of a deviation of  is , it is natural to consider that  does not change when it is transported in parallel from k to . However, its e-representation is (9.62)so its e-representation changes at  as . In order to compensate for this change, we define the
         m-parallel transport of  from k to  by (9.63)where  is the m-parallel transport operator from k to . It satisfies (9.64)The two parallel transports are dual, as is shown in the following theorem.


Theorem 9.2

The e- and m-parallel transports are dual, keeping the inner product invariant: (9.65)


The proof is easy from the definitions (9.60) and (9.64).


Lemma

The nuisance tangent space  is invariant under the m-parallel transport from k to , where u is fixed.



Proof

Since any tangent vector at k is written in the form of (9.56) by using b(v), it is m-parallelly transported to  and is written in the same form by using the same b(v), where k is replaced by . 


We can now characterize the estimating function in geometrical terms.


Theorem 9.3

An estimating function is a tangent vector orthogonal to the nuisance tangent space and is invariant under the e-parallel transportation along . It includes a non-zero component in the tangent direction  of the parameter of interest.



Proof

Because of (9.32), (9.66)holds so that it is invariant under the e-parallel transport along the nuisance direction. Let us take a curve k(v, t) and differentiate (9.32) with respect to t. Then we have (9.67)Since the nuisance tangent space  is spanned by , f is orthogonal to all the nuisance tangent vectors. We next differentiate (9.32) with respect to u. We then have (9.68)Since (9.69)
f should include a component in the direction  of interest. 


Consider the projection of the score vector  to the subspace orthogonal to the tangent space  of nuisance parameter and denote it by . We call it the efficient score in . Although it depends on k(v), it is an estimating function for any k(v) when it is fixed.
We construct the tangent nuisance space  in terms of the nuisance score (9.70)of M. The tangent nuisance space  of  is spanned by the tangent vectors in the directions of b(v) along the curve given by (9.53). Let (9.71)be the derivative of the delta function. Since b(v) satisfies (9.54), any b(v) is written as a weighted integration of , (9.72)where the weight is (9.73)Hence, the tangent vector in the direction of  is written from (9.56) as (9.74)by using the nuisance score  of M. Thus,  at k is spanned by the m-parallel transports of the elementary tangent scores  for all w and (9.75)The following theorem is immediate.


Theorem 9.4

The nuisance tangent space is m-parallelly invariant, (9.76)and spanned by the m-parallel transports of elementary nuisance scores  for all w.

Let  be an estimating function. It is e-parallelly invariant and orthogonal to . Therefore, because (9.77)it is orthogonal to the elementary nuisance v-score  of M for any . In order to obtain the efficient scores in , we consider the tangent vector in the direction of u at a specific point , where we put . Then, it is the same as the u-score in M, (9.78)We construct an efficient score from it, by making it orthogonal to . Since  is spanned by all the elementary nuisance scores, we need to project  to the space orthogonal to all the m-transports of  from  to  for all . The projected score is e-invariant, so it is an estimating function. The efficient score  at k is constructed by a linear combination with respect to k(v) of these elementary efficient scores.
We have the following theorem from this.


Theorem 9.5

An estimating function exists when, and only when, the efficient score is non-zero. Any estimating function is written, using an arbitrary nuisance function , in the form (9.79)where an ancillary tangent vector  depends on .



Proof

It is easy to see that  is orthogonal to both  and . 




Theorem 9.6

Let  be the true probability distribution. Then, the best estimating function is  and the asymptotic error covariance is (9.80)


The theorem gives a bound on the asymptotic covariance of error. However, since the true  is unknown, we cannot use it. But  works well even for an approximate value  of . Even when  is quite different from the true one,  still gives a consistent estimator.


Remark

A statistical model in the Neyman-Scott problem is linear in k(v), because it is a mixture model. The nuisance tangent space is invariant under the m-parallel transport in such a linear model. However, if we study a general semiparametric model where the probability density is not linear with respect to the nuisance function, the tangent nuisance spaces are not invariant by the m-parallel transport. An estimation function is therefore required to be orthogonal to all the tangent nuisance scores at all k. Hence, it is the projection of the u-score vector to the subspace orthogonal to m-transports of the nuisance subspace at all . This is called the information score at k. See Amari and Kawanabe (1997).



9.5 Solutions to Neyman-Scott Problems

9.5.1 Estimating Function in the Exponential Case
We consider a typical case where  is of the exponential type with respect to v, that is, (9.81)where  and  are functions of  and u.


Lemma

The u-score at k is given by (9.82)where  is the conditional expectation conditioned on s.



Proof

We calculate the u-score by differentiating the logarithm of (9.27) with respect to u. By taking (9.81) into account, (9.83)where  and  are derivatives of s, r and  with respect to u. Since v is a random variable subject to k(v), we consider the joint probability of v and . Then, we have the conditional distribution of v conditioned on , (9.84)Hence, we have from (9.83) (9.85)



The tangent direction corresponding to a change of k by  is written as (9.86)Hence, by putting  and using (9.74), the tangent nuisance space is spanned by (9.87)for all w, which corresponds to a change of k(v) at w. The score corresponding to a change  in the nuisance function k(v) is similarly written in the form of conditional expectation by using (9.84), (9.88)This is a function of . Hence, the nuisance subspace is generated by  and is written as (9.89)by using an arbitrary function h of s. We finally have the following theorem.


Theorem 9.7

The efficient score at k is given by (9.90)




Proof

The efficient score is the projection of the score of interest to the subspace orthogonal to the nuisance tangent space. Since, for two random variables s and t,  is the projection of t to the subspace orthogonal to the space generated by s, we have the theorem. 




Corollary

When the derivative of s with respect to u is a function of s, we have (9.91)




Proof

In this case, (9.92)which gives (9.91). Since (9.91) does not depend on k, this gives the asymptotically optimal estimating function. 




9.5.2 Coefficient of Linear Dependence
After a long journey, we can now solve specific Neyman-Scott problems. The first is the problem of linear dependence. The problem stated in (9.20) is of the exponential type, so it is written in the form of (9.81), where (9.93)
 (9.94)Since r does not depend on u, the efficient score is given as (9.95)We put (9.96)Then, we have a class of estimating functions written as (9.97)where h is an arbitrary function.
When the true nuisance function is k, the best h(s) is given by (9.98)which depends on the unknown k. The point is that, even when we do not know k, an estimating function in the class (9.97) gives a consistent estimator of which the error covariance decreases in proportion to 1 / N.
The TLS estimator is obtained by putting (9.99)The gross average estimator is obtained from (9.100)where c is a constant. Let us consider a simple linear function (9.101)which will give a better estimator than the two above by choosing c adequately. The estimating equation is (9.102)Let  be the solution of (9.102). Then we have (9.103)where (9.104)Therefore, the error is minimized by choosing (9.105)This shows that, when the distribution of k(v) is wide-spread, the TLS is a good estimator, whereas, when the distribution of k(v) is tight, the gross average estimator is better.


9.5.3 Scale Problem
There are two versions in the scale problem. One is to estimate the accuracy of a scale by using N specimens. The other is to estimate the weight of a specimen by using N scales of different accuracies.

1. Accuracy of a scale: We prepare N specimens of which weights  are different and unknown. Our aim is to estimate the error variance  of a scale. When the weight is v and error variance is , the measurement x is a random variable subject to . We repeat measurements m times for each specimen. Let  be m measurements by a specimen. The probability density of  is (9.106)which can be rewritten as (9.107)where we put (9.108)
 (9.109)
 (9.110)Since (9.111)is a function of s, the efficient score is (9.112)This is the orthogonal projection of  to the subspace orthogonal to . The estimating function is (9.113)which does not include k. Hence, this gives an efficient estimator, (9.114)
 (9.115)This is the best estimator different from the MLE. When the numbers  of measurements are different, we can solve the problem in a similar way.

2. Weight of a specimen by using  N  scales: We next consider the case in which we have N scales having different unknown error covariances. In this case, we have only one specimen, the weight of which we want to know. We measure its weight m times by using each scale. In this case, we put (9.116)so, for one scale, the probability density is (9.117)In this case, we have (9.118)
 (9.119)We can check that  is orthogonal to s, so the efficient score is (9.120)where h is an arbitrary function. If we fix h(s), then the estimator is (9.121)The optimum h depends on the unknown k(v), (9.122)but any h will give an asymptotically consistent estimator. It is a surprise that this simple problem has such a complicated structure.


9.5.4 Temporal Firing Pattern of Single Neuron
Let us consider a single neuron which fires stochastically. We assume that it fires at time , which are random variables. The intervals of spikes are (9.123)Obviously, when the firing rate is high, the interval is short. The simplest model of a
           temporal firing pattern is that all  are independent, subject to the exponential distribution (9.124)where v is the firing rate. The number of spikes is subject to the Poisson distribution. However,  are not independent in reality, because of the effect of refractoriness. It is known that the gamma distribution fits well, (9.125)which includes another parameter , called the
           shape parameter. We want to know , which is the parameter of interest, so we put , whereas v is the nuisance parameter. The average and variance of  are (9.126)The parameter  represents the irregularity of spike intervals. When  is large, the spikes are emitted regularly and have almost the same intervals. When  are independent, and when  is small, the irregularity increases.
Given observed data , it is easy to estimate the parameters  and v. This is a simple problem of estimation. However, in a real experimental situation, the firing rate v changes over time but the shape parameter  is fixed, depending on the type of the neuron. So we regard v as a nuisance parameter changing over time, while  is the parameter of interest. This is a typical Neyman-Scott problem.
We assume that v takes the same value for two consecutive times. (It can be m consecutive times for , but we consider the simplest case.) So we collect two observations  and , and put them in a box. Hence, the kth observation is . The two intervals ,  in a box are subject to the same distribution (9.127)where  may change arbitrarily in each box.
We calculate the u-score and v-score as (9.128)The efficient score is obtained in this case after calculations (see Miura et al. 2006) as (9.129)where (9.130)is the di-gamma function. Since this does not include v, it is the best estimating function, and the estimating equation is (9.131)The statistics used in the estimating function is summarized as (9.132)which includes all the information.
Shinomoto et al. (2003) proposed to use another statistic: (9.133)Interestingly, the two statistics are derived from the same two consecutive time intervals, (9.134)The statistic in (9.132) is the geometric mean, whereas Shinomoto's  is the arithmetic mean. From the point of the efficiency of estimation, S is theoretically the best but  may be more robust.


Remarks

The Neyman-Scott problem is an interesting estimation problem. It looks simple, but it is very difficult to obtain an optimal solution. Statisticians have struggled with this problem for many years, searching for the optimal solution. In 1984, when Sir David Cox visited Japan and talked about this problem as one of the interesting unsolved problems. I thought it a good challenge for information geometry. It would be wonderful if information geometry could provide a good answer to it.
It is related to a more general semiparametric problem. Since we need a function space of infinite dimensions, it is difficult to construct a mathematically rigorous theory. Bickel et al. (1994) established a rigorous theory of semiparametric estimation by using functional analysis. Information geometry could be more transparent in understanding the structure of the Neyman-Scott problem. We were successful in obtaining a complete set of the estimating functions.
The information-geometric theory is useful, even though the rigorous mathematical foundation is missing. It can solve many famous Neyman-Scott problems. When my official retirement time from the University of Tokyo was approaching, I thought that the results should be publicised even though they include mathematical flaw. So we submitted a paper to Bernoulli. The reviewers pointed out the lack of mathematical justification in the function space. However, the editor Ole Barndorff-Nielsen considered that this was an interesting and useful paper even without rigorous justification being given. So he decided that it was acceptable in the spirit of experimental mathematics, provided that the Theorem-Proof style of statements was replaced by the Proposition and Outline of Proof style.
We did not have many good examples at that time. But later, we found many examples, including neural spike analysis and independent component analysis, the latter of which will be shown in Chap. 13.














Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_10




10. Linear Systems and Time Series




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp






A time series is a sequence of random variables , which appears as a function of time. The present chapter deals with an ergodic time series which is generated by a linear system when white noise is applied to its input. We study the geometrical structure of the manifold of the time series. One may identify a time series with a linear system to generate it. Then, the geometry of the time series is identified with the geometry of linear systems, which is important for studying problems of control. For the sake of simplicity, we study only stable systems of discrete time, having one-input and one-output, but generalization is not difficult in principle. The set of all time series has infinite-dimensional degrees of freedom, so our treatment is intuitive and not mathematically rigorous, although it is well-founded
      
 the case of finite-dimensional systems and related time series.

10.1 Stationary Time Series and Linear System
Let us consider a time series , where t denotes discrete time, . White Gaussian noise  is one of the simplest, which is composed of independent Gaussian random variables with mean 0 and variance 1, so that (10.1)We assume that the mean of  is equal to 0. A time series is stationary when the probability of  is the same as its time-shifted version  for any . More strongly, we consider an ergodic time series.

Ergodic Theorem: For an
         ergodic time series , the temporal average of a function  of  converges to the ensemble average with probability 1, (10.2)We consider a discrete time linear system, which transforms an input time series into an output time series linearly (Fig. 10.1). When the input is white Gaussian , the output  is written as a linear combination of inputs, (10.3)A system is characterized by the sequence of parameters, (10.4)called the impulse responses of the system. It is assumed that (10.5)because (10.6)The output series is stationary when the input is.Fig. 10.1Linear system and generated time series

We introduce a time-shift operator z by (10.7)Then, (10.3) is written as (10.8)By defining (10.9)the output is written as (10.10)
H(z) is called the
         transfer function of the system when it is considered as a function of a complex number z, rather than the time shift operator. We assume that H(z) is analytic in the region .
We define the Fourier transform of an ergodic time series  in the wide sense by (10.11)Then,  is a complex-valued random function of frequency . Its absolute value (10.12)is called the
         power spectrum and is a deterministic function of , but the phase of  is random, uniformly distributed over . We assume (10.13)The power spectrum of  is written using the transfer function as (10.14)Conversely, given a time series  having power spectrum , we want to identify a system H(z). Such a system exists but is not unique. When  outside the unit circle of z (that is ), such a system is uniquely determined. It is a system of minimal phase. Under this condition, there is one-to-one correspondence among the set of ergodic time series, the set of power spectra  and the set of transfer functions H(z). They form an infinite-dimensional manifold L. We will show their coordinates later.


10.2 Typical Finite-Dimensional Manifolds of Time Series
We give typical examples of finite-dimensional systems or time series.


1. AR model


        An
         auto-regressive (AR) model is a time series generated from white noise  by (10.15)This is an AR model of degree p, denoted by AR(p), where  is a linear combination (weighted sum) of past p values  added to by a new Gaussian noise  called innovation. A system is specified by  parameters .
The transfer function is (10.16)and the power spectrum is (10.17)
2. MA model


        A
         moving-average (MA) model of degree q is a time series generated from white noise by (10.18)where  are the parameters. The present  is given by a weighted average of past q noise values. Its transfer function and power
         spectrum are (10.19)
 (10.20)respectively.

3. ARMA model

An ARMA model of degrees (p, q) is the concatenation of AR and MA models, given by (10.21)Its transfer function and power spectrum are, respectively, given by (10.22)
 (10.23)The above three are of frequent use in time series analysis. The transfer functions are rational functions of .
A continuous-time version of a linear system is used in control systems theory, where time t is continuous and the time-shift operator z is replaced by differential operator . The input-output relation of a system is described by (10.24)for input u(t). Information geometry gives a similar theory to it.


10.3 Dual Geometry of System Manifold
We introduce a Riemannian metric and dually flat affine connections to the manifold L of linear systems. Since L is infinite-dimensional, our theory is intuitive. The Fourier transform  of  gives complex-valued Gaussian random variables indexed by frequency . We can prove that  and  are independent when  so that we have (10.25)For complex random variable  of (10.11), the phase is uniformly distributed. Therefore, we may write its probability density as (10.26)This is an exponential family, where random variables are  and the natural parameter indexed by  is (10.27)This is e-flat coordinates and the expectation parameter is (10.28)which is m-flat coordinates. We rewrite the probability density in the form (10.29)Two dually coupled potential functions are (10.30)
 (10.31)and they satisfy (10.32)The Riemannian metric is calculated from (10.30) by differentiation, (10.33)so that we have (10.34)This is diagonal and hence the squared length of deviation  is written as (10.35)or in terms 
 (10.36)Hence the metric is Euclidean.

        The
         KL-divergence between two systems is written, using their power spectra, as (10.37)The Shannon entropy is given by (10.38)We expand the e-affine coordinates  in Fourier series as (10.39)and m-affine coordinates  as (10.40)where the basis functions are sinusoidal, (10.41)Since the resultant coefficients  and  are linear transformations of  and , respectively, we can use them as new - and -coordinates.
It is known that the coefficients  are expressed as (10.42)which are called the
         auto-correlation coefficients. Hence, the m-coordinates are the auto-correlation coefficients.
The inverse system of H(z) is , which is obtained by reversing the input and the output. Its power spectrum is . Hence,  are the auto-correlation coefficients of the inverse system. They are called the inverse auto-correlations. The inverse auto-correlations form e-flat coordinate systems.
It is noteworthy that  and  are orthogonal, (10.43)where  is the tangent vector of  coordinate axis and  is that of  axis. This implies that  are parameters which are orthogonal to the auto-correlation coefficients . Hence, they represent directions orthogonal to the auto-correlations up to k.
It is easy to introduce the -connection to L by using the cubic tensor (10.44)We can prove the following theorem.


Theorem 10.1


L is dually flat for any , having the Euclidean metric. The -divergence is given by (10.45)


To prove the theorem, we introduce the -representation of the power spectrum as (10.46)Then, its Fourier coefficients are proved to be the -flat coordinates. The theorem shows that L is like the manifold  of positive measure rather than the manifold  of probability distributions.
We have two dually coupled affine coordinate systems (10.47)
 (10.48)The AR model of degree p, AR(p), is characterized by (10.49)where . It is defined by the linear constraints (10.50)in the e-coordinates. Hence, it is an e-flat submanifold. Moreover, the families of all AR models of various degrees form a hierarchical system, (10.51)The white noise  belongs to AR(0), having the coordinates .
The MA model of degree q, MA(q), is characterized by (10.52)where . It is defined by (10.53)in the m-coordinate system. Hence, it is an m-flat submanifold and the MA models of various degrees form a hierarchical system (10.54)



10.4 Geometry of AR, MA and ARMA Models

AR model: An AR model of degree p, AR(p), is a finite-dimensional model determined by  in (10.15). By expanding the inverse of the its power spectrum , we have (10.55)The m-affine coordinates of AR(p) are the auto-correlation coefficients . However, the higher-order coefficients  are not 0, although they are not free but determined by . Given a system with power spectrum  having auto-correlations , we consider the system in AR(p) of which the auto-correlations are the same as  up to  and its higher-degree auto-correlations  are 0. It is called the p-th order stochastic realization of . We denote its power spectrum by . The set of systems having the same auto-correlations up to  form an m-flat submanifold, because they have the same values in the first p m-coordinates but the others are free. We denote it by . The  is the intersection of the m-flat submanifold  and the submanifold AR(p). The two submanifolds are orthogonal. Hence,  is given by the m-projection of  to AR(p). See Fig. 10.2.Fig. 10.2Stochastic realization of  up to p-th order auto-correlations

Let  be white noise given by (10.56)It belongs to AR(p) for any p. From the Pythagorean theorem, we have (10.57)The stochastic realization is characterized by maximization
         of entropy.


Theorem 10.2

(Maximum Entropy) The stochastic realization  is the one that maximizes entropy among all systems having the same .



Proof

From (10.38), we have (10.58)From relation (10.57), we see that  is the minimizer of  for all . However,  is related to the negative of entropy  by (10.59)Hence,  is the maximizer of entropy among all systems having the same . 



MA model: Similar discussions hold for MA(q) families. They are m-flat and MA(q) is defined by the constraint (10.60)We can define the dual stochastic realization of a system  in MA(q), that is the system in AR(q) of which the inverse auto-correlations  are the same as the given  up to q. It is interesting to see the following minimum
         entropy theorem.


Theorem 10.3

(Minimum Entropy) The dual stochastic realization  is the one that minimizes entropy among all systems having the same inverse auto-covariances .



Proof

We have (10.61)from the Pythagorean theorem. Now we see (10.62)Hence minimizing  is equivalent to minimizing entropy, proving the theorem. 


One may say that the Pythagorean relation or the projection theorem is more fundamental than the maximum entropy principle.

ARMA model: The ARMA model of degrees p, q is given by (10.21). This is a finite-dimensional subset of L. They form a doubly hierarchical system. However, they are neither e-flat nor m-flat. Moreover, the set is not a submanifold in the mathematical sense, because it includes singular points. We show this by a simple example. Consider ARMA(1, 1), which is described by (10.63)Its transfer function is (10.64)The parameter (a, b) plays the role of coordinates, where  should be satisfied because of the stability of the system. However, on the diagonal line , all the systems are equivalent, because the nominator and the denominator of (10.64) cancel one another out. Therefore, all the systems satisfying  are the same, simply given by .
We reduce the equivalent systems to one point. Then, as is shown in Fig. 10.3, the set AR(1, 1) consists of two subsets (submanifolds) connected by one singular point. This type of reduction happens in any ARMA(p, q) when the denominator and nominator of (10.22) include the same factor which cancels one another out. This fact is pointed out by Brockett (1976). We deal with such singularity later in Chap. 12 where multilayer perceptrons are discussed.Fig. 10.3Singularity of (1, 1) ARMA model



Remarks

Linear systems and time series have long histories of research, having highly organized structures in their fields. Therefore, we only touch upon them from the information geometry point of view, not explaining details. Since we have used Gaussian white noise as inputs, our study includes only systems of minimal phase. We need non-Gaussian white noise to overcome this difficulty. Finite-dimensional time series and systems are well-founded mathematically, but if we want to treat infinite-dimensional cases, we suffer from a lack of rigorous mathematical foundation. The difficulty is the same as in the case of a manifold of infinite-dimensional probability distributions. The present study will be a starting point for investigating information geometry of systems. See a trial by Ohara and Amari (1994).
There is a statistical problem of estimation from observations of a finite size sample  of time series. We can identify the model which generates the sample by using an adequate degree of AR, MA and ARMA or many other models. The sample is not iid, but we can construct a similar theory of estimation. A higher-order asymptotic theory has been constructed. See Amari and Nagaoka (2000) and Taniguchi (1991) for more details. An AR model is an e-flat manifold, provided we consider time series  of infinite length . However, it is a curved exponential family when  only are observed, because of the effect of initial and final 's. See Ravishanker et al. (1990) and Martin (2000) for applications and Choi and Mullhaupt (2015) for recent developments using KhÃ¤lerian geometry.
It is interesting to see that an ARMA model includes singularities. Brockett (1976) pointed out that the set of linear systems of which transfer functions are rational functions, nominators with degree p, and denominators with degree q, are split in a number of disjoint components. This is a topological structure of the set of linear systems. When cancellation occurs, the degrees of the nominator and denominator decrease. R. Brockett excluded such low-degree systems from the set. However, a lower degree system is a special case of a higher degree system. Therefore, if we consider rational systems having a nominator degree lower or equal to p and a denominator degree lower than or equal to q, the set splits into multiple components where they are connected by singular points of reduced degrees.
We have considered regular statistical models, which form a manifold. However, not a few important statistical models include this type of singularities. The behavior of an estimator when the true model lies at or close to singularities is interesting. See Fukumizu and Kuriki (2004). We study multilayer perceptrons in Chap. 12, considering how the singularity affects the dynamics of learning.
We did not study multi-input and multi-output systems. The manifold of linear systems having n inputs and m outputs is a Grassman manifold. This is another interesting subject of research from the geometrical point of view.
A Markov chain generates an infinite series of states (10.65)where  is a state from which  is determined stochastically by a state transition matrix . An AR model is regarded as a Markov chain. A Markov chain is an exponential family, so it is dually flat. We can construct a similar geometrical theory (Amari 2001). However, if we consider a finite range  of observations, a Markov chain , , is a curved exponential family because of the effects of initial and final values. Its e-curvature decreases in the order of 1 / T, converging to 0 as T tends to infinity. See Amari (2001), and Hayashi and Watanabe (2014) for information geometry of Markov chains. Takeuchi (2014) used the e-curvature to evaluate the asymptotic error of estimation, which is also related to the minimum regret of a Markov chain (Takeuchi et al. 2013).










Part IVApplications of Information Geometry










Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_11




11. Machine Learning




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp







11.1 Clustering Patterns
Patterns are categorized
         into a number of classes. Pattern recognition is the problem of identifying the
         class to which a given pattern belongs. When a divergence is defined in the manifold of patterns, classification is brought into effect by using the divergence. We begin with the problem of obtaining a representative of a cluster of patterns, called the center of the cluster. When patterns are categorized into clusters, pattern recognition determines the cluster to which a given pattern is supposed to belong, based on the closeness due to the divergence.
Another problem is to divide a non-labeled aggregate of patterns into a set of clusters. This is the problem of clustering. A generalized k-means method is presented by using a divergence. The entire pattern space is divided into regions based on representatives of clusters. Such a division is called a divergence-based Voronoi diagram. When patterns are generated randomly subject to a probability distribution depending on each class, we have a stochastic version of the above problems. Information geometry is useful for understanding these problems in terms of divergence.

11.1.1 Pattern Space and Divergence
Let us consider patterns represented by vector . They belong to a pattern manifold X. We study the case where a divergence  is defined between two patterns  and . In a Euclidean space, we have (11.1)which is a half of the square of the Euclidean distance. We consider a general dually flat manifold induced by a Bregman divergence. For the sake of notational convenience, we suppose that pattern  is represented in the dual affine coordinate system, so that it is represented by the -coordinates as (11.2)Then, we use the dual divergence between two patterns  and 
 (11.3)which is constructed from a dual convex function .
We will later use the primal affine coordinate system  given by the Legendre transformation (11.4)The primal convex function  is given by the Legendre relation (11.5)
 (11.6)
Fig. 11.1
-center of cluster C




11.1.2 Center of Cluster
Let C be a cluster consisting of k patterns . We search for the representative of C which should be as close to all the members of C as possible (Fig. 11.1). To obtain such a representative, we calculate the average of the dual divergences from the members of the cluster to a point , as (11.7)The minimizer of (11.7) is called the
          
          -center of cluster C due to the divergence . If we use the -coordinates, this is written as (11.8)where  is the -coordinates of . The following theorem is due to Banerjee et al. (2005).


Theorem 11.1

The -center of cluster C is given by (11.9)for any .



Proof

By differentiating (11.7) with respect to  and using (11.3), we have (11.10)where (11.11)is a positive-definite matrix. Hence, the minimizer is given by (11.9). 


We can generalize the situation that a probability distribution  of  is given instead of cluster C. Then the center of the distribution is defined by the minimizer of (11.12)The center is merely the expectation of  for any , (11.13)



11.1.3 
k-Means: Clustering Algorithm
Assume N points  are given, and we categorize them into m clusters such that a cluster includes mutually close points. Let  be clusters to be formed and let , be their centers. It is required that a point  belongs to cluster  when the divergence  is the smallest of . That is,  is the closest cluster center from , (11.14)Let (11.15)be the total sum of the divergences from each point  to the cluster center  it belongs to. The best clustering with respect to the -divergence is the one that minimizes (11.15). We can apply the well-known k-means algorithm, which is usually done by using the Euclidean distance. It is easy to extend it to the general case of a dually flat divergence, because the cluster center is given by the arithmetic mean in the dual coordinates. See Banerjee et al. (2005).

k-means method)
1.Initial Step: Choose m cluster centers  arbitrarily such that they are all different. 2.Classification Step: For each , calculate the -divergences to the m cluster centers. Assign  to cluster  that minimizes the -divergence,  (11.16) Thus, new clusters  are formed. 3.Renewal Step: Calculate the -centers of the renewed clusters, obtaining new cluster centers . 4.Termination Step: Repeat the above procedures until convergence. 

It is known that the procedures terminate within a finite number of steps, giving a good clustering result, although there is no guarantee that it is optimal. The k-means method was proposed for choosing good initial values of  by Arthur and Vassilvitshii (2007).


11.1.4 
 Diagram
Given a point , we need to find the cluster it belongs to. This is information retrieval or pattern classification to decide which category it belongs to. A subset  of X is called the region of  when it is decided that pattern  belongs to . The entire X is partitioned into m regions .
We consider a simple case consisting of two clusters  and  for an explanation. The entire X is divided into two regions  and . For , (11.17)Therefore, the two regions are separated by the hypersurface  that is the boundary of the regions, (11.18)



Theorem 11.2

The hypersurface separating two decision regions is the geodesic hyperplane orthogonal to the dual geodesic connecting the two -centers of the clusters at the midpoint of the dual geodesic.



Proof

Connect two -centers  and  by the dual geodesic (11.19)The midpoint  is defined by (11.20)Let  be the geodesic hypersurface (that is the linear subspace in the  coordinates) passing through  and orthogonal to the dual geodesic (Fig. 11.2). Then, due to the Pythagorean theorem, any point  on the hyperplane satisfies (11.21)Hence, we have (11.22)




Fig. 11.2Boundary of two cluster regions

The boundary surface is linear in the -coordinates but is nonlinear in the -coordinates. When the divergence is the square of the Euclidean distance, - and -coordinates are the same, so that the boundary is linear in the -coordinates. This is a special case.
When there are m clusters  is partitioned into m regions , where the boundary of  and  is the geodesic hypersurface satisfying (11.23)Such a partition is called the Voronoi diagram due to the -divergence (Fig. 11.3). See Nielsen and Nock (2014), Nock and Nielsen (2009), Boissonnat et al. (2010), etc. for details.Fig. 11.3Voronoi diagram



11.1.5 Stochastic Version of Classification and Clustering

11.1.5.1 Probability Distribution Associated with Category
Let us consider a cluster  of which -center is . We generate a probability distribution (11.24)It is centered at  and the probability density of  decreases exponentially as the divergence between  and  increases.
As we have shown in Sect. 2.â6, it is an exponential family (Banerjee et al. 2005).


Theorem 11.3

The cluster  of which the center is  defines a probability distribution of patterns , which is an exponential family, (11.25)with respect to the underlying measure (11.26)The natural parameter  of the distribution is the Legendre dual of .



11.1.5.2 
 Clustering Algorithm
We consider a mixture of probability distributions of exponential families, (11.27)where  are the prior probabilities that  is generated from category  and is the unknown parameters which we estimate from a number of observations . Here, the parameter vector is (11.28)The maximum likelihood estimator is given by (11.29)Before analyzing the MLE, we consider the conditional distribution of categories given , (11.30)For pattern , the above probabilities show the posterior probabilities of the categories. This is a stochastic classification or soft classification which assigns  to categories according to the posterior probabilities. When we pick up the category that maximizes the probability, it attains hard classification.
Since the distribution (11.29) is a mixture of exponential families, we can use the EM algorithm for estimating . The M-step is usually computationally heavy, but in the present case, it is simple because of (11.13).

Soft Clustering Algorithm (soft k-means)
1.Initial Step: Choose prior probabilities  and different cluster centers , arbitrarily. 2.Classification Step: For each , calculate the conditional probabilities  by using the current  and . 3.Renewal Step: By using the conditional probabilities, the new prior  of class  is calculated as  (11.31) Calculate the new cluster center by  (11.32)
 4.Termination: Repeat the above procedures until convergence. 

The Voronoi diagram is defined in a similar way. When we use hard classification based on the posteriori probabilities, the boundary surface of two categories  and  is given by (11.33)



Theorem 11.4

The boundary of two decision regions is the geodesic hypersurface that is orthogonal to the dual geodesic connecting two cluster centers and passes through it at the point satisfying (11.34)





11.1.6 
 Cluster Center
When a cluster C composed of  is given, we can calculate the -center of cluster by (11.9). Assume that a new point  is added to C that might be far from the others. By adding this point, the cluster center might deviate largely. If this new point is an outlier, for example given by mistake, it is not desirable that the cluster center is affected heavily by this point. A robust clustering reduces the undesirable influence due to outliers.
More formally, we define the influence function of an outlier . Let  be the center of cluster C, and let  be the center of  in which  is newly added. We assume that k is large so that the influence of each  is only of the order 1 / k. Let us denote the change of  to  by  and define  by (11.35)as a function of . It is called an influence function. When (11.36)holds for a constant c, i.e.,  is bounded, the cluster center is robust, because even if an infinitely large  is merged in C, its effect is bounded and is very small when k is large. A robust center does not seriously
           suffer from contamination by outliers.

11.1.6.1 Total Bregman Divergence
The Bregman divergence  is measured by the height  at  from the tangent hypersurface of  drawn at . This is the vertical length of point  to the tangent hypersurface (Fig. 11.4a). One may consider the orthogonal projection of  to the tangent hypersurface (Fig. 11.4b). It defines another measure of divergence from  to . This idea, hinted at in the total least squares in regression, was proposed by Vemuri et al. (2011) and called the total Bregman divergence, denoted as tBD.Fig. 11.4
a Bregman divergence D; b total Bregman divergence tBD


The length of the orthogonal projection is easily calculated and given by (11.37)where (11.38)It is invariant under orthogonal transformations of -space. Since the scale of  is arbitrary, we introduce a free parameter c which changes  to  and define tBD by (11.39)This is a conformal transformation of Bregman divergence. The free parameter c controls the degree of conformal modification.


11.1.6.2 Total BD is Robust
The following is one of the remarkable characteristics of tBD, proved in Liu et al. (2012).


Theorem 11.5

The tBD -center of a cluster is robust.



Proof

When an outlier  is newly added to C of which the previous center is , the new center  under tBD is the minimizer of (11.40)The influence function  is defined by (11.35). Assuming k is large, we expand the new center in the Taylor series, obtaining (11.41)where (11.42)Since (11.43)is bounded for any large  is bounded, and hence the tBD -center is robust. 


Vemuri et al. (2011) used tBD to analyze MRI images, obtaining good results. Liu et al. (2012) applied the tBD to the problem of image retrieval, obtaining a state-of-the-art result. Conformal transformations of a Bregman divergence are further developed in Nock et al. (2015).



11.1.7 Asmptotic Evaluation of Error Probability in Pattern Recognition: Chernoff Information
We consider two probability distributions (11.44)in an exponential family. Here, we use -coordinates related to  and the KL-divergence  instead of the previous -coordinates related to  and the dual divergence . When N observations  are derived, all of which are supposed to be generated from either  or , we need to decide which is the true distribution. Let us divide the manifold in two regions  and  such that, when the observed point (11.45)belongs to , we decide that the true distribution is .
When N is large, the probability that  is generated from  is given, due to the large deviation theorem in Chap. 3, by (11.46)where  is the primal coordinates of . In order to minimize the probability of misclassification, the regions  should be determined as (11.47)That is, the boundary of  and  is the hypersurface satisfying (11.48)Let us consider the e-geodesic connecting  and , (11.49)or (11.50)in the -coordinates. Its midpoint is defined by  satisfying (11.51)Due to the Pythagorean theorem,  is the m-geodesic hyperplane orthogonal to the e-geodesic, passing through it at . (See Fig. 11.5.)Fig. 11.5Decision boundary  and separation midpoint 


The midpoint  is given by the minimizer of (11.52)
 (11.53)The asymptotic error bound is hence given by (11.54)The negative exponent of error, (11.55)is called the
           Chernoff information or
           Chernoff divergence (Chernoff 1952). This is related to the -divergence . We have (11.56)Hence, by letting  be the maximizer of , we have (11.57)



Remark

One may use a prior distribution  on two classes  and  in the Bayesian standpoint. However, the asymptotic error bound does not depend on it.




11.2 Geometry of Support Vector Machine

        The
         support vector machine (SVM) is one of the powerful learning machines for pattern recognition and regression (Cortes and Vapnik 1995; Vapnik 1998). It embeds pattern signals to a higher-dimensional space, even an infinite-dimensional Hilbert space, and uses a kernel function to calculate outputs. Although the Hilbert space is infinite-dimensional in general, the kernel trick makes it possible to work within a finite regime, avoiding difficulties of infinitely large degrees of freedom. We do not describe the details of the SVM, but focus only on its Riemannian structure. It is used for modifying a given kernel to improve the performance of the machine.

11.2.1 Linear Classifier
We begin with a
           linear machine for classifying patterns, which is a simple perceptron. Given input pattern , consider a linear function (11.58)having parameters . The machine classifies patterns into two classes  and , according to the signature of output function . That is, when (11.59)
 is classified into , and otherwise into .
Consider a set of training examples  which are divided into two classes  and . When , it is accompanied by teacher signal , and when , it is accompanied by . They are linearly separable when there exists  and b, for which (11.60)holds. When  is such a solution,  is also a solution for any . We eliminate this indefiniteness of scale by imposing the constraints (11.61)Since the Euclidean distance from point  to the separating hyperplane (11.62)is (11.63)the distance from  to the separating hyperplane is given by (11.64)The minimum of these distances is given by (11.65)and is attained by the points  that satisfy (11.66)We call these points  the support vectors of the training set D and the minimal distance the
           margin. There are in general a number of support vectors. See Fig. 11.6. A good machine has a large margin. So the problem of obtaining the optimal linear machine is to minimize (11.67)under the constraint (11.68)
Fig. 11.6Linear classifier and support vectors

Let us use Lagrange multipliers  for solving the problem. Then, the problem reduces to the unconstrained minimization of (11.69)By differentiating it with respect to  and b and making the derivatives equal to 0, we have (11.70)Substituting (11.70) in (11.69), the problem is reformulated in the dual form using the dual variables : (11.71)with respect to  under the constraint (11.72)Since the objective function (11.71) is a quadratic function of , there is a well-known algorithm to solve it. It should be remarked that  when  is not a
           support vector.
The optimized output function is written as (11.73)in terms of the solution . The function is given by using only the support vectors and the other non-support examples  are irrelevant.
The linear output function is useful even when patterns D are not linearly separable. We use slack variables in this case. It can also be used as a regression function, where the output y takes analog values. See textbooks about the support vector machine.


11.2.2 Embedding into High-Dimensional Space
Patterns are not linearly separable in many problems and a linear machine does not work well in many cases. In overcoming this difficulty, it has been known since the early nineteen-sixties that nonlinear embedding of patterns into a high-dimensional space helps. Let us consider a nonlinear transformation of  into a high-dimensional space   by (11.74)Then pattern  is represented in  as (11.75)where (11.76)The classification problem is formulated in  by using , where the linear classification function in  is written as (11.77)This was known as the
            
          -function method (see Aizerman et al. 1964). The nonlinear embedding improves the linear separability of patterns.
Consider a simple example in which patterns belonging to  are inside a circle and those belonging to  are outside the circle (see Fig. 11.7a). The patterns are not linearly separable in . However, if we use the following embedding to , (11.78)they become linearly separable, as is seen in Fig. 11.7b.Fig. 11.7
a Non-separable in ; b separable in 


It is expected that patterns become linearly separable when m is large. The multilayer perceptron of Rosenblatt (1961) uses random threshold logic functions in the hidden layer for this purpose. The linear separability is assured when m is sufficiently large. The universality of a three-layer perceptron guarantees that any function  can be approximated by a linear function after embedding, provided m is sufficiently large.
However, we need to find good embedding functions for good pattern separation. This is a difficult problem. Moreover, when m is large, in particular infinitely large, calculations of embedded  are computationally difficult. It is the kernel trick that resolves the difficulty.


11.2.3 Kernel Method
We consider the inner product of  and  after embedding, (11.79)This is a symmetric function of  and . Moreover, for any coefficients , positivity (11.80)is guaranteed for , provided  are linearly independent. One may consider that  is an infinite-dimensional positive-definite matrix in an infinite-dimensional space of , where  and  are regarded as indices for specifying the rows and columns of the matrix. That is,  plays the role of K(i, j), which is a matrix specified by row i and column j.
We consider the eigenvalue problem, (11.81)where  are eigenvalues and  are corresponding eigen-functions. Here, m can be infinite. We call 
             the
           kernel function operating on a function  as in the integral (11.81). By using the eigen-functions, the kernel function is expanded as (11.82)Comparing this with (11.79), we see that the embedding functions are the eigen-functions divided by the square roots of the eigenvalues, (11.83)The optimal output function (11.73) can be written using the kernel function as (11.84)because of (11.69). This is another expression of (11.77) in terms of the kernel function, where the embedding functions  are eliminated. Therefore, even when m is infinite, we do not need to calculate  and the kernel is sufficient to compose the optimal output function. This is called the kernel trick. See Scholkopf (1997) and Shawe-Taylor and Cristianini (2004).
We may start from a kernel function , without specifying embedding functions, provided  is positive-definite satisfying (11.80), called the Mercer condition.

          The
           Gaussian kernel (11.85)is used frequently, where  is a free parameter to be adjusted. Its eigen-functions are (11.86)so that the expansion of a function  in terms of the eigen-functions corresponds to the Fourier expansion.
Another kernel of frequent use is the
           polynomial kernel of order p defined by (11.87)The eigen-functions are polynomials of  up to certain degrees and m is finite. The kernel method can be used even when  are discrete symbols, by defining an adequate positive-definite kernel. Therefore, it is a powerful tool in symbol processing and bioinformatics.


11.2.4 Riemannian Metric Induced by Kernel
The kernel method is computationally tractable using a modern computer. However, a good choice of kernel depends on the problem to be solved and no good criteria exist except for trial-and-error. This section considers the geometry induced by a kernel and proposes a method to improve a given kernel (Amari and Wu 1999; Wu and Amari 2002; Williams et al. 2005).
The original space  of patterns is embedded in , possibly in , as a curved n-dimensional submanifold. A Riemannian metric is induced in  by this embedding. Two nearby points  and  are embedded to  and , respectively, and the square of their Euclidean distance in  is (11.88)Therefore, the induced Riemannian metric is given by (11.89)which is expressed in terms of the kernel as (11.90)The volume element at point  is given by (11.91)which shows how the volume is enlarged or contracted at around . Since only the support vectors play a role in the output function, we consider expanding neighborhoods of the support vectors in , while other parts remain as they are.
To this end, we modify the current kernel  to (11.92)where  represents how the volume is enlarged at around . It should be large near the support vectors, so (11.93)was chosen in Amari and Wu (1999), Wu and Amari (2002), where  are the support vectors and  are adequate constants. Later, (11.94)was proposed as a more natural choice (Williams et al. 2005).
The transformation (11.92) is called the
           conformal transformation of a kernel. The Riemannian metric changes to (11.95)where (11.96)When (11.97)which is satisfied by the Gaussian kernel, we have a simplified expression (11.98)Computer simulations show that the performance of recognition is improved by up to ten percent by a conformal transformation. This might shed light on the problem of choosing a good kernel.
Recently, Lin and Jiang (2015) proposed another method of choosing  adaptively from data.



11.3 Stochastic Reasoning: Belief Propagation and CCCP Algorithms
A graphical model specifies stochastic interactions among a number of random variables. Stochastic reasoning is a procedure to estimate the values of unobserved random variables from those of observed variables based on its graphical structure. propagation (BP) (Pearl 1988) and
         convex-concave computational procedure (CCCP) (Yuille 2002) are methods in frequent use to obtain good estimates in artificial intelligence and machine learning.
The joint probability distributions of random variables in a graphical model form an exponential family. It has a dually flat Riemannian structure, so these algorithms are well understood from the point of view of dual geometry. The present section studies the BP and CCCP algorithms based on the dually flat structure, based on Ikeda et al. (2004a, b). The belief of each node about the value of its variable is propagated through e- and m-projections to obtain a harmonized consensus in BP. It is a merit of dual geometry that a new simplified version of CCCP is derived naturally.

11.3.1 Graphical Model
Let us consider a set of mutually interacting random variables . That is,  is a random variable of which the value is determined stochastically under the influence of other variables (11.99)A random variable  is called a parent of  when it is an element of . We study joint probability distributions of . The probability of  is given by the conditional probability distribution  conditioned on the values of its parents. We use a graph to represent the parent-child relation (Fig. 11.8). The graph is composed of n nodes corresponding to the random variables . There is a branch between nodes  and  when  is a parent of . The branches are oriented in this case, but we consider a non-oriented graph by disregarding the direction of a branch. This is called a
           graphical model of random variables. See Wainright and Jordan (2008) and Lauritzen (1996), for example.Fig. 11.8Graphical model

The joint probability distribution is written using the product of the conditional distributions as (11.100)A graphical model is also called a random Markov field. It is an extension of the Markov chain, representing the stochastic causality.
A subgraph composed of nodes  is called a
           clique when it is a complete graph. A graph is complete when any two nodes in it are connected by a branch. See Fig. 11.7, where  and  are examples of cliques, but  and  are not. Assume that a graphical model has L cliques . Then, it is known that the joint probability distribution (11.100) is decomposed as (11.101)where c is a normalization constant, , is a function of  and , is a function of the variables in clique . The decomposition is not unique in general, but is unique when we use only maximal cliques. A clique is maximal when it is not included in any complete subgraphs.
Divide the nodes of a graphical model into two parts,  and . Assume that values of the variables in  are observed but those in  are not. Stochastic reasoning is the problem of estimating the values of unobserved variables in , under the condition that the variables in  are observed. We use the conditional probability of  conditioned on  to estimate the unknown values of .
Let us fix the values of  and consider the conditional distribution of , (11.102)where  is omitted in the notation of . It is again represented by a graphical model consisting of nodes of . So the problem is the estimation of the values of  in the reduced graphical model, where the values of  are fixed and omitted from the notation. We hereafter denote  simply as X and use the vector notation (11.103)We consider the simple binary case where each  takes binary values 1 and . The maximum likelihood estimate  based on  is the maximizer of . However, this is computationally heavy when n is large, because there are  's and we need to compare the values of  for all of them. We use the following simple estimate that the estimated value of  is 1 when the probability of  is larger than that of , and otherwise . In other words, let us calculate the expectation of , (11.104)and  when  is positive and , when  is negative. That is, the estimate is given by (11.105)This minimizes the sum of the error probabilities of all the variables.
The problem reduces to the calculation of the expected value of . However, this is again computationally heavy, because (11.106)includes  terms.
We need a computationally tractable algorithm of obtaining a good approximation of the mean values. This problem appears in physics, too, and the mean field approximation is well known to obtain such an approximate solution.


11.3.2 Mean Field Approximation and m-Projection
The probability distribution (11.101) of a graphical model can be written as (11.107)where  is the normalization constant, called free energy in physics, with (11.108)and (11.109)is the term due to clique .
We consider a new expanded exponential family (11.110)
 (11.111)which includes two e-affine parameters, namely  and . The original  is a member of this family and is given by (11.112)When , the distributions do not include interaction terms so that the submanifold specified by  is the family of independent distributions of . We denote it by (11.113)Figure 11.9 shows the expanded model  and the independent model . The expectation of  is easily calculated for a distribution in , because all  are independent. It is given by (11.114)
Fig. 11.9
m-projection and e-projection of  to 


Given , we consider the independent distribution  that has the same expected value of  as . The following theorem shows the relation between  and .


Theorem 11.6


            The m
            -projection of  to  keeps the expectation of  invariant.



Proof

Let us put (11.115)where  is the operator of m-projection to  and let the e-coordinates of  be . The m-coordinates are (11.116)The tangent vector of  at  is represented by (11.117)On the other hand, the tangent vector of the m-geodesic connecting q and  is given by (11.118)They are orthogonal because of the m-projection, so we have (11.119)This shows (11.120)proving the theorem. 


However, the m-projection of  is not computationally easy. Statistical physics uses the
           mean field approximation, which replaces the m-projection by the e-projection (Tanaka 2000, see Amari et al. 2001 for the -projection). The m-projection is given by the minimizer of the KL-divergence . The mean field approximation uses the dual KL-divergence KL[p : q] and minimizes it with respect to . The minimizer is given by the e-projection of q to . This is computationally tractable so it can be used as an approximate solution. See Fujiwara and Shuto (2010) for higher-order mean-field approximation.
We consider (11.121)as a specific example, which represents a spin system where the interaction of two spins  and  are given by . The cliques consist of branches . It does not include interactions of more than two nodes and is known as the Boltzmann machine in neural networks, where  represents the strength of the synaptic weights of connection between two neurons  and .
The KL-divergence from  to q is given by (11.122)It is easy to see (11.123)because  and  are independent under p and hence, we have (11.124)By differentiating it with respect to  and making the derivatives equal to 0, we obtain (11.125)where (11.126)is taken into account. This is the equation to obtain the minimizer  of (11.122).
This is a well-known equation. The solution  is different from the m-projection so that it is an approximation.  is e-flat but not m-flat. Therefore, the m-projection is unique but the e-projection is not necessarily unique. Hence, the solution of (11.125) is not necessarily unique. Moreover, the solution can be a maximum or a saddle point of KL[p : q].


11.3.3 Belief Propagation
Belief propagation is an algorithm, proposed by Pearl (1988), to obtain an approximate value of the expectation of  efficiently. This is a cooperative procedure, where each node exchanges its belief about the expected value through branches. The belief is renewed by taking the beliefs of the other nodes into account. The procedure terminates when a consensus is reached. The information geometry of BP was formulated by Ikeda et al. (2004a, b). We here present a simplified version of it.
Corresponding to each clique , we construct a submodel  of , (11.127)It includes only one nonlinear term  corresponding to clique . The sum of all the other interactions,  of , , is replaced by a linear term . It is an exponential family, having e-parameter . This is a submanifold of  obtained by putting (11.128)In addition to the independent submodel , there are L such submodels . Since  includes only one nonlinear term, it is computationally easy to m-project a member of  to .
To avoid complications, we use notational simplification. Since all the probability distributions have the term  in common, we neglect it in the following. This term should be added to the final solution. Mathematically, this corresponds to defining probability densities with respect to the common measure . By this simplification, our target distribution (11.107) is (11.129)and submodels are (11.130)
 (11.131)All the submodels are e-flat in .
Each submodel tries to approximate  such that the expectation of  becomes close to . Since  includes only one nonlinear term, all the other interaction terms are replaced by the linear term . They exchange their results concerning the expectation, and eventually reach a consensus satisfying (11.132)where  is the expectation with respect to . If the consensus is equal to the expectation of  with respect to , it is the true solution. But this does not occur in general. However, it would give a good approximation.
We consider the following procedure for reaching the consensus:

1. Initial step: Assign arbitrary initial values  to submodels . They can be 0. Continue the following steps  until convergence.

2. -projection step: m-project  at time t of  to . Denote the resultant distribution in  by , (11.133)
3. Calculation of belief of : Calculate (11.134)Since the m-projection of  to  is , it includes not only  but also the linearization of the . Hence,  in (11.134) corresponds to the linearization of the single nonlinear term . It represents the linearized version of  in . It is regarded as the belief of  that its nonlinear term  is effectively given by  in .

4. Renewal of the candidate in  at : Add all the beliefs  of  of  to give a distribution of  at , (11.135)
5. Renewal of  at : Construct a new candidate  of , where the nonlinear terms  other than  are replaced by the sum of the beliefs  of , but  is used as it is. Therefore, (11.136)When the procedure converges, the converged  and  satisfy (11.137)so all the models reach a consensus, having the same expectation of .


11.3.4 Solution of BP Algorithm
We study the solution to which the BP algorithm converges from the geometrical point of view. It should be remarked that there is no guarantee of convergence for the BP algorithm. Note that the CCCP algorithm in the next section always converges.


Theorem 11.7

When the BP algorithm converges
            , the following two conditions are satisfied:

 -condition: ,


-condition
              : 
            .



Proof

The m-condition is the consequence of consensus (11.137). The e-condition is derived by using (11.134) and (11.135). 



Fig. 11.10
m-condition

We remark that the e-condition is always satisfied for  and  after step 5 of the procedure, but the m-condition is not. The procedure terminates when the m-condition is satisfied. The implications of the two conditions are as follows. See Figs. 11.10 and 11.11. Let  be the m-flat submanifold connecting all of  and , (11.138)Let  be the e-flat submanifold connecting all of them, (11.139)
Fig. 11.11
e-condition



Corollary

The m- and e-conditions are equivalent to the following two, respectively:

-condition:  is orthogonal to .

-condition:  includes the true distribution .

If  includes , its m-projection to  is . The solution is exact in such a case. The following theorem is known.


Theorem 11.8

When the underlying graph is acyclic, that is, it does not include cycles,  includes  and the solution gives the exact answer.

The BP algorithm is stated in geometrical terms in the above explanation. It is beneficial to show the relation between the geometrical algorithm and the conventional BP algorithm written in textbooks. The two are essentially the same. We show only the case where interactions exist between pairs of nodes and no higher-order interactions exist. The conventional algorithm calculates the belief  at node  and message , which is transmitted from node  to node  through branch (i, k). The belief is constructed from the messages by (11.140)where Z is the normalization constant and N(i) is the set of nodes which are connected with node . The messages at  are updated by (11.141)The correspondence of the quantities appearing in the two approaches are given by (11.142)
 (11.143)where r is the branch (clique) connecting i and j.


11.3.5 CCCP (Convex-Concave Computational Procedure)
A new algorithm called CCCP was proposed by Yuille (2002), see also Yuille and Rangarajan (2003). We show a new version of it based on information geometry, which is much simpler than the original one, because the new one does not include double loops in the procedure.
The BP algorithm chooses a set  at each step that satisfies the e-condition and m-projects this set to . It modifies the results toward the satisfaction of the m-condition in the renewal steps. Contrary to this, we may choose  at each step that satisfies the m-condition. Then, we modify them in the renewal steps toward satisfying the e-condition.
This gives a new algorithm (Ikeda et al. 2004a):

1. Initial step: Assign an initial value . It can be . Do the following iterations until convergence, for 


2. -condition step: Inversely m-project  to , that is, to find  such that (11.144)Then,  satisfies the m-condition.

3. Renew the  by (11.145)The e-condition is satisfied when the algorithm converges.
The original form proposed by Yuille (2002) is based on a different idea. In analogy with physics, the BP algorithm is proved to search for the critical point of a function  called free energy where  is the state variables, which in our case is  (Yedidia et al. 2001). This function is not convex, so there is no guarantee that the gradient descent method converges. Yuille (2002) proved that a function  of  is always decomposed into a sum of a convex function and a concave function, (11.146)The decomposition is not unique. The CCCP is an iterative algorithm for obtaining the critical point of F by (11.147)It always converges, whereas BP does not necessarily do so. When it converges, the convergent point satisfies both the m-condition and e-condition.
The original CCCP algorithm by Yuille is written in our geometrical terminology as follows:1.Calculate  from  (11.148) where  is given by solving 2.
 (11.149)
 

When comparing these with (11.144) and (11.145),  is used in (11.148) instead of  in (11.145). Hence, we need to solve the nonlinear equations to obtain  and  in one step. After that, we proceed to the next iteration step increasing t by 1. So it includes double loops and is computationally expensive. Our geometrical algorithm is simpler, and does not include the double loops. The approximation errors due to BP or CCCP are analyzed in Ikeda et al. (2004a) by using the curvature.



11.4 Information Geometry of Boosting
A single learning machine might not be powerful. There is an idea due to M. Kearns and L. Valiant: A powerful machine might be constructed from a number of weak learning machines by integration. This idea was realized by Freund and Schapire (1997) and Schapire et al. (1998) under the name of "boosting". It was shown by Lebanon and Lafferty (2001) that information geometry is useful for understanding the boosting algorithm. The idea was expanded further by Japanese researchers (including Murata et al. 2004; Takenouchi and Eguchi 2004; Kanamori et al. 2007; and Takenouchi et al. 2008).

11.4.1 
Boosting: Integration of Weak Machines
Consider a pattern classifier, which learns from training examples . Here  is an input pattern at time t and  is the correct answer corresponding to , which takes binary values 1 and . A classifier uses an analog-valued output function  and the output y is decided by the decision function  which is the signature of , (11.150)Assume that we have T weak machines of which the decision functions are (11.151)The performance of a weak machine may be very weak, although its error probability should be less than 0.5. By integrating them, we construct a machine of which the output function is (11.152)where  are parameters to be determined from the data. See Fig. 11.12. We begin with a weak machine and add new weak machines one by one. The weights  are also determined sequentially.Fig. 11.12Integration of weak machines

There are two problems to be solved. One is how to compose the next weak machine  at time t, and the other is how to determine the weight .


11.4.2 Stochastic Interpretation of Machine
Although a weak learning machine is deterministic, we introduce a stochastic interpretation to evaluate its performance. We consider it as if it were a stochastic machine such that the probability of emitting y is given by (11.153)where c is a normalization constant. Obviously, when  takes a large positive value, the probability of  is large and when it takes a negative value with a large magnitude, the probability of  is large. We rewrite (11.153) as (11.154)where  is the true output value to  and (11.155)Note that  does not depend on y. Since an error occurs when , the probability of error for  is (11.156)We define the loss caused by a machine for input 
 (11.157)by neglecting the constant . We normalize the losses for all the data as (11.158)where (11.159)Then,  is a distribution of losses over the training examples such that their sum is normalized to 1.
Let  be the set of indices i such that  are erroneously answered by machine . The performance of the machine is evaluated by the error probability (11.160)



11.4.3 Construction of New Weak Machines
The weak machines are constructed one by one. Assume that we have constructed t weak machines  and integrated them into the current machine (11.161)The performance of a machine is evaluated by the error distribution given by (11.162)It is reasonable to add a new machine of which the performance is good for those examples that are bad in the current machine.
To this end, we set up a new machine and train it using the training examples D, but patterns  are applied not equally, but with frequency . This implies that the new training examples are generated from D by resampling such that those which are difficult for the current machine appear frequently. Any type of machine can be used as a new weak machine to be trained, a simple or multilayer perceptron, a support vector machine, a decision tree, and others.


11.4.4 Determination of the Weights of Weak Machines
We add a newly trained weak machine  to the previous weak machines, forming a new machine (11.163)Here,  is the parameter to be decided. The conditional probability of y by the new machine is (11.164)This forms a one-dimensional exponential family  where the e-coordinate is . Therefore, given the training data D, the best distribution to fit the training data is given by the m-projection of the empirical distribution of data to the exponential family . See Fig. 11.13.Fig. 11.13Determination of weight 


The coefficient c in (11.164) is a complicated function of  and D. We ignore this term, considering  as a family of unnormalized positive measures, (11.165)Then, the optimum solution is obtained by m-projecting (11.166)to , that is, by minimizing . From (11.167)where c is ignored, the KL-divergence is written as (11.168)where C is a term not depending on . Since  and the objective function to be minimized is (11.169)by differentiating it with respect to , we have (11.170)We introduce a new index set  such that  implies that pattern  is wrongly classified by the new machine , that is, (11.171)Let us put (11.172)Then, (11.170) reduces to (11.173)We obtain the solution (11.174)The weight of example  is renewed as (11.175)




11.5 Bayesian Inference and Deep Learning
Information geometry of Bayesian statistics has not yet been well developed except for preliminary studies (e.g., Zhu and Rohwer 1995). Bayesian theory regards data and parameters as random variables at the same time. Hence, information geometry is applied to their joint probability distributions. It is hoped to construct a deeper structure beyond superficial Bayesian information geometry, which would be useful for machine learning, in particular for deep learning. This section proposes a preliminary trial concerning information geometry of Bayesian statistics. We use the restricted Boltzmann machine (RBM) for this purpose, which is an important constituent in deep learning.

11.5.1 Bayesian Duality in Exponential Family
An exponential family of probability distributions is represented by (11.176)where  is a vector random variable,  is a vector parameter and  corresponds to the underlying measure of , (11.177)Bayesian statistics assumes that the parameter  is also a random variable subject to a  prior distribution . Then, the joint probability of  and  is (11.178)where (11.179)
          The
           Bayesian posterior distribution is the conditional distribution of  given  and is written as (11.180)where (11.181)
 (11.182)It is an exponential family, where the random variable is  and the natural parameter to specify a distribution is . Although the roles of  and  are different, the conditional distributions have the same exponential form shown in (11.176) and (11.180). We call it the
           Bayesian duality.
The e-affine parameter is  in the manifold of probability distributions (11.176) and hence, the dual m-affine parameter is (11.183)whereas, the e-affine parameter is  in the manifold of the posterior probability distributions (11.180) and hence the m-affine parameter is the conditional posterior expectation of , (11.184)We extend (11.178) to a family of joint probability distributions parameterized by a hyper parameter . Then,  forms a manifold consisting of exponential families. Its simple example is the case when a prior distribution  is given in a parametric form as . Here, the extra parameter  is called a hyper parameter. A family of prior distributions called
           conjugate priors is used sometimes, because of its simplicity. A conjugate prior  has the same form as the conditional distribution . In our exponential case, because of (11.180), the conjugate prior is written as (11.185)where  is the hyper parameter and  is a normalization factor. When we use N independent observations , the posterior distribution under prior  is explicitly given by (11.186)where (11.187)is the observed point. This makes the role of the conjugate prior clear: The conjugate prior has the effect of shifting the observed point from  to , that is, of adding  additional pseudo-observations of which the observed value is  to the previous . Alternatively, observed data D change the parameter of the conjugate prior as follows: (11.188)The geometry of the conjugate prior is studied by Agarwal and DaumÃ© III (2010).
We can enlarge our framework by considering a curved exponential family, where  is specified by a low-dimensional parameter  such that (11.189)The random variable  may be an embedded version of low-dimensional signals , (11.190)Then, probability distributions of  and  form a curved exponential family.
We may further consider an extended family of distributions such that a joint distribution (11.178) is specified by an additional parameter W as . We use this as a model of machine learning or the brain. Here,  or  is information given from the environment.  or  represents a higher-order concept which specifies the distribution of . An inference system guesses  from  such that  is generated from . See Fig. 11.14. This is a simple layered model of the brain, where  is given to an input layer and  is generated in the next layer by Bayesian inference. There may be feedback connections from the higher-order layer to the lower-order layer so that a dynamical process takes place between them. The RBM is its stochastic model.Fig. 11.14Bayesian inference of higher information  from 




11.5.2 Restricted Boltzmann Machine

          The
           Boltzmann machine was proposed by Ackley et al. (1985). It is a Markov chain over state , of which the stable distribution is given by (11.191)where  is a vector and  is a symmetric matrix.

          The
           restricted Boltzmann machine (RBM) is a layered machine consisting of two layers and there are no interactions among elements (we call them neurons) within each layer. Interactions (connections) exist only between neurons of different layers. This was proposed by Smolensky (1986) and has been extensively used in deep learning (Hinton and Salakhutdinov 2006 and others).
We divide  into two parts, , where  and  are binary vector random variables representing activities of neurons of the two layers in the RBM (Fig. 11.15). The first layer is called an input layer or visible layer, to which a signal  is applied from the environment. The second layer is called a hidden layer of which activity pattern  is generated from input  in the first layer.Fig. 11.15RBM (restricted Boltzmann machine)

The stable probability distribution of an RBM is written as (11.192)since there are no connections among the neurons in each layer. This is an exponential family of distributions. The stable probabilities of  and  are given by its marginal probability distributions, (11.193)
 (11.194)and they are not of the exponential type.
We compare the RBM with the Bayesian scheme in the previous section. When the number m of neurons in the hidden layer is smaller than the number n in the visible layer, we introduce new random variables by (11.195)
 (11.196)In the opposite case, we introduce (11.197)
 (11.198)In either case, the stationary probability distribution is written in the standard form (11.178) of Bayesian joint distribution. Therefore, we may consider an RBM as representing the Bayesian mechanism of statistical inference.


11.5.3 Unsupervised Learning of RBM
For an RBM having the stationary joint probability (11.192), we have the two conditional distributions (11.199)
 (11.200)They show the probabilities of activities of one layer given the activities of the other layer. Let  be a probability distribution of  given from the environment, subject to which input  is generated. An RBM is trained by receiving  such that its stationary marginal distribution  approximates . This is done by modifying  and  so that the KL-divergence  is minimized. The minimizing  are the maximum likelihood estimator. For the sake of notational simplicity, we hereafter neglect the bias terms  and  by making them equal to 0, but they can be treated in a similar manner. This is only for the purpose of avoiding unnecessary complication.Fig. 11.16
m-projection of  to 


Let  be a submanifold consisting of the marginal probability distributions of  of the RBM, (11.201)in the entire manifold  of probability distributions of . The minimizer  of the KL-divergence  is given by the m-projection of  to the submanifold  (Fig. 11.16). However, it is simpler to treat the manifold of joint distributions of  rather than the marginal distributions of . To this end, we consider a manifold  consisting of all joint probability distributions of  and . We study two submanifolds in it. One is the submanifold of the RBM, (11.202)parameterized by . The other is the data submanifold  given by (11.203)where  is fixed and  is an arbitrary conditional distribution of  conditioned on . The marginal distribution of any member of  is . Consider the KL-divergence between the two submanifolds, (11.204)



Theorem 11.9

The minimizers of the KL-divergence  between two submanifolds are given by  and , where  is the MLE of  for data  generated from .



Proof

We can decompose  as follows: (11.205)Therefore, the minimum of the  with respect to  is attained by  and the minimum with respect to  is attained by the minimizer of . 


Let  and  be the closest pair of . Then,  is given by the m-projection of  and  is the e-projection of . This is clear from the em (EM) algorithm in the presence of hidden variable , since the e-projection keeps the conditional probability  and the m-projection maximizes the  likelihood. See Fig. 11.17, where the minimization problem in  is mapped onto that in .Fig. 11.17Minimizer of 


We now give the learning algorithm established by Ackley et al. (1985). This is the stochastic descent method of .


Theorem 11.10

The averaged learning rule of RBM is given by (11.206)where  is a learning constant,  is the average of  subject to the joint probability distribution (11.207)and  is the average over the stationary distribution  of the RBM.



Proof

Since we have (11.208)we have (11.209)because (11.210)



This is the ordinary gradient descent method. The natural gradient method would work better, if we had its computational algorithm. Since the learning rule (11.206) includes only the expectation of the cross term of  and  with respect to  and , all the other higher-order interaction terms are irrelevant. Therefore, this suggests the use of a mixed coordinate system, which separates the second-order terms from higher-order terms of interactions (see Akaho and Takabatake 2008).


11.5.4 Geometry of Contrastive Divergence
The learning algorithm (11.206) is computationally heavy. This is because, in order to calculate the expectation of , we need a long run of MCMC procedures for obtaining samples from the stable distribution . The MCMC procedures work as follows:1.Begin with an arbitrary  and generate  by using the conditional distribution . 2.Generate  from the current  by using the conditional distribution . 3.Repeat the procedures, . 

We then have a sequence of  of which the empirical distribution converges to . These data can be used to calculate the average  in (11.206) or (11.209).

          The
           contrastive divergence is an approximation of the KL-divergence, proposed by Hinton (2002). This has been used frequently in deep learning. It runs a finite number, say k, of iterations of the above procedures. The order k contrastive divergence () uses a pair of , where  is derived from  as an initial value,  is derived from  and  is derived from . Repeating the procedures up to  from many initial 's, the derived empirical distribution of  is used to obtain an approximation of .
We study the probability distribution  of , which we call the  distribution, following Karakida et al. (2014). Let its marginal distributions be  and . They are (11.211)
 (11.212)Then, the  distributions are calculated recursively by (11.213)
 (11.214)In order to understand the  distributions, we consider two submanifolds  and  in . They are defined by (11.215)
 (11.216)where  and  are arbitrary distributions. They intersect at , because, when  and when , both the distributions are equal to . Moreover, both  and  are e-flat, because the e-geodesic connecting  and , (11.217)is included in , where we have omitted the normalization factor c(t). The same situation holds for . See Fig. 11.18.Fig. 11.18CDR distribution 


The initial distribution is given by putting  as (11.218)Then, the sequence of  distributions is given by the geometrical procedures in the following theorem, due to R. Karakida.


Theorem 11.11


 is the m-projection of  to  and  is the m-projection of  to .



Proof

Given , its m-projection to  is given by the minimizer of (11.219)with respect to , where c is a term not depending on . By adding the constraint (11.220)the variation of  gives (11.221)The other case is proved similarly. 


The theorem shows that  converges to  as j increases. Hence,  may be used as an approximation of  in calculations of .
The following is an interesting observation based on the Pythagorean theorem.


Theorem 11.12

The KL-divergence from  to  is decomposed as (11.222)




Proof

Since  is an orthogonal triangle in which the m-geodesic  is orthogonal to the e-geodesic , we can apply the Pythagorean theorem to decompose  (Fig. 11.17). Similar decomposition holds for . Hence, repeating the decomposition recursively, we have the theorem. 




11.5.5 Gaussian RBM
We may consider an analog RBM in which both  and  take analog values. A typical one is a
           Gaussian RBM in which both  and  are Gaussian random variables. The stationary distribution is written as (11.223)Here, the quadratic terms of  and  exist but they do not include cross terms such as , so that there are no mutual connections among the neurons in each layer.
The Gaussian RBM is simple and hence tractable, because all related distributions are described in the framework of Gaussian distributions. The conditional distributions are Gaussian given by (11.224)
 (11.225)and the marginal distribution is also Gaussian, (11.226)where c,  and  are adequate constants.
Karakida et al. (2014) analyzed the behavior of the Gaussian RBM when the distribution  of  given from the outside is mean 0 and its covariance matrix is . Since (11.227)
 (11.228)hold, the equation of learning (11.206) is written as (11.229)where we use continuous time. They also calculated the equation of learning for , obtaining (11.230)We can easily see that (11.230) converges to (11.229) as k tends to infinity.
We study the equilibrium solutions and their stability for the above equations. The following theorem shows that a Gaussian RBM performs a PCA-like analysis. To this end, let  be n eigenvalues of  (where we assume that they are all distinct) and let  be the orthogonal matrix that diagonalizes , (11.231)



Theorem 11.13

Assume that there are r eigenvalues which are larger than . Then, the equilibrium solutions of (11.229) and (11.230) are the same, given by (11.232)where  is an arbitrary  orthogonal matrix and (11.233)


The proof is technical and is omitted (see Karakida et al. 2014). The stability of solutions is also analyzed.
By choosing the coordinate axes of  adequately, we see that the marginal distribution of RBM is given: (11.234)This shows that the Gaussian RBM performs the PCA analysis, neglecting smaller eigenvalues. It is also shown that the  learning method has a sufficiently good performance compared to the original RBM learning method (maximum likelihood method).


Remarks

We have glanced at topics of machine learning from the information geometry point of view. Since stochastic uncertainty is involved in the real world, it is expected that information geometry will provide good ideas, useful suggestions and clear understanding of aspects of machine learning. Clustering techniques are the main tools of information retrieval, where divergence functions are used. They are connected with information geometry. We have demonstrated that robust clustering is achieved by tBD. This field is developing quickly. See Nock et al. (2015).
Support vector machines are useful tools in pattern recognition and regression. We have avoided following the main stream of the kernel method and instead touched upon how the performance of a kernel is improved by a conformal transformation. This might give a hint for a good choice of kernels.
Stochastic reasoning is an important procedure, where belief propagation (BP) plays a key role. We can reformulate the BP algorithm by using information geometry. This gives a more transparent understanding of the algorithm than the conventional one. Moreover, it provides an efficient algorithm of stochastic inference, which is a new version of the convex-concave computational procedure (CCCP). The boosting of weak learners is also outlined.
Deep learning is a hot topic, for which we still lack convincing theories. We have proposed a way to understand it from information geometry of Bayesian statistics. The restricted Boltzmann machine (RBM) is understood in the framework of Bayesian information geometry. Karakida et al. (2014; 2016) studied the performance of the Gaussian-Bernoulli RBM and showed that it performs ICA in restricted situations. However, this still remains as a half-baked idea, emerging in the last stage of completing this monograph. The geometry of contrast divergences is mostly due to on-going research by R. Karakida (PhD student at the University of Tokyo) and it might be too early to be included here. In order to understand deep learning, we need to construct a good model of  which involves hierarchical structure. Hierarchies of hidden layers unveil their hidden structure one layer at a time. This is unsupervised learning. The supervised aspect of deep learning is related to singularities existing ubiquitously in a neuromanifold, and will be one of the main topics of the next chapter.














Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_12




12. Natural Gradient Learning and Its Dynamics in Singular Regions




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp






Learning takes place in a parameter space, which is not Euclidean in general but Riemannian. Therefore, we need to take the Riemannian structure into account when designing a learning method. The natural gradient method, which is a version of stochastic descent learning, is proposed for this purpose, using the Riemannian gradient. It is a Fisher efficient on-line method of estimation. Its performance is excellent in general and it has been used in various types of learning problems such as neural learning, policy gradient in reinforcement learning, optimization by means of stochastic relaxation, independent component analysis, Monte Carlo Markov Chain (MCMC) in a Riemannian manifold and others.
Some statistical models are singular, implying that its parameter space includes singular regions. The multilayer perceptron (MLP) is a typical singular model. Since supervised learning of MLP is involved in deep learning, it is important to study the dynamical behavior of learning in singular regions, in which learning is very slow. This is known as plateau phenomena. The natural gradient method overcomes this difficulty.

12.1 Natural Gradient Stochastic Descent Learning

12.1.1 On-Line Learning and Batch Learning
Huge amounts of data exist in the real world. Consider a set of data which are generated randomly subject to a fixed but unknown probability distribution. A typical example is shown in the regression problem, where input signal  is generated randomly, accompanied by a desired response . A teacher signal y, which is a noisy version of the desired output , (12.1)is given together with , where  is random noise. The task of a learning machine is, in this case, to estimate the desired output mapping  by using the available examples of input-output pairs , called training examples. They are subject to an unknown joint probability distribution, (12.2)where  is the probability distribution of  and  is the probability distribution of noise , typically Gaussian. This is a usual scheme of supervised learning.
We use a parameterized family  of functions as candidates for the desired output, where  is a vector parameter. The set of  is a parameter space and we search for the optimal  that approximates the true  by using training examples D. When y takes an analog value, this is a regression problem. When y is discrete, say binary, this is pattern recognition.
In order to evaluate the performance of machine , we define a loss function or cost function. The
           instantaneous loss of processing  by machine  is typically given by (12.3)in the case of regression, which is a half of the square of the difference between the teacher output y and machine output .
The loss function of machine  is the expectation of the instantaneous loss over all possible pairs , (12.4)where the expectation is taken with respect to the unknown joint probability distribution . However, since we do not know , we use the average over the training data, (12.5)This is called the
           training error, since the average loss is evaluated by using the data that we used for training. In contrast, (12.4) is called the
           generalization error, since it evaluates the performance over all possible data  not used in the process of training. Since we do not know L, we minimize the training error  to obtain . A regularization term may be added to  in order to obtain a regularized optimal solution  by learning.
A loss function is defined similarly in the case of pattern recognition by the expectation of an instantaneous loss. Even in the case of binary y,  or 1, we can use (12.3) as a loss. However, it is more natural to formulate the problem in terms of logistic regression such that the probability of y is given as a function of  by (12.6)where the normalization factor  is (12.7)This implies (12.8)The instantaneous loss function is the negative of log , (12.9)In the problem of estimation of parameters  in a statistical model , we use (12.10)the negative of  likelihood, where only 's are observed. The generalization error is (12.11)where  is the true parameter, such that  is generated from . The regression problem is regarded as an estimation problem to estimate  of , where random variables are  and we do not care about .

          An
           on-line learning procedure modifies the current candidate  at time t to obtain  at the next time based on the current training example  so as to decrease the instantaneous loss (Rumelhart et al. 1986). Usually, the negative of the gradient is used to update , (12.12)where  is the gradient with respect to  and coefficient  is called a learning constant, which may depend on t. Since training data are given one by one, the change (12.13)is a random variable depending on . The expectation of  is equal to . Therefore, the change  is random but its expectation is in the direction of . See Fig. 12.1. Hence, (12.12) is called a
           stochastic descent learning method. Amari (1967) might be the first to have used this idea for training a multilayer perceptron. The method is now well established as the
           back-propagation learning method.Fig. 12.1Gradient descent of expected loss L and stochastic gradient descent of l


A batch learning procedure is an iterative method which uses all the training data for modifying  at one step, such that  is modified to  by (12.14)The two types of learning, batch and on-line, have different merits and demerits.


12.1.2 Natural Gradient: Steepest Descent Direction in Riemannian Manifold
Given a function  in a manifold, it is widely believed that the gradient (12.15)is the direction of the steepest change of . In a geographical map with contour lines, the steepest direction is given by the gradient of the height function , that is , which is orthogonal to contour lines. However, this is true only when an orthonormal coordinate system is used in a Euclidean space.
In a Riemannian manifold, the square of local distance between two nearby points  and  is given by the quadratic form (12.16)where  is a Riemannian metric tensor. Note that we use the Einstein convention so that the summation symbol  is omitted in (12.16). Let us change the current point  to , and see how the value of  changes, depending on the direction . We search for the direction in which L changes most rapidly. In order to make a fair comparison, the step-size of  should have the same magnitude in all directions, so that the length of  should be the same, (12.17)where  is a small constant. We put  and require that (12.18)Then, the steepest direction of L is the maximizer of (12.19)under the constraint (12.18). See Fig. 12.2. By using the variational method of maximizing (12.19) under the constraint (12.18), we easily obtain the following formulation: (12.20)This is a quadratic problem and the steepest direction is obtained as (12.21)We call (12.22)
          the
           Riemannian gradient or
           natural gradient of L, where (12.23)is the natural gradient operator.Fig. 12.2Natural gradient  of L


From the point of view of geometry, the natural gradient is a contravariant vector (12.24)and the ordinary gradient is a covariant vector (12.25)in the index notation. They are equal when and only when (12.26)that is, when an orthonormal coordinate system is used in a Euclidean space.

          The
           natural gradient learning method, which was suggested in Amari (1967), was formally introduced in Amari (1998) and defined by (12.27)In the batch mode, it is (12.28)In the case of statistical estimation where the Fisher information is a Riemannian metric, the loss function L and the Riemannian metric  is defined by using the same  likelihood function . In this case, the natural gradient method is regarded as a version of the Gauss-Newton method. However, there are many other cases where the loss function and the Riemannian metric are not related. The natural gradient learning method is useful in such cases, too. Independent component analysis (ICA) is such an example, where the parameter space is a set of mixing matrices and the Riemannian metric is given by the invariant metric of the underlying Lie group, but the loss is measured by the degree of independence of unmixed signals. In the next subsection, we show an interesting new idea of natural gradient using the "absolute value" of the Hessian as a Riemannian metric (Daupin et al. 2014).
The natural gradient is also used in deep learning (Roux et al. 2007; Ollivier 2015) and in reinforcement learning as a
           policy natural gradient (e.g., Kakade 2002; Peters and Schaal 2008; Morimura et al. 2009). Another application is found in the optimization problem with stochastic relaxation technique (MalagÃ² and Pistone 2014; MalagÃ² et al. 2013; Yi et al. 2009; see also Hansen and Ostermeier 2001).


12.1.3 Riemannian Metric, Hessian and Absolute Hessian
The Newton method uses the Hessian of  for obtaining the minimizer of  by solving  recursively. It updates the current  to give (12.29)where (12.30)The natural gradient replaces  by the Riemannian metric . Therefore, it is interesting to see the relation between  and .
We study the case where the noise is Gaussian with mean 0 and variance . The joint probability distribution is written as (12.31)Hence, the loss function is the same as the negative of the log likelihood except for the constant. Minimizing  is equivalent to maximizing the likelihood of the unknown parameter . The on-line learning algorithm (12.27) is regarded as a sequential estimation procedure, and the batch learning algorithm is an iteration procedure of obtaining the maximum likelihood estimator.
The Fisher information in this case is given by (12.32)On the other hand, the Hessian of the loss function  is (12.33)where the expectation is taken with respect to the true distribution  from which teacher signal y is generated.
By using (12.3) or by assuming  in (12.31), we easily have (12.34)
 (12.35)where  is the expectation with respect to .  is in general positive-definite, but  is not necessarily so. (We discuss the singular case later where  and  degenerate.) However,  and  are exactly equal at . Moreover, they are equal when  holds. We show later that they are equal at critical or singular regions in MLP.
Recently, an interesting new idea of defining a Riemannian metric by the "absolute value" of the Hessian matrix was proposed (Dauphin et al. 2014). The Hessian is decomposed as (12.36)where  is an orthogonal matrix and  is a diagonal matrix having eigenvalues of  as the diagonal elements. The matrix of the absolute value of  is defined by (12.37)When  is used as a Riemannian metric, the natural gradient method becomes (12.38)The method is called the
           saddle-free Newton method (SFN) and its good performance is demonstrated. When  is a saddle point, the Newton method stabilizes the saddle and converges to it. Hence, the Newton method does not work well. It is shown that most critical points of L are saddles in high dimensions (Dauphin et al. 2014). Hence, the new idea is introduced as a method of avoiding saddle points, but keeping the good performance of the Newton method. Any natural gradient method is not trapped in a saddle whereas the Newton method is. Moreover, the behaviors of the Fisher information-based natural gradient and the
           absolute-value-based Hessian natural gradient are the same at around the optimal point , both enjoying the Fisher efficiency. It is also interesting to see that their behaviors are the same in the critical or singular regions studied later, which are the main source of plateau phenomena (retardation of learning).


12.1.4 Stochastic Relaxation of Optimization Problem
We show a problem in which the natural gradient plays an important role. Let us consider the problem of searching for the minimizer of  over . The problem is difficult to solve when f is not convex, in particular when  is discrete. The integer programming is a typical example of the discrete type.
Let us introduce a family of probability distribution  and consider the expectation (12.39)The problem of searching for the minimizer of  with respect to  is called the
           stochastic relaxation of the original problem (MalagÃ² and Pistone 2014; see also Hansen and Ostermeier 2001). It changes the problem of a search in X to a search in M, so the gradient descent method is applicable even when X is discrete. Since M is a Riemannian manifold, we can apply the natural gradient method, (12.40)By choosing model M carefully, it works well. Yi et al. (2009) proposed an efficient way of implementing the natural gradient.


12.1.5 Natural Policy Gradient in Reinforcement Learning
We summarize the natural gradient method in
           reinforcement learning, following Peters and Schaal (2008). It is called the natural policy gradient method, formulated in the framework of the Markov decision process. See a survey paper by Grondman et al. (2012). Let us consider a system having state space  and action space . At each discrete time t, an action is chosen, depending on the current state , subject to policy , which specifies the probability (density) of action . We assume that it is a parameterized family of conditional probabilities specified by a vector parameter , denoted as . The state transition takes place stochastically depending on the current  and , and its probability (density) function is given by . While a state transition takes place, an instantaneous reward is derived, which is a function of the current  and , written as . See Fig. 12.3.Fig. 12.3Markov decision process, reward and action

The expected reward at time t is a sum of the current reward  and future rewards , but future rewards are discounted. Hence, the expected reward at state , including future rewards, is written as (12.41)where  is a discount factor. It depends on policy  or its parameter . This is called the state-value function. We also define (12.42)which is the expected reward when the state is at  and action  is chosen. The expectation is taken throughout all the possible trajectories of  pairs.
Let us fix an initial state . The expected reward by taking the policy  is (12.43)which is rewritten as (12.44)where (12.45)is the discounted probability of a sequence of states.
We define the Fisher information matrix at the current state  by (12.46)The entire Fisher information matrix is its expectation along all the trajectories, (12.47)See Kakade (2001), Peters and Schaal (2008).
The natural gradient method, called the
           natural policy gradient or natural actor-critic, is given by (12.48)However, this is computationally heavy. A good idea is to approximate the state-action value function by a linear combination of adequate basis functions  as (12.49)where  is the parameters of weight to be adjusted. We choose (12.50)as basis functions. Since the gradient of the expected reward is written as (12.51)its gradient becomes (12.52)Therefore, the natural gradient takes a very simple form as (12.53)In order to implement the natural policy gradient, we need to evaluate  which gives the best approximation of Q. We use the TD error (12.54)and solve the linear regression problem recursively as (12.55)where the basis function  is (12.56)It is reported that the natural policy gradient demonstrates excellent performance in many cases.


12.1.6 Mirror Descent and Natural Gradient

          The
           mirror descent method was introduced by Nemirovski and Yudin (1983) (see also Beck and Teboulle 2003) as a tool to search for the minimum of a convex function . It is used in convex optimization problems with a constrained region. It uses another convex function  together with its Legendre dual . They implicitly use a dually flat structure together with a Riemannian metric (12.57)The dual coordinates (12.58)are used to update the current  as (12.59)where  is a learning rate. Since both  and  are covariant quantities, it is invariant. The result is transformed back to the primal coordinates by (12.60)Since (12.61)we have (12.62)This is the natural gradient method with the Riemannian metric . See Raskutti and Mukherjee (2015).
Since the underlying manifold is dually flat, e- and m-projections can be used to project a point on the restricted region. See sparse signal processing in the next chapter.


12.1.7 Properties of Natural Gradient Learning

12.1.7.1 Natural Gradient Learning is Fisher Efficient
On-line learning is a sequential procedure of modifying the current estimator  by using one example  at a time. Once an example has been used, it is discarded and not used again. This is useful for the estimator  to trace the change when the optimal  is slowly changing over time or suddenly changes at certain times. However, when the true target is fixed, this might cause loss of efficiency compared with the maximum likelihood estimator which is obtained by batch learning using all the data. This would be a cost to be paid for the benefit of traceability. To our surprise, this is not true. On-line learning can attain Fisher efficient estimation asymptotically, provided the learning constant is chosen adequately. The following theorem shows this (Amari 1998).


Theorem 12.1

The estimator obtained by on-line natural gradient learning (12.63)is Fisher efficient, attaining the CramÃ©r-Rao bound asymptotically.



Proof

Let us denote the error covariance matrix of the estimator at time t by (12.64)where  is the true value of . We expand the loss at  as (12.65)Then, subtracting  from both sides of (12.63) and substituting it in (12.64), we have (12.66)where (12.67)
 (12.68)are taken into account. We also note that (12.69)Then the solution of (12.66) is asymptotically (12.70)which proves the theorem. 




12.1.7.2 Natural Gradient is Saturation Free
Consider a regression problem, where the output is written as (12.71)First we explain a simple perceptron, where f is written as (12.72)Here, we neglect the bias term for simplicity. The parameter is a vector  and the activation function  is a sigmoid function, for example, (12.73)The gradient is written as (12.74)When the absolute value of  is large, function  saturates for most , becoming nearly equal 1 or . This is the saturation problem, where the gradient becomes almost equal to 0 because , and ordinary stochastic gradient descent learning becomes slow.
This is not serious in the case of a simple perceptron, but is serious in the case of
             multilayer perceptrons used in
             deep learning, where  is composed of a concatenation of many f's. We may write the output as (12.75)in the case of MLP, where  is the connection weight matrix of the jth layer to the th layer, . Its derivative with respect to , for example, includes the product of many 's. Hence, it is almost vanishing in many cases. This is considered as a flaw of back-propagation in deep learning.
The natural gradient learning method is free of such a saturation problem. The gradient is written as (12.76)The Fisher information is given by (12.77)The magnitude of the ordinary gradient would be very small in many cases but the natural gradient is different. We evaluate the magnitude of the natural gradient vector (12.78)by its Riemannian magnitude, (12.79)



Theorem 12.2

The magnitude of the natural gradient is given by (12.80)where (12.81)It does not vanish even when  is small. Moreover, (12.82)in a neighborhood of the optimal , where k is the dimension of .



Proof

From (12.78), we have (12.83)which proves (12.80). When , we easily have (12.82). 




12.1.7.3 Adaptive Natural Gradient Learning
The natural gradient method uses , so that we need to calculate the inverse of  at each step. When the number of parameters is large, this is computationally intractable. Moreover, calculation of  is not easy in the case when the distribution  of  is unknown. To avoid this situation, an adaptive method of obtaining  recursively has been proposed (Amari et al. 2000). By using the Taylor expansion of (12.84)and inverting it, we have an adaptive method of calculating  recursively by (12.85)where  is another learning constant.
Park et al. (2000) demonstrated performance of
             adaptive natural gradient learning using a number of simple examples, and confirmed that its performance is excellent. See also Zhao et al. (2015). The adaptive method can be used to calculate the inverse of the Hessian, (12.86)



12.1.7.4 Approximation and Practical Implementation of Natural Gradient
It is not easy to implement the natural gradient in a large network because of a large computational cost. There are many trials to overcome the difficulty and to give a good approximate solution. See Martens (2015) for the perspectives of the natural gradient method.
Martens and Grosse (2015) proposed an efficient method of approximating natural gradient descent in deep neural networks, called the
             Kronecker-factored approximate curvature (K-FAC). It uses two stages for the approximation of the Fisher information. One is to use the Kronecker product of the matrices due to error terms and activation terms, and the expectation is taken separately for calculating the Fisher information. The other is to use the tridiagonal approximation for the inverse of the Fisher information matrix (the Riemannian metric). A deep network consists of a concatenation of many layers, and the Fisher information matrix has a block structure. The tridiagonal approximation neglects off-diagonal blocks except for the blocks corresponding to consecutive  layers. It is demonstrated that this is not only computationally tractable but its performance is excellent.
We remark that the two approximations do not destroy most of the singular structure of the original Fisher information, studied in the next section. Since the singular regions are the main cause of retardation in learning, the K-FAC works well, getting rid of the plateau phenomena.


12.1.7.5 Adaptive Learning Constant
The dynamical behavior of learning depends on the
             learning constant . When the current  is far from the optimal value , it is desirable to use large , because we need to shift  toward  with a large step-size. On the other hand, when  is near the optimal value, if  is large, the stochastic fluctuation of  dominates so that it is better to choose a small . When the optimal value of the target is fixed, a good choice of learning constant is given by stochastic approximation, (12.87)When  satisfies (12.87), the estimator  converges to the optimal  with probability one. A typical case is given by (12.88)When the target does not move, the trade-off between the speed of convergence and the accuracy of estimation is given in Amari (1967) for a fixed . For the cases when the target moves, the idea of modifying  adaptively depending on the current situation of the estimator was considered from the early time. An excellent idea of modifying the learning constant was proposed by Barkai et al. (1995) in the case when y is binary. Amari (1998) generalized it and analyzed its behavior. A new
             adaptive learning method is given by (12.89)
 (12.90)where  are constants. Here, the natural gradient method is fortified by a learning rule of learning constant (12.90). The learning rate  increases, roughly speaking, when the instantaneous loss  is large, which implies that the target lies far away and  decreases when the target is closer.
In order to analyze its behavior mathematically, we use the continuous-time version of the learning equation, (12.91)
 (12.92)where the equations are averaged over possible input-output pairs ,  representing the average with respect to .
By using the Taylor expansion (12.93)where we put , we have (12.94)
 (12.95)We introduce the squared error at time t by (12.96)Then, the equations reduce to (12.97)
 (12.98)when  is fixed. The behaviors of the error  and learning constant  described by (12.97) and (12.98) are interesting. The origin (0, 0) is its stable equilibrium, so both  and  converge to 0. The solution is written approximately as (12.99)
 (12.100)for large t. This shows that the error converges to 0 in the order of 1 / t as t goes to infinity when  is fixed. When the target changes over time,  traces its change nicely by modifying .




12.2 Singularity in Learning: Multilayer Perceptron
The multilayer perceptron (MLP), proposed by Rosenblatt (1961), is a universal machine that can approximate any input-output function, provided it includes a sufficiently large number of hidden neurons. Although it seemed to be gradually being replaced by new powerful learning machines such as the support vector machine (SVM), MLP has been revived in the 21st century in
         "deep learning", where a network has a considerably large number of layers. Lots of new tricks are proposed to facilitate deep learning, including unsupervised learning (self-organization) as preprocessing, the convolutional structure, and the drop-out technique in supervised learning. Deep learning has recorded benchmark performances, winning most competitions on pattern recognition. See Schmidhuber (2015) for example. Researchers are astonished by the reincarnation of the multilayer perceptron. The back-propagation learning method is used at the final stage.
There is, however, a serious problem in the parameter space of a multilayer perceptron. It includes singularities, in the sense that the same output function is realized by continuously many parameters in a specific region. One cannot determine the parameter uniquely in such a region, and so the parameter is not identifiable. The Fisher information matrix degenerates in this region. This causes the dynamics of learning to become extremely slow, which is known as a critical slowdown or the plateau phenomena.
The present section studies typical
         singular structure in the manifold of multilayer perceptrons and clarifies its implications for statistical inference. The dynamical behavior of learning near singularities is studied in detail. Finally, it is shown that the natural gradient learning method, including SFN, overcomes these difficulties.

12.2.1 Multilayer Perceptron

          The
           multilayer perceptron is a layered machine composed of artificial neurons, which receives input  and emits output y. The behavior of an analog artificial neuron is described as follows: It receives a vector input signal , calculates a weighted sum of inputs and subtracts a threshold as (12.101)where . It emits an output (12.102)where  is a sigmoidal function. We use (12.103)because this is convenient for obtaining explicit analytical solutions. The coefficients  are called the synaptic weights. In order to make descriptions simpler, we put  in the following.
A multilayer perceptron consists of many layers in deep learning, but we consider here only three layers, an input layer, a hidden layer and an output layer (Fig. 12.4). The ith neuron of the hidden layer calculates the weighted sum of input  as (12.104)and emits output , where  is the weight vector of the ith hidden neuron. We consider a simple case that the output layer consists of only one output neuron. It calculates a weighted sum of the outputs of the hidden neurons and the final output is written as (12.105)where  are the weights of the output neuron. We may apply a sigmoidal nonlinear function to y, but it is only a nonlinear scale change. So we use a linear output neuron, but a nonlinear function is used when the output neurons are connected to the next layer as its input.Fig. 12.4Multilayer perception

A multilayer perceptron is specified by synaptic weights (12.106)Let M be the parameter space of perceptrons. Then, it is an N-dimensional manifold, where  is a coordinate system including  components. We write the input-output relation of the perceptron specified by  as (12.107)Learning takes place in the manifold M, where the current value  is modified by a stochastic gradient descent method using the current input-output example .


12.2.2 Singularities in M

The manifold M includes a set of points which have the same output functions (12.108)for . Two such points  and  are said to be equivalent and are denoted by (12.109)since their output functions are the same. When  has an equivalent point in M other than itself, we cannot identify  uniquely from the output function. There are two types of
           unidentifiability, originating from the invariance under the following transformations of parameters:
 1. Sign change:
: This is because  is an odd function, , so that . The unidentifiability due to the sign change is simple, and we may eliminate the unidentifiability by restricting the region within . However, the boundary  causes singularities, as will be shown soon.2. Permutation:Let  be a permutation of indices and i be transformed to  as . Then,  (12.110)
  
We divide M by the equivalence relation  and put (12.111)Equivalent points in M are reduced to one point in , the space of the output functions of multilayer perceptrons.  is not a manifold in the exact mathematical sense, as will be shown in the following, because it includes singular points due to unidentifiability. It is a manifold if we simply remove the singular points.  is called a behavior manifold or neuromanifold, although it is not a manifold in the exact sense.
We explain the singularity by using simple examples. Consider a very simple perceptron consisting of one hidden neuron, which is included in a larger model as a subnetwork. Its output function is (12.112)and the parameter space M is . When , whatever  is, the output function is 0. On the other hand, when , whatever v is, the output function is also 0, because . We call the set of these points a critical or singular region R of M, that is, (12.113)All the points in R are equivalent. By dividing M by the equivalence relation,  consists of two parts (not four because  and  are equivalent), which are connected by a single point corresponding to  or . It is a singular point in . See Fig. 12.5. More generally, we consider the following
           eliminating singularity.Fig. 12.5Eliminating singularity


(1)Eliminating singularity: When , whatever the value of  is, any  gives the same output function. Hence,  is not identifiable in this case. When , whatever  is, the output of the neuron is 0. Such a neuron has no effect on the output and it can be eliminated. 

Consider a subnetwork consisting of two hidden neurons i and j. Their output function is (12.114)
(2)Overlapping singularity: When
                   two neurons i and j in the hidden layer have identical weight vectors,  (12.115) their contribution to the output is  (12.116) Therefore, the output is the same whatever values  and  take, as long as  is equal to a fixed value v. That is, the output is the same on the line satisfying  (12.117) for any constant v. Hence,  and  themselves are not identifiable. This occurs when two neurons have the same weight vector , with their weight vectors overlapping completely. A similar situation holds when , but we omit this case for simplicity's sake. 
Fig. 12.6Overlapping singularity


          The
           critical region due to the overlapping singularity is given by (12.118)See Fig. 12.6, where  is mapped to a single point in . The images of the  form a continuous submanifold as  and v vary. The critical region in M is written as (12.119)which is a union of critical submanifolds (12.118).
We consider an equivalence class  specified by two parameters  and v, such that any networks in this class have the same output function (12.120)It consists of three parts, , and , (12.121)where (12.122)
 (12.123)
 (12.124)
 is a one-dimensional subspace corresponding to the overlapping singularity, where  is a free parameter in it, keeping the sum  constant.  and  correspond to the eliminating singularity. They are n-dimensional, since  and , respectively, can take any values.  is an elementary critical region which is a union of three parts, as is shown in Fig. 12.7. All the points in it are mapped to a single point  in the behavior manifold . This is a
           singular point in .Fig. 12.7Critical region 


There are infinitely many such critical regions, because we have an elementary critical region for each  and v and they are distributed continuously. So they form a continuum of singular points in the behavior manifold  where  and v are parameters. The region is further contracted when (12.125)holds. Such critical regions exist for each pair (i, j) in a larger network and they intersect. So M includes a rich net of critical regions spreading over M.
The trajectory of learning is given by (12.12) in M. It is mapped to  and it may pass through a critical region in M or a singular point in . We study the dynamical behavior of learning near singularities.
The loss function takes the same value in a critical region , so that its derivative in the tangent directions of  is always 0. This also implies that the Fisher information degenerates in the critical region  of M, because there are directions  in  such that (12.126)holds for any c, as is derived from (12.118).  is one-dimensional in region  and n-dimensional in regions  and  (Fig. 12.7). Hence, the score function, that is the derivative of -likelihood, becomes 0 in these directions. This implies that the Fisher information matrix has null directions in which (12.127)So it degenerates and  diverges on the critical region. The Fisher information exists and is non-degenerate in  except for singular points. No tangent space exists at a singular point of . This is the same for the absolute Hessian metric and (12.128)holds in R in the direction satisfying .
A probability distribution  accompanies each point of M and , but these probability distributions do not form a regular statistical model, because the non-degenerate Fisher information does not exist in critical regions or at singular points. We will discuss how the singularity affects statistical inference in a later subsection.


12.2.3 Dynamics of Learning in M

Multilayer perceptrons suffer from two types of flaw in their learning behavior. One is local minima such that the global minimum might not be attained by the gradient method. The second is the slowness of convergence, because the trajectory of learning is often trapped on a
           plateau, staying there for a long time before escaping from it (Amari et al. 2006). This is mostly due to the symmetric structure, such that its behavior is invariant under sign changes and permutations of hidden neurons.
Geometrically speaking, the plateau phenomena are given rise to by the singular structure. A critical region forms a plateau. We will analyze the dynamics of vanilla stochastic gradient learning in the neighborhood of a critical region. We will also show that the natural gradient is free of the plateau phenomena.
In order to analyze the dynamics, we use a very simple model consisting of two hidden neurons described in (12.114). Such simple models are embedded in a general perceptron as parts and cause a serious slowdown in learning. Instead of the difference Eq. (12.12) of stochastic descent learning, we use the averaged version in the continuous time, (12.129)where  is the average with respect to the joint probability distribution  of the true or teacher system from which training examples are generated. We further assume that the probability distribution of input  is subject to the Gaussian distribution  with mean 0 and covariance matrix , the identity matrix. These assumptions are useful for obtaining explicit solutions.
In order to analyze the behavior of dynamics (12.129) consisting of two hidden neurons, we use a new coordinate system  (Wei et al. 2008), (12.130)where (12.131)
 (12.132)and we use suffixes 1, 2 instead of i, j. The critical region  is given in this new coordinate system by (12.133)in which  and  hold. We divide it into two parts , (12.134)
 (12.135)where  is the overlapping singularity and  is the eliminating singularity.
The dynamics (12.129) are described in the new coordinate system as (12.136)where  is the Jacobian matrix of the coordinate transformation from  to , (12.137)The output function f is written as (12.138)in terms of the new coordinates. We expand it in the Taylor series in the neighborhood of , (12.139)
 (12.140)where higher-order terms of  are neglected. We then have the learning dynamics in terms of  in the neighborhood of . The dynamics concerning variables  and r are subject to the usual differential equations (fast dynamics) and their values converge rapidly to their equilibrium values, even when the behaviors of  and z are suffering from a critical slowdown (slow dynamics). Hence, we analyze the equations concerning  and z, where  and r are assumed to have converged to their equilibrium values  and v. The resultant dynamics are (12.141)
 (12.142)where (12.143)It is clear that (12.144)in the region , so any points in R are equilibria. The stability of the equilibria depends on . We show the results without proofs (which are technical and complicated but not difficult, see Wei et al. 2008; Wei and Amari 2008).


Theorem 12.3

When the teacher output function is in the critical region, the equilibria are stable.

This case occurs when the system is over-realizable, having redundant parameters.


Theorem 12.4

When the teacher output function is outside the critical region, we have three cases, depending on the eigenvalues of :(1)The equilibrium solutions on  satisfying  are stable and those satisfying  are unstable when  is positive-definite. (2)The equilibrium solutions on  satisfying  are stable and those satisfying  are unstable when  is negative-definite. (3)The solutions on  are unstable when some eigenvalues are positive and some negative. 


We further analyze the trajectories of the solutions in the neighborhood of . Let us introduce a function (12.145)which shows how far the current  is from . Its time derivative is given, from (12.141) and (12.142), as (12.146)The equation is integrable, and the solution is (12.147)where c is an arbitrary constant that specifies a trajectory.


Theorem 12.5

The trajectories of learning are (12.148)in the neighborhood of .

The family of trajectories shows how the dynamics proceed in the neighborhood of . The behaviors are the same for any , but their stabilities depend on  and . See Fig. 12.8. When  is in R, R is stable. When  is positive-definite or negative-definite, the trajectory starting from the basin of attraction reaches a stable point in  and is trapped in it, fluctuating in it randomly before escaping from it.Fig. 12.8Landscape of error function and learning trajectory



12.2.4 Critical Slowdown of Dynamics
          

We consider the two cases separately.

Case 1: The teacher function is in . When the number of hidden neurons is larger in the model network (student network) to be trained than in the teacher network (true network), some neurons are redundant because the optimal solution is realized by using a smaller number of neurons. This is the over-realizable case. In this case, elimination of neurons or overlap of synaptic weight vectors occurs, implying that the optimal solution is in R.
When the teacher network is , (12.143) is written as (12.149)where (12.150)is the error term and is 0 when , in particular, when . By expanding the error term, we can easily obtain (12.151)This implies that the dynamics of  are (12.152)Hence, the speed of convergence of  to 0 is extremely slow, taking a long time for training (Fig. 12.9a). This is frequently observed in simulations.Fig. 12.9Trajectories of learning near singularity: a Teacher is at singularity; b  is stable; c  is stable


Case 2: The optimal solution lies outside . Points in R are equilibrium solutions.  is not small in this case, because the error term is not small at R. When  is positive-definite or negative-definite, the part of  or , respectively, is stable but the other part is unstable. The landscape of the loss function is shown in this case in Fig. 12.8, where  is shown by the solid line. Starting  at some initial point belonging to the basin of attraction, the state is attracted to the stable part of . See Fig. 12.9b, c. The value of the loss function is the same and its derivative is 0 on  since all points in  are equivalent. However, this is not the optimal point. The state fluctuates in the neighborhood of  by stochastic dynamics due to randomly selected input . Thus, a random walk of the state takes place in the neighborhood of  and the state eventually reaches the boundary  of the stable region. It thus enters the unstable region and then escapes from  immediately, moving toward the true optimal point. However, it takes a long time before leaving the stable critical region. See Fig. 12.10. Precisely speaking, the fluctuation around  is not a random walk, because there are systematic flows out of the stable region in the neighborhood of , but the flow is very small when  is small.Fig. 12.10Trajectory of learning near the singularity

Although the trajectories passing through R have incoming flows and outgoing flows at R, this is completely different from those at a saddle point. The basin of attraction has measure 0 in the case of a saddle. Therefore, it is at measure 0 that the state reaches the saddle. Moreover, the state escapes from the saddle quickly by a small perturbation. On the other hand, the basin of attraction of R has a finite measure and the trajectory exactly reaches R in this case. A small perturbation moves the state but it again reaches R. This does not prevent a trajectory reaching R. A saddle does not cause any serious effect on the slowdown of dynamics. It is a critical region that causes a critical slowdown.Fig. 12.11Trajectories in 


We can consider the same dynamics in  where R is reduced to one point by the equivalence. The point corresponding to R is a singular point. It is a Milnor attractor in , of which the basin of attraction has a finite measure (Milnor 1985). The trajectories enter it and then emerge from it (Fig. 12.11). A general multilayer perceptron includes a net of such critical regions within it. The trajectory of vanilla stochastic gradient learning is trapped in such critical regions many times before it reaches the optimum solution. This is known as the
           plateau phenomena. See Fig. 12.12 for an example of learning curves.Fig. 12.12Plateaus



12.2.5 Natural Gradient Learning Is Free of Plateaus
The plateau phenomena are given rise to by the singularities. Let us consider a simple case of (12.114), where the horizontal line (z-axis) in Fig. 12.7 is the critical region and all the points in this line are equivalent. The Riemannian length is 0 along this line and the Riemannian metric degenerates in this direction. The inverse of the Fisher metric diverges in this direction to infinity at R. The gradient of the cost function is also 0 in this direction because all the points in R are equivalent. Therefore, the natural gradient, , is 0 multiplied by infinity at the singular points. Because of this, the natural gradient takes an ordinary value even in a very small neighborhood of R.
Cousseau et al. (2008) analyzed the dynamics of natural gradient learning near singularity when the teacher  is in R. After complicated calculations, (12.153)
 (12.154)is derived in the one-dimensional case. This shows that the dynamics converges to R in the linear order. Hence, no retardation takes place.
When  is outside R, the trajectory is trapped in plateaus in the case of ordinary stochastic gradient learning. However, in the case of natural gradient learning, no retardation takes place, because the Riemannian metric is 0 along the -direction so that all the points are reduced to a single point. That is, the trajectory enters a point in R and goes out immediately not staying within it. This is well understood by considering the trajectory in .
In , R reduces to the single singular point, and all the other points in  are regular, having a non-degenerate Riemannian metric. Even in a very small neighborhood of R,  takes ordinary values. Hence, a critical slowdown does not occur. To show this, Cousseau et al. (2008) used the
           blow-down technique of algebraic geometry. They introduced a new coordinate system , (12.155)
 (12.156)when  is one-dimensional. All the points in singular region R is mapped to a single point . The Fisher information  takes ordinary values even in a small neighborhood of R except for (0, 0) at which it is not defined. They showed that (12.157)holds in this coordinate system when the teacher is in R. Hence, the natural gradient learning dynamics becomes very simple, (12.158)in a neighborhood of R, when the teacher is inside R. When the teacher is outside R, the trajectory enters R, that is,  without retardation, and then escapes from it immediately. It is interesting to see that, starting from various initial points, the trajectories once enter R and then go out. The basin of attraction of R has a finite major, although the trajectories leave it immediately (see Fig. 12.11). This is a typical
           Milnor attractor. The new coordinate system , using the blow-down technique, is useful. It should be remarked that absolute Hessian dynamics have the same characteristics.
See Fig. 12.13 for examples of the learning curves of the adaptive natural gradient learning method compared to the ordinary back-propagation method.Fig. 12.13Learning curves




12.2.6 Singular Statistical Models
A statistical model  is regular when it satisfies the two conditions:(1)The parameter  belongs to an open set in a Euclidean space. (2)The Fisher information matrix exists and is non-singular. 

In this case, n score functions (12.159)are linearly independent and the tangent space  is spanned by them. The standard asymptotic theory of statistics holds, as is highlighted by the CramÃ©r-Rao theorem. However, the theory is violated in a singular statistical model.
There are many
           singular statistical models. One type is the case in which the Fisher information matrix degenerates at singularities. A mixture model (12.160)where  is a regular statistical model specified by , belongs to this class. The MLP belongs to this class. When  is a Gaussian distribution with varying mean and variance, it is called a Gaussian mixture model. The changing time model (sometimes called the Nile River model) and the ARMA model in time series also belong to this type.
Another type deals with the case where the Fisher information matrix diverges to infinity. A typical example is the location model written as (12.161)where f(x) is a function having a finite support and its derivative is not 0 at the boundaries. The unknown parameter is the mean value . A typical example is the uniform distribution over . We do not discuss this case, although its geometry is interesting, because its metric is not Riemannian but Finslerian. We do not have a good geometrical theory yet. See a preliminary study by Amari (1984).
For N observations from a probability distribution , consider the  likelihood ratio divided by , (12.162)It is asymptotically subject to the -distribution with n degrees of freedom, where n is the dimension number of , when M is regular. By analyzing its behavior, we can prove that the maximum likelihood estimator is asymptotically best, unbiased and Gaussian, the error covariance matrix of which is the inverse of the Fisher information matrix divided by N asymptotically.
The maximum likelihood estimator is no more subject to the Gaussian distribution even asymptotically in a singular statistical model of the first type when the true distribution is at a singular point. However, it is asymptotically consistent and its convergence speed is in the order of . It has been known for many years that some statistical models are singular. Fukumizu (2003) proved that the  likelihood (12.162) diverges to infinity in the order of  and  in the cases of multilayer perceptrons and mixture models, respectively. There is a Japanese monograph by Fukumizu and Kuriki (2004), which studies singular statistical models in detail.
Model selection is an important problem, which decides the number of hidden neurons from observed data in the case of the multilayer perceptron. As is well known, a model having a large number of free parameters fits the observed data well. The training error decreases as the number of parameters increases. However, the estimated parameters overfit and are not useful for predicting the behavior of future data, because the generalization error increases as the number of parameters increases beyond a certain value. There is an adequate number of parameters, which should be decided from the observed data.

          The
           Akaike Information Criterion (AIC) and
           Minimum Description Length (MDL) are two well-known criteria for model selection. The Baysian Information Criterion (BIC) is the same as MDL, although their underlying philosophies are different.
Multilayer perceptrons and Gaussian mixtures are models of frequent use in applications. They are hierarchical singular models in which a lower degree model is included in the critical region of a higher degree model. We need to decide an adequate degree, that is, the number of parameters from the observed data. AIC and MDL are frequently used for this purpose without the singular structure being taken into account. There have been many discussions concerning which criteria are to be used, AIC or MDL. Both AIC and MDL are derived by using the maximum likelihood estimator, assuming that it is asymptotically Gaussian with covariance matrix 1 / N times the inverse of the Fisher information. However, it is not Gaussian when the true parameter is in the critical region. When the true distribution is in a smaller model, it is in a critical region of a larger model. So neither MDL nor AIC are valid in such hierarchical models. They need to be modified. We should take account of corrections due to the singularity. In the case of multilayer perceptrons, the penalty term of AIC should be  times the number of parameters, instead of twice the number of parameters. This comes from the asymptotic property of log likelihood. Watanabe (2010) proposed a new information criterion taking the singular structure into account.


12.2.7 Bayesian Inference and Singular Model
Bayesian inference presumes a prior distribution  on the parameters  of a statistical model. For a family of probability distributions , the joint probability of  and  is given by (12.163)Therefore, the conditional distribution of , conditioned on the observed training data is (12.164)Its logarithm divided by N is (12.165)where c is a term not depending on . The maximum posterior estimate is its maximizer, (12.166)As is shown in (12.165), a penalty term due to the Bayesian prior distribution is added to the loss function, which is the negative of the  prior probability.
The effect of the prior distribution decreases as the number of the training examples N increases in a regular statistical model, as is seen from (12.165). The maximum a posteriori estimator (MAP) converges to the maximum likelihood estimator in this case. However, a singular statistical model has different characteristics.
Let us consider a smooth non-zero prior in a singular model like the multilayer perceptron. It includes the critical region R which is a union of subspaces, including an infinite number of points. Such a region is reduced to one point in the space of the outputs functions . Hence, a uniform prior (improper prior) on the parameter space M is not uniform on . The prior of a singular point is an integration of prior probabilities over an equivalence class R, so that the prior distribution of  is singular, because singular points in  have an infinitely large prior probability measure compared to a regular point.
The parameter space  of a perceptron including n hidden neurons is included in  as a submanifold. But  is included in  as a critical region, because it is given by ,  or  in . Hence, when we consider a smooth non-zero prior in , a singular point  collects prior probabilities of infinitely many points in a critical region of .
When we take the maximum a posteriori estimator, a model having a smaller number of parameters is advantageous because of the
           singular prior. Hence, the Bayesian MAP has a tendency to select a smaller model, automatically selecting an adequate model, although there is no guarantee that this is optimal.
Watanabe and his school (Watanabe 2001, 2009) have studied the effects of singularity in Bayesian inference by using modern algebraic geometry. The theory uses deeper knowledge of mathematics and is beyond the scope of the present monograph.


Remarks

The present chapter focuses on the natural gradient method in a Riemannian manifold. Since many engineering problems are formulated in a Riemannian manifold, the natural gradient is useful. We have treated on-line and batch learning procedures and shown that the natural gradient method demonstrates excellent performance.
The multilayer perceptron uses the gradient method (back-propagation) in a Riemannian manifold of parameters. It is a constituent of deep learning, so its dynamical performance should be studied carefully. However, the parameter space includes widely spread singular regions in which the Fisher metric degenerates. Hence it is not a regular statistical model but is a singular statistical model. We have studied the dynamics of back-propagation learning based on the vanilla gradient, showing its bad performance due to singularities. The natural gradient method is free from such flaws both for the Fisher metric and the absolute Hessian metric. This characteristic is retained in the K-FAC approximation (Martens and Grosse 2015). However, it remains as a problem to be studied how the dynamics of learning behaves in a neighborhood of singularity when the true model is not in the singular region. We will be able to show by using the blow-down technique that the trajectory is not trapped in the singularity. We have also studied the statistical problem related to singularities.
There are other interesting topics related to the natural gradient in a Riemannian manifold. One may use any Riemannian metric, such as the Killing metric in Gl(n) and the absolute Hessian metric (Dauphin et al. 2014). Girolami and Calderhead (2011) presented the MCMC method in a Riemannian manifold by using the natural gradient. Reinforcement learning also uses the natural gradient in a policy manifold which is Riemannian. See, e.g., Kakade (2001), Kim et al. (2010), Roux et al. (2014), Peters and Schaal (2008), Thomas et al. (2013). Optimization in the stochastic relaxation regime is another area where natural gradient learning is effective (MalagÃ² and Pistone 2014; MalagÃ² et al. 2013, Hansen and Ostermeier 2001). One important problem is to evaluate the inverse of the Fisher information or its approximation effectively. See Martens (2015) and Martens and Grosse (2015). The adaptive natural gradient method is one solution.
The natural gradient method is a first-order gradient method in a Riemannian manifold and is different from a second-order method such as the Newton method. We can further extend the natural gradient method to the natural Newton method, natural conjugate gradient method, etc. in a Riemannian manifold. See Edelman et al. (1998), Honkela et al. (2010) and Malago and Pistone (2014).














Â© Springer Japan 2016


Shun-ichi Amari



Information Geometry and Its Applications


Applied Mathematical Sciences
194

10.1007/978-4-431-55978-8_13




13. Signal Processing and Optimization




Shun-ichi Amari
1  




(1)
Brain Science Institute, RIKEN, Wako, Saitama, Japan

 



 

Shun-ichi Amari


Email: 
amari@brain.riken.jp






In the real world, signals are mostly stochastic. Signal processing makes use of stochastic properties to find the hidden structure we want to know about. The present chapter begins with principal component analysis (PCA), by studying the correlational structure of signals to find principal components in which the directions of signals are widely spread. Orthogonal transformations are used to decompose signals into non-correlated principal components. However, "no correlation" does not mean "independence" except in the special case of Gaussian distributions. Independent component analysis (ICA) is a technique of decomposing signals into independent components. Information geometry, in particular semi-parametrics, plays a fundamental role in this. It has stimulated the rise of new techniques of positive matrix decomposition and sparse component analysis, which we also touch upon. The optimization problem under convex constraints and a game theory approach are briefly discussed in this chapter from the information geometry point of view. The HyvÃ¤rinen scoring method
       shows an attractive direction to be studied further from information geometry.

13.1 Principal Component Analysis

13.1.1 Eigenvalue Analysis
Let  be a vector random variable, which has already been preprocessed such that its expectation is 0, (13.1)Then, its covariance matrix is (13.2)If we transform  into  by using an orthogonal matrix , (13.3)the covariance matrix of  is given by (13.4)Let us consider the eigenvalue problem of , (13.5)Then, we have n eigenvalues  and corresponding n unit eigenvectors , where we assume that there are no multiple eigenvalues. (When there exist multiple eigenvalues, rotational indefiniteness appears. We do not treat such a case here.) Let  be the orthogonal matrix consisting of the eigenvectors (13.6)Then,  is a diagonal matrix (13.7)and the components of  are uncorrelated, (13.8)



13.1.2 Principal Components, Minor Components and Whitening
Signal  is decomposed into a sum of uncorrelated components as (13.9)Since the variance of  is ,  has the largest magnitude on average,  the second, and finally  has the smallest magnitude. See Fig. 13.1. We call  the (first)
           principal component of , which is obtained by projecting  to . The first k largest components are given by . We call the subspace spanned by k eigenvectors  the 
            k-dimensional
           principal subspace. The vector (13.10)is the projection of  to the principal subspace.Fig. 13.1Principal components 


The dimensions of  are reduced by the projection, keeping the resultant vector as close to the original one as possible in the sense that the magnitude of the lost part (13.11)is minimized. So the principal components are used for approximating  with a small number of components, reducing the dimensions.
Similarly, the k minor components are given by , which are projections of  to . The subspace spanned by , is called the 
            k-dimensional
           minor subspace. The projection of  to the minor subspace is given by (13.12)This is the maximizer of (13.13)Note that the minor components of  are the principal components of , because the eigenvalues of  are . The eigenvectors of  are the same as those of , but the order is reversed as .
Let us rescale the magnitudes of n eigenvectors to give a new set of basis vectors (13.14)Then,  is written in the new basis as (13.15)where (13.16)so that (13.17)This implies that the covariance matrix of  is the identity matrix (13.18)The transformation of  to  is called whitening of . This naming originates from the fact that, when we deal with time series , the transformation (13.15) changes the time series x(t) into white noise series .
Since  is the identity matrix, it is invariant if we further transform  by using an arbitrary orthogonal matrix  as (13.19)Hence, whitening is not unique and there remains the indefiniteness of rotation, i.e., a further transformation by . In factor analysis, this fact is known as the indefiniteness of rotation. In order to dissolve the indefiniteness, we need to use higher-order statistics by assuming that the signals are not Gaussian. This is the motivation for discussing independent component analysis (ICA) in the next section.


13.1.3 Dynamics of Learning of Principal and Minor Components
When N examples  are observed as data D, we estimate the covariance matrix by (13.20)and find the principal components by calculating its eigenvalues and eigenvectors. When examples are given one by one, we use a learning algorithm. We begin with a simple case of deriving the first principal component . Let  be the candidate of the first principal eigenvector, satisfying (13.21)Let (13.22)be the projection of  to . Then the loss function to be minimized is (13.23)under the constraint (13.21). By using the Lagrangian multiplier, the stochastic gradient method of obtaining the principal component is given by (13.24)This was derived by Amari (1977) as a special case of neural learning, because the relation (13.22) is regarded as the output of a linear neuron. The same algorithm was discovered by Oja (1982) and was generalized to obtain the k-dimensional principal subspace (Oja 1992).
Let  be an  matrix consisting of k orthogonal unit column vectors , (13.25)satisfying (13.26)where  is the  unit matrix. The set of all such matrices forms a manifold , called the Stiefel manifold. The projection of  to the subspace spanned by  is (13.27)where (13.28)For obtaining the k-dimensional principal subspace spanned by the column vectors of , the loss function to be minimized is (13.29)The gradient descent learning equation for  is (13.30)Its averaged version in continuous time is (13.31)where  denotes the time derivative d / dt.
The solution  of learning Eqs. (13.30) or (13.31) converges to the subspace spanned by k principal eigenvectors. However, each  does not correspond to the eigenvectors , although the principal subspace is spanned by .
In order to obtain the k principal eigenvectors, Xu (1993) introduced a diagonal matrix (13.32)satisfying  and modified (13.31) as (13.33)This algorithm gives the principal eigenvectors .
It appears that a similar algorithm would be applicable to the problem of obtaining the minor component subspace. We need to find  that maximizes (13.29). If we use gradient ascent instead of gradient descent, the algorithm would be (13.34)However, this does not work. Why (13.34) does not work had been a puzzle.
Both algorithms (13.31) and (13.34) work well when  is limited in the
           Stiefel manifold . The manifold  is a submanifold of , which is the manifold of all  matrices. When we solve (13.34) or its stochastic version numerically,  deviates from  because of numerical errors. Algorithms (13.31) and (13.34) define flows  in the entire , where , when  is replaced by . The flow is closed in , that is,  when .  is a stable submanifold of the flow (13.31) in . Hence, when a small fluctuation occurs in  and it deviates from  into , it automatically returns to  (Fig. 13.2a). However, in the case of the flow (13.34) for minor components,  is not stable in  and  leaves  due to the small deviation (Fig. 13.2b). This is the reason why the algorithm (13.34) does not work.Fig. 13.2Flow in a principal subspace, b minor subspace

Consider two modified differential equations in  due to Chen et al. (1998), (13.35)
 (13.36)Then, we can prove that the submanifold  is neutrally stable with regard to both of the flows. Therefore, we can use (13.35) to obtain the principal components and (13.36) to obtain the minimal components. The on-line learning versions of (13.35) and (13.36) are (13.37)where  is the ith column vector of .
The dynamics (13.35) and (13.36) possess interesting invariants. Let (13.38)be the singular decomposition of , where  is an element of  consisting of k orthogonal unit vectors,  is a  orthogonal matrix and  is a  diagonal matrix with diagonal entries .


Lemma 13.1


(1)
 is an invariant of (13.35) and (13.36), . (2)
 is an invariant of (13.35) and (13.36), . (3)
 is an invariant of (13.35) and (13.36), . 


We omit the proof (see Chen et al. 1998). We immediately obtain the algorithm of Xu (1993) by using an initial condition  and rewriting (13.35) in terms of . When , both (13.35) and (13.36) give the Brockett flow (Brockett 1991), where the cost function is (13.39)This is the natural gradient flow in the manifold of the orthogonal matrices (see Chen et al. 1998).
Since  is neutrally stable in Eqs. (13.35) and (13.36), numerical errors may accumulate. Chen and Amari (2001) proposed the following equations (13.40)
 (13.41)where  is a positive diagonal matrix related to the initial value of , (13.42)
 is stable both under (13.40) and (13.41), so both the principal eigenvectors and minor eigenvectors are extracted stably by the respective equations, which differ only in signature.



13.2 Independent Component Analysis
        

Consider the problem of decomposing vector random variable  into n independent components, (13.43)such that  are independent random variables and  is a new set of basis vectors. We consider the case where n independent component signals  exist under an adequate basis. When  is Gaussian, PCA is successful for performing this job. However, there are infinitely many such decompositions due to rotational indefiniteness, as stated in the previous section. Moreover, when  is non-Gaussian, PCA does not work for this purpose. This is because, even if no correlations exist among n signals , this does not imply that they are independent.Fig. 13.3
a Uniform distribution P(s); b Its linear transformation p(x)

We give a simple example. Let  and  be two independent signals, where both  and  are subject to the uniform distribution over . They are distributed uniformly over the square (Fig. 13.3a). We construct their mixtures  by (13.44)
 (13.45)Then,  is uniformly distributed in a parallelepiped (see Fig. 13.3b). Its covariance matrix is (13.46)of which the eigenvectors are different from the original  and  axes. The PCA solution gives non-correlated components but they are not independent. So we need other methods to decompose  into independent components. Higher-order statistics beyond the covariance is useful for solving the problem.
An illustrative example of ICA is the
         cocktail party problem. There are n persons in a cocktail party room who are speaking independently. Let  be the voice of person i at time t. m microphones are placed in the party room, so that each microphone records a mixture of voices of n persons. Let  be the sound recorded by microphone j at time t. See Fig. 13.4. They are written as (13.47)where  is a coefficient of mixing depending on the distance between person i and microphone j. The problem is to recover the sounds  of all the persons from the recorded mixtures , without any knowledge of . Here we assume that the numbers of persons and microphones are the same, . When , we first apply PCA to , projecting it to the n-dimensional principal subspace. Then, the problem reduces to the case of . When , we need techniques of sparse signal processing.Fig. 13.4
n persons and m microphones in a room

We assume that  is a regular  matrix. When  is known, the problem is trivially solved by (13.48)and  is equal to the original . However,  or  is unknown. We transform  by using a matrix  as (13.49)and check if n components of  in time series  are independently distributed or not. If they are not independent, we modify  such that the degree of non-independence decreases. To this end, we need to define the degree of non-independence of n random variables . Since it is a function of , we can apply the stochastic gradient descent or the natural gradient descent method to obtain  that recovers the independent signals.
Before defining the degree of non-independence, we note the indefiniteness of the solution. As is known, the independent components are recovered only when all the components of  except for one are non-Gaussian. Further, the order of signals  is not recovered, since any permutation of n independent signals keeps their independence. Moreover, the magnitude of  is not recovered, because, when  are independent,  are independent for any constants . Hence, the independent components are recovered to within the scales and order.
We formulate the problem mathematically. Let  be the probability density function of the ith independent component , where we assume that (13.50)Then, the joint probability density of  is (13.51)For  determined from (13.49), the joint probability density is written as (13.52)Here, we used the general formula that probability density function  changes to (13.53)when  is transformed to  as (13.54)The KL-divergence from  to , (13.55)would be used as a degree of non-independence. This would be a good choice if we knew . However, we do not know  and what we know is only the fact that  is decomposed into the product of unknown . We use n arbitrary independent distributions, (13.56)and define (13.57)as a function to show the degree of non-independence. This choice is reasonable as follows.
We consider the manifold of all the probability distribution (13.58)to understand the situation geometrically. We define the submanifold  of all the independent distributions (13.59)which is an e-flat submanifold of S. It includes both  and . Another submanifold we consider is (13.60)which is parameterized by . For each , we have a distribution  given by the transformation of . It is not a flat submanifold. See Fig. 13.5.Fig. 13.5
 e-flat submanifold of independent distributions,  submanifold generated by . They are orthogonal

We use a loss function (13.61)when we know .  and  intersect at  and the loss function L is 0 at this point. However, we do not know , so we use (13.62)by using an adequately chosen q (Bell and Sejnowski 1995). We can show that  and  intersect orthogonally. In spite of this, we cannot apply the Pythagorean theorem, because  is not m-flat. However, because of the orthogonality, we show that  is a critical point of L. It is a local minimum, saddle or local maximum depending on the choice of q. The stability of the critical point depends on q and the m-embedding curvature of  at . When q is close to k,  is certainly a global minimum. We neglect the indefiniteness of  concerning scales and permutations in the present discussions, but the situation is the same for all equivalent .
We should remark that there are many loss functions other than (13.62). By mixing independent , the central limit theorem suggests that the distribution of  approaches a jointly Gaussian distribution. Hence, the degree of non-Gaussianity can be used as a loss function. The
         higher-order cumulants of  vanish when  is Gaussian, so that the sum of the absolute values of the third- and fourth-order cumulants play the role of a loss function. We may use other measures of non-Gaussianity as a loss function. See HyvÃ¤rinen et al. (2001) and Cichocki and Amari (2002). The following analysis is common to all such loss functions.
The stochastic descent on-line learning algorithm is given by (13.63)The loss function is written as (13.64)where (13.65)is the entropy of  expressed as a function of . We see (13.66)In order to calculate the gradient of the instantaneous loss (13.67)with respect to , where H(X) is neglected because it does not depend on , we consider a small change of  due to a small change of , from  to .
We have (13.68)Similarly, we have (13.69)We put (13.70)Further, from (13.71)we have, for , (13.72)Hence, we have (13.73)from which the gradient of the instantaneous loss l with respect to , , is calculated by using the component form.
In order to obtain the natural gradient, we need to introduce a Riemannian metric in the manifold Gl(n) of matrices. Let  be a small line element, which is written as (13.74)where  is a matrix whose (i, j) element is 1 and all the other elements are 0. They form a basis in the tangent space. We consider the Lie group structure of Gl(n).  is mapped to the identity matrix by multiplying  from the right, (13.75)We also map a nearby point  by multiplying  from the right, giving (13.76)Hence, a small line element  in the tangent space of Gl(n) at  is mapped to (13.77)in the tangent space at . See Fig. 13.6.Fig. 13.6Mapping of  to 


We define the magnitude of  at  simply by (13.78)A Riemannian metric is defined by defining the magnitude of  at the tangent space at . We use the Lie group invariance such that the magnitude does not change by the right multiplication of . Then, the magnitude of  is defined by that of the corresponding , (13.79)This is rewritten as (13.80)which is called the Killing metric. The length of a tangent vector is invariant by multiplying a matrix from the right.
One may wonder if there is a coordinate transformation of , (13.81)from which  is derived by (13.82)Unfortunately, there is no such coordinate transformation. We can define  but it is not integrable, that is, the integration of 
 (13.83)from  to  depends on the path connecting  and . So we do not have a coordinate system  in Gl(n) such that  are increments along new coordinate curves. Such virtual coordinates  are called a
         non-holonomic coordinate system, in which only  is defined. This non-holonomic basis of the tangent space is convenient for introducing a Riemannian metric to Gl(n) and defining the natural gradient.
The small change (13.73) of l is written in terms of  as (13.84)This is written in the components as (13.85)Since the inner product  is Euclidean, as is seen from (13.78), it is the natural gradient due to the
         Killing metric. The increment of  is written as (13.86)by using , where  is the gradient with respect to . By using (13.77), this is rewritten in terms of the gradient with respect to  as (13.87)Because of this, the natural gradient has an invariant property that the convergence of learning dynamics is the same whatever the true  is. The stability does not depend on , either. These are desirable properties given by Cardoso and Laheld (1996) and Amari et al. (1996).

13.2.1 Estimating Function of ICA: Semiparametric Approach
The probability density function of observed  can be written as (13.88)In this statistical model, the unknown parameters include not only  but also n functions , which are the probability densities of the independent source signals. The probability distribution of  is specified by  matrix , which are the parameters of interest to be estimated, and also by n functions , which are nuisance parameters of function-degrees of freedom. Therefore, ICA is a semi-parametric statistical problem (Amari and Cardoso 1997).
An estimation function is a matrix  which satisfies  (13.89)Here, the expectation is taken with respect to , and  implies that  and  are equivalent to within the scales and permutations. The estimating equation is given by (13.90)A sequential estimation is realized by the learning equation (13.91)which is expected converge to the solution of (13.90), although the convergence is not necessarily guaranteed.
Information geometry gives a general class of estimating functions. See Amari (1999) for details. Let  be an arbitrary vector function of . Then, an effective class of estimating functions is generated from (13.92)including arbitrary vector function . Let  be a linear reversible transformation of matrices acting on  as (13.93)
 is a tensor having four indices and written in the component form as (13.94)The estimating equation is the same for  and , because (13.95)is equivalent to (13.90).
The on-line learning equation using  is (13.96)Although, the equilibrium point does not depend on , its stability depends on  and so does the speed of convergence. Therefore, we need to choose  and  carefully.
Once  is chosen, the Newton method is applicable to solve the iterative procedure. From the estimating Eq. (13.90), we have (13.97)where  and  is used for taking the trace of matrix multiplication. Using (13.98)we define the operator (13.99)The Newton method is written as (13.100)Therefore, the Newton method is derived by choosing  in the following way: (13.101)The operator  is a fourth-order tensor, and we can calculate it explicitly, but it depends on the true , which we do not know.
An estimating function  is said to be standard when it satisfies (13.102)Given an estimating function , we have its standard version by (13.103)The learning equation using a
           standard estimating function corresponds to the Newton method. The HyvÃ¤rinen fast algorithm (HyvÃ¤rinen 2005) uses a standard estimating function.
Since the standard estimating function using  is written in the form of (13.104)where  and  are adequate parameters, we can use an adaptive method of choosing them from the data. The separating  is stable when we use a standard estimating function, because the Newton method is applied.
One of surprising results is the following "super efficiency". We define the covariance of the recovered signal at t by (13.105)Then, it converges to 0 when the source separation is successful.
We have the following
           super efficiency results:


Theorem 13.1

When (13.106)by using the standard estimating function , the covariances decrease in the order of  for the natural gradient learning, (13.107)and in the order of  when the learning constant  is fixed, (13.108)


The condition (13.106) is satisfied in the following two cases: (13.109)
 (13.110)See Amari (1999) for detailed discussions and proofs.


Remark

When independent source signals  have temporal correlations such that (13.111)which are not 0 for some , we can use this information even if we do not know  explicitly. The previous results are valid even in this case, but we have more efficient methods by taking the existence of temporal correlation into account. The joint diagonalization of the delayed covariance matrices is one good idea. See Cardoso and Souloumiac (1996). The method works well even when the source signals are Gaussian.

It is possible to develop a method of estimating functions even in this case. We obtain a general form of estimating functions, which includes arbitrary temporal filters to be applied to the observed signals . The joint diagonalization is a special example of the estimating function method. See Amari (2000) for details.



13.3 Non-negative Matrix Factorization
        

Given a series of observed signals , let us arrange all of them in an  matrix form, (13.112)ICA searches for the basis vectors , which form an  mixing matrix (13.113)and  is decomposed as (13.114)such that  are independent. (13.114) is represented as (13.115)in the matrix notation.
There are many cases where  is not a mixture of independent sources. ICA does not work in such cases. On the other hand, there are cases where the components  are all non-negative. Visual images are such signals, where s(i, j) are the brightness of an image at pixel (i, j).
When all the components of  are non-negative, they are distributed on the first quadrant of the signal space, which is a cone. When signals are transformed linearly by  as (13.116)
's are distributed in another cone, because linear transformation  transforms one cone to another cone. Hence, from a number of observations , we can find the cone in which the 's sit (Fig. 13.7). The mixture matrix  is recovered from the cone of . When the elements of  are also non-negative, those of  are non-negative. Therefore, the problem is formulated as follows:Fig. 13.7A transforms the positive quadrant to a positive cone


Non-negative matrix factorization (NMF): Given non-negative matrix , factorize it as the product of two non-negative matrices  and , (13.117)We define a divergence  between two non-negative matrices  and . Then, the loss function of decomposition is given by (13.118)The Frobenius matrix norm (13.119)is a divergence of frequent use. This is the square of the Euclidean norm and is symmetric with respect to  and . Another divergence is the KL-divergence defined by (13.120)Other divergences such as -, - and -divergences are also used on their own merits. See Cichocki et al. (2011).
The alternating minimization is a useful procedure to find the minimum of two variables . We fix  at time , and minimize  with respect to . Let the minimizer be . We then fix  and minimize  with respect to . The minimizer is written as . We repeat this procedure until convergence.
The gradient descent method is used to obtain the minimizer of the loss function. However, we need to take the non-negativity of  and  into account. The conventional gradient descent method does not satisfy this requirement and components of matrices would become negative in the procedure.
The exponential gradient descent (Kivinen and Warmuth 1997) is proposed to overcome this difficulty. Its procedure is as follows: (13.121)where  is a learning constant. By using the logarithm, we have (13.122)Hence, (13.121) is the gradient descent applied to  and . When D is the Frobenius norm (13.119), we have (13.123)In this analogy, we have the following algorithm, originally proposed by Lee and Seung (1999): (13.124)
 (13.125)There are many algorithms for NMF. See Cichocki et al. (2011), for example. NMF is further generalized to non-negative tensor factorization (NTF), where tensors are quantities having more than two indices.


13.4 Sparse Signal Processing
We have studied linear signal decomposition from  to , (13.126)This section deals with the case that they are mixtures of a very few non-zero components, that is, a vector signal  is sparse. A signal  is said to be
         k-sparse when the components of  are zero except for at most k components. When k is much smaller than the dimension number n of , it is called a
         sparse vector. We consider a typical case that k is of the order  or smaller, when n is large.
We interpret (13.126) such that  is a linear combination of n basis vectors  and a basis  is activated when  is non-zero. Only a small number of basis vectors are activated in the sparse case. We assume that  is generated sparsely but do not know which basis vectors are activated. Let m be the dimension number of vector . We regard the m components of  as m measurements concerning an unknown signal , where  are known. When , (13.126) is overdetermined, that is, the number m of equations is larger than the number n of unknowns. We usually assume that the observations are contaminated by noise, such that (13.127)where  is a noise vector, and we search for the least-squares solution.
When , the equation is underdetermined. There are infinitely many solutions satisfying (13.126) even when it is noise contaminated. A conventional solution is the generalized inverse that minimizes the Euclidean norm among all possible solutions. When we know that  is sparse, we have a different solution. This was first noted by Chen et al. (1998). The following surprising theorem is known (Donoho 2006; Candes et al. 2006).


Theorem 13.2

When n and m are large,  is recovered correctly in most cases, provided  is k-sparse and (13.128)


Roughly speaking, when k is a constant, a constant multiple of  observations are enough to recover the n-dimensional . Since a very small number of sensors are enough, provided the original signal is sparse, the paradigm is called compressed sensing (Donoho 2006; Candes and Walkin 2008). Such a paradigm has emerged from statistics, ICA, signal processing and many related fields. It has grown to form a very hot field. There are many monographs and papers on this topic, see, e.g., Elad (2010), Eldar and Kutyniok (2012) and Bruckstein et al. (2009).

13.4.1 Linear Regression and Sparse Solution
Let us formulate the linear regression problem (13.129)where  is the observation vector,  is a known design matrix,  is the factor or explanatory vector to be determined and  is a noise vector. We use  instead of  for the purpose of emphasizing that  is an e-affine coordinate system. The loss function to be minimized is (13.130)We use  for the loss function in this subsection, because it plays the role of a convex function defining dually flat structure. This is the negative of the  likelihood when the noises are independent Gaussian. Since  is a quadratic function in the case of (13.130), by defining (13.131)we have (13.132)where c is a constant. When ,  is regular in general and the optimal solution is (13.133)When ,  is singular and there are infinitely many solutions in this underdetermined case. Let  be a solution. Then, for any null vector satisfying (13.134)
 is a solution. The solution that minimizes the -norm is given by (13.135)where  is the
           generalized inverse defined by (13.136)However, this solution is not sparse and almost all components are non-zero.
The sparsest solution is the one that minimizes the number of non-zero components (13.137)However, this is a combinatorial problem and computationally difficult to solve for large n. One may use the
           -norm instead of
           -norm, (13.138)to obtain a sparse solution (Ishikawa 1996). There are many studies concerning when the minimum -norm solution is identical to the minimum -norm solution. It is now known that the solutions of the two problems coincide when (13.139)for a randomly generated  with high probability. See, e.g., Candes et al. (2006).


13.4.2 Minimization of Convex Function Under  Constraint
We generalize the linear regression problem and study the problem of minimizing a general convex function  under the -constraint. See Hirose and Komaki (2010). The constraint is given by (13.140)We define a region of  by (13.141)As c decreases, the constraint becomes stronger and finally when , it includes only , the extremely sparse solution. See Fig. 13.8.Fig. 13.8Convex set  and m-projection of  to it

We have assumed in (13.129) that the noise is Gaussian. When it is not Gaussian, the negative of the  likelihood function, , is convex but is not a quadratic function. Another typical example is the logistic regression. In this case, given input , the response  is binary, taking values 0 and 1. Its probability is given by (13.142)where (13.143)The loss function is the negative of  probability of the correct answer, (13.144)This is convex and is strictly convex when .
The problem is the minimization of (13.145)where  is the Lagrange multiplier. We begin with the overdetermined case because it is simpler. The underdetermined case can be treated similarly, as will be stated later (see Donoho and Tsaig 2008). In the overdetermined case, there is a unique optimum  minimizing , that satisfies (13.146)This is the solution corresponding to a large enough c and is not sparse.
We introduce the dually flat geometry, where the e-affine coordinates are  and the dual coordinates (m-flat coordinates) are given by (13.147)The Riemannian metric is (13.148)The divergence from  to , derived from , is (13.149)Therefore, from (13.146), we see that (13.150)Hence, minimizing  is equivalent to minimizing the divergence from  to , that is the dual divergence from  to . Since the area  defined by the constraint (13.141) is e-convex, the following is immediate from the projection theorem.


Theorem 13.3

The solution  that minimizes  in the area  is given by the m-projection of  to . The projection is unique.

The analytical equation for  is obtained, by differentiating (13.145) with respect to , (13.151)Since the solution is the m-projection of  to , the m-geodesic connecting  and  is orthogonal to the boundary of  if it lies on a smooth surface of  (Fig. 13.8). The gradient  is the normal vector of the surface of L, which is the supporting hypersurface of  at this point. However, since convex set  is a polyhedron, it is not differentiable at low-dimensional faces, such as vertices, edges, etc., where some components satisfy (13.152)There are infinitely many supporting hypersurfaces at a non-differentiable point. The set of the normal vectors of the supporting hypersurfaces is called the subgradient of L at that point (Fig. 13.9).Fig. 13.9Gradient and subgradient of L


We give an explicit form of the subgradient. Let  be the set of indices for which , (13.153)It is called the
           active set of , because  is active, that is, not 0, for . Then, the subgradient is written as  (13.154)where  may take an arbitrary value in .
There is only one m-geodesic passing through a regular boundary point of  orthogonally. On the other hand, there are infinitely many m-geodesics which pass through a non-regular point and their tangent directions belong to the subgradient. Therefore, there exist a larger number of points  that are mapped to a non-regular point by the m-projection as the sparsity becomes large. This explains why a sparse solution is obtained by the  regularization. See Fig. 13.9.


13.4.3 Analysis of Solution Path
Let us call 
             the
           solution path, considering c as a parameter along the path. It connects the origin 0 and the optimal point  as c changes from 0 to a large value. Hence, the solution path gives sparse solutions of which the sparsity is specified by c. LASSO is proposed for this purpose (Tibshirani 1996). Since the Lagrangian multiplier  is determined as a monotone function  of c, we may also regard  as another parameter of the path (Efron et al. 2004). The dual coordinates of the optimal solution satisfy (13.155)By differentiating it with respect to c, the path satisfies (13.156)which is the equation to show the direction  of the solution path. See Amari and Yukawa (2013) and Yukawa and Amari (2015).
Let us trace the path  starting from a sufficiently large c, where . As c decreases, the path follows (13.156) as long as the active set  does not change. But at a point where some  becomes newly 0, the active set A changes and the direction  of the path changes discontinuously, because  of (13.154) changes, although the path itself is continuous.
We divide the indices into two parts, one belonging to the active set A and the other to its complement (inactive set) , and use the mixed coordinates (13.157)
 (13.158)Then, we have the following lemma.


Lemma 13.2

The solution path satisfies (13.159)while the active set does not change, where  is the vector of which the components are .

The following
           least equiangle theorem of Efron et al. (2004) holds even in our general case.


Theorem 13.4

(Least Equiangle Property) The direction  of the solution path has the following properties:
(1) For any coordinate axis belonging to the active set A, the angle between  and the coordinate axis is the same, (13.160)where  is the tangent vector along the coordinate .
(2) For any axis belonging to , the angle between  and the coordinate axis is larger than that of the axis belonging to A, (13.161)




Proof

The angle between  and any coordinate axis  is calculated by the inner product, (13.162)Since  is proportional to , whereas (13.163)for  and (13.164)for , (13.160) and (13.162) hold. The direction of  changes only when i changes from  to A.


This is the principle of
           Least Angle Regressions (LARS) of Efron et al. (2004), extended to the general class of convex optimization.


13.4.4 Minkovskian Gradient Flow
A gradient flow is the set of paths satisfying (13.165)for some function . A gradient flow converges to a minimum of  when  is bounded, and no oscillation occurs. We show that the solution path of the extended LARS is a gradient flow under the
           Minkovskian gradient, which is defined in the following (Amari and Yukawa 2013). The natural gradient of  is the direction  in which the change of f is the largest. We define it by (13.166)under the condition that the norm of  is kept constant. The natural gradient uses the Riemannian norm. We consider the -norm (13.167)which is a Minkovskian norm. The -norm is a special case of the Minkovskian norm. It is easy to see that the steepest direction is given by (13.168)where c is a constant.
Since we are dealing with the -constraint, we define the Minkovskian gradient with respect to the -norm by taking the limit of q approaching to 1 from the above. We take the constant c as (13.169)Then, the limit is (13.170)This is the Minkovskian gradient corresponding to the -norm. The Minkovskian gradient of f is written as (13.171)Its components are  when the absolute values of  are maximal and 0 for all the other components. See Amari and Yukawa (2013).
Consider the Minkovskian gradient flow, (13.172)starting from the origin in terms of the dual coordinates. This is the solution path of our problem. The components of  are zero except for those indices that give the maximal values of , since  is the derivative of  with respect to i. Hence, along the Minkovskian gradient flow, only the components , which have the largest absolute values change. We need to solve the equation in terms of the primal coordinate system . Any components of  will change subject to the equiangle property.
We restate the LARS algorithm. Starting from the origin 0, we calculate the Minkovskian gradient of  and pick up the index , (13.173)The active set consists of a single . (We ignore cases where two or more indices become the maximizer, but it is easy to consider such cases.) The path  proceeds in this direction of the Minkovskian gradient as c increases, while  is the smallest. As c becomes larger, another index  joins the set of the indices of the maximizer, satisfying (13.174)We then add this to the active set, and the Minkovskian gradient is calculated for the new active set. In this way, the active set increases stepwise, until the path converges to . The Minkovskian gradient flow explains the properties of LARS in terms of the geometry of the gradient flow.


13.4.5 Underdetermined Case
We have so far studied the overdetermined case, where the unique unconstrained optimum  exists. In the underdetermined case of ,  is not strictly convex and the solution of (13.175)is not unique. The solutions form a submanifold. The problem is to obtain the one that has the minimum -norm. The Hessian  is not strictly positive-definite in this case. Hence, the Riemannian metric does not exists. The transformation (13.147) from  to  exists but is not bijective and the inverse transformation is not necessarily unique.
In spite of these differences, the Eq. (13.151) obtained from the Lagrangian holds. Hence, the equation of the solution path (13.156) holds as well. We can prove the least-angle theorem in a similar way. Therefore, the solution path is given by a Minkovskian gradient flow starting at the origin . We can use the same algorithm for solving the problem in the underdetermined case. See Donoho and Tsaig (2008) in the regression case.



13.5 Optimization in Convex Programming

        Mathematical
         programming is a problem of finding the optimum solution under various constraints. A typical example is linear programming (LP), which minimizes a linear function under constraints given by linear inequalities. More generally, there is a problem of minimizing a linear loss function in a convex region. See Nesterov and Nemirovski (1993). This is called convex programming. A typical example of it is positive-semidefinite programming. An inner point method searches for the optimum solution sequentially inside the convex region. Since a convex region defines a dually flat structure, information geometry is useful in understanding these problems.

13.5.1 Convex Programming
Let us consider a manifold M having a coordinate system  and a bounded convex region . A differentiable function  is called a
           barrier function when it is convex and diverges to infinity at the boundary  of the region . Let (13.176)be the supporting hypersurface of  at point  (Fig. 13.10). The convex region  is defined by (13.177)Since (13.178)diverges to infinity at the boundary, the convex function (13.179)is a barrier function.Fig. 13.10Convex region  and supporting hyperplane at 


The supporting hypersurfaces in the case of LP are (13.180)Hence,  is a polyhedron and the convex function is (13.181)The cost function to be minimized is (13.182)The positive
           semi-definite programming is the problem of obtaining the positive semi-definite matrix  that minimizes the linear function (13.183)where  is a constant matrix. The set of all positive semi-definite matrices forms a cone. We impose the constraints which  must satisfy: (13.184)where  are constant matrices. The region defined by (13.184) is convex. This type of problem is also called the cone programming problem, appearing in many fields of research, e.g., in control theory. See Ohara (1999).
The barrier function for positive-definite matrices is given by (13.185)The geometrical structure is the same as the invariant geometry of Gaussian distributions with mean 0 and covariance matrix .


13.5.2 Dually Flat Structure Derived from Barrier Function
Since a barrier function  is convex, it gives a dually flat structure to the manifold M, where  is e-affine coordinates and its Legendre transform (13.186)is m-affine coordinates.
The Riemannian metric  is given by (13.187)(Nesterov and Todd 2002). Hence, (13.188)
 (13.189)in the case of (13.181).
The interior point method is a sequential search for the solution that minimizes , by changing  in the decreasing direction of C inside . The natural gradient gives the steepest direction of C and is given by (13.190)The LP problem uses a linear function (13.191)as a cost function. By using continuous time, the natural gradient flow is (13.192)where  is a constant. The affine-projection method of Karmarkar solves this by using the discrete time step, (13.193)It is known that this gives an algorithm of polynomial-time complexity. See Tanabe (1980).
The dynamic equation (13.192) reduces to the simple equation given by (13.194)in the dual coordinates. The solution is a m-geodesic, (13.195)Although the solution is very simple in the dual coordinates, we need the solution in the  coordinate system. Hence, the algorithm is not simple in the  coordinates and the transformation between  and  is expensive. It is popular to solve the problem in the primal-dual formulation by using the Newton method.


13.5.3 Computational Complexity and m-curvature
In order to evaluate the number of steps to reach the optimal solution, we analyze the solution path. To this end, consider the following loss function parameterized by t: (13.196)where the barrier function is added to the cost function. Let  be the minimizer of . This defines a path inside  parameterized by t, which cannot cross the boundary of . As , the effect of the barrier function disappears, so  converges to the optimum solution  of the original problem.
By differentiating (13.196) with respect to , we obtain the solution path in the dual coordinates, (13.197)We call the point  the center of . The solution path is a dual geodesic connecting the center and the optimum solution . This is the steepest descent path starting at the center by using the natural gradient.
The path is an m-geodesic but is curved in the e-coordinates . When the curvature of the path is small, we can solve the discretized path equation by taking a large step size, but when the curvature is large, we need to use a small step size. Therefore, the number of steps depends on the curvature of the path. Kakihara, Ohara and Tsuchiya (2012) evaluated the necessary number of steps to obtain the optimum solution within a preassigned accuracy in terms of the
           embedding curvature of the path.



13.6 Dual Geometry Derived from Game Theory

13.6.1 Minimization of Game-Score
Statistical inference can be regarded as a
           game against Nature, where the player estimates the probability distribution Nature has assigned. Nature shows a realized value of random variable x subject to the true probability distribution p(x). The player chooses an action a from the set A of actions. Let l(x, a) be the instantaneous loss when a is chosen for x. The expected loss is (13.198)See Topsoe (1979), GrÃ¼nwald and Dawid (2004), Dawid (2007) and Dawid et al. (2012) for a detailed formulation.
In the case of estimation, the player's action is to choose a probability distribution q(x) from a set of actions consisting of probability distributions, . We call the loss l(x, q) a
           game-score in the case of probability distributions and denote it by S(x, q), (13.199)When N independent observations  are available, the game-score is written as (13.200)where  is the empirical distribution (13.201)The conventional loss used in statistics is the log loss, so the corresponding game-score is (13.202)Minimization of the game-score (13.200) under  loss (13.202) gives the maximum likelihood estimator. We study another type of the game-score in the next subsection, called the HyvÃ¤rinen score (HyvÃ¤rinen 2005) given by (13.203)where (13.204)and  etc. are differentiations with respect to x.
For two probability distributions p(x) and q(x), let us define the game-relative-entropy by (13.205)The game-entropy of p(x) is given by . When the game-score is given by (13.202), it is the Shannon entropy.
A game-score is proper when (13.206)holds for any p and q. It is strictly proper when the equality holds only for . We study a strictly proper game-score. In this case, we define the
           game-divergence between p(x) and q(x) by (13.207)This is the KL-divergence when the game-score is given by (13.202). We can derive a dual geometrical structure  induced from the game-divergence (Dawid 2007) for any strictly positive game-score S(x, q). We call it the S-geometry, which includes the invariant geometry as a special case of  loss.
Let us consider a parametric form of statistical model , where x is a scalar or a vector. We show only a scalar case, but it is easy to generalize results to the vector case. For a strictly proper game-score (13.208)the divergence is written as a function of  and  as (13.209)Hence, from (13.210)we have (13.211)This shows that (13.212)is an estimating function derived from game-score S. The estimating equation is (13.213)This is equivalent to minimizing  for the empirical distribution .
We show that there are strict proper game-scores other than . One type is derived from a Bregman divergence  given by (13.214)where  is a strictly convex function. It is easy to see that this is a Bregman divergence, and the related game-score is (13.215)It reduces to the  score when (13.216)The estimating function in this case is (13.217)where (13.218)Since  is a Bregman divergence, a dually flat structure is introduced in the manifold . As is seen from (13.214), the convex function is , where the -coordinates of  are of function degrees of freedom, (13.219)and the -coordinates are (13.220)The Riemannian metric and cubic tensor are derived from .
The estimator  derived from a game-score is consistent, because  is an estimating function. We study its efficiency. Let  be the true value and let us put (13.221)where  is the estimator satisfying the estimating equation, (13.222)By the Taylor expansion, we have (13.223)Due to the central limit theorem,  of the first term of (13.223) converges to a Gaussian random variable , the mean of which is 0 and the covariance is (13.224)The coefficient of the second term converges, due to the law of large numbers, to (13.225)Therefore, the estimation error is (13.226)The asymptotic error covariance of  is (13.227)which is larger than the inverse  of the Fisher information matrix in general.
The loss of information or efficiency is analyzed as follows. Let us decompose random variable  in the direction of the score vector , which consists of random variables representing the tangent vectors along the coordinate curves , and orthogonal to it, (13.228)
 (13.229)We may put , since the estimating equation is the same for any . Then, we have (13.230)because (13.231)and (13.232)The term  is explicitly given by (13.233)Hence, we have (13.234)and (13.235)where (13.236)Therefore, the asymptotic error covariance increases by . The estimator is Fisher efficient when and only when .


13.6.2 HyvÃ¤rinen Score
          

HyvÃ¤rinen (2005, 2007) proposed an interesting game-score given by (13.237)where  and  denotes the differentiation with respect to x. When  is a vector, it is (13.238)where  is the Laplacian and  is the gradient with respect to . The related game-entropy is (13.239)and the divergence is (13.240)



Lemma 13.3


            The
             HyvÃ¤rinen divergence is rewritten as (13.241)




Proof

We calculate  by putting (13.242)Then (13.243)where the formula of partial integration is used.  is calculated similarly, and we have (13.241).

The HyvÃ¤rinen divergence is not a Bregman divergence and hence the geometry derived from it is not dually flat. Note that it does not depend on the normalizing constant of q, because (13.244)for any c. Hence, it can be used for estimation when the normalization factor is difficult to calculate.
For parametric family of probability distributions , the HyvÃ¤rinen estimating function is given by (13.245)It is a homogeneous estimating function, because it does not depend on the normalization factor  of a probability distribution. For example, an exponential family is written as (13.246)but  and  do not include . Hence, one can easily obtain an estimator without calculating . Calculation of the normalization factor  is computationally heavy in Bayesian inference, so the HyvÃ¤rinen score is useful in such a case.
We give a simple illustrative example.


Example 13.1

Consider a simple exponential family, (13.247)We can calculate  in this case as (13.248)Therefore, the -coordinate is (13.249)The MLE is given by (13.250)The HyvÃ¤rinen score is (13.251)Hence, the related estimator is (13.252)which is asymptotically unbiased but is not efficient, because the score  is not included in the space of (13.253)


The following theorem shows the case when the HyvÃ¤rinen estimator is Fisher efficient. See HyvÃ¤rinen (2005).


Theorem 13.5

The HyvÃ¤rinen estimator is Fisher efficient for multivariate Gaussian distributions and is not efficient for other distributions.



Proof

Both  and  are quadratic functions of  in the multi-variate Gaussian case,  spanning all the quadratic functions of . Hence,  is included in the space spanned by  and . On the other hand, this occurs only for multivariate Gaussian distributions.


Parry et al. (2012) and HyvÃ¤rinen (2007) extend the HyvÃ¤rinen score applicable to the case of discrete  such as a graphical model. We show another new idea.
Consider the case where  is a discrete random variable having a graphical structure. When  and  are connected by a branch,  is a neighbor of , , where  is the set of neighbors of . A typical example is a Boltzmann machine, where  is a neighbor of  when one and only one component of  is different from . Hence, the graph is represented by an n-cube.

          The
           graph Laplacian  is an operator, acting on function  as (13.254)where  is the cardinality of . It can be rewritten as (13.255)where (13.256)An interesting property is shown in the following lemma.


Lemma


 (13.257)where (13.258)When the graph is homogeneous, having constant , (13.259)




Proof

From (13.260)(13.257) follows immediately.

We define a new game score when  is discrete and the graph is homogenous, that is, , by (13.261)This does not depend on the normalization factor of . The estimating function  is defined in the parametric case as (13.262)This gives the estimating equation (13.263)not depending on the normalization factor.
The meaning of this score is given by the following theorem.


Theorem 13.6

The divergence derived from the score (13.261) is (13.264)




Proof

We calculate  as before. However we use (13.265)instead of the formula of partial integration used in the continuous case. We then have the theorem.
We can calculate the efficiency of the derived estimator by calculating .



Remarks

The last chapter deals with miscellaneous subjects concerning signal processing. PCA is an old subject but is still active. We have focused on the dynamics of learning for PCA from the point of view of geometry. ICA is a relatively newly developed subject, in which non-Gaussianity of distributions plays an important role. Information geometry elucidates its structure. The natural gradient in the manifold of matrices is useful for this purpose. Moreover, it is formulated as a semi-parametric statistical problem, so that a general form of estimating functions is given by information geometry. We can stabilize and accelerate its learning dynamics by using the Newton method in the manifold of matrices. We have further touched upon the NMF problem.
Sparse signal processing is a hot topic on which many researchers are working. We are not able to overview most of the excellent results in this field. Instead, we have touched upon the minimization problem from the information geometry point of view. The Minkovskian gradient is a new topic, reinterpreting the -constrained minimization. The problem of minimization under  is another interesting subject. See Xu et al. (2012), Yukawa and Amari (2015) and Jeong et al. (2015), for example.
Convex programming is a big field in operations research. We discussed only the interior point method, in which information geometry plays an interesting role. Another important topic related to optimization is the stochastic relaxation framework which is useful even for discrete optimization (MalagÃ² et al. 2013), touched upon in the previous chapter. We also touched upon an information geometry framework given by game theory (Dawid 2007). The HyvÃ¤rinen score  when  is discrete is a new idea emerged at the last stage in preparing the monograph. The dual geometry derived from the HyvÃ¤rinen score is an interesting subject in future research.














Volume 194
Applied Mathematical Sciences

Editors-in-Chief

S.S Antman

Dept of Mathematics, Inst for Physi, Univ of Maryland, College Park, Maryland, USA

Leslie Greengard

New York University, New York, USA

Philip Holmes

Dept. Mechanical &, Princeton University, Princeton, New Jersey, USA




Series Editors

John Bell

CCSE, Lawrence Berkeley National Lab, Berkeley, California, USA

Peter Constantin

Department of Mathematics, Princeton University, Princeton, New Jersey, USA

Joseph Keller

Mathematics, Stanford University, Stanford, USA

Robert Kohn

New York, New York, USA

Robert Pego

Carnegie Mellon University, Pittsburgh, Pennsylvania, USA

Lenya Ryzhik

Department of Mathematics, Stanford University, Stanford, California, USA

Amit Singer

Dept of Math, Fine Hall, Princeton University, Princeton, New Jersey, USA

Angela Stevens

Angew. Mathematik MÃ¼nster, WestfÃ¤lische Wilhelms-Univ MÃ¼nster, MÃ¼nster, Germany

Andrew Stuart

University of Warwick, Coventry, United Kingdom

Stephen Wright

Computer Science Dept, University of Wisconsin-Madison, Madison, Wisconsin, USA





          More information about this series at
          http://âwww.âspringer.âcom/âseries/â34






Shun-ichi Amari



Information Geometry and Its Applications
1st ed. 2016












Shun-ichi Amari

Brain Science Institute, RIKEN, Wako, Saitama, Japan




ISSN 0066-5452
e-ISSN 2196-968X



					ISBN 978-4-431-55977-1
e-ISBN 978-4-431-55978-8

DOI 10.1007/978-4-431-55978-8
Library of Congress Control Number: 2015958849
Â© Springer Japan 2016
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for any errors or omissions that may have been made.
Printed on acid-free paper
This Springer imprint is published by SpringerNature The registered company is Springer Japan KK


Preface

Information geometry is a method of exploring the world of information by means of modern geometry. Theories of information have so far been studied mostly by using algebraic, logical, analytical, and probabilistic methods. Since geometry studies mutual relations between elements such as distance and curvature, it should provide the information sciences with powerful tools.
Information geometry has emerged from studies of invariant geometrical structure involved in statistical inference. It defines a Riemannian metric together with dually coupled affine connections in a manifold of probability distributions. These structures play important roles not only in statistical inference but also in wider areas of information sciences, such as machine learning, signal processing, optimization, and even neuroscience, not to mention mathematics and physics.
It is intended that the present monograph will give an introduction to information geometry and an overview of wide areas of application. For this purpose, Part I begins with a divergence function in a manifold. We then show that this provides the manifold with a dually flat structure equipped with a Riemannian metric. A highlight is a generalized Pythagorean theorem in a dually flat information manifold. The results are understandable without knowledge of differential geometry.
Part II gives an introduction to modern differential geometry without tears. We try to present concepts in a way which is intuitively understandable, not sticking to rigorous mathematics. Throughout the monograph, we do not pursue a rigorous mathematical basis but rather develop a framework which gives practically useful and understandable descriptions.
Part III is devoted to statistical inference, where various topics will be found, including the Neyman-Scott problem, semiparametric models, and the EM algorithm. Part IV overviews various applications of information geometry in the fields of machine learning, signal processing, and others.
Allow me to review my own personal history in information geometry. It was in 1958, when I was a graduate student on a master's course, that I followed a seminar on statistics. The text was "Information Theory and Statistics" by S. Kullback, and a professor suggested to me that the Fisher information might be regarded as a Riemannian metric. I calculated the Riemannian metric and curvature of the manifold of Gaussian distributions and found that it is a manifold of constant curvature, which is no different from the famous PoincarÃ© half-plane in non-Euclidean geometry. I was enchanted by its beauty. I believed that a beautiful structure must have important practical significance, but I was not able to pursue its consequences further.
Fifteen years later, I was stimulated by a paper by Prof. B. Efron and accompanying discussions by Prof. A.P. Dawid, and restarted my investigation into information geometry. Later, I found that Prof. N.N. Chentsov had developed a theory along similar lines. I was lucky that Sir D. Cox noticed my approach and organized an international workshop on information geometry in 1984, in which many active statisticians participated. This was a good start for information geometry.
Now information geometry has been developed worldwide and many symposia and workshops have been organized around the world. Its areas of application have been enlarged from statistical inference to wider fields of information sciences.
To my regret, I have not been able to introduce many excellent works by other researchers around the world. For example, I have not been able to touch upon quantum information geometry. Also I have not been able to refer to many important works, because of my limited capability.

                Last but not least, I would like to thank Dr. M. Kumon and Prof. H. Nagaoka, who collaborated in the early period of the infancy of information geometry. I also thank the many researchers who have supported me in the process of construction of information geometry, Profs. D. Cox, C.R. Rao, O. Barndorff-Nielsen, S. Lauritzen, B. Efron, A.P. Dawid, K. Takeuchi, and the late N.N. Chentsov, among many many others. Finally, I would like to thank Ms. Emi Namioka who arranged my handwritten manuscripts in the beautiful
                
                form. Without her devotion, the monograph would not have appeared.
              


Shun-ichi Amari

April 2015



Contents




Part I Geometry of Divergence Functions: Dually Flat Riemannian Structure





1 Manifold, Divergence and Dually Flat Structure

3




1.â1 Manifolds

3




1.â1.â1 Manifold and Coordinate Systems

3





1.â1.â2 Examples of Manifolds

5






1.â2 Divergence Between Two Points

9




1.â2.â1 Divergence

9





1.â2.â2 Examples of Divergence

11






1.â3 Convex Function and Bregman Divergence

12




1.â3.â1 Convex Function

12





1.â3.â2 Bregman Divergence

13






1.â4 Legendre Transformation

16





1.â5 Dually Flat Riemannian Structure Derived from Convex Function

19




1.â5.â1 Affine and Dual Affine Coordinate Systems

19





1.â5.â2 Tangent Space, Basis Vectors and Riemannian Metric

20





1.â5.â3 Parallel Transport of Vector

23






1.â6 Generalized Pythagorean Theorem and Projection Theorem

24




1.â6.â1 Generalized Pythagorean Theorem

24





1.â6.â2 Projection Theorem

26





1.â6.â3 Divergence Between Submanifolds:â Alternating Minimization Algorithm

27







2 Exponential Families and Mixture Families of Probability Distributions

31




2.â1 Exponential Family of Probability Distributions

31





2.â2 Examples of Exponential Family:â Gaussian and Discrete Distributions

34




2.â2.â1 Gaussian Distribution

34





2.â2.â2 Discrete Distribution

35






2.â3 Mixture Family of Probability Distributions

36






                        2.4 Flat Structure:
                        
                        -flat and
                        
                        -flat
                      

37





2.â5 On Infinite-Dimensional Manifold of Probability Distributions

39





2.â6 Kernel Exponential Family

42





2.â7 Bregman Divergence and Exponential Family

43





2.â8 Applications of Pythagorean Theorem

44




2.â8.â1 Maximum Entropy Principle

44





2.â8.â2 Mutual Information

46





2.â8.â3 Repeated Observations and Maximum Likelihood Estimator

47







3 Invariant Geometry of Manifold of Probability Distributions

51




3.â1 Invariance Criterion

51





3.â2 Information Monotonicity Under Coarse Graining

53





                          3.2.1 Coarse Graining and Sufficient Statistics in
                          


53





3.â2.â2 Invariant Divergence

54







                        3.3 Examples of
                        
                        -Divergence in
                        


57




3.â3.â1 KL-Divergence

57






                          3.3.2
                          
                          -Divergence
                        

57






                          3.3.3
                          
                          -Divergence
                        

57







                        3.4 General Properties of
                        
                        -Divergence and KL-Divergence
                      

59





                          3.4.1 Properties of
                          
                          -Divergence
                        

59





3.â4.â2 Properties of KL-Divergence

60






3.â5 Fisher Information:â The Unique Invariant Metric

62






                        3.6
                        
                        -Divergence in Manifold of Positive Measures
                      

65







                      4
                      
                      -Geometry, Tsallis
                      
                      -Entropy and Positive-Definite Matrices
                    

71




4.â1 Invariant and Flat Divergence

71




4.â1.â1 KL-Divergence Is Unique

71






                          4.1.2
                          
                          -Divergence Is Unique in
                          


72







                        4.2
                        
                        -Geometry in
                        
                        and
                        


75





                          4.2.1
                          
                          -Geodesic and
                          
                          -Pythagorean Theorem in
                          


75






                          4.2.2
                          
                          -Geodesic in
                          


76






                          4.2.3
                          
                          -Pythagorean Theorem and
                          
                          -Projection Theorem in
                          


76






                          4.2.4 Apportionment Due to
                          
                          -Divergence
                        

77






                          4.2.5
                          
                          -Mean
                        

77






                          4.2.6
                          
                          -Families of Probability Distributions
                        

80






                          4.2.7 Optimality of
                          
                          -Integration
                        

82






                          4.2.8 Application to
                          
                          -Integration of Experts
                        

83







                        4.3 Geometry of Tsallis
                        
                        -Entropy
                      

84





                          4.3.1
                          
                          -Logarithm and
                          
                          -Exponential Function
                        

85






                          4.3.2
                          
                          -Exponential Family (
                          
                          -Family) of Probability Distributions
                        

86






                          4.3.3
                          
                          -Escort Geometry
                        

87






                          4.3.4 Deformed Exponential Family:
                          
                          -Escort Geometry
                        

89






                          4.3.5 Conformal Character of
                          
                          -Escort Geometry
                        

91







                        4.4
                        
                        -Divergence: Dually Flat Divergence in Manifold of Positive Measures
                      

92





                          4.4.1 Decomposable
                          
                          -Divergence
                        

92






                          4.4.2 General
                          
                          Flat Structure in
                          


95






4.â5 Invariant Flat Divergence in Manifold of Positive-Definite Matrices

96





                          4.5.1 Bregman Divergence and Invariance Under
                          


96






                          4.5.2 Invariant Flat Decomposable Divergences Under
                          


98





4.â5.â3 Non-flat Invariant Divergences

101






4.â6 Miscellaneous Divergences

102





                          4.6.1
                          
                          -Divergence
                        

102






                          4.6.2 Other Types of
                          
                          -Divergences
                        

102





4.â6.â3 Burbea-Rao Divergence and Jensen-Shannon Divergence

103






                          4.6.4
                          
                          -Structure and
                          
                          -Structure
                        

104







Part II Introduction to Dual Differential Geometry





5 Elements of Differential Geometry

109




5.â1 Manifold and Tangent Space

109





5.â2 Riemannian Metric

111





5.â3 Affine Connection

112





5.â4 Tensors

114





5.â5 Covariant Derivative

116





5.â6 Geodesic

117





5.â7 Parallel Transport of Vector

118





5.â8 Riemann-Christoffel Curvature

119




5.â8.â1 Round-the-World Transport of Vector

120





5.â8.â2 Covariant Derivative and RC Curvature

122





5.â8.â3 Flat Manifold

123






5.â9 Levi-Civita (Riemannian) Connection

124





5.â10 Submanifold and Embedding Curvature

126




5.â10.â1 Submanifold

126





5.â10.â2 Embedding Curvature

127







6 Dual Affine Connections and Dually Flat Manifold

131




6.â1 Dual Connections

131





6.â2 Metric and Cubic Tensor Derived from Divergence

134





6.â3 Invariant Metric and Cubic Tensor

136






                        6.4
                        
                        -Geometry
                      

136





6.â5 Dually Flat Manifold

137





6.â6 Canonical Divergence in Dually Flat Manifold

138





6.â7 Canonical Divergence in General Manifold of Dual Connections

141





6.â8 Dual Foliations of Flat Manifold and Mixed Coordinates

143





                          6.8.1
                          
                          -cut of Dual Coordinate Systems: Mixed Coordinates and Foliation
                        

144





6.â8.â2 Decomposition of Canonical Divergence

145





6.â8.â3 A Simple Illustrative Example:â Neural Firing

146





6.â8.â4 Higher-Order Interactions of Neuronal Spikes

148






6.â9 System Complexity and Integrated Information

150





6.â10 Input-Output Analysis in Economics

157






Part III Information Geometry of Statistical Inference





7 Asymptotic Theory of Statistical Inference

165




7.â1 Estimation

165





7.â2 Estimation in Exponential Family

166





7.â3 Estimation in Curved Exponential Family

168





7.â4 First-Order Asymptotic Theory of Estimation

171





7.â5 Higher-Order Asymptotic Theory of Estimation

173





7.â6 Asymptotic Theory of Hypothesis Testing

175






8 Estimation in the Presence of Hidden Variables

179




8.â1 EM Algorithm

179




8.â1.â1 Statistical Model with Hidden Variables

179





8.â1.â2 Minimizing Divergence Between Model Manifold and Data Manifold

182





8.â1.â3 EM Algorithm

184





8.â1.â4 Example:â Gaussian Mixture

184






8.â2 Loss of Information by Data Reduction

185





8.â3 Estimation Based on Misspecified Statistical Model

186






9 Neyman-Scott Problem:â Estimating Function and Semiparametric Statistical Model

191




9.â1 Statistical Model Including Nuisance Parameters

191





9.â2 Neyman-Scott Problem and Semiparametrics

194





9.â3 Estimating Function

197





9.â4 Information Geometry of Estimating Function

199





9.â5 Solutions to Neyman-Scott Problems

206




9.â5.â1 Estimating Function in the Exponential Case

206





9.â5.â2 Coefficient of Linear Dependence

208





9.â5.â3 Scale Problem

209





9.â5.â4 Temporal Firing Pattern of Single Neuron

211







10 Linear Systems and Time Series

215




10.â1 Stationary Time Series and Linear System

215





10.â2 Typical Finite-Dimensional Manifolds of Time Series

217





10.â3 Dual Geometry of System Manifold

219





10.â4 Geometry of AR, MA and ARMA Models

223






Part IV Applications of Information Geometry





11 Machine Learning

231




11.â1 Clustering Patterns

231




11.â1.â1 Pattern Space and Divergence

231





11.â1.â2 Center of Cluster

232






                          11.1.3
                          
                          -Means: Clustering Algorithm
                        

233





11.â1.â4 Voronoi Diagram

234





11.â1.â5 Stochastic Version of Classification and Clustering

236





11.â1.â6 Robust Cluster Center

238





11.â1.â7 Asmptotic Evaluation of Error Probability in Pattern Recognition:â Chernoff Information

240






11.â2 Geometry of Support Vector Machine

242




11.â2.â1 Linear Classifier

242





11.â2.â2 Embedding into High-Dimensional Space

245





11.â2.â3 Kernel Method

246





11.â2.â4 Riemannian Metric Induced by Kernel

247






11.â3 Stochastic Reasoning:â Belief Propagation and CCCP Algorithms

249




11.â3.â1 Graphical Model

250






                          11.3.2 Mean Field Approximation and
                          
                          -Projection
                        

252





11.â3.â3 Belief Propagation

255





11.â3.â4 Solution of BP Algorithm

257





11.â3.â5 CCCP (Convex-Concave Computational Procedure)

259






11.â4 Information Geometry of Boosting

260




11.â4.â1 Boosting:â Integration of Weak Machines

261





11.â4.â2 Stochastic Interpretation of Machine

262





11.â4.â3 Construction of New Weak Machines

263





11.â4.â4 Determination of the Weights of Weak Machines

263






11.â5 Bayesian Inference and Deep Learning

265




11.â5.â1 Bayesian Duality in Exponential Family

266





11.â5.â2 Restricted Boltzmann Machine

268





11.â5.â3 Unsupervised Learning of RBM

269





11.â5.â4 Geometry of Contrastive Divergence

273





11.â5.â5 Gaussian RBM

275







12 Natural Gradient Learning and Its Dynamics in Singular Regions

279




12.â1 Natural Gradient Stochastic Descent Learning

279




12.â1.â1 On-Line Learning and Batch Learning

279





12.â1.â2 Natural Gradient:â Steepest Descent Direction in Riemannian Manifold

282





12.â1.â3 Riemannian Metric, Hessian and Absolute Hessian

284





12.â1.â4 Stochastic Relaxation of Optimization Problem

286





12.â1.â5 Natural Policy Gradient in Reinforcement Learning

287





12.â1.â6 Mirror Descent and Natural Gradient

289





12.â1.â7 Properties of Natural Gradient Learning

290






12.â2 Singularity in Learning:â Multilayer Perceptron

296




12.â2.â1 Multilayer Perceptron

296






                          12.2.2 Singularities in
                          


298






                          12.2.3 Dynamics of Learning in
                          


302





12.â2.â4 Critical Slowdown of Dynamics

305





12.â2.â5 Natural Gradient Learning Is Free of Plateaus

309





12.â2.â6 Singular Statistical Models

310





12.â2.â7 Bayesian Inference and Singular Model

312







13 Signal Processing and Optimization

315




13.â1 Principal Component Analysis

315




13.â1.â1 Eigenvalue Analysis

315





13.â1.â2 Principal Components, Minor Components and Whitening

316





13.â1.â3 Dynamics of Learning of Principal and Minor Components

319






13.â2 Independent Component Analysis

322




13.â2.â3 Estimating Function of ICA:â Semiparametric Approach

330






13.â3 Non-negative Matrix Factorization

333





13.â4 Sparse Signal Processing

336




13.â4.â1 Linear Regression and Sparse Solution

337






                          13.4.2 Minimization of Convex Function Under
                          
                          Constraint
                        

338





13.â4.â3 Analysis of Solution Path

341





13.â4.â4 Minkovskian Gradient Flow

343





13.â4.â5 Underdetermined Case

344






13.â5 Optimization in Convex Programming

345




13.â5.â1 Convex Programming

345





13.â5.â2 Dually Flat Structure Derived from Barrier Function

347






                          13.5.3 Computational Complexity and
                          
                          -curvature
                        

348






13.â6 Dual Geometry Derived from Game Theory

349




13.â6.â1 Minimization of Game-Score

349





13.â6.â2 HyvÃ¤rinen Score

353






References
359


Index
371






















References


D. Ackley, G. E. Hinton and J. Sejnowski, A learning algorithm for Boltzmann machines. Cognitive Science, 9, 147-169, 1985.


A. Agarwal and H. DaumÃ© III, A geometric view of conjugate priors. Machine Learning, 81, 99-113, 2010.MathSciNet


M. Aizerman, E. Braverman and L. Rozonoer, Theoretical foundations of the potential function method in pattern recognition learning. Automation and Remote Control, 25, 821-837, 1964.MathSciNet


M. Akahira and K. Takeuchi, Asymptotic Efficiency of Statistical Estimators: Concepts and Higher Order Asymptotic Efficiency, Springer LN in Statistics, vol. 7, 1981.


S. Akaho and K. Takabatake, Information geometry of contrastive divergence. In Information Theory and Statistical Learning, 3-9, 2008.


M. S. Ali and S. D. Silvey, A general class of coefficients of divergence of one distribution from another. Journal of Royal Statistical Society, B, 28, 131-142, 1966.MathSciNet


S. Amari, On some primary structures of non-Riemannian plasticity theory. RAAG Memoirs, 3, D-IX, 99-108, 1962.


S. Amari, A geometrical theory of moving dislocations. RAAG Memoirs, 4, D-XVII, 153-161, 1968.


S. Amari, Theory of adaptive pattern classifiers. IEEE Transactions on Electronic Computers, 16, 299-307, 1967.


S. Amari, Neural theory of association and concept-formation. Biological Cybernetics, 26, 175-185, 1977.MathSciNet


S. Amari, Differential geometry of curved exponential familiesâcurvature and information loss. Annals of Statistics, 10, 357-385, 1982.MathSciNet


S. Amari, Finsler geometry of non-regular statistical models. RIMS Kokyuroku (in Japanese), Non-Regular Statistical Estimation, Ed. M. Akahira, 538, 81-95, 1984.


S. Amari, Differential-Geometrical Methods in Statistics. Lecture Notes in Statistics, 28, Springer, 1985.


S. Amari, Differential geometry of a parametric family of invertible linear systemsâRiemannian metric, dual affine connections and divergence. Mathematical Systems Theory, 20, 53-82, 1987.MathSciNet


S. Amari, Information geometry of the EM and em algorithms for neural networks. Neural Networks, 8, 1379-1408, 1995.


S. Amari, Natural gradient works efficiently in learning. Neural Computation, 10, 251-276, 1998.


S. Amari, Superefficiency in blind source separation. IEEE Transactions on Signal Processing, 47, 936-944, 1999.


S. Amari, Estimating functions of independent component analysis for temporally correlated signals. Neural Computation, 12, 2083-2107, 2000.


S. Amari, Information geometry on hierarchy of probability distributions. IEEE Transactions on Information Theory, 47, 1701-1711, 2001.MathSciNet



                S. Amari, Integration of stochastic models by minimizing
                
                -divergence. Neural Computation, 19, 2780-2796, 2007.
              MathSciNet



                S. Amari,
                
                -divergence is unique, belonging to both
                
                -divergence and Bregman divergence classes. IEEE Transactions on Information Theory, 55, 11, 4925-4931, 2009.
              MathSciNet


S. Amari, Information geometry of positive measures and positive-definite matrices: Decomposable dually flat structure. Entropy, 16, 2131-2145, 2014.MathSciNet


S. Amari and J. Armstrong, Curvature of Hessian manifolds, Differential Geometry and its Applications 33, 1-12, 2014.MathSciNet


S. Amari and J-F. Cardoso, Blind source separationâSemiparametric statistical approach. IEEE Transactions on Signal Processing, 45, 2692-2700, 1997.


S. Amari, A. Cichocki and H. Yang, A new learning algorithm for blind signal separation. In Advances in Neural Information Processing Systems (Eds. M. Mozer et al.), 8, 757-763, 1996.


S. Amari and M. Kawanabe, Information geometry of estimating functions in semi-parametric statistical models. Bernoulli, 3, 29-54, 1997.MathSciNet



                S. Amari, S. Ikeda and H. Shimokawa, Information geometry of
                
                -projection in mean field approximation. In M. Opper and D. Saad (Eds), Advanced Mean Field Methods: Theory and Practice, 241-257. MIT Press, 2001.
              


S. Amari, K. Kurata and H. Nagaoka, Information geometry of Boltzmann machines. IEEE Transactions on Neural Networks, 3, 260-271, 1992.


S. Amari and H. Nagaoka, Methods of Information Geometry. American Mathematical Society and Oxford University Press, 2000.


S. Amari, H. Nakahara, S. Wu and Y. Sakai, Synchronous firing and higher-order interactions in neuron pool. Neural Computation, 15, 127-142, 2003.



                S. Amari and A. Ohara, Geometry of
                
                -exponential family of probability distributions. Entropy, 13, 1170-1185, 2011.
              MathSciNet


S. Amari, A. Ohara and H. Matsuzoe, Geometry of deformed exponential families: Invariant, dually flat and conformal geometry. Physica A, 391, 4308-4319, 2012.MathSciNet


S. Amari, H. Park and K. Fukumizu, Adaptive method of realizing natural gradient learning for multilayer perceptrons. Neural Computation, 12, 1399-1409, 2000.


S. Amari, H. Park and T. Ozeki, Singularities affect dynamics of learning in neuromanifolds. Neural Computation, 18, 1007-1065, 2006.MathSciNet


S. Amari and S. Wu, Improving support vector machine classifiers by modifying kernel functions. Neural Networks, 12, 783-789, 1999.


S. Amari and M. Yukawa, Minkovskian gradient for sparse optimization. IEEE Journal of Selected Topics in Signal Processing, 7, 576-585, 2013.



                D. Arthur and S. Vassilvitskii,
                
                -means++: The advantages of careful seeding, Proceedings of the 18th Annual ACM-SIAM Symposium on Discrete Algorithms, 1027-1035, 2007.
              


K. Arwini and C. T. J. Dodson, Information Geometry. Springer, 2008.


N. Ay, An information-geometric approach to a theory of pragmatic structuring. Annals of Probability, 30, 416-436, 2002.MathSciNet


N. Ay, Information geometry on complexity and stochastic interaction. Entropy, 17, 2432-2458, 2015.MathSciNet



                N. Ay, J. Jost, H. V. LÃª and L. SchwachhÃ¶fer, Information Geometry and Sufficient Statistics.
                arXiv:â1207.â6736
                , 2013.
              


N. Ay and S. Amari, A novel approach to canonical divergences within information geometry. Entropy, 17, 8111-8129, 2015.


N. Ay and A. Knauf, Maximizing multi-information. Kybernetika, 42, 517-538, 2006.MathSciNet


N. Ay, E. Olbrich, N. Bertschinger and. J. Jost, A geometric approach to complexity. Chaos, 21, 037103, 2011.MathSciNet


D. Balduzzi and G. Tononi, Integrated information in discrete dynamical systems: Motivation and theoretical framework. PLos Computational Biology, 4, e1000091, 2008.


A. Banerjee, S. Merugu, I. Dhillon and J. Ghosh, Clustering with Bregman divergences. Journal of Machine Learning Research, 6, 1705-1749, 2005.MathSciNet


N. Barkai, H. S. Seung, and H. Sompolinsky. On-line learning of dichotomies. Advances in Neural Information Processing Systems, 7, 303-310, 1995.


O. E. Barndorff-Nielsen, Information and Exponential Families in Statistical Theory. Wiley, 1978.


A. B. Barrett and A. K. Seth, Practical measures of integrated information for time-series data. PLoS Computational Biology, 7, e1001052, 2011.MathSciNet


M. Basseville, Divergence measures for statistical data processingâAn annotated bibliography. Signal Processing, 93, 621-633, 2013.


A. Beck and M. Teboulle, Mirror descent and nonlinear projected subgradient methods for convex optimization. Operations Research Letters, 31, 167-175, 2003.MathSciNet


J. M. Begun, W. J. Hall, W. M. Huang and J. A. Wellner, Information and asymptotic efficiency in parametric-nonparametric models. Annals of Statistics, 11, 432-452, 1983.MathSciNet


A. J. Bell and T. Sejnowski, An information maximization approach to blind separation and blind deconvolution. Neural Computation, 7, 1129-1159, 1995.


P. J. Bickel, C. A. J. Ritov, and J. A. Wellner, Efficient and Adaptive Estimation for Semiparametric Models. Johns Hopkins University Press, 1994.


J.-D. Boissonnat, F. Nielsen and R. Nock, Bregman Voronoi diagrams. Discrete and Computational Geometry, 44, 281-307, 2010.MathSciNet


L. Bregman, The relaxation method of finding a common point of convex sets and its applications to the solution of problems in convex programming. USSR Computational Mathematics and Mathematical Physics, 7, 200-217, 1967.


R. Brockett, Some geometric questions in the theory of linear systems. IEEE Transactions on Automatic Control, 21, 449-455, 1976.MathSciNet


R. Brockett, Dynamical systems that sort lists, diagonalize matrices, and solve linear programming problems. Linear Algebra and its Applications, 146, 79-91, 1991.MathSciNet


A. Bruckstein, D. Donoho and M. Elad, From sparse solutions of systems of equations to sparse modeling of signals and images. SIAM Review, 51, 34-81, 2009.MathSciNet


J. Burbea and C. R. Rao, On the convexity of some divergence measures based on entropy functions. IEEE Transactions on Information Theory, 28, 489-495, 1982.MathSciNet


W. Byrne, Alternating minimization and Boltzmann machine learning. IEEE Transactions on Neural Networks, 3, 612-620, 1992.


O. Calin and C. Udriste, Geometric Modeling in Probability and Statistics. Springer, 2013.


L. L. Campbell, An extended Chentsov characterization of a Riemannian metric. Proceedings of American Mathematical Society, 98, 135-141, 1986.


E. J. Candes, J. Romberg and T. Tao, Stable signal recovery from incomplete and inaccurate measurements. Communications on Pure and Applied Mathematics 59, 1207-1223, 2006.MathSciNet


E. J. Candes and M. B. Walkin, An introduction to compressive sampling. IEEE Signal Processing Magazine, 25, 21-30, 2008.


J.-F. Cardoso and B. H. Laheld, Equivariant adaptive source separation. IEEE Transactions on Signal Processing, 44, 3017-3030, 1996.


J.-F. Cardoso and A. Souloumiac, Jacobi angles for simultaneous diagonalization. SIAM Journal on Mathematical Analysis and Applications, 17, 161-164, 1996.MathSciNet


A. Cena and G. Pistone, Exponential statistical manifold. Annals of Institute of Statistical Mathematics, 59, 27-56, 2007.MathSciNet


T. Chen and S. Amari, Unified stabilization approach to principal and minor components extraction algorithms. Neural Networks, 14, 1377-1387, 2001.


T. P. Chen, S. Amari and Q. Lin, A unified algorithm for principal and minor components extraction. Neural Networks, 11, 3, 385-390, 1998.


S. S. Chen, D. L. Donoho and M. A. Saunders, Atomic decomposition by basis pursuit. SIAM Journal on Scientific Computation, 20, 33-61, 1998.MathSciNet


N. N. Chentsov, Statistical Decision Rules and Optimal Inference, AMS, 1982 (originally published in Russian, Nauka, 1972).


H. Chernoff, A measure of asymptotic efficiency for tests of a hypothesis based on a sum of observations. Annals of Mathematical Statistics, 23, 493-507, 1952.MathSciNet



                H. Choi, S. Choi, A. Katake and Y. Choe, Parameter learning for
                
                -integration. Neural Computation, 25, 1585-1604, 2013.
              MathSciNet


J. Choi and A. P. Mullhaupt, Kahlerian information geometry for signal processing. Entropy, 17, 1581-1605, 2015.MathSciNet


A. Cichocki and S. Amari, Adaptive Blind Signal and Image Processing. John Wiley, 2002.



                A. Cichocki and S. Amari, Families of
                
                -,
                
                - and
                
                -divergences: flexible and robust measures of similarities. Entropy, 12, 1532-1568, 2010.
              MathSciNet



                A. Cichocki, S. Cruces and S. Amari, Generalized
                
                -
                
                divergences and their application to robust nonnegative matrix factorization. Entropy, 13, 134-170, 2011.
              



                A. Cichocki, S. Cruces and S. Amari, Log-determinant divergences revisited:
                
                -
                
                and
                
                log-det divergences. Entropy, 17, 2988-3034, 2015.
              MathSciNet


A. Cichocki, R. Zdunek, A. H. Phan and S. Amari, Nonnegative Matrix and Tensor Factorizations. John Wiley and Sons, UK, 2009.


C. Cortes and V. Vapnik, Support-vector networks. Machine Learning, 20, 273-297, 1995.


F. Cousseau, T. Ozeki and S. Amari, Dynamics of learning in multilayer perceptrons near singularities. IEEE Transactions on Neural Networks, 19, 1313-1328, 2008.


F. Critchley, P. K. Marriott and M. Salmon, Preferred point geometry and statistical manifolds. Annals of Statistics, 21, 1197-1224, 1993.MathSciNet


I. CsiszÃ¡r, Information-type measures of difference of probability distributions and indirect observation. Studia Scientiarum Mathematicarum Hungarica, 2, 229-318, 1967.


I. CsiszÃ¡r, Information measures: A critical survey. in Proceedings of 7th Conference on Information Theory, Prague, Czech Republic, 83-86, 1974.


I. CsiszÃ¡r, Why least squares and maximum entropy? An axiomatic approach to inference for linear inverse problems. Annals of Statistics, 19, 2032-2066, 1991.MathSciNet


I. CsiszÃ¡r and G. Tusnady, Information geometry and alternating minimization procedure. In E. F. Dedewicz, et. al. (Eds.), Statistics and Decision, 205-237, Oldenburg Verlag, 1984.



                Y. Dauphin, R. Pascanu, C. Gulcehre, K. Cho, S. Ganguli and Y. Bengio, Identifying and attacking the saddle point problem in high-dimensional non-convex optimization.
                arXiv:â1406.â2572
                , NIPS, 2014.
              


A. P. Dawid, The geometry of proper scoring rules. Annals of Institute of Statistical Mathematics, 59, 77-93, 2007.MathSciNet


A. P. Dawid, S. Lauritzen and M. Parry, Proper local scoring rules on discrete sample spaces. Annals of Statistics, 40, 593-608, 2012.MathSciNet


A. P. Dempster, N. M. Laird and D. B. Rubin, Maximum likelihood from incomplete data via the EM algorithm. Journal Royal Statistical Society, B, 39, 1-38, 1977.MathSciNet


S. Dhillon and J. A. Tropp, Matrix nearness problems with Bregman divergences. SIAM Journal on Matrix Analysis and Applications, 29, 1120-1146, 2007.MathSciNet


D. L. Donoho, Compressed sensing. IEEE Transactions on Information Theory, 52, 1289-1306, 2006.MathSciNet



                D. L. Donoho and Y. Tsaig, Fast solution of
                
                -norm minimization problems when the solution may be sparse. IEEE Transaction on Information Theory, 54, 4789-4812, 2008.
              MathSciNet


A. Edelman, A. A. Arias and S. T. Smith, The geometry of algorithms with orthogonality constraints. SIAM Journal on Matrix Analysis and Applications, 20, 303-353, 1998.MathSciNet


B. Efron, Defining the curvature of a statistical problem (with application to second order efficiency). Annals of Statistics, 3, 1189-1242, 1975.MathSciNet


B. Efron, T. Hastie, I. Johnstone and R. Tibshirani, Least angle regression. Annals of Statistics, 32, 407-499, 2004.MathSciNet


S. Eguchi, Second order efficiency of minimum contrast estimators in a curved exponential family. Annals of Statistics, 11, 793-803, 1983.MathSciNet


S. Eguchi, O. Komori and A. Ohara, Duality of maximum entropy and minimum divergence. Entropy, 16, 3552-3572, 2014.MathSciNet


M. Elad, Sparse and Redundant Representations: From Theory to Applications in Signal and Image Processing. Springer, 2010.


Y. Eldar and G. Kutyniok, Compressed Sensing. Cambridge University Press, 2012.


Y. Freund and R. E. Schapire, A decision-theoretic generalization of on-line learning and an application to boosting. Journal Computer and Systems Sciences, 55, 119-139, 1997.MathSciNet


H. Fujisawa and S. Eguchi, Robust parameter estimation with a small bias against heavy contamination. Journal Multivariate Analysis, 99, 2053-2081, 2008.MathSciNet


A. Fujiwara and S. Shuto, Hereditary structure in Hamiltonians: Information geometry of Ising spin chains. Physics Letters A, 374, 911-914, 2010.MathSciNet


K. Fukumizu, Likelihood ratio of unidentifiable models and multilayer neural networks. Annals of Statistics, 31, 833-851, 2003.MathSciNet


K. Fukumizu, Exponential manifold by reproducing kernel Hilbert spaces. In Algebraic and Geometric Methods in Statistics (P. Gibilisco, E. Riccomagno, M.-P. Rogantin and H. Winn Eds.), 291-306, Cambridge University Press, 2009.


K. Fukumizu and S. Kuriki, Statistics of Singular Models. Frontiers in Statistical Sciences, 7, Iwanami, 2004 (in Japanese).


S. Furuichi, An axiomatic characterization of a two-parameter extended relative entropy. Journal of Mathematical Physics, 51, 2010.


P. Gibilisco and G. Pistone, Connections on non-parametric statistical manifolds by Orlicz space geometry: infinite-dimensional analysis. Quantum Probabilities and Related Topics, 1, 325-347, 1998.MathSciNet


M. Girolami and B. Calderhead, Riemannian manifold Langevin and Hamiltonian Monte Carlo methods. Journal of Royal Statistical Society, B-73, 123-214, 2011.


V. P. Godambe, Estimating Functions. Oxford University Press, 1991.


M. Grasselli, Dual connections in nonparametric classical information geometry. Annals of Institute of Statistical Mathematics, 62, 873-896, 2010.MathSciNet


I. Grondman, L. BuÅoniu, G.A.D. Lopes and R. BabuÅ¡ka, A survey of actor-critic reinforcement learning: Standard and natural policy gradients. IEEE Transactions on Systems, Man, and Cybernetics-Part C: Applications and Reviews, 42, 1291-1307, 2012.


P. D. GrÃ¼nwald and A. P. Dawid, Game theory, maximum entropy, minimum discrepancy and robust Bayesian decision theory. Annals of Statistics, 32, 1367-1433, 2004.MathSciNet


N. Hansen and A Ostermeier, Completely derandomized self-adaptation in evolution strategies. Evolutionary Computation, 9, 159-195, 2001.


G. H. Hardy, J. E. Littlewood and G. Polya, Inequalities (2nd ed.). Cambridge: Cambridge University Press, 1952.



                K. V. Harsha and K. S. S. Moosath,
                
                -geometry and Amari's
                
                -geometry on a statistical manifold. Entropy, 16, 2472-2487, 2014.
              MathSciNet


M. Hayashi and S. Watanabe, Information geometry approach to parameter estimation in Markov chains. IEEE Transactions on Information Theory, 2014.


M. Henmi and R. Kobayashi, Hooke's law in statistical manifolds and divergence. Journal Nagoya Mathematical, 159, 1-24, 2000.


G. E. Hinton, Training products of experts by minimizing contrastive divergence. Neural Computation, 14, 1771-1800, 2002.


G. E. Hinton and E. R. Salakhutdinov, Reducing the dimensionality of data with neural networks. Science, 313, 504-507, 2006.MathSciNet


Y. Hirose and F. Komaki, An extension of least angle regression based on the information geometry of dually flat spaces. Journal of Computational and Graphical Statistics, 19, 1007-1023, 2010.MathSciNet


S. W. Ho and R. W. Yeung, On the discontinuity of the Shannon information measures. IEEE Transactions on Information Theory, 55, 5362-5374, 2009.MathSciNet


A. Honkela, T. Raiko, M. Kuusela, M. Tornio and J. Karhunen, Approximate Riemannian conjugate gradient learning for fixed-form variational Bayes. Journal of Machine Learning Research, 11, 3235-3268, 2010.MathSciNet


A. HyvÃ¤rinen, Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research, 6, 695-709, 2005.


A. HyvÃ¤rinen, Some extensions of score matching. Computational Statistics & Data Analysis, 51:2499-2512, 2007.MathSciNet


A. HyvÃ¤rinen, J. Karhunen and E. Oja, Independent Component Analysis. John Wiley, 2001.


T. Ichimori, On rounding off quotas to the nearest integers in the problem of apportionment methods. JSIAM Letters, 3, 21-24, 2011.MathSciNet


S. Ikeda, T. Tanaka and S. Amari, Stochastic reasoning, free energy, and information geometry. Neural Computation, 16, 1779-1810, 2004a.


S. Ikeda, T. Tanaka and S. Amari, Information geometry of turbo and low-density parity-check codes. IEEE Transactions on Information Theory, 50, 1097-1114, 2004b.MathSciNet


M. Ishikawa, Structural learning with forgetting. Neural Networks, 9, 509-521, 1996.


R. A. Jacobs, M. I. Jordan, S. J. Nolwan and G. E. Hinton, Adaptive mixtures of local experts. Neural Computation, 3, 79-87, 1991.


A. T. James, The variance information manifold and the function on it. Multivariate Statistical Analysis, Ed. P. K. Krishnaiah, Academic Press, 157-169, 1973.


H. Jeffreys, Theory of Probability, 1st ed. Clarendon Press, 1939.


H. Jeffreys, An invariant form for the prior probability in estimation problems. Proceedings of Royal Society of London, Series A, Mathematical and Physical Sciences, 186, 453-461, 1946.MathSciNet


H. Jeffreys, Theory of Probability, 2nd ed. Oxford University Press, 1948.



                K. Jeong, M. Yukawa and S. Amari, Can critical-point paths under
                
                -regularization (
                
                ) reach the sparsest least square solutions?. IEEE Transactions on Information Theory, 60, 2960-2968, 2014.
              MathSciNet


J. Jiao, T. M. Courtade, A. No, K. Venkat and T. Weissman, Information measure: The curious case of the binary alphabet. IEEE Transactions on Information Theory, 60, 7616-7626, 2015.MathSciNet


S. Kakade, A natural policy gradient. In Advances in Neural Information Processing, 14, 1531-1538, 2001.



                S. Kakihara, A. Ohara and T. Tsuchiya, Information geometry and interior-point algorithms in semidefinite programs and symmetric cone programs. Journal of Optimization Theory and Applications, DOI 
                10.â1007/âs10957-012-0189-9
                , 2012.
              


T. Kanamori, T. Takenouchi, S. Eguchi and N. Murata, Robust loss function for boosting. Neural Computation, 19, 2183-2244, 2007.MathSciNet


K. Kanatani, Statistical optimization and geometric inference in computer vision. Philosophical Transactions of Royal Society of London, Ser. A, 356, 1303-1320, 1998.


Y. Kano, Beyond third-order efficiency. Sankhya, 59, 179-197, 1997.MathSciNet


Y. Kano, More higher order efficiency. Journal of Multivariate Analysis. 67, 349-366, 1998.MathSciNet


R. Karakida, M. Okada and S. Amari, Analyzing feature extraction by contrastive divergence learning in RBM. NIPS Workshop on Deep Learning, 2014.


R. Karakida, M. Okada and S. Amari, Dynamical analysis of contrastive divergence learning. Restricted Boltzmann machines with Gaussian visible units, To appear, 2016.


R. E. Kass and P. Vos, Geometrical Foundations of Asymptotic Inference. Wiley, 1997.


A. Kim, J. Park S. Park and S. Kang, Impedance learning for robotic contact tasks using natural actor-critic algorithm. IEEE Transactions on Systems, Man and Machine, B39, 433-443, 2010.


J. Kivinen and M. K. Warmuth, Exponentiated gradient versus gradient descent for linear predictors. Information and Computation, 132, 1-63, 1997.MathSciNet


G. Kniadakis and A. Scarfone, A new one parameter deformation of the exponential function. Physica A, 305, 69-75, 2002.MathSciNet


K. Kumon and S. Amari, Geometrical theory of higher-order asymptotics of test, interval estimator and conditional inference. Proceedings of Royal Society of London, A 387, 429-458, 1983.MathSciNet


M. Kumon, A. Takemura and K. Takeuchi, Conformal geometry of statistical manifold with application to sequential estimation. Sequential Analysis, 30, 308-337, 2011.MathSciNet


T. Kurose, Dual connections and affine geometry. Mathematische Zeitschrift, 203, 115-121, 1990.MathSciNet


T. Kurose, On the divergence of 1-conformally flat statistical manifolds. Tohoku Mathematical Journal, 46, 427-433, 1994.MathSciNet


T. Kurose, Conformal-projective geometry of statistical manifolds. Interdisciplinary Information Sciences, 8, 89-100, 2002.MathSciNet


S. Lauritzen, Graphical Models. Oxford University Press, 1996.


H. V. LÃª, Statistical manifolds are statistical models. Journal of Geometry, 84, 83-93, 2005.MathSciNet


G. Lebanon and J. Lafferty, Boosting and maximum likelihood for exponential models. In Advances in Neural Information Processing Systems (NIPS), 14, 2001.


D. D. Lee and S. Seung, Algorithms for nonnegative matrix factorization. Nature, 401, 788-791, 1999.


C. Lin and J. Jiang, Supervised optimizing kernel locality preserving projection with its application to face recognition and palm biometrics. Submitted, 2015.


M. Liu, B. C. Vemuri, S. Amari and F. Nielsen, Shape retrieval using hierarchical total Bregman soft clustering. IEEE Transactions on Pattern Analysis and Machine Learning, 34, 2407-2419, 2012.


L. MalagÃ², M. Matteucci and G. Pistone, Natural gradient, fitness modelling and model selection: A unifying perspective. IEEE Congress on Evolutionary Computation, 486-493, 2013.


L. MalagÃ² and G. Pistone, Combinatorial optimization with information geometry: Newton method. Entropy 16, 4260-4289, 2014.MathSciNet


P. Marriott, On the local geometry of mixture models. Biometrika, 89, 77-93, 2002.MathSciNet


P. Marriott and M. Salmon, Applications of Differential Geometry to Econometrics. Academic Press, 2011.



                J. Martens, New perspectives on the natural gradient method.
                arXiv:â1412.â1193
                , 2015.
              



                J. Martens and R. Grosse, Optimizing neural networks with Kronecker-factored approximate curvature.
                arXiv:â1503.â05671
                , 2015.
              


R. J. Martin, A metric for ARMA processes. IEEE Transactions on Signal Processing, 48, 1164-1170, 2000.MathSciNet


T. Matumoto, Any statistical manifold has a contrast functionâOn the C3-functions taking the minimum at the diagonal of the product manifold. Hiroshima Mathematical Journal, 23, 327-332, 1993.MathSciNet



                Y. Matsuyama, The
                
                -EM algorithm: Surrogate likelihood maximization using
                
                -logarithmic information measures. IEEE Transactions on Information Theory, 49, 692-706, 2003.
              MathSciNet


H. Matsuzoe, On realization of conformally-projectively flat statistical manifolds. Hokkaido Mathematical Journal, 27, 409-421, 1998.MathSciNet


H. Matsuzoe, Geometry of contrast functions and conformal geometry. Hokkaido Mathematical Journal, 29, 175-191, 1999.MathSciNet


H. Matsuzoe, J. Takeuchi and S. Amari, Equiaffine structures on statistical manifolds and Bayesian statistics. Differential Geometry and Its Applications, 24, 567-578, 2006.MathSciNet


J. Milnor, On the concept of attractor. Communications of Mathematical Physics, 99, 177-195, 1985.MathSciNet



                M. Minami and S. Eguchi, Robust blind source separation by
                
                -divergence. Neural Computation, 14, 1859-1886, 2004.
              


K. Miura, M. Okada and S. Amari, Estimating spiking irregularities under changing environments. Neural Computation, 18, 2359-2386, 2006.MathSciNet



                T. Morimoto, Markov processes and the
                
                -theorem. Journal of Physical Society of Japan, 12, 328-331, 1963.
              MathSciNet


T. Morimura, E. Uchibe, J. Yoshimoto and K. Doya, A generalized natural actor-critic algorithm. In Advances in Neural Information Processing Systems, 22, MIT Press, 1312-1320, 2009.


R. Morioka and K. Tsuda, Information geometry of input-output table. Technical Report IEICE, 110, 161-168, 2011 (in Japanese).



                N. Murata, T. Takenouchi, T. Kanamori and S. Eguchi, Information geometry of
                
                -boost and Bregman divergence. Neural Computation, 16, 1432-1481, 2004.
              


M. K. Murray and J. W. Rice, Differential Geometry and Statistics. Chapman Hall, 1993.


H. Nagaoka and S. Amari, Differential geometry of smooth families of probability distributions. Technical Report METR 82-7, University of Tokyo, 1982.


H. Nakahara and S. Amari, Information-geometric measure for neural spikes. Neural Computation, 14, 2269-2316, 2002.


H. Nakahara, S. Amari and B. Richmond, A comparison of descriptive models of a single spike train by information-geometric measure. Neural Computation, 18, 545-568, 2006.MathSciNet


J. Naudts, Generalized Thermostatistics. Springer, 2011.


A. Nemirovski and D. Yudin, Problem Complexity and Method Efficiency in Optimization, Wiley, 1983.


Y. Nesterov and A. Nemirovski, Interior Point Polynomial Methods in Convex Programming: Theory and Algorithms. SIAM Publications, 1993.


Y. Nesterov and M. Todd, On the Riemannian geometry defined by self-concordant barriers and interior-point methods. Foundations of Computational Mathematics, 2, 333-361, 2002.MathSciNet


N. J. Newton, An infinite-dimensional statistical manifold modeled on Hilbert space. Journal of Functional Analysis, 263, 1661-1681, 2012.MathSciNet


J. Neyman and E. L. Scott, Consistent estimates based on partially consistent observation. Econometrica, 16, 1-32, 1948.MathSciNet



                F. Nielsen and R. Nock, On the
                
                -square and higher-order
                
                -distances for approximating
                
                -divergences. IEEE Signal Processing Letters, 21, 10-13, 2014.
              


R. Nock and F. Nielsen, Bregman divergences and surrogates for learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31, 2048-2059, 2009.


R. Nock, F. Nielsen and S. Amari, On conformal divergences and their population minimizers. IEEE Transactions on Information Theory, accepted, 2015.


K. Nomizu and T. Sasaki, Affine Differential Geometry. Oxford University Press, 1994.


A. Ohara, Information geometric analysis of an interior point method for semidefinite programming. In O. Barndorff-Nielsen and E. Jensen Eds, Geometry in Present Day Science, World Scientific, 49-74, 1999.


A. Ohara, Geometry of distributions associated with Tsallis statistics and properties of relative entropy minimization. Physics Letters, A, 370, 184-193, 2007.MathSciNet


A. Ohara and S. Amari, Differential geometric structures of stable state feedback systems with dual connections. Kybernetika, 30, 369-386, 1994.MathSciNet



                A. Ohara and S. Eguchi, Group invariance of information geometry on
                
                -Gaussian distributions induced by beta-divergence. Entropy, 15, 4732-4747, 2013.
              MathSciNet


A. Ohara, H. Matsuzoe and S. Amari, Conformal geometry of escort probability and its applications. Modern Physics Letters B, 26, 10, 1250063, 2012.


M. Oizumi, L. Albantakis and G. Tononi, From phenomenology to the mechanism of consciousness: Integrated information theory 3.0. PLoS Computational Biology, 10, e1003588, 2014.



                M. Oizumi, S. Amari, T. Yanagawa, N. Fujii and N. Tsuchiya, Measuring integrated information from the decoding perspective.
                arXiv:â1505.â04368
                [q-bio.NC], To appear in PLoS Computational Biology, 2015.
              


M. Oizumi, M. Okada and S. Amari, Information loss associated with imperfect observation and mismatched decoding. Frontiers in Computational Neuroscience, 5, 1-13, 2011.


M. Oizumi, N. Tsuchiya and S. Amari, A unified framework for information integration based on information geometry. Submitted, 2016.


E. Oja, A simplified neuron model as a principal component analyzer. Journal of Mathematical Biology, 15, 267-273, 1982.MathSciNet


E. Oja, Principal components, minor components, and linear neural networks. Neural Networks, 5, 927-935, 1992.


I. Okamoto, S. Amari and K. Takeuchi, Asymptotic theory of sequential estimation: Differential-geometrical approach. Annals of Statistics, 19, 961-981, 1991.MathSciNet


T. Okatani and K. Deguchi, Easy calibration of a multi-projector display system. International Journal of Computer Vision, 2009.



                Y. Ollivier, Riemannian metric for neural networks I: Feedforward networks. Information and Inference, 4, 108-153, 2015, DOI 
                10.â1093/âimaiai/âiav006
                .
              


H. Park, S. Amari and K. Fukumizu, Adaptive natural gradient learning algorithms for various stochastic models. Neural Networks, 13, 755-764, 2000.


M. Parry, A. P. Dawid and S. Lauritzen, Proper local scoring rule. Annals of Statistics, 40, 561-592, 2012.MathSciNet


J. Pearl, Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, 1988.


J. Peters and S. Schaal, Natural actor-critic. Neurocomputing, 71, 1180-1190, 2008.


G. Pistone, Examples of the application of nonparametric information geometry to statistical physics. Entropy, 15, 4042-4065, 2013.MathSciNet


G. Pistone and M. P. Rogantin, The exponential statistical manifold: mean parameters, orthogonality and space transformations. Bernoulli, 5, 721-760, 1999.MathSciNet


G. Pistone and C. Sempi, An infinite-dimensional geometric structure on the space of all the probability measures equivalent to a given one. Annals of Statistics, 23, 1543-1561, 1995.MathSciNet


C. R. Rao, Information and accuracy attainable in the estimation of statistical parameters. Bulletin of the Calcutta Mathematical Society, 37, 81-91, 1945.MathSciNet


C. R. Rao, Efficient estimates and optimum inference procedures in large samples. Journal of Royal Statistical Society, B, 24, 46-72, 1962.


G. Raskutti and S. Mukherjee, The information geometry of mirror descent. IEEE Transactions on Information Theory, 61, 1451-1457, 2015.MathSciNet


J. Rauh, Finding the maximizers of the information divergence from an exponential family. IEEE Transactions on Information Theory, 57, 3236-3247, 2011.MathSciNet


N. Ravishanker, E. L. Melnik and C. Tsai, Differential geometry of ARMA models. Journal of Time Series Analysis, 11, 259-274, 1990.MathSciNet


A. RÃ©nyi, On measures of entropy and information, in Proc. 4th Symposium on Mathematical Statistics and Probability Theory, Berkeley, CA, 1, 547-561, 1961.


F. Rosenblatt, Principles of Neurodynamics. Spartan, 1962.


N. L. Roux, P.-A. Manzagol and Y. Bengio, Topmoumoute online natural gradient algorithm. In Advances in Neural Information Processing Systems, 17, 849-856, 2007.


D. E. Rumelhart, G. E. Hinton and R. J. Williams, Learning representations by back-propagating errors. Nature, 323, 533-536, 1986.


R. E. Schapire, Y. Freend, P. Bartlett and W. S. Lee, Boosting the margin: A new explanation for the effectiveness of voting methods. Annals of Statistics, 26, 1651-1686, 1998.MathSciNet


J. Schmidhuber, Deep Learning in Neural Networks: An Overview. Neural Networks, 61, 85-117, 2015.


B. Scholkopf, Support Vector Learning. Oldenbourg, 1997.


J. A. Schouten, Ricci Calculus. Springer, 1954.


J. Shawe-Taylor and N. Cristianini, Kernel Methods for Pattern Analysis. Cambridge University Press, 2004.


H. Shima, The Geometry of Hessian Structures. World Scientific, 2007.


S. Shinomoto, K. Shima and J. Tanji, Differences in spiking patterns among cortical neurons. Neural Computation, 15, 2823-2842, 2003.


P. Smolensky, Information processing in dynamical systems: Foundations of harmony theory, In D. E. Rumelhart and J. L. McLelland (Eds.), Parallel Distributed Processing, 1, 194-281, MIT Press, 1986.


A. Soriano and L. Vergara, Fusion of scores in a detection context based on alpha integration. Neural Computation, 27, 1983-2010, 2015.


S. M. Stigler, The epic story of maximum likelihood. Statistical Science, 22, 598-620, 2007.MathSciNet


T. Takenouchi and S. Eguchi, Robustifying AdaBoost by adding the naive error rate. Neural Computation 16, 767-787, 2004.


T. Takenouchi, S. Eguchi, N. Murata and T. Kanamori, Robust boosting algorithm against mislabeling in multiclass problems. Neural Computation, 20, 1596-1630, 2008.MathSciNet


J. Takeuchi, Geometry of Markov chains, finite state machines and tree models. Technical Report of IEICE, 2014.


J. Takeuchi, T. Kawabata and A. Barron, Properties of Jeffreys mixture for Markov sources. IEEE Transactions on Information Theory, 41, 643-652, 2013.MathSciNet


K. Tanabe, Geometric method in nonlinear programming. Journal of Optimization Theory and Applications, 30, 181-210, 1980.MathSciNet


T. Tanaka, Information geometry of mean field approximation. Neural Computation, 12, 1951-1968, 2000.


M. Taniguchi, Higher-Order Asymptotic Theory for Time Series Analysis. Springer Lecture Notes in Statistics, 68, 1991.


P. S. Thomas, W. Dabney, S. Mahadeven and S. Giguere, Projected natural actor-critic. In Advances in Neural Information Processing Systems, 26, 2013.


R. Tibshirani, Regression shrinkage and selection via the LASSO. Journal of Royal Statistical Society, Series B, 58, 267-288, 1996.MathSciNet


G. Tononi, Consciousness as integrated information: a provisional manifest. Biological Bulletin, 215, 216-242, 2008.


F. Topsoe, Information-theoretical optimization techniques. Kybernetika, 15, 8-27, 1979.MathSciNet


C. Tsallis, Possible generalization of Boltzmann-Gibbs statistics. Journal of Statistical Physics, 52, 479-487, 1988.MathSciNet


C. Tsallis, Introduction to Nonextensive Statistical Mechanics: Approaching a Complex World, Springer, 2009.



                K. Uohashi,
                
                -conformal equivalence of statistical submanifolds. Journal of Geometry, 75, 179-184, 2002.
              MathSciNet


V. N. Vapnik, Statistical Learning Theory. John Wiley, 1998.


B. C. Vemuri, M. Liu, S. Amari and F. Nielsen, Total Bregman divergence and its applications to DTI analysis. IEEE Transactions on Medical Imaging, 30, 475-483, 2011.



                R. F. Vigelis, and C. C. Cavalcante, On
                
                -families of probability distributions. Journal of Theoretical Probabilities, 26, 870-884, 2013.
              MathSciNet


P. Vos, A geometric approach to detecting influential cases. Annals of Statistics, 19, 1570-1581, 1991.MathSciNet


J. Wada, A divisor apportionment method based on the Kolm-Atkinson social welfare function and generalized entropy. Mathematical Social Sciences, 63, 243-247, 2012.MathSciNet


M. J. Wainwright and M. I. Jordan, Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning, 1, 1-305, 2008.


S. Watanabe, Algebraic geometrical methods for hierarchical learning machines. Neural Networks, 14, 1409-1060, 2001.


S. Watanabe, Algebraic Geometry and Statistical Learning Theory. Cambridge University Press, 2009.


S. Watanabe, Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular statistical learning theory. Journal of Machine Learning Research, 11, 3571-3591, 2010.


H. Wei and S. Amari, Dynamics of learning near singularities in radial basis function networks. Neural Networks, 21, 989-1005, 2008.


H. Wei, J. Zhang, F. Cousseau, T. Ozeki and S. Amari, Dynamics of learning near singularities in layered networks. Neural Computation, 20, 813-843, 2008.MathSciNet


P. Williams, S. Wu and J. Feng, Two scaling methods to improve performance of the support vector machine. In Support Vector Machines: Theory and Applications, Ed. L. Wang, 205-218, Springer, 2005.



                D. Wu, Parameter estimation for
                
                -GMM based on maximum likelihood criterion. Neural Computation, 21, 1776-1795, 2009.
              MathSciNet


S. Wu and S. Amari, Conformal transformation of kernel functions: A data-dependent way to improve support vector machine classifiers. Neural Processing Letters, 15, 59-67, 2002.


S. Wu, S. Amari and H. Nakahara, Population coding and decoding in a neural field: A computational study. Neural Computation, 14, 999-1026, 2002.


L. Xu, Least mean square error reconstruction principle for self-organizing neural nets. Neural Networks, 6, 627-648, 1993.



                Z. Xu, X. Chang, F. Xu and H. Zhang,
                
                regularization: A thresholding representation theory and a fast solver. IEEE Transactions on Neural Networks and Learning Systems, 23, 1013-1027, 2012.
              


S. Yi, D. Wierstra, T. Schaul and J. Schmidhuber, Stochastic search using the natural gradient. ICML Proceedings of the 26th Annual Internatinal Conference on Machine Learning, 1161-1168, 2009.


J. S. Yedidia, W. T. Freeman and Y. Weiss, Generalized belief propagation. In T. K. Leen, T. G. Dietrich and V. Tresp (Eds.), Advances in Neural Information Processing Systems, 13, 689-695, MIT Press, 2001.


A. Yuille, CCCP algorithms to minimize the Bethe and Kikuchi free energies: Convergent alternatives to belief propagation. Neural Computation, 14, 1691-1722, 2002.


A. L. Yuille and A. Rangarajan, The concave-convex procedure. Neural Computation, 15, 915-936, 2003.



                M. Yukawa and S. Amari,
                
                -regularized least squares (0
                
p

                1) and critical path. IEEE Transactions on Information Theory, 62, 1-15, 2016.
              


J. Zhang, Divergence function, duality and convex analysis. Neural Computation, 16, 159-195, 2004.


J. Zhang, From divergence function to information geometry: Metric, equiaffine and symplectic structures. Geometry Symposium, Japan Mathematical Society, Proceedings, 47-62, 2011.


J. Zhang, Nonparametric information geometry: From divergence function to referential-representational biduality on statistical manifolds. Entropy, 15, 5384-5418, 2013.MathSciNet


J. Zhang, On monotone embedding in information geometry. Entropy, 17, 4485-4499, 2015.


J. Zhao, H. Wei, C. Zhang, W. Li, W. Guo and K. Zhang, Natural gradient learning algorithms for RBF networks. Neural Computation, 27, 481-505, 2015.


H. Y. Zhu and R. Rohwer, Bayesian invariant measurements of generalization. Neural Processing Letters, 2, 28-31, 1995.





Index



Symbols




                  -
                  
                  -divergence
                




                  -divergence
                



                  (
                  
                  -
                  
                  )-
                  
                  -det divergence
                




                  -divergence
                




                  -expert machine
                




                  -family of probability distributions
                




                  -function
                




                  -geodesic
                




                  -geometry
                




                  -integration
                




                  -mean
                




                  -projection theorem
                




                  -Pythagorean theorem
                




                  -divergence
                




                  -divergence
                




                  -escort distribution
                




                  -exponential family
                




                  -affine parameter
                




                  -condition
                




                  -flat
                




                  -geodesic
                




                  -parallel transport
                




                  algorithm
                




                  -structure
                




                  -divergence
                




                  -divergence
                




                  -cut
                




                  -means
                




                  -sparse
                




                  -exponential family
                




                  -norm
                




                  -norm
                




                  -affine parameter
                




                  -condition
                




                  -flat
                




                  -geodesic
                




                  -parallel transport
                




                  -projection
                




                  -center of cluster
                




                  -function method
                




                  -divergence
                




                  -entropy
                




                  -escort geometry
                




                  -exponential
                




                  -exponential family
                




                  -free energy
                




                  -logarithm
                




                  -metric
                




                  -structure
                




                  -divergence
                




                  -divergence
                




                  -structure
                




A


Absolute-value-based Hessian natural gradient


Active set


Adaptive learning method


Adaptive natural gradient learning


Affine connection


Affine coordinate system


Affine flat structure


Akaike information criterion


Alternating minimization algorithm


Amari-Chentsov structure


Amari-Chentsov tensor


Ancillary submanifold


Ancillary tangent subspace


ARMA model


AR model


Asymptotic theory of hypothesis testing


Auto-correlation coefficients


Auto-regression model




B


Back-propagation learning


Barrier function


Basis vectors


Bayesian duality


Bayesian posterior distribution


Belief propagation


Blow-down technique


Boltzmann machine


Boosting


Bregman divergence




C


Canonical divergence


Canonical parameter


Central limit theorem


Chernoff divergence


Chernoff information


Clique


Clustering


Clustering algorithm


Coarse graining


Cocktail party problem


Coefficient of proportionality


Coefficients of affine connection


Conformal transformation


Conformal transformation of a kernel


Conjugate priors


Consistent estimator


Contrastive divergence


Convex-concave computational procedure


Convex function


Convex programming


Coordinate system


Coordinate transformation


Covariant derivative


CramÃ©r-Rao bound


CramÃ©r-Rao theorem


Critical region


Critical slowdown


Cubic tensor


Cumulant generating function




D


Decomposable divergence


Deep learning


Deformed exponential family


Divergence


Dual affine structure


Dual connections


Dual convex function


Dual geodesic


Dually flat manifold




E


Efficient


Efficient score


Einstein summation convention


Eliminating singularity


EM algorithm


Embedding curvature


Ergodic time series


Error covariance matrix


Escort probability distribution


Estimating function


Estimator


Euler-Schouten curvature


Exponential family




F


First-order asymptotic theory


Fisher information matrix


Foliation


Free energy




G


Game


Game-divergence


Game-score


Gaussian kernel


Gaussian mixture model


Gaussian RBM


Generalization error


Generalized inverse


Generalized Pythagorean theorem


Geodesic


Graph Laplacian


Graphical model




H


Hidden variable


Higher-order asymptotic theory of estimation


Higher-order correlations


Higher-order cumulants


HyvÃ¤rinen divergence


HyvÃ¤rinen score




I


Independent component analysis


Information integration


Information monotonicity


Inner product


input-output analysis


Instantaneous loss


Integrated information


Integration of weak machines


Invariance criterion


Invariant divergences


Invariant Riemannian metrics




K


Kernel exponential family


Kernel function


Killing metric


KL-divergence


Kronecker-factored approximate curvature


Kullback-Leibler (KL) divergence




L


Large deviation


Large deviation theorem


Learning constant


Least angle regressions


Least equiangle theorem


Legendre transformation


Levi-Civita connection


Linear machine


Linear system


Loss of information by data reduction




M


Machine learning


MA model


Manifold


Margin


Maximum entropy


Maximum entropy principle


Maximum likelihood estimator


Mean field approximation


Metric affine connection


Milnor attractor


Minimum description length


Minimum entropy


Minkovskian gradient


Minor subspace


Mirror descent method


Misspecified model


Mixed coordinate system


Mixture family


Moving-average model


Multilayer perceptron




N


Natural gradient


Natural gradient learning method


Natural parameter


Natural policy gradient


Negative entropy


Neyman-Scott problem


Non-holonomic coordinate system


Non-negative matrix factorization


Nuisance parameter


Nuisance tangent subspace




O


Observed point


Observed submanifold


On-line learning


Overlapping singularity




P


Parallel transport


Parameter of interest


Plateau


Plateau phenomena


Policy natural gradient


Polynomial kernel


Positive-definite symmetric matrix


Power spectrum


Principal component


Principal component analysis


Principal subspace


Prior distribution


Projection theorem




R


RAS transformation


RC curvature


Reinforcement learning


Restricted Boltzmann machine


Riemann-Christoffel curvature tensor


Riemannian connection


Riemannian geometry


Riemannian gradient


Riemannian metric


Riemannian structure


Robust cluster center




S


Saddle-free Newton method


Scale problem


Score function


Semi-definite programming


Shape parameter


Singular point


Singular prior


Singular statistical models


Singular structure


Soft clustering


Solution path


Sparse vector


Standard estimating function



                  standard
                  
                  -divergence
                


Stiefel manifold


Stochastic descent learning method


Stochastic relaxation


Submanifold


Sufficient statistic


Super efficiency


Support vector


Support vector machine


System complexity




T


Tangent space


Tangent subspace of interest


Temporal firing pattern


Tensor


Time series


Total Bregman divergence


Total least squares


Training error


Transfer function




U


Unidentifiability




V


Voronoi diagram







